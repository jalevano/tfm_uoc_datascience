{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/nDAWXLZt2MO53C3Eek48",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/04_VLM_setup_validacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "FASE VLM - REQUISITO 1: SETUP Y VALIDACIÓN\n",
        "================================================================================\n",
        "Trabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\n",
        "Universidad Oberta de Catalunya (UOC)\n",
        "Autor: Jesús L.\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "Objetivo:\n",
        "    Establecer infraestructura para análisis VLM (Gemini Pro Vision) integrando\n",
        "    resultados de segmentación previos con análisis fotográfico automatizado.\n",
        "\n",
        "Decisiones metodológicas documentadas:\n",
        "    - EXIF extraído de archivos RAW originales (metadatos fiables)\n",
        "    - Análisis visual sobre imágenes editadas (coherencia con segmentación)\n",
        "    - Máscara de OneFormer (mejor modelo global)\n",
        "    - Formato de entrada: imagen + overlay de máscara (lado a lado)\n",
        "    - Formato de salida: JSON estructurado\n",
        "\n",
        "Requisitos:\n",
        "    - Google Colab con acceso a Google Drive\n",
        "    - API Key de Google AI Studio (Gemini)\n",
        "    - Índice maestro y recursos de fases anteriores\n",
        "================================================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "cVafIwBXj31K",
        "outputId": "771cd4d8-a1ba-4bde-e4f0-083d91574367"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nFASE VLM - REQUISITO 1: SETUP Y VALIDACIÓN\\n================================================================================\\nTrabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\\nUniversidad Oberta de Catalunya (UOC)\\nAutor: Jesús L.\\nFecha: Diciembre 2025\\n\\nObjetivo:\\n    Establecer infraestructura para análisis VLM (Gemini Pro Vision) integrando\\n    resultados de segmentación previos con análisis fotográfico automatizado.\\n\\nDecisiones metodológicas documentadas:\\n    - EXIF extraído de archivos RAW originales (metadatos fiables)\\n    - Análisis visual sobre imágenes editadas (coherencia con segmentación)\\n    - Máscara de OneFormer (mejor modelo global)\\n    - Formato de entrada: imagen + overlay de máscara (lado a lado)\\n    - Formato de salida: JSON estructurado\\n\\nRequisitos:\\n    - Google Colab con acceso a Google Drive\\n    - API Key de Google AI Studio (Gemini)\\n    - Índice maestro y recursos de fases anteriores\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# INSTALACIÓN Y CONFIGURACIÓN\n",
        "# ==============================================================================\n",
        "\n",
        "!pip install google-generativeai pillow numpy pandas --quiet"
      ],
      "metadata": {
        "id": "gEAsYNRhkyPf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "gotpprVuk9dG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-d4AM3RlEW_",
        "outputId": "210acb80-ffda-4b4a-8596-483a2cd6ea16"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfigVLM:\n",
        "    \"\"\"Configuración centralizada para el pipeline VLM.\"\"\"\n",
        "\n",
        "    # Rutas base\n",
        "    BASE_PATH = Path(\"/content/drive/MyDrive/TFM\")\n",
        "\n",
        "    # Recursos de entrada\n",
        "    INDICE_MAESTRO = BASE_PATH / \"3_Analisis\" / \"fase1_integracion\" / \"indice_maestro.json\"\n",
        "    FOTOS_EDITADAS = BASE_PATH / \"0_Imagenes\"\n",
        "    CARACTERISTICAS_JSON = BASE_PATH / \"1_Caracteristicas\" / \"json\"\n",
        "    METRICAS_CSV = BASE_PATH / \"3_Analisis\" / \"fase2b_correlaciones\" / \"metricas_fusionadas.csv\"\n",
        "\n",
        "    # Salidas VLM\n",
        "    OUTPUT_DIR = BASE_PATH / \"3_Analisis\" / \"fase_vlm\"\n",
        "    OUTPUT_IMAGENES = OUTPUT_DIR / \"imagenes_compuestas\"\n",
        "    OUTPUT_RESPUESTAS = OUTPUT_DIR / \"respuestas_vlm\"\n",
        "    OUTPUT_CONSOLIDADO = OUTPUT_DIR / \"consolidado\"\n",
        "\n",
        "    # Configuración del modelo\n",
        "    MODELO_SEGMENTACION = \"oneformer\"  # Mejor modelo global\n",
        "    GEMINI_MODEL = \"gemini-2.5-flash\"  # Alternativa: gemini-1.5-pro\n",
        "\n",
        "    # Parámetros de generación\n",
        "    GENERATION_CONFIG = {\n",
        "        \"temperature\": 0.3,  # Baja para respuestas consistentes\n",
        "        \"top_p\": 0.95,\n",
        "        \"top_k\": 40,\n",
        "        \"max_output_tokens\": 4096,\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def crear_directorios(cls) -> None:\n",
        "        \"\"\"Crea estructura de directorios para outputs.\"\"\"\n",
        "        for directorio in [cls.OUTPUT_DIR, cls.OUTPUT_IMAGENES,\n",
        "                          cls.OUTPUT_RESPUESTAS, cls.OUTPUT_CONSOLIDADO]:\n",
        "            directorio.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"[OK] Directorios creados en: {cls.OUTPUT_DIR}\")\n",
        "\n",
        "    @classmethod\n",
        "    def validar_rutas(cls) -> Dict[str, bool]:\n",
        "        \"\"\"Valida existencia de recursos necesarios.\"\"\"\n",
        "        validaciones = {\n",
        "            \"indice_maestro\": cls.INDICE_MAESTRO.exists(),\n",
        "            \"fotos_editadas\": cls.FOTOS_EDITADAS.exists(),\n",
        "            \"caracteristicas\": cls.CARACTERISTICAS_JSON.exists(),\n",
        "            \"metricas_csv\": cls.METRICAS_CSV.exists(),\n",
        "        }\n",
        "\n",
        "        print(\"\\n=== Validación de Rutas ===\")\n",
        "        for recurso, existe in validaciones.items():\n",
        "            estado = \"[OK]\" if existe else \"[ERROR]\"\n",
        "            print(f\"  {estado} {recurso}\")\n",
        "\n",
        "        return validaciones"
      ],
      "metadata": {
        "id": "J_DZX8RklJ1J"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CONFIGURACIÓN DE API GEMINI\n",
        "# ==============================================================================\n",
        "\n",
        "def configurar_gemini(api_key: str) -> genai.GenerativeModel:\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    modelo = genai.GenerativeModel(\n",
        "        model_name=ConfigVLM.GEMINI_MODEL,\n",
        "        generation_config=ConfigVLM.GENERATION_CONFIG\n",
        "    )\n",
        "\n",
        "    print(f\"[OK] Modelo {ConfigVLM.GEMINI_MODEL} configurado\")\n",
        "    return modelo"
      ],
      "metadata": {
        "id": "2K1POODUqabD"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_conexion_gemini(modelo: genai.GenerativeModel) -> bool:\n",
        "    \"\"\"Verifica que la conexión con Gemini funciona.\"\"\"\n",
        "    try:\n",
        "        respuesta = modelo.generate_content(\"Responde solo con: OK\")\n",
        "        if respuesta.text:\n",
        "            print(f\"[OK] Conexión verificada. Respuesta: {respuesta.text.strip()}\")\n",
        "            return True\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Fallo de conexión: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "dHhxuEV_qyUV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. Configurar API Key\n",
        "# API_KEY = \"XXXXXX\"\n",
        "\n",
        "# # 2. Configurar modelo\n",
        "# modelo_vlm = configurar_gemini(API_KEY)\n",
        "\n",
        "# # 3. Test de conexión\n",
        "# test_conexion_gemini(modelo_vlm)"
      ],
      "metadata": {
        "id": "huk3kku8sKHx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CARGA DE DATOS\n",
        "# ==============================================================================\n",
        "\n",
        "def cargar_indice_maestro(ruta: Path) -> Dict:\n",
        "    \"\"\"Carga el índice maestro con referencias a todos los recursos.\"\"\"\n",
        "    with open(ruta, 'r', encoding='utf-8') as f:\n",
        "        indice = json.load(f)\n",
        "\n",
        "    fotos = {k: v for k, v in indice.items() if isinstance(v, dict) and 'foto_id' in v}\n",
        "\n",
        "    print(f\"[OK] Índice maestro cargado: {len(fotos)} fotografías\")\n",
        "    return fotos\n",
        "\n",
        "def cargar_metricas_segmentacion(ruta: Path) -> pd.DataFrame:\n",
        "    \"\"\"Carga métricas consolidadas de Fase 2A.\"\"\"\n",
        "    df = pd.read_csv(ruta)\n",
        "    print(f\"[OK] Métricas cargadas: {len(df)} registros\")\n",
        "    return df\n",
        "\n",
        "def obtener_iou_por_foto(df_metricas: pd.DataFrame,\n",
        "                          modelo: str = \"oneformer\") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Obtiene el mejor IoU de OneFormer para cada foto.\n",
        "\n",
        "    Args:\n",
        "        df_metricas: DataFrame con métricas consolidadas\n",
        "        modelo: Nombre del modelo a filtrar\n",
        "\n",
        "    Returns:\n",
        "        Diccionario {codigo_foto: mejor_iou}\n",
        "    \"\"\"\n",
        "    # Filtrar por modelo (columna 'modelo' contiene el nombre base)\n",
        "    df_modelo = df_metricas[df_metricas['modelo'].str.lower().str.contains(modelo.lower())]\n",
        "\n",
        "    # Obtener mejor IoU por foto (columna 'codigo_foto')\n",
        "    iou_por_foto = df_modelo.groupby('codigo_foto')['iou'].max().to_dict()\n",
        "\n",
        "    print(f\"[OK] IoU extraído para {len(iou_por_foto)} fotos (modelo: {modelo})\")\n",
        "    return iou_por_foto\n",
        "\n",
        "def obtener_exif_desde_csv(df_metricas: pd.DataFrame,\n",
        "                            codigo_foto: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extrae datos EXIF del CSV fusionado para una foto específica.\n",
        "\n",
        "    Args:\n",
        "        df_metricas: DataFrame con métricas fusionadas\n",
        "        codigo_foto: Identificador de la foto\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con datos EXIF\n",
        "    \"\"\"\n",
        "    # Filtrar por foto (tomar primera fila, EXIF es igual para todas las configs)\n",
        "    df_foto = df_metricas[df_metricas['codigo_foto'] == codigo_foto]\n",
        "\n",
        "    if df_foto.empty:\n",
        "        return {\n",
        "            \"apertura\": \"N/A\", \"iso\": \"N/A\", \"distancia_focal\": \"N/A\",\n",
        "            \"tiempo_exposicion\": \"N/A\", \"ancho\": \"N/A\", \"alto\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    fila = df_foto.iloc[0]\n",
        "\n",
        "    return {\n",
        "        \"apertura\": fila.get('exif_apertura', \"N/A\"),\n",
        "        \"iso\": fila.get('exif_iso', \"N/A\"),\n",
        "        \"distancia_focal\": fila.get('exif_focal', \"N/A\"),\n",
        "        \"tiempo_exposicion\": fila.get('exif_exposicion_seg', \"N/A\"),\n",
        "        \"ancho\": fila.get('meta_ancho', \"N/A\"),\n",
        "        \"alto\": fila.get('meta_alto', \"N/A\"),\n",
        "    }\n",
        "\n",
        "def cargar_caracteristicas_foto(ruta_json: Path) -> Dict[str, Any]:\n",
        "    \"\"\"Carga características extraídas del RAW original.\"\"\"\n",
        "    with open(ruta_json, 'r', encoding='utf-8') as f:\n",
        "        datos = json.load(f)\n",
        "    return datos\n",
        "\n",
        "\n",
        "def extraer_exif_relevante(caracteristicas: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extrae métricas EXIF relevantes para el análisis VLM.\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con: apertura, iso, focal, dimensiones\n",
        "    \"\"\"\n",
        "    exif = caracteristicas.get(\"exif\", {})\n",
        "    dimensiones = caracteristicas.get(\"dimensiones\", {})\n",
        "\n",
        "    return {\n",
        "        \"apertura\": exif.get(\"apertura_fnumber\", \"N/A\"),\n",
        "        \"iso\": exif.get(\"iso\", \"N/A\"),\n",
        "        \"distancia_focal\": exif.get(\"distancia_focal\", \"N/A\"),\n",
        "        \"tiempo_exposicion\": exif.get(\"tiempo_exposicion_segundos\", \"N/A\"),\n",
        "        \"ancho\": dimensiones.get(\"ancho\", \"N/A\"),\n",
        "        \"alto\": dimensiones.get(\"alto\", \"N/A\"),\n",
        "    }"
      ],
      "metadata": {
        "id": "VkZrgUT9rQm1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# GENERACIÓN DE IMAGEN COMPUESTA\n",
        "# ==============================================================================\n",
        "\n",
        "def cargar_mascara(ruta_npz: Path) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Carga máscara de segmentación desde archivo NPZ.\n",
        "\n",
        "    Maneja diferentes estructuras de NPZ según el modelo.\n",
        "    \"\"\"\n",
        "    datos = np.load(ruta_npz, allow_pickle=True)\n",
        "\n",
        "    # Intentar diferentes claves según estructura del modelo\n",
        "    claves_posibles = ['mask', 'mascara', 'segmentation', 'arr_0']\n",
        "\n",
        "    for clave in claves_posibles:\n",
        "        if clave in datos:\n",
        "            mascara = datos[clave]\n",
        "            # Si es 0D (escalar), extraer el array interno\n",
        "            if mascara.ndim == 0:\n",
        "                mascara = mascara.item()\n",
        "            return mascara\n",
        "\n",
        "    # Si no encuentra, usar primera clave disponible\n",
        "    primera_clave = list(datos.keys())[0]\n",
        "    return datos[primera_clave]\n",
        "\n",
        "def redimensionar_mascara(mascara: np.ndarray,\n",
        "                          tamaño_objetivo: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Redimensiona máscara al tamaño de la imagen original.\n",
        "\n",
        "    Args:\n",
        "        mascara: Array 2D con la máscara binaria\n",
        "        tamaño_objetivo: (ancho, alto) de la imagen destino\n",
        "\n",
        "    Returns:\n",
        "        Máscara redimensionada\n",
        "    \"\"\"\n",
        "    mascara_pil = Image.fromarray(mascara.astype(np.uint8) * 255)\n",
        "    mascara_redim = mascara_pil.resize(tamaño_objetivo, Image.NEAREST)\n",
        "    return np.array(mascara_redim) > 127\n",
        "\n",
        "def crear_overlay_mascara(imagen: Image.Image,\n",
        "                          mascara: np.ndarray,\n",
        "                          color: Tuple[int, int, int] = (0, 255, 0),\n",
        "                          alpha: float = 0.4) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Crea overlay semitransparente de la máscara sobre la imagen.\n",
        "\n",
        "    Args:\n",
        "        imagen: Imagen PIL original\n",
        "        mascara: Array booleano 2D\n",
        "        color: Color RGB del overlay\n",
        "        alpha: Transparencia (0-1)\n",
        "\n",
        "    Returns:\n",
        "        Imagen con overlay aplicado\n",
        "    \"\"\"\n",
        "    # Asegurar que la imagen está en RGB\n",
        "    if imagen.mode != 'RGB':\n",
        "        imagen = imagen.convert('RGB')\n",
        "\n",
        "    # Crear capa de color\n",
        "    overlay = Image.new('RGB', imagen.size, color)\n",
        "\n",
        "    # Crear máscara de transparencia\n",
        "    mascara_alpha = Image.fromarray((mascara * int(255 * alpha)).astype(np.uint8))\n",
        "\n",
        "    # Componer\n",
        "    resultado = imagen.copy()\n",
        "    resultado.paste(overlay, mask=mascara_alpha)\n",
        "\n",
        "    return resultado\n",
        "\n",
        "def crear_imagen_compuesta(imagen_original: Image.Image,\n",
        "                           mascara: np.ndarray,\n",
        "                           max_ancho: int = 1024) -> Image.Image:\n",
        "    \"\"\"\n",
        "    Crea imagen compuesta: original | overlay de máscara.\n",
        "\n",
        "    Args:\n",
        "        imagen_original: Imagen PIL\n",
        "        mascara: Array booleano 2D\n",
        "        max_ancho: Ancho máximo por imagen (para optimizar API)\n",
        "\n",
        "    Returns:\n",
        "        Imagen compuesta lado a lado\n",
        "    \"\"\"\n",
        "    # Redimensionar si es necesario\n",
        "    ratio = min(1.0, max_ancho / imagen_original.width)\n",
        "    if ratio < 1.0:\n",
        "        nuevo_tamaño = (int(imagen_original.width * ratio),\n",
        "                        int(imagen_original.height * ratio))\n",
        "        imagen_original = imagen_original.resize(nuevo_tamaño, Image.LANCZOS)\n",
        "        mascara = redimensionar_mascara(mascara, nuevo_tamaño)\n",
        "\n",
        "    # Crear overlay\n",
        "    imagen_overlay = crear_overlay_mascara(imagen_original, mascara)\n",
        "\n",
        "    # Combinar lado a lado\n",
        "    ancho_total = imagen_original.width * 2\n",
        "    alto = imagen_original.height\n",
        "\n",
        "    compuesta = Image.new('RGB', (ancho_total, alto))\n",
        "    compuesta.paste(imagen_original, (0, 0))\n",
        "    compuesta.paste(imagen_overlay, (imagen_original.width, 0))\n",
        "\n",
        "    return compuesta"
      ],
      "metadata": {
        "id": "ExR3bjzira9S"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PROMPT ENGINEERING\n",
        "# ==============================================================================\n",
        "\n",
        "# Plantilla de prompt para análisis fotográfico\n",
        "# ------------------------------------------------------------------------------\n",
        "PROMPT_ANALISIS_FOTOGRAFICO = \"\"\"Eres un experto en fotografía de retrato con amplia experiencia en análisis técnico y artístico.\n",
        "\n",
        "Analiza la siguiente imagen de retrato. A la izquierda está la fotografía original, a la derecha la misma imagen con la máscara de segmentación de la persona superpuesta en verde.\n",
        "\n",
        "CONTEXTO TÉCNICO DE CAPTURA (extraído del archivo RAW original):\n",
        "- Apertura: f/{apertura}\n",
        "- ISO: {iso}\n",
        "- Distancia focal: {distancia_focal}mm\n",
        "- Tiempo de exposición: {tiempo_exposicion}s\n",
        "- Dimensiones: {ancho}x{alto} píxeles\n",
        "- Calidad de segmentación (IoU): {iou:.3f}\n",
        "\n",
        "Proporciona tu análisis en el siguiente formato JSON exacto:\n",
        "\n",
        "{{\n",
        "  \"composicion\": {{\n",
        "    \"valoracion\": <número del 1 al 10>,\n",
        "    \"regla_tercios\": \"<cumple/parcial/no cumple>\",\n",
        "    \"espacio_negativo\": \"<adecuado/excesivo/insuficiente>\",\n",
        "    \"observaciones\": \"<texto breve>\"\n",
        "  }},\n",
        "  \"iluminacion\": {{\n",
        "    \"valoracion\": <número del 1 al 10>,\n",
        "    \"tipo_principal\": \"<natural/artificial/mixta>\",\n",
        "    \"direccion\": \"<frontal/lateral/contraluz/rembrandt/otra>\",\n",
        "    \"ratio_estimado\": \"<texto, ej: 2:1, 3:1>\",\n",
        "    \"observaciones\": \"<texto breve>\"\n",
        "  }},\n",
        "  \"tecnica\": {{\n",
        "    \"enfoque\": \"<correcto/suave/fallido>\",\n",
        "    \"zona_enfoque\": \"<ojos/rostro/otro>\",\n",
        "    \"exposicion\": \"<correcta/subexpuesta/sobreexpuesta>\",\n",
        "    \"profundidad_campo\": \"<muy reducida/reducida/moderada/amplia>\",\n",
        "    \"observaciones\": \"<texto breve>\"\n",
        "  }},\n",
        "  \"segmentacion\": {{\n",
        "    \"calidad_percibida\": \"<excelente/buena/aceptable/deficiente>\",\n",
        "    \"bordes\": \"<precisos/aceptables/irregulares>\",\n",
        "    \"zonas_problematicas\": \"<ninguna/cabello/manos/ropa/otra>\",\n",
        "    \"observaciones\": \"<texto breve>\"\n",
        "  }},\n",
        "  \"valoracion_global\": {{\n",
        "    \"puntuacion\": <número del 1 al 10>,\n",
        "    \"fortalezas\": [\"<fortaleza 1>\", \"<fortaleza 2>\"],\n",
        "    \"areas_mejora\": [\"<mejora 1>\", \"<mejora 2>\"]\n",
        "  }},\n",
        "  \"recomendaciones\": [\n",
        "    \"<recomendación concreta 1>\",\n",
        "    \"<recomendación concreta 2>\",\n",
        "    \"<recomendación concreta 3>\"\n",
        "  ]\n",
        "}}\n",
        "\n",
        "IMPORTANTE: Responde ÚNICAMENTE con el JSON, sin texto adicional antes o después.\"\"\"\n",
        "\n",
        "\n",
        "# Función para generar prompt con contexto\n",
        "# ------------------------------------------------------------------------------\n",
        "def generar_prompt(exif: Dict[str, Any], iou: float) -> str:\n",
        "    \"\"\"\n",
        "    Genera prompt completo con contexto técnico.\n",
        "\n",
        "    Args:\n",
        "        exif: Diccionario con datos EXIF relevantes\n",
        "        iou: Valor IoU de la segmentación\n",
        "\n",
        "    Returns:\n",
        "        Prompt formateado\n",
        "    \"\"\"\n",
        "    return PROMPT_ANALISIS_FOTOGRAFICO.format(\n",
        "        apertura=exif.get(\"apertura\", \"N/A\"),\n",
        "        iso=exif.get(\"iso\", \"N/A\"),\n",
        "        distancia_focal=exif.get(\"distancia_focal\", \"N/A\"),\n",
        "        tiempo_exposicion=exif.get(\"tiempo_exposicion\", \"N/A\"),\n",
        "        ancho=exif.get(\"ancho\", \"N/A\"),\n",
        "        alto=exif.get(\"alto\", \"N/A\"),\n",
        "        iou=iou if isinstance(iou, (int, float)) else 0.0\n",
        "    )"
      ],
      "metadata": {
        "id": "axxlXDqvrBYj"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# LLAMADA AL VLM\n",
        "# ==============================================================================\n",
        "\n",
        "def analizar_fotografia(modelo: genai.GenerativeModel,\n",
        "                        imagen_compuesta: Image.Image,\n",
        "                        prompt: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Envía imagen al VLM y obtiene análisis estructurado.\n",
        "\n",
        "    Args:\n",
        "        modelo: Modelo Gemini configurado\n",
        "        imagen_compuesta: Imagen PIL (original + overlay)\n",
        "        prompt: Prompt con contexto técnico\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con análisis o error\n",
        "    \"\"\"\n",
        "    try:\n",
        "        respuesta = modelo.generate_content([prompt, imagen_compuesta])\n",
        "\n",
        "        # Extraer texto de respuesta\n",
        "        texto = respuesta.text.strip()\n",
        "\n",
        "        # Limpiar posibles marcadores de código\n",
        "        if texto.startswith(\"```json\"):\n",
        "            texto = texto[7:]\n",
        "        if texto.startswith(\"```\"):\n",
        "            texto = texto[3:]\n",
        "        if texto.endswith(\"```\"):\n",
        "            texto = texto[:-3]\n",
        "        texto = texto.strip()\n",
        "\n",
        "        # Parsear JSON\n",
        "        analisis = json.loads(texto)\n",
        "        analisis[\"_metadata\"] = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"modelo_vlm\": ConfigVLM.GEMINI_MODEL,\n",
        "            \"estado\": \"exito\"\n",
        "        }\n",
        "\n",
        "        return analisis\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return {\n",
        "            \"_metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"estado\": \"error_json\",\n",
        "                \"error\": str(e),\n",
        "                \"respuesta_raw\": texto if 'texto' in dir() else \"N/A\"\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"_metadata\": {\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"estado\": \"error\",\n",
        "                \"error\": str(e)\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "DOTXEcJhrrow"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PIPELINE DE VALIDACIÓN\n",
        "# ==============================================================================\n",
        "\n",
        "def test_pipeline_completo(modelo_vlm: genai.GenerativeModel,\n",
        "                           indice: Dict,\n",
        "                           df_metricas: pd.DataFrame,\n",
        "                           foto_test: str = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ejecuta pipeline completo con una fotografía de prueba.\n",
        "\n",
        "    Args:\n",
        "        modelo_vlm: Modelo Gemini configurado\n",
        "        indice: Índice maestro (fotos en nivel raíz)\n",
        "        df_metricas: DataFrame con métricas\n",
        "        foto_test: Código de foto específica (opcional, ej: '_DSC0023')\n",
        "\n",
        "    Returns:\n",
        "        Resultado del análisis\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TEST DE PIPELINE COMPLETO\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Seleccionar foto de prueba (índice tiene fotos directamente en raíz)\n",
        "    fotos_disponibles = list(indice.keys())\n",
        "    if not fotos_disponibles:\n",
        "        print(\"[ERROR] No hay fotos en el índice maestro\")\n",
        "        return None\n",
        "\n",
        "    if foto_test and foto_test in fotos_disponibles:\n",
        "        codigo_foto = foto_test\n",
        "    else:\n",
        "        codigo_foto = fotos_disponibles[0]\n",
        "\n",
        "    print(f\"\\n[1/6] Foto seleccionada: {codigo_foto}\")\n",
        "\n",
        "    # Obtener datos de la foto del índice\n",
        "    datos_foto = indice[codigo_foto]\n",
        "\n",
        "    # Cargar imagen editada desde rutas.imagen\n",
        "    print(\"[2/6] Cargando imagen editada...\")\n",
        "    ruta_imagen = Path(datos_foto.get(\"rutas\", {}).get(\"imagen\", \"\"))\n",
        "\n",
        "    if not ruta_imagen.exists():\n",
        "        # Intentar ruta alternativa\n",
        "        ruta_imagen = ConfigVLM.FOTOS_EDITADAS / f\"{codigo_foto}.jpg\"\n",
        "\n",
        "    if not ruta_imagen.exists():\n",
        "        print(f\"[ERROR] No se encuentra imagen: {ruta_imagen}\")\n",
        "        return None\n",
        "\n",
        "    imagen = Image.open(ruta_imagen)\n",
        "    print(f\"       Tamaño: {imagen.size}\")\n",
        "\n",
        "    # Cargar máscara de OneFormer (evitando configs inválidas)\n",
        "    print(\"[3/6] Cargando máscara OneFormer...\")\n",
        "    modelos_disponibles = datos_foto.get(\"modelos_disponibles\", {})\n",
        "\n",
        "    # Buscar configuración OneFormer válida (evitar instance y t0.85)\n",
        "    mascara = None\n",
        "    config_usada = None\n",
        "    for config_nombre, config_datos in modelos_disponibles.items():\n",
        "        if \"oneformer\" in config_nombre.lower():\n",
        "            # Evitar configs que sabemos que fallan\n",
        "            if \"instance\" in config_nombre.lower():\n",
        "                continue\n",
        "            if \"t0.85\" in config_nombre or \"t085\" in config_nombre:\n",
        "                continue\n",
        "\n",
        "            ruta_mascara = Path(config_datos.get(\"ruta_mascara\", \"\"))\n",
        "            if ruta_mascara.exists():\n",
        "                mascara = cargar_mascara(ruta_mascara)\n",
        "                config_usada = config_nombre\n",
        "                print(f\"       Config: {config_nombre}\")\n",
        "                print(f\"       Shape: {mascara.shape}\")\n",
        "                break\n",
        "\n",
        "    if mascara is None:\n",
        "        print(\"[ERROR] No se encontró máscara OneFormer válida\")\n",
        "        return None\n",
        "\n",
        "    # Crear imagen compuesta\n",
        "    print(\"[4/6] Generando imagen compuesta...\")\n",
        "    # Redimensionar máscara al tamaño de la imagen\n",
        "    mascara_redim = redimensionar_mascara(mascara, imagen.size)\n",
        "    imagen_compuesta = crear_imagen_compuesta(imagen, mascara_redim)\n",
        "    print(f\"       Tamaño compuesta: {imagen_compuesta.size}\")\n",
        "\n",
        "    # Guardar imagen compuesta para verificación\n",
        "    ruta_compuesta = ConfigVLM.OUTPUT_IMAGENES / f\"{codigo_foto}_compuesta.jpg\"\n",
        "    imagen_compuesta.save(ruta_compuesta, quality=90)\n",
        "    print(f\"       Guardada en: {ruta_compuesta}\")\n",
        "\n",
        "    # Obtener EXIF desde el CSV fusionado\n",
        "    print(\"[5/6] Extrayendo datos EXIF del CSV...\")\n",
        "    exif = obtener_exif_desde_csv(df_metricas, codigo_foto)\n",
        "    print(f\"       EXIF: f/{exif['apertura']}, ISO {exif['iso']}, {exif['distancia_focal']}mm\")\n",
        "\n",
        "    # Obtener IoU de OneFormer\n",
        "    iou_dict = obtener_iou_por_foto(df_metricas, modelo=\"oneformer\")\n",
        "    iou = iou_dict.get(codigo_foto, 0.0)\n",
        "    print(f\"       IoU OneFormer: {iou:.4f}\")\n",
        "\n",
        "    # Generar prompt y analizar\n",
        "    print(\"[6/6] Enviando a Gemini Pro Vision...\")\n",
        "    prompt = generar_prompt(exif, iou)\n",
        "    resultado = analizar_fotografia(modelo_vlm, imagen_compuesta, prompt)\n",
        "\n",
        "    # Añadir metadata de la foto al resultado\n",
        "    resultado[\"_foto\"] = {\n",
        "      \"codigo_foto\": codigo_foto,\n",
        "      \"config_mascara\": config_usada,\n",
        "      \"iou\": float(iou) if iou else 0.0,\n",
        "      \"exif\": {k: (float(v) if isinstance(v, (np.floating, np.integer)) else v) for k, v in exif.items()}\n",
        "    }\n",
        "\n",
        "    # Mostrar resultado\n",
        "    estado = resultado.get(\"_metadata\", {}).get(\"estado\", \"desconocido\")\n",
        "    print(f\"\\n       Estado: {estado}\")\n",
        "\n",
        "    if estado == \"exito\":\n",
        "        print(\"\\n--- RESULTADO DEL ANÁLISIS ---\")\n",
        "        print(json.dumps(resultado, indent=2, ensure_ascii=False))\n",
        "\n",
        "        # Guardar resultado\n",
        "        ruta_resultado = ConfigVLM.OUTPUT_RESPUESTAS / f\"{codigo_foto}_analisis.json\"\n",
        "        with open(ruta_resultado, 'w', encoding='utf-8') as f:\n",
        "            json.dump(resultado, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n[OK] Resultado guardado en: {ruta_resultado}\")\n",
        "    else:\n",
        "        print(f\"\\n[ERROR] {resultado.get('_metadata', {}).get('error', 'Error desconocido')}\")\n",
        "        if '_metadata' in resultado and 'respuesta_raw' in resultado['_metadata']:\n",
        "            print(f\"       Respuesta raw: {resultado['_metadata']['respuesta_raw'][:500]}...\")\n",
        "\n",
        "    return resultado"
      ],
      "metadata": {
        "id": "FJZxBoRarycq"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# EJECUCIÓN PRINCIPAL\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Ejecución principal del Requisito 1: Setup y Validación.\n",
        "\n",
        "    Pasos:\n",
        "        1. Validar rutas y recursos\n",
        "        2. Configurar API Gemini\n",
        "        3. Cargar datos del TFM\n",
        "        4. Ejecutar test de pipeline\n",
        "    \"\"\"\n",
        "    print(\"=\"*70)\n",
        "    print(\"FASE VLM - REQUISITO 1: SETUP Y VALIDACIÓN\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Timestamp: {datetime.now().isoformat()}\")\n",
        "\n",
        "    # 1. Crear directorios\n",
        "    print(\"\\n[PASO 1] Creando estructura de directorios...\")\n",
        "    ConfigVLM.crear_directorios()\n",
        "\n",
        "    # 2. Validar rutas\n",
        "    print(\"\\n[PASO 2] Validando recursos...\")\n",
        "    validaciones = ConfigVLM.validar_rutas()\n",
        "\n",
        "    if not all(validaciones.values()):\n",
        "        print(\"\\n[ADVERTENCIA] Algunos recursos no están disponibles.\")\n",
        "        print(\"Verifica las rutas en ConfigVLM antes de continuar.\")\n",
        "        return\n",
        "\n",
        "    # 3. Configurar Gemini\n",
        "    API_KEY = \"\"\n",
        "\n",
        "    modelo_vlm = configurar_gemini(API_KEY)\n",
        "\n",
        "    # 5. Cargar datos\n",
        "    print(\"\\n[PASO 5] Cargando datos del TFM...\")\n",
        "    indice = cargar_indice_maestro(ConfigVLM.INDICE_MAESTRO)\n",
        "    df_metricas = cargar_metricas_segmentacion(ConfigVLM.METRICAS_CSV)\n",
        "\n",
        "    # 6. Test de pipeline\n",
        "    print(\"\\n[PASO 6] Ejecutando test de pipeline...\")\n",
        "    resultado = test_pipeline_completo(modelo_vlm, indice, df_metricas)\n",
        "\n",
        "    # Resumen final\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"RESUMEN DE VALIDACIÓN\")\n",
        "    print(\"=\"*70)\n",
        "    if resultado and resultado.get(\"_metadata\", {}).get(\"estado\") == \"exito\":\n",
        "        print(\"[OK] Pipeline VLM validado correctamente\")\n",
        "        print(\"[OK] Listo para procesar las 20 fotografías\")\n",
        "    else:\n",
        "        print(\"[PENDIENTE] Revisar errores antes de continuar\")"
      ],
      "metadata": {
        "id": "KNwNrZ9Ur4ho"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar si es script principal\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ImaP0nVEsEp-",
        "outputId": "593f4eb7-d472-4587-a2b7-788b7ad9d691"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FASE VLM - REQUISITO 1: SETUP Y VALIDACIÓN\n",
            "======================================================================\n",
            "Timestamp: 2025-12-14T22:30:55.274007\n",
            "\n",
            "[PASO 1] Creando estructura de directorios...\n",
            "[OK] Directorios creados en: /content/drive/MyDrive/TFM/3_Analisis/fase_vlm\n",
            "\n",
            "[PASO 2] Validando recursos...\n",
            "\n",
            "=== Validación de Rutas ===\n",
            "  [OK] indice_maestro\n",
            "  [OK] fotos_editadas\n",
            "  [OK] caracteristicas\n",
            "  [OK] metricas_csv\n",
            "[OK] Modelo gemini-2.5-flash configurado\n",
            "\n",
            "[PASO 5] Cargando datos del TFM...\n",
            "[OK] Índice maestro cargado: 20 fotografías\n",
            "[OK] Métricas cargadas: 2360 registros\n",
            "\n",
            "[PASO 6] Ejecutando test de pipeline...\n",
            "\n",
            "============================================================\n",
            "TEST DE PIPELINE COMPLETO\n",
            "============================================================\n",
            "\n",
            "[1/6] Foto seleccionada: _DSC0023\n",
            "[2/6] Cargando imagen editada...\n",
            "       Tamaño: (4000, 6000)\n",
            "[3/6] Cargando máscara OneFormer...\n",
            "       Config: oneformer_ade20k_tiny_panoptic_t040\n",
            "       Shape: (6000, 4000)\n",
            "[4/6] Generando imagen compuesta...\n",
            "       Tamaño compuesta: (2048, 1536)\n",
            "       Guardada en: /content/drive/MyDrive/TFM/3_Analisis/fase_vlm/imagenes_compuestas/_DSC0023_compuesta.jpg\n",
            "[5/6] Extrayendo datos EXIF del CSV...\n",
            "       EXIF: f/1.8, ISO 200.0, 85.0mm\n",
            "[OK] IoU extraído para 20 fotos (modelo: oneformer)\n",
            "       IoU OneFormer: 0.9558\n",
            "[6/6] Enviando a Gemini Pro Vision...\n",
            "\n",
            "       Estado: exito\n",
            "\n",
            "--- RESULTADO DEL ANÁLISIS ---\n",
            "{\n",
            "  \"composicion\": {\n",
            "    \"valoracion\": 8,\n",
            "    \"regla_tercios\": \"parcial\",\n",
            "    \"espacio_negativo\": \"adecuado\",\n",
            "    \"observaciones\": \"Composición equilibrada con un encuadre cerrado que enfatiza el rostro. La mirada directa de la modelo crea una fuerte conexión con el espectador, aunque la centralidad es bastante marcada.\"\n",
            "  },\n",
            "  \"iluminacion\": {\n",
            "    \"valoracion\": 9,\n",
            "    \"tipo_principal\": \"natural\",\n",
            "    \"direccion\": \"frontal\",\n",
            "    \"ratio_estimado\": \"2:1\",\n",
            "    \"observaciones\": \"Iluminación suave y difusa, probablemente de una fuente de luz grande (como una ventana), que realza los rasgos del modelo sin crear sombras duras. Excelentes luces de captura en los ojos que aportan vida a la mirada.\"\n",
            "  },\n",
            "  \"tecnica\": {\n",
            "    \"enfoque\": \"correcto\",\n",
            "    \"zona_enfoque\": \"ojos\",\n",
            "    \"exposicion\": \"correcta\",\n",
            "    \"profundidad_campo\": \"muy reducida\",\n",
            "    \"observaciones\": \"Ejecución técnica impecable. El enfoque es nítido en los ojos, y la apertura f/1.8 con una distancia focal de 85mm ha creado una profundidad de campo muy reducida, aislando al sujeto de manera efectiva con un bokeh cremoso.\"\n",
            "  },\n",
            "  \"segmentacion\": {\n",
            "    \"calidad_percibida\": \"excelente\",\n",
            "    \"bordes\": \"precisos\",\n",
            "    \"zonas_problematicas\": \"ninguna\",\n",
            "    \"observaciones\": \"La máscara de segmentación es excepcionalmente precisa, incluso en áreas complejas como el cabello y los bordes de la ropa, lo que se alinea con el alto IoU proporcionado y demuestra una gran calidad del algoritmo.\"\n",
            "  },\n",
            "  \"valoracion_global\": {\n",
            "    \"puntuacion\": 9,\n",
            "    \"fortalezas\": [\n",
            "      \"Enfoque nítido y preciso en los ojos\",\n",
            "      \"Iluminación suave y favorecedora que realza al sujeto\",\n",
            "      \"Excelente aislamiento del sujeto gracias a la profundidad de campo muy reducida\",\n",
            "      \"Alta calidad de la segmentación, con bordes muy precisos\",\n",
            "      \"La expresión y mirada de la modelo son atractivas y conectan con el espectador\"\n",
            "    ],\n",
            "    \"areas_mejora\": [\n",
            "      \"Explorar composiciones menos centrales para añadir mayor dinamismo o interés visual\",\n",
            "      \"Considerar variar ligeramente la pose o el ángulo para introducir más narrativa o movimiento\"\n",
            "    ]\n",
            "  },\n",
            "  \"recomendaciones\": [\n",
            "    \"Experimentar con la regla de tercios o la espiral de oro para composiciones más dinámicas, colocando los ojos o el rostro en puntos de interés.\",\n",
            "    \"Probar diferentes ángulos de cámara o poses (por ejemplo, un ligero giro del cuerpo o la cabeza) para añadir variedad y profundidad a la narrativa del retrato.\",\n",
            "    \"Si se busca un look aún más plano y uniforme en las sombras, considerar el uso de un reflector para rellenar ligeramente las zonas oscuras.\"\n",
            "  ],\n",
            "  \"_metadata\": {\n",
            "    \"timestamp\": \"2025-12-14T22:31:20.063871\",\n",
            "    \"modelo_vlm\": \"gemini-2.5-flash\",\n",
            "    \"estado\": \"exito\"\n",
            "  },\n",
            "  \"_foto\": {\n",
            "    \"codigo_foto\": \"_DSC0023\",\n",
            "    \"config_mascara\": \"oneformer_ade20k_tiny_panoptic_t040\",\n",
            "    \"iou\": 0.9557597216182652,\n",
            "    \"exif\": {\n",
            "      \"apertura\": 1.8,\n",
            "      \"iso\": 200.0,\n",
            "      \"distancia_focal\": 85.0,\n",
            "      \"tiempo_exposicion\": 0.0025,\n",
            "      \"ancho\": 4016.0,\n",
            "      \"alto\": 6016.0\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "[OK] Resultado guardado en: /content/drive/MyDrive/TFM/3_Analisis/fase_vlm/respuestas_vlm/_DSC0023_analisis.json\n",
            "\n",
            "======================================================================\n",
            "RESUMEN DE VALIDACIÓN\n",
            "======================================================================\n",
            "[OK] Pipeline VLM validado correctamente\n",
            "[OK] Listo para procesar las 20 fotografías\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import json\n",
        "# from pathlib import Path\n",
        "\n",
        "# # Cargar índice maestro\n",
        "# with open(\"/content/drive/MyDrive/TFM/3_Analisis/fase1_integracion/indice_maestro.json\", 'r') as f:\n",
        "#     indice = json.load(f)\n",
        "\n",
        "# fotos = {k: v for k, v in indice.items() if isinstance(v, dict) and 'foto_id' in v}\n",
        "# print(f\"Total fotos: {len(fotos)}\")\n",
        "\n",
        "# invalidas = []\n",
        "# total_por_modelo = {}\n",
        "\n",
        "# for idx_foto, (foto_id, datos_foto) in enumerate(fotos.items()):\n",
        "#     print(f\"\\n[{idx_foto+1}/{len(fotos)}] Foto: {foto_id}\")\n",
        "\n",
        "#     modelos_disponibles = datos_foto.get(\"modelos_disponibles\", {})\n",
        "#     print(f\"    Configuraciones: {len(modelos_disponibles)}\")\n",
        "\n",
        "#     for config_nombre, config_datos in modelos_disponibles.items():\n",
        "#         ruta_mascara = config_datos.get(\"ruta_mascara\", \"\")\n",
        "#         if not ruta_mascara:\n",
        "#             continue\n",
        "\n",
        "#         ruta = Path(ruta_mascara)\n",
        "#         if not ruta.exists():\n",
        "#             continue\n",
        "\n",
        "#         # Identificar modelo base\n",
        "#         modelo = config_nombre.split(\"_\")[0]\n",
        "#         if modelo not in total_por_modelo:\n",
        "#             total_por_modelo[modelo] = {\"total\": 0, \"invalidas\": 0}\n",
        "\n",
        "#         try:\n",
        "#             datos = np.load(ruta, allow_pickle=True)\n",
        "#             for clave in ['mascara', 'mask', 'masks', 'arr_0']:\n",
        "#                 if clave in datos:\n",
        "#                     arr = datos[clave]\n",
        "#                     if hasattr(arr, 'shape') and arr.ndim >= 2:\n",
        "#                         pct = (arr > 0).sum() / arr.size * 100\n",
        "#                         total_por_modelo[modelo][\"total\"] += 1\n",
        "\n",
        "#                         if pct > 99 or pct < 1:\n",
        "#                             total_por_modelo[modelo][\"invalidas\"] += 1\n",
        "#                             invalidas.append({\n",
        "#                                 'foto': foto_id,\n",
        "#                                 'modelo': modelo,\n",
        "#                                 'config': config_nombre,\n",
        "#                                 'pct_unos': pct\n",
        "#                             })\n",
        "#                     break\n",
        "#         except Exception as e:\n",
        "#             pass\n",
        "\n",
        "# print(\"\\n\" + \"=\"*60)\n",
        "# print(\"RESUMEN FINAL\")\n",
        "# print(\"=\"*60)\n",
        "\n",
        "# print(\"\\nPor modelo:\")\n",
        "# for modelo, datos in sorted(total_por_modelo.items()):\n",
        "#     pct = datos[\"invalidas\"] / datos[\"total\"] * 100 if datos[\"total\"] > 0 else 0\n",
        "#     print(f\"  {modelo:15} | {datos['invalidas']:4}/{datos['total']:4} inválidas ({pct:5.1f}%)\")\n",
        "\n",
        "# print(f\"\\nTotal máscaras inválidas: {len(invalidas)}\")\n",
        "\n",
        "# if len(invalidas) > 0:\n",
        "#     df_inv = pd.DataFrame(invalidas)\n",
        "#     print(f\"\\nTop 10 configs con más inválidas:\")\n",
        "#     print(df_inv.groupby('config').size().sort_values(ascending=False).head(10))"
      ],
      "metadata": {
        "id": "uEfiHlzyy7jI"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}
