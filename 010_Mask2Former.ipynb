{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkIT2J5Q5CnNFQLkOKzXii",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/010_Mask2Former.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BavQ4XeSfGoB",
        "outputId": "3f048d2d-ee12-4ead-e045-558db584e28d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. SETUP INICIAL\n",
        "# ==========================================\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation\n",
        "from PIL import Image, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuración centralizada\"\"\"\n",
        "    DATASET_PATH: Path = Path(\"/content/drive/MyDrive/TFM/mask2former/imagenes\")\n",
        "    OUTPUT_PATH: Path = Path(\"/content/drive/MyDrive/TFM/mask2former/resultados\")\n",
        "\n",
        "    # Umbrales predefinidos\n",
        "    UMBRALES = {\n",
        "    'ultra': [0.0001, 0.001, 0.01, 0.1],\n",
        "    'agresivo': [0.001, 0.01, 0.05, 0.1, 0.3],\n",
        "    'normal': [0.01, 0.1, 0.3, 0.5],\n",
        "    'conservador': [0.3, 0.5, 0.7]\n",
        "    }\n",
        "\n",
        "    MODELOS = [\n",
        "        \"facebook/mask2former-swin-large-coco-instance\",\n",
        "        \"facebook/mask2former-swin-base-ade-semantic\",\n",
        "        \"facebook/mask2former-swin-small-coco-instance\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "_6tzVhPjk8NV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
        "print(\"Setup completado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFOEdEGzk9nU",
        "outputId": "50fd2d4e-03b6-45cc-ffd8-bba81e6b1dee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "#  2: UTILIDADES BÁSICAS\n",
        "# ==========================================\n",
        "class Utils:\n",
        "    \"\"\"Utilidades reutilizables\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagenes(ruta: str) -> List[str]:\n",
        "        \"\"\"Carga lista de imágenes\"\"\"\n",
        "        path = Path(ruta)\n",
        "        extensiones = (\".jpg\", \".png\", \".jpeg\")\n",
        "        imagenes = [str(p) for p in path.glob(\"**/*\") if p.suffix.lower() in extensiones]\n",
        "        print(f\"Encontradas {len(imagenes)} imágenes\")\n",
        "        return imagenes\n",
        "\n",
        "    @staticmethod\n",
        "    def preparar_imagen(ruta: str, max_size: int = 1024) -> Image.Image:\n",
        "        \"\"\"Prepara imagen para procesamiento\"\"\"\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "        if max(img.size) > max_size:\n",
        "            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash(ruta: str) -> str:\n",
        "        \"\"\"Calcula hash único de archivo\"\"\"\n",
        "        return hashlib.md5(open(ruta, 'rb').read()).hexdigest()[:8]\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Any, archivo: str) -> None:\n",
        "        \"\"\"Guarda datos en JSON\"\"\"\n",
        "        with open(archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Guardado: {archivo}\")\n",
        "\n",
        "print(\"Utilidades definidas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWVk3grDliyZ",
        "outputId": "7d4413d3-687f-432c-ab08-fbfe8c23e326"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilidades definidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3: DETECTOR CORE\n",
        "# ==========================================\n",
        "class DetectorPersonas:\n",
        "    \"\"\"Detector principal - Clase única y enfocada\"\"\"\n",
        "\n",
        "    def __init__(self, modelo_name: str):\n",
        "        self.modelo_name = modelo_name\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"Cargando: {modelo_name}\")\n",
        "        self.processor = AutoImageProcessor.from_pretrained(modelo_name)\n",
        "        self.model = AutoModelForUniversalSegmentation.from_pretrained(modelo_name)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        self.es_semantico = ('ade' in modelo_name.lower() or 'semantic' in modelo_name.lower())\n",
        "\n",
        "        if hasattr(self.model.config, 'id2label'):\n",
        "            self.id2label = self.model.config.id2label\n",
        "            print(f\"Clase 0: {self.id2label.get(0, 'DESCONOCIDA')}\")\n",
        "\n",
        "            # Buscar clase persona si no es 0\n",
        "            self.clase_persona = 0\n",
        "            for clase_id, nombre in self.id2label.items():\n",
        "                if 'person' in nombre.lower() or 'people' in nombre.lower():\n",
        "                    self.clase_persona = clase_id\n",
        "                    print(f\"Clase persona encontrada: {clase_id} = {nombre}\")\n",
        "                    break\n",
        "        else:\n",
        "            self.clase_persona = 0\n",
        "\n",
        "        print(f\"Modelo cargado en {self.device} (semántico: {self.es_semantico})\")\n",
        "\n",
        "    def detectar_en_imagen(self, imagen: Image.Image, umbrales: List[float]) -> Dict:\n",
        "        \"\"\"VERSIÓN CORREGIDA - Detecta personas con post-procesamiento correcto\"\"\"\n",
        "\n",
        "        # CORRECCIÓN 1: Orden correcto height, width\n",
        "        w, h = imagen.size  # PIL: width, height\n",
        "\n",
        "        # Inferencia una sola vez\n",
        "        inputs = self.processor(images=imagen, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        inicio = time.time()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        tiempo_ms = (time.time() - inicio) * 1000\n",
        "\n",
        "        resultados = {'tiempo_inferencia_ms': tiempo_ms}\n",
        "\n",
        "        # CORRECCIÓN 2: Post-procesamiento según tipo de modelo\n",
        "        if self.es_semantico:\n",
        "            # Modelos semánticos - un solo resultado\n",
        "            try:\n",
        "                resultado_semantico = self.processor.post_process_semantic_segmentation(\n",
        "                    outputs, target_sizes=[(h, w)]  # CORRECCIÓN: (height, width)\n",
        "                )[0]\n",
        "\n",
        "                # Analizar máscara semántica\n",
        "                unique_classes = torch.unique(resultado_semantico)\n",
        "\n",
        "                # Para cada umbral (en semánticos simulamos diferentes sensibilidades)\n",
        "                for umbral in umbrales:\n",
        "                    # Contar píxeles de clase persona\n",
        "                    persona_mask = (resultado_semantico == self.clase_persona)\n",
        "                    persona_pixels = persona_mask.sum().item()\n",
        "                    total_pixels = resultado_semantico.numel()\n",
        "\n",
        "                    # Umbral por porcentaje de píxeles\n",
        "                    porcentaje_minimo = umbral * 100  # umbral 0.1 = mínimo 10% píxeles\n",
        "                    porcentaje_actual = (persona_pixels / total_pixels) * 100\n",
        "\n",
        "                    personas = 1 if porcentaje_actual >= porcentaje_minimo and persona_pixels > 50 else 0\n",
        "\n",
        "                    resultados[f'umbral_{umbral}'] = {\n",
        "                        'personas': personas,\n",
        "                        'total': len(unique_classes),\n",
        "                        'todas_clases': unique_classes.tolist(),\n",
        "                        'persona_pixels': persona_pixels,\n",
        "                        'porcentaje_persona': porcentaje_actual,\n",
        "                        'scores_personas': [1.0] if personas > 0 else []\n",
        "                    }\n",
        "\n",
        "            except Exception as e:\n",
        "                for umbral in umbrales:\n",
        "                    resultados[f'umbral_{umbral}'] = {\n",
        "                        'error': str(e), 'personas': 0, 'total': 0\n",
        "                    }\n",
        "        else:\n",
        "            # Modelos de instancia - resultado por umbral\n",
        "            for umbral in umbrales:\n",
        "                try:\n",
        "                    resultado = self.processor.post_process_instance_segmentation(\n",
        "                        outputs, target_sizes=[(h, w)], threshold=umbral  # CORRECCIÓN\n",
        "                    )[0]\n",
        "\n",
        "                    labels = resultado.get(\"labels\", torch.tensor([]))\n",
        "                    scores = resultado.get(\"scores\", torch.tensor([]))\n",
        "\n",
        "                    # CORRECCIÓN 3: Usar self.clase_persona en lugar de asumir 0\n",
        "                    personas = sum(1 for l in labels if int(l.item()) == self.clase_persona)\n",
        "                    total_detecciones = len(labels)\n",
        "\n",
        "                    scores_personas = [\n",
        "                        float(s.item()) for l, s in zip(labels, scores)\n",
        "                        if int(l.item()) == self.clase_persona\n",
        "                    ]\n",
        "\n",
        "                    todas_clases = [int(l.item()) for l in labels]\n",
        "                    todos_scores = [float(s.item()) for s in scores]\n",
        "\n",
        "                    resultados[f'umbral_{umbral}'] = {\n",
        "                        'personas': personas,\n",
        "                        'total': total_detecciones,\n",
        "                        'scores_personas': scores_personas,\n",
        "                        'todas_clases': todas_clases,\n",
        "                        'todos_scores': todos_scores,\n",
        "                        'max_score': max(todos_scores) if todos_scores else 0.0\n",
        "                    }\n",
        "\n",
        "                except Exception as e:\n",
        "                    resultados[f'umbral_{umbral}'] = {\n",
        "                        'error': str(e), 'personas': 0, 'total': 0\n",
        "                    }\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def limpiar(self):\n",
        "        \"\"\"Limpia memoria\"\"\"\n",
        "        del self.model, self.processor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"DetectorPersonas definido\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUUIIdwlytw",
        "outputId": "77c0f34b-9ce2-4734-fa02-dc632e89411d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DetectorPersonas definido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4: PROCESADOR DE RESULTADOS\n",
        "# ==========================================\n",
        "class ProcesadorResultados:\n",
        "    \"\"\"Procesa y formatea resultados\"\"\"\n",
        "\n",
        "    def __init__(self, output_path: str):\n",
        "        self.output_path = Path(output_path)\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: str, detector: DetectorPersonas,\n",
        "                       umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Procesa una imagen completa\"\"\"\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # Preparar imagen\n",
        "            imagen = Utils.preparar_imagen(ruta_imagen)\n",
        "            hash_img = Utils.calcular_hash(ruta_imagen)\n",
        "\n",
        "            # Información básica\n",
        "            img_array = np.array(imagen)\n",
        "            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            info_imagen = {\n",
        "                'archivo': os.path.basename(ruta_imagen),\n",
        "                'hash': hash_img,\n",
        "                'tamaño': imagen.size,\n",
        "                'brillo_promedio': float(np.mean(gray))\n",
        "            }\n",
        "\n",
        "            # Detectar\n",
        "            resultados_deteccion = detector.detectar_en_imagen(imagen, umbrales)\n",
        "\n",
        "            # Resultado final\n",
        "            tiempo_total = (time.time() - inicio) * 1000\n",
        "\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': info_imagen,\n",
        "                'deteccion': resultados_deteccion,\n",
        "                'tiempo_total_ms': tiempo_total,\n",
        "                'modelo': detector.modelo_name,\n",
        "                'exitoso': True\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {'archivo': os.path.basename(ruta_imagen)},\n",
        "                'error': str(e),\n",
        "                'exitoso': False\n",
        "            }\n",
        "\n",
        "    def mostrar_resumen(self, resultados: List[Dict]) -> None:\n",
        "        \"\"\"Muestra resumen de resultados\"\"\"\n",
        "        exitosos = sum(1 for r in resultados if r.get('exitoso', False))\n",
        "        print(f\"\\nRESUMEN: {exitosos}/{len(resultados)} imágenes procesadas\")\n",
        "\n",
        "        if exitosos == 0:\n",
        "            return\n",
        "\n",
        "        # Estadísticas por umbral\n",
        "        for umbral in config.UMBRALES['agresivo']:\n",
        "            personas_detectadas = []\n",
        "            for r in resultados:\n",
        "                if r.get('exitoso', False):\n",
        "                    deteccion = r.get('deteccion', {})\n",
        "                    umbral_data = deteccion.get(f'umbral_{umbral}', {})\n",
        "                    personas_detectadas.append(umbral_data.get('personas', 0))\n",
        "\n",
        "            if personas_detectadas:\n",
        "                total_personas = sum(personas_detectadas)\n",
        "                imagenes_con_personas = sum(1 for p in personas_detectadas if p > 0)\n",
        "                print(f\"  Umbral {umbral:5.3f}: {total_personas} personas en {imagenes_con_personas} imágenes\")\n",
        "\n",
        "print(\"ProcesadorResultados definido\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txkQ0UPPmUbc",
        "outputId": "2cd04455-eca9-498d-bf7a-66a781594743"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProcesadorResultados definido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5: FUNCIONES EJECUTABLES\n",
        "# ==========================================\n",
        "\n",
        "def ejecutar_evaluacion_basica(modelo_idx: int = 0, umbral_config: str = 'agresivo'):\n",
        "    \"\"\"\n",
        "    FUNCIÓN EJECUTABLE: Evaluación básica\n",
        "\n",
        "    Args:\n",
        "        modelo_idx: Índice del modelo (0, 1, 2)\n",
        "        umbral_config: Configuración de umbrales ('conservador', 'normal', 'agresivo', 'ultra')\n",
        "    \"\"\"\n",
        "    print(f\"EVALUACIÓN BÁSICA - Modelo {modelo_idx}, Umbrales: {umbral_config}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Validar parámetros\n",
        "    if modelo_idx >= len(config.MODELOS):\n",
        "        print(f\"Modelo index inválido. Máximo: {len(config.MODELOS)-1}\")\n",
        "        return\n",
        "\n",
        "    if umbral_config not in config.UMBRALES:\n",
        "        print(f\"Configuración inválida. Disponibles: {list(config.UMBRALES.keys())}\")\n",
        "        return\n",
        "\n",
        "    # Cargar datos\n",
        "    imagenes = Utils.cargar_imagenes(config.DATASET_PATH)\n",
        "    if not imagenes:\n",
        "        print(\"No hay imágenes\")\n",
        "        return\n",
        "\n",
        "    # Ejecutar\n",
        "    modelo = config.MODELOS[modelo_idx]\n",
        "    umbrales = config.UMBRALES[umbral_config]\n",
        "\n",
        "    detector = DetectorPersonas(modelo)\n",
        "    procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "    # Procesar cada imagen\n",
        "    resultados = []\n",
        "    for i, ruta in enumerate(tqdm(imagenes, desc=\"Procesando\")):\n",
        "        print(f\"[{i+1:3d}/{len(imagenes)}] {os.path.basename(ruta)}\")\n",
        "        resultado = procesador.procesar_imagen(ruta, detector, umbrales)\n",
        "        resultados.append(resultado)\n",
        "\n",
        "        # Log básico\n",
        "        if resultado.get('exitoso', False):\n",
        "            deteccion = resultado['deteccion']\n",
        "            mejor_umbral = min(umbrales)  # Usar el más sensible\n",
        "            datos = deteccion.get(f'umbral_{mejor_umbral}', {})\n",
        "            personas = datos.get('personas', 0)\n",
        "            total = datos.get('total', 0)\n",
        "            print(f\"{personas} personas de {total} detecciones\")\n",
        "        else:\n",
        "            print(f\"Error: {resultado.get('error', 'unknown')}\")\n",
        "\n",
        "    # Guardar y mostrar resumen\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    archivo = config.OUTPUT_PATH / f\"evaluacion_{modelo_idx}_{umbral_config}_{timestamp}.json\"\n",
        "    Utils.guardar_json(resultados, str(archivo))\n",
        "\n",
        "    procesador.mostrar_resumen(resultados)\n",
        "    detector.limpiar()\n",
        "\n",
        "    return str(archivo)\n",
        "\n",
        "def probar_imagen_individual(ruta_imagen: str, mostrar_detalles: bool = True):\n",
        "    \"\"\"\n",
        "    FUNCIÓN EJECUTABLE: Probar una imagen específica\n",
        "\n",
        "    Args:\n",
        "        ruta_imagen: Ruta completa a la imagen\n",
        "        mostrar_detalles: Si mostrar información detallada\n",
        "    \"\"\"\n",
        "    print(f\"PRUEBA INDIVIDUAL: {os.path.basename(ruta_imagen)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if not os.path.exists(ruta_imagen):\n",
        "        print(f\"Imagen no encontrada: {ruta_imagen}\")\n",
        "        return\n",
        "\n",
        "    # Usar modelo más potente y umbrales ultra sensibles\n",
        "    detector = DetectorPersonas(config.MODELOS[0])  # El más grande\n",
        "    procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "    resultado = procesador.procesar_imagen(ruta_imagen, detector, config.UMBRALES['ultra'])\n",
        "\n",
        "    if not resultado.get('exitoso', False):\n",
        "        print(f\"Error: {resultado.get('error')}\")\n",
        "        detector.limpiar()\n",
        "        return\n",
        "\n",
        "    # Mostrar resultados\n",
        "    deteccion = resultado['deteccion']\n",
        "    imagen_info = resultado['imagen']\n",
        "\n",
        "    print(f\"Imagen: {imagen_info['tamaño']} pixels, brillo: {imagen_info['brillo_promedio']:.1f}\")\n",
        "    print(f\"Tiempo: {deteccion['tiempo_inferencia_ms']:.1f}ms\")\n",
        "    print()\n",
        "\n",
        "    # Resultados por umbral\n",
        "    print(\"DETECCIONES POR UMBRAL:\")\n",
        "    for umbral in config.UMBRALES['ultra']:\n",
        "        datos = deteccion.get(f'umbral_{umbral}', {})\n",
        "        if 'error' in datos:\n",
        "            print(f\"  {umbral:6.3f}: Error - {datos['error']}\")\n",
        "            continue\n",
        "\n",
        "        personas = datos.get('personas', 0)\n",
        "        total = datos.get('total', 0)\n",
        "        max_score = datos.get('max_score', 0)\n",
        "\n",
        "        print(f\"  {umbral:6.3f}: {personas:2d} personas de {total:2d} total (max score: {max_score:.4f})\")\n",
        "\n",
        "        if mostrar_detalles and datos.get('todas_clases'):\n",
        "            clases_unicas = sorted(set(datos['todas_clases']))\n",
        "            print(f\"             Clases: {clases_unicas}\")\n",
        "\n",
        "    # Recomendación\n",
        "    mejor_umbral_data = deteccion.get('umbral_0.01', deteccion.get('umbral_0.001', {}))\n",
        "    personas_detectadas = mejor_umbral_data.get('personas', 0)\n",
        "\n",
        "    print(f\"\\nRESULTADO: {personas_detectadas} personas detectadas\")\n",
        "    if personas_detectadas == 0:\n",
        "        total_detecciones = mejor_umbral_data.get('total', 0)\n",
        "        if total_detecciones > 0:\n",
        "            print(\" Se detectaron otros objetos pero no personas\")\n",
        "            print(\"   Posibles soluciones:\")\n",
        "            print(\"   - Usar umbrales aún más bajos\")\n",
        "            print(\"   - Verificar que la imagen contenga personas visibles\")\n",
        "            print(\"   - Probar con otro modelo\")\n",
        "        else:\n",
        "            print(\" No se detectó ningún objeto\")\n",
        "\n",
        "    detector.limpiar()\n",
        "    return resultado\n",
        "\n",
        "def comparar_modelos_rapido(max_imagenes: int = 3):\n",
        "    \"\"\"\n",
        "    FUNCIÓN EJECUTABLE: Comparación rápida de modelos\n",
        "\n",
        "    Args:\n",
        "        max_imagenes: Número máximo de imágenes a procesar\n",
        "    \"\"\"\n",
        "    print(f\"COMPARACIÓN RÁPIDA - {max_imagenes} imágenes máximo\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    imagenes = Utils.cargar_imagenes(config.DATASET_PATH)[:max_imagenes]\n",
        "    if not imagenes:\n",
        "        print(\"No hay imágenes\")\n",
        "        return\n",
        "\n",
        "    umbrales = config.UMBRALES['agresivo']\n",
        "    resultados_comparacion = {}\n",
        "\n",
        "    for i, modelo in enumerate(config.MODELOS):\n",
        "        print(f\"\\nModelo {i+1}/{len(config.MODELOS)}: {modelo.split('/')[-1]}\")\n",
        "\n",
        "        detector = DetectorPersonas(modelo)\n",
        "        procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "        resultados_modelo = []\n",
        "        for ruta in imagenes:\n",
        "            resultado = procesador.procesar_imagen(ruta, detector, umbrales)\n",
        "            resultados_modelo.append(resultado)\n",
        "\n",
        "        # Estadísticas rápidas\n",
        "        exitosos = sum(1 for r in resultados_modelo if r.get('exitoso', False))\n",
        "\n",
        "        personas_totales = 0\n",
        "        tiempo_promedio = 0\n",
        "\n",
        "        for resultado in resultados_modelo:\n",
        "            if resultado.get('exitoso', False):\n",
        "                # Usar umbral más sensible para contar\n",
        "                deteccion = resultado['deteccion']\n",
        "                umbral_data = deteccion.get('umbral_0.01', deteccion.get('umbral_0.05', {}))\n",
        "                personas_totales += umbral_data.get('personas', 0)\n",
        "                tiempo_promedio += resultado.get('tiempo_total_ms', 0)\n",
        "\n",
        "        if exitosos > 0:\n",
        "            tiempo_promedio /= exitosos\n",
        "\n",
        "        resultados_comparacion[modelo] = {\n",
        "            'exitosos': exitosos,\n",
        "            'personas_totales': personas_totales,\n",
        "            'tiempo_promedio_ms': tiempo_promedio\n",
        "        }\n",
        "\n",
        "        print(f\" {exitosos}/{len(imagenes)} exitosas\")\n",
        "        print(f\" {personas_totales} personas detectadas\")\n",
        "        print(f\" {tiempo_promedio:.1f}ms promedio\")\n",
        "\n",
        "        detector.limpiar()\n",
        "\n",
        "    # Resumen final\n",
        "    print(f\"\\nRESUMEN COMPARACIÓN:\")\n",
        "    print(\"-\" * 40)\n",
        "    for modelo, datos in resultados_comparacion.items():\n",
        "        nombre = modelo.split('/')[-1]\n",
        "        print(f\"{nombre:30s}: {datos['personas_totales']:2d} personas, {datos['tiempo_promedio_ms']:5.1f}ms\")\n",
        "\n",
        "    return resultados_comparacion\n",
        "\n",
        "print(\"Funciones ejecutables definidas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFGSs_jRmurU",
        "outputId": "39d44622-80cf-4f2a-e576-ec6435b8e2ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funciones ejecutables definidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ejecutamos evaluación básica.\n",
        "for i in range(len(config.MODELOS)):\n",
        "    for umbral in config.UMBRALES.keys():\n",
        "        ejecutar_evaluacion_basica(i, umbral)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GaIHsaRnZvg",
        "outputId": "eb73bc38-a831-48d0-fe19-1ef09a6c33fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUACIÓN BÁSICA - Modelo 0, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-large-coco-instance\n",
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  1.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_ultra_20250902_184211.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 0, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_agresivo_20250902_184213.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 0, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_normal_20250902_184215.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 0, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_conservador_20250902_184217.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 1, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: wall\n",
            "Clase persona encontrada: 12 = person\n",
            "Modelo cargado en cuda (semántico: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 personas de 6 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_ultra_20250902_184218.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 1 personas en 1 imágenes\n",
            "  Umbral 0.010: 1 personas en 1 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 1 personas en 1 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 1, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: wall\n",
            "Clase persona encontrada: 12 = person\n",
            "Modelo cargado en cuda (semántico: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 personas de 6 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_agresivo_20250902_184220.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 1 personas en 1 imágenes\n",
            "  Umbral 0.010: 1 personas en 1 imágenes\n",
            "  Umbral 0.050: 1 personas en 1 imágenes\n",
            "  Umbral 0.100: 1 personas en 1 imágenes\n",
            "  Umbral 0.300: 1 personas en 1 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 1, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: wall\n",
            "Clase persona encontrada: 12 = person\n",
            "Modelo cargado en cuda (semántico: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 personas de 6 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_normal_20250902_184222.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 1 personas en 1 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 1 personas en 1 imágenes\n",
            "  Umbral 0.300: 1 personas en 1 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 1, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: wall\n",
            "Clase persona encontrada: 12 = person\n",
            "Modelo cargado en cuda (semántico: True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 personas de 6 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_conservador_20250902_184223.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 1 personas en 1 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 2, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_ultra_20250902_184225.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 2, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_agresivo_20250902_184227.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 2, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_normal_20250902_184228.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n",
            "EVALUACIÓN BÁSICA - Modelo 2, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 imágenes\n",
            "Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase 0: person\n",
            "Clase persona encontrada: 0 = person\n",
            "Modelo cargado en cuda (semántico: False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|██████████| 1/1 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_conservador_20250902_184230.json\n",
            "\n",
            "RESUMEN: 1/1 imágenes procesadas\n",
            "  Umbral 0.001: 0 personas en 0 imágenes\n",
            "  Umbral 0.010: 0 personas en 0 imágenes\n",
            "  Umbral 0.050: 0 personas en 0 imágenes\n",
            "  Umbral 0.100: 0 personas en 0 imágenes\n",
            "  Umbral 0.300: 0 personas en 0 imágenes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}