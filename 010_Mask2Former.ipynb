{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9ZvX55IMVz/wfctRdbdrx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/010_Mask2Former.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BavQ4XeSfGoB",
        "outputId": "a4273df6-b0bd-44b3-b771-08184477bd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# 1. SETUP INICIAL\n",
        "# ==========================================\n",
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Any, Optional\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation\n",
        "from PIL import Image, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuraci√≥n\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"Configuraci√≥n centralizada\"\"\"\n",
        "    DATASET_PATH: Path = Path(\"/content/drive/MyDrive/TFM/mask2former/imagenes\")\n",
        "    OUTPUT_PATH: Path = Path(\"/content/drive/MyDrive/TFM/mask2former/resultados\")\n",
        "\n",
        "    # Umbrales predefinidos\n",
        "    UMBRALES = {\n",
        "        'conservador': [0.3, 0.5, 0.7],\n",
        "        'normal': [0.1, 0.3, 0.5],\n",
        "        'agresivo': [0.01, 0.05, 0.1, 0.3],\n",
        "        'ultra': [0.001, 0.01, 0.05, 0.1]\n",
        "    }\n",
        "\n",
        "    MODELOS = [\n",
        "        \"facebook/mask2former-swin-large-coco-instance\",\n",
        "        \"facebook/mask2former-swin-base-ade-semantic\",\n",
        "        \"facebook/mask2former-swin-small-coco-instance\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "_6tzVhPjk8NV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config()\n",
        "os.makedirs(config.OUTPUT_PATH, exist_ok=True)\n",
        "print(\"Setup completado\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFOEdEGzk9nU",
        "outputId": "79f2b063-97bb-4198-80c0-ab5e24a5db37"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "#  2: UTILIDADES B√ÅSICAS\n",
        "# ==========================================\n",
        "class Utils:\n",
        "    \"\"\"Utilidades reutilizables\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagenes(ruta: str) -> List[str]:\n",
        "        \"\"\"Carga lista de im√°genes\"\"\"\n",
        "        path = Path(ruta)\n",
        "        extensiones = (\".jpg\", \".png\", \".jpeg\")\n",
        "        imagenes = [str(p) for p in path.glob(\"**/*\") if p.suffix.lower() in extensiones]\n",
        "        print(f\"Encontradas {len(imagenes)} im√°genes\")\n",
        "        return imagenes\n",
        "\n",
        "    @staticmethod\n",
        "    def preparar_imagen(ruta: str, max_size: int = 1024) -> Image.Image:\n",
        "        \"\"\"Prepara imagen para procesamiento\"\"\"\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "        if max(img.size) > max_size:\n",
        "            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
        "        return img\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash(ruta: str) -> str:\n",
        "        \"\"\"Calcula hash √∫nico de archivo\"\"\"\n",
        "        return hashlib.md5(open(ruta, 'rb').read()).hexdigest()[:8]\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Any, archivo: str) -> None:\n",
        "        \"\"\"Guarda datos en JSON\"\"\"\n",
        "        with open(archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Guardado: {archivo}\")\n",
        "\n",
        "print(\"Utilidades definidas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWVk3grDliyZ",
        "outputId": "daae3691-39c5-41a5-a760-eca55e9547d2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilidades definidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3: DETECTOR CORE\n",
        "# ==========================================\n",
        "class DetectorPersonas:\n",
        "    \"\"\"Detector principal - Clase √∫nica y enfocada\"\"\"\n",
        "\n",
        "    def __init__(self, modelo_name: str):\n",
        "        self.modelo_name = modelo_name\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        print(f\"ü§ñ Cargando: {modelo_name}\")\n",
        "        self.processor = AutoImageProcessor.from_pretrained(modelo_name)\n",
        "        self.model = AutoModelForUniversalSegmentation.from_pretrained(modelo_name)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        print(f\"Modelo cargado en {self.device}\")\n",
        "\n",
        "    def detectar_en_imagen(self, imagen: Image.Image, umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Detecta personas con m√∫ltiples umbrales\"\"\"\n",
        "        h, w = imagen.size[1], imagen.size[0]  # PIL format\n",
        "\n",
        "        # Inferencia una sola vez\n",
        "        inputs = self.processor(images=imagen, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        inicio = time.time()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        tiempo_ms = (time.time() - inicio) * 1000\n",
        "\n",
        "        # Probar cada umbral\n",
        "        resultados = {'tiempo_inferencia_ms': tiempo_ms}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            try:\n",
        "                resultado = self.processor.post_process_instance_segmentation(\n",
        "                    outputs, target_sizes=[(h, w)], threshold=umbral\n",
        "                )[0]\n",
        "\n",
        "                # Extraer informaci√≥n\n",
        "                labels = resultado.get(\"labels\", [])\n",
        "                scores = resultado.get(\"scores\", [])\n",
        "\n",
        "                # Contar personas (clase 0) y otras detecciones\n",
        "                personas = sum(1 for l in labels if int(l.item()) == 0)\n",
        "                total_detecciones = len(labels)\n",
        "\n",
        "                # Scores de personas\n",
        "                scores_personas = [\n",
        "                    float(s.item()) for l, s in zip(labels, scores)\n",
        "                    if int(l.item()) == 0\n",
        "                ]\n",
        "\n",
        "                # Todas las clases detectadas\n",
        "                todas_clases = [int(l.item()) for l in labels]\n",
        "                todos_scores = [float(s.item()) for s in scores]\n",
        "\n",
        "                resultados[f'umbral_{umbral}'] = {\n",
        "                    'personas': personas,\n",
        "                    'total': total_detecciones,\n",
        "                    'scores_personas': scores_personas,\n",
        "                    'todas_clases': todas_clases,\n",
        "                    'todos_scores': todos_scores,\n",
        "                    'max_score': max(todos_scores) if todos_scores else 0.0\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                resultados[f'umbral_{umbral}'] = {\n",
        "                    'error': str(e),\n",
        "                    'personas': 0,\n",
        "                    'total': 0\n",
        "                }\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def limpiar(self):\n",
        "        \"\"\"Limpia memoria\"\"\"\n",
        "        del self.model, self.processor\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "print(\"DetectorPersonas definido\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUUIIdwlytw",
        "outputId": "0c091680-66c1-4efb-989b-4cd22803dbd7"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DetectorPersonas definido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4: PROCESADOR DE RESULTADOS\n",
        "# ==========================================\n",
        "class ProcesadorResultados:\n",
        "    \"\"\"Procesa y formatea resultados\"\"\"\n",
        "\n",
        "    def __init__(self, output_path: str):\n",
        "        self.output_path = Path(output_path)\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: str, detector: DetectorPersonas,\n",
        "                       umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Procesa una imagen completa\"\"\"\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # Preparar imagen\n",
        "            imagen = Utils.preparar_imagen(ruta_imagen)\n",
        "            hash_img = Utils.calcular_hash(ruta_imagen)\n",
        "\n",
        "            # Informaci√≥n b√°sica\n",
        "            img_array = np.array(imagen)\n",
        "            gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            info_imagen = {\n",
        "                'archivo': os.path.basename(ruta_imagen),\n",
        "                'hash': hash_img,\n",
        "                'tama√±o': imagen.size,\n",
        "                'brillo_promedio': float(np.mean(gray))\n",
        "            }\n",
        "\n",
        "            # Detectar\n",
        "            resultados_deteccion = detector.detectar_en_imagen(imagen, umbrales)\n",
        "\n",
        "            # Resultado final\n",
        "            tiempo_total = (time.time() - inicio) * 1000\n",
        "\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': info_imagen,\n",
        "                'deteccion': resultados_deteccion,\n",
        "                'tiempo_total_ms': tiempo_total,\n",
        "                'modelo': detector.modelo_name,\n",
        "                'exitoso': True\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {'archivo': os.path.basename(ruta_imagen)},\n",
        "                'error': str(e),\n",
        "                'exitoso': False\n",
        "            }\n",
        "\n",
        "    def mostrar_resumen(self, resultados: List[Dict]) -> None:\n",
        "        \"\"\"Muestra resumen de resultados\"\"\"\n",
        "        exitosos = sum(1 for r in resultados if r.get('exitoso', False))\n",
        "        print(f\"\\nRESUMEN: {exitosos}/{len(resultados)} im√°genes procesadas\")\n",
        "\n",
        "        if exitosos == 0:\n",
        "            return\n",
        "\n",
        "        # Estad√≠sticas por umbral\n",
        "        for umbral in config.UMBRALES['agresivo']:\n",
        "            personas_detectadas = []\n",
        "            for r in resultados:\n",
        "                if r.get('exitoso', False):\n",
        "                    deteccion = r.get('deteccion', {})\n",
        "                    umbral_data = deteccion.get(f'umbral_{umbral}', {})\n",
        "                    personas_detectadas.append(umbral_data.get('personas', 0))\n",
        "\n",
        "            if personas_detectadas:\n",
        "                total_personas = sum(personas_detectadas)\n",
        "                imagenes_con_personas = sum(1 for p in personas_detectadas if p > 0)\n",
        "                print(f\"  Umbral {umbral:5.3f}: {total_personas} personas en {imagenes_con_personas} im√°genes\")\n",
        "\n",
        "print(\"ProcesadorResultados definido\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txkQ0UPPmUbc",
        "outputId": "5f3f4c74-9d56-456e-acf3-b815c3471697"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ProcesadorResultados definido\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5: FUNCIONES EJECUTABLES\n",
        "# ==========================================\n",
        "\n",
        "def ejecutar_evaluacion_basica(modelo_idx: int = 0, umbral_config: str = 'agresivo'):\n",
        "    \"\"\"\n",
        "    FUNCI√ìN EJECUTABLE: Evaluaci√≥n b√°sica\n",
        "\n",
        "    Args:\n",
        "        modelo_idx: √çndice del modelo (0, 1, 2)\n",
        "        umbral_config: Configuraci√≥n de umbrales ('conservador', 'normal', 'agresivo', 'ultra')\n",
        "    \"\"\"\n",
        "    print(f\"EVALUACI√ìN B√ÅSICA - Modelo {modelo_idx}, Umbrales: {umbral_config}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Validar par√°metros\n",
        "    if modelo_idx >= len(config.MODELOS):\n",
        "        print(f\"Modelo index inv√°lido. M√°ximo: {len(config.MODELOS)-1}\")\n",
        "        return\n",
        "\n",
        "    if umbral_config not in config.UMBRALES:\n",
        "        print(f\"Configuraci√≥n inv√°lida. Disponibles: {list(config.UMBRALES.keys())}\")\n",
        "        return\n",
        "\n",
        "    # Cargar datos\n",
        "    imagenes = Utils.cargar_imagenes(config.DATASET_PATH)\n",
        "    if not imagenes:\n",
        "        print(\"No hay im√°genes\")\n",
        "        return\n",
        "\n",
        "    # Ejecutar\n",
        "    modelo = config.MODELOS[modelo_idx]\n",
        "    umbrales = config.UMBRALES[umbral_config]\n",
        "\n",
        "    detector = DetectorPersonas(modelo)\n",
        "    procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "    # Procesar cada imagen\n",
        "    resultados = []\n",
        "    for i, ruta in enumerate(tqdm(imagenes, desc=\"Procesando\")):\n",
        "        print(f\"[{i+1:3d}/{len(imagenes)}] {os.path.basename(ruta)}\")\n",
        "        resultado = procesador.procesar_imagen(ruta, detector, umbrales)\n",
        "        resultados.append(resultado)\n",
        "\n",
        "        # Log b√°sico\n",
        "        if resultado.get('exitoso', False):\n",
        "            deteccion = resultado['deteccion']\n",
        "            mejor_umbral = min(umbrales)  # Usar el m√°s sensible\n",
        "            datos = deteccion.get(f'umbral_{mejor_umbral}', {})\n",
        "            personas = datos.get('personas', 0)\n",
        "            total = datos.get('total', 0)\n",
        "            print(f\"{personas} personas de {total} detecciones\")\n",
        "        else:\n",
        "            print(f\"Error: {resultado.get('error', 'unknown')}\")\n",
        "\n",
        "    # Guardar y mostrar resumen\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    archivo = config.OUTPUT_PATH / f\"evaluacion_{modelo_idx}_{umbral_config}_{timestamp}.json\"\n",
        "    Utils.guardar_json(resultados, str(archivo))\n",
        "\n",
        "    procesador.mostrar_resumen(resultados)\n",
        "    detector.limpiar()\n",
        "\n",
        "    return str(archivo)\n",
        "\n",
        "def probar_imagen_individual(ruta_imagen: str, mostrar_detalles: bool = True):\n",
        "    \"\"\"\n",
        "    FUNCI√ìN EJECUTABLE: Probar una imagen espec√≠fica\n",
        "\n",
        "    Args:\n",
        "        ruta_imagen: Ruta completa a la imagen\n",
        "        mostrar_detalles: Si mostrar informaci√≥n detallada\n",
        "    \"\"\"\n",
        "    print(f\"PRUEBA INDIVIDUAL: {os.path.basename(ruta_imagen)}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if not os.path.exists(ruta_imagen):\n",
        "        print(f\"Imagen no encontrada: {ruta_imagen}\")\n",
        "        return\n",
        "\n",
        "    # Usar modelo m√°s potente y umbrales ultra sensibles\n",
        "    detector = DetectorPersonas(config.MODELOS[0])  # El m√°s grande\n",
        "    procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "    resultado = procesador.procesar_imagen(ruta_imagen, detector, config.UMBRALES['ultra'])\n",
        "\n",
        "    if not resultado.get('exitoso', False):\n",
        "        print(f\"Error: {resultado.get('error')}\")\n",
        "        detector.limpiar()\n",
        "        return\n",
        "\n",
        "    # Mostrar resultados\n",
        "    deteccion = resultado['deteccion']\n",
        "    imagen_info = resultado['imagen']\n",
        "\n",
        "    print(f\"Imagen: {imagen_info['tama√±o']} pixels, brillo: {imagen_info['brillo_promedio']:.1f}\")\n",
        "    print(f\"Tiempo: {deteccion['tiempo_inferencia_ms']:.1f}ms\")\n",
        "    print()\n",
        "\n",
        "    # Resultados por umbral\n",
        "    print(\"DETECCIONES POR UMBRAL:\")\n",
        "    for umbral in config.UMBRALES['ultra']:\n",
        "        datos = deteccion.get(f'umbral_{umbral}', {})\n",
        "        if 'error' in datos:\n",
        "            print(f\"  {umbral:6.3f}: Error - {datos['error']}\")\n",
        "            continue\n",
        "\n",
        "        personas = datos.get('personas', 0)\n",
        "        total = datos.get('total', 0)\n",
        "        max_score = datos.get('max_score', 0)\n",
        "\n",
        "        print(f\"  {umbral:6.3f}: {personas:2d} personas de {total:2d} total (max score: {max_score:.4f})\")\n",
        "\n",
        "        if mostrar_detalles and datos.get('todas_clases'):\n",
        "            clases_unicas = sorted(set(datos['todas_clases']))\n",
        "            print(f\"             Clases: {clases_unicas}\")\n",
        "\n",
        "    # Recomendaci√≥n\n",
        "    mejor_umbral_data = deteccion.get('umbral_0.01', deteccion.get('umbral_0.001', {}))\n",
        "    personas_detectadas = mejor_umbral_data.get('personas', 0)\n",
        "\n",
        "    print(f\"\\nRESULTADO: {personas_detectadas} personas detectadas\")\n",
        "    if personas_detectadas == 0:\n",
        "        total_detecciones = mejor_umbral_data.get('total', 0)\n",
        "        if total_detecciones > 0:\n",
        "            print(\" Se detectaron otros objetos pero no personas\")\n",
        "            print(\"   Posibles soluciones:\")\n",
        "            print(\"   - Usar umbrales a√∫n m√°s bajos\")\n",
        "            print(\"   - Verificar que la imagen contenga personas visibles\")\n",
        "            print(\"   - Probar con otro modelo\")\n",
        "        else:\n",
        "            print(\" No se detect√≥ ning√∫n objeto\")\n",
        "\n",
        "    detector.limpiar()\n",
        "    return resultado\n",
        "\n",
        "def comparar_modelos_rapido(max_imagenes: int = 3):\n",
        "    \"\"\"\n",
        "    FUNCI√ìN EJECUTABLE: Comparaci√≥n r√°pida de modelos\n",
        "\n",
        "    Args:\n",
        "        max_imagenes: N√∫mero m√°ximo de im√°genes a procesar\n",
        "    \"\"\"\n",
        "    print(f\"‚öñÔ∏è COMPARACI√ìN R√ÅPIDA - {max_imagenes} im√°genes m√°ximo\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    imagenes = Utils.cargar_imagenes(config.DATASET_PATH)[:max_imagenes]\n",
        "    if not imagenes:\n",
        "        print(\"No hay im√°genes\")\n",
        "        return\n",
        "\n",
        "    umbrales = config.UMBRALES['agresivo']\n",
        "    resultados_comparacion = {}\n",
        "\n",
        "    for i, modelo in enumerate(config.MODELOS):\n",
        "        print(f\"\\nModelo {i+1}/{len(config.MODELOS)}: {modelo.split('/')[-1]}\")\n",
        "\n",
        "        detector = DetectorPersonas(modelo)\n",
        "        procesador = ProcesadorResultados(config.OUTPUT_PATH)\n",
        "\n",
        "        resultados_modelo = []\n",
        "        for ruta in imagenes:\n",
        "            resultado = procesador.procesar_imagen(ruta, detector, umbrales)\n",
        "            resultados_modelo.append(resultado)\n",
        "\n",
        "        # Estad√≠sticas r√°pidas\n",
        "        exitosos = sum(1 for r in resultados_modelo if r.get('exitoso', False))\n",
        "\n",
        "        personas_totales = 0\n",
        "        tiempo_promedio = 0\n",
        "\n",
        "        for resultado in resultados_modelo:\n",
        "            if resultado.get('exitoso', False):\n",
        "                # Usar umbral m√°s sensible para contar\n",
        "                deteccion = resultado['deteccion']\n",
        "                umbral_data = deteccion.get('umbral_0.01', deteccion.get('umbral_0.05', {}))\n",
        "                personas_totales += umbral_data.get('personas', 0)\n",
        "                tiempo_promedio += resultado.get('tiempo_total_ms', 0)\n",
        "\n",
        "        if exitosos > 0:\n",
        "            tiempo_promedio /= exitosos\n",
        "\n",
        "        resultados_comparacion[modelo] = {\n",
        "            'exitosos': exitosos,\n",
        "            'personas_totales': personas_totales,\n",
        "            'tiempo_promedio_ms': tiempo_promedio\n",
        "        }\n",
        "\n",
        "        print(f\" {exitosos}/{len(imagenes)} exitosas\")\n",
        "        print(f\" {personas_totales} personas detectadas\")\n",
        "        print(f\" {tiempo_promedio:.1f}ms promedio\")\n",
        "\n",
        "        detector.limpiar()\n",
        "\n",
        "    # Resumen final\n",
        "    print(f\"\\nRESUMEN COMPARACI√ìN:\")\n",
        "    print(\"-\" * 40)\n",
        "    for modelo, datos in resultados_comparacion.items():\n",
        "        nombre = modelo.split('/')[-1]\n",
        "        print(f\"{nombre:30s}: {datos['personas_totales']:2d} personas, {datos['tiempo_promedio_ms']:5.1f}ms\")\n",
        "\n",
        "    return resultados_comparacion\n",
        "\n",
        "print(\"Funciones ejecutables definidas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFGSs_jRmurU",
        "outputId": "52a86de9-cd50-4958-a556-d31b02f17c3a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funciones ejecutables definidas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Ejecutamos evaluaci√≥n b√°sica.\n",
        "\n",
        "for i in range(len(config.MODELOS)):\n",
        "    for umbral in config.UMBRALES.keys():\n",
        "        ejecutar_evaluacion_basica(i, umbral)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GaIHsaRnZvg",
        "outputId": "9cd683df-6e72-496b-d1f8-da7f76369c63"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUACI√ìN B√ÅSICA - Modelo 0, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-large-coco-instance\n",
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_conservador_20250901_191543.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 0, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_normal_20250901_191545.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 0, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_agresivo_20250901_191547.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 0, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-large-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_0_ultra_20250901_191549.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 1, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_conservador_20250901_191551.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 1, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_normal_20250901_191552.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 1, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_agresivo_20250901_191554.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 1, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-base-ade-semantic\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_1_ultra_20250901_191556.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 2, Umbrales: conservador\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_conservador_20250901_191558.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 2, Umbrales: normal\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_normal_20250901_191600.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 2, Umbrales: agresivo\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_agresivo_20250901_191601.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n",
            "EVALUACI√ìN B√ÅSICA - Modelo 2, Umbrales: ultra\n",
            "============================================================\n",
            "Encontradas 1 im√°genes\n",
            "ü§ñ Cargando: facebook/mask2former-swin-small-coco-instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado en cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1/1] _DSC0147.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 personas de 0 detecciones\n",
            "Guardado: /content/drive/MyDrive/TFM/mask2former/resultados/evaluacion_2_ultra_20250901_191603.json\n",
            "\n",
            "RESUMEN: 1/1 im√°genes procesadas\n",
            "  Umbral 0.010: 0 personas en 0 im√°genes\n",
            "  Umbral 0.050: 0 personas en 0 im√°genes\n",
            "  Umbral 0.100: 0 personas en 0 im√°genes\n",
            "  Umbral 0.300: 0 personas en 0 im√°genes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9_3TOySQqE39"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}