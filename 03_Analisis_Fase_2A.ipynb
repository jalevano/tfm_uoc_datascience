{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjeumVhKF+HCX4B73xUajA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "SQIa4Dfp3GqH",
        "outputId": "7d9482cb-14c1-4deb-b19e-db02ca777e39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nFASE 2A - EVALUACIÓN CUANTITATIVA Y ANÁLISIS GEOMÉTRICO\\n================================================================================\\nTrabajo Fin de Máster: Evaluación Comparativa de Técnicas de Segmentación\\nen Fotografía de Retrato\\n\\nAutor: Jesús Lévano Lévano\\nUniversidad: Universidad Oberta de Catalunya (UOC)\\nTutor: Miguel Alejandro Ponce Proaño\\nFecha: Noviembre 2025\\n\\nDESCRIPCIÓN:\\nFase 2A del análisis comparativo de modelos de segmentación. Calcula métricas\\ncuantitativas exhaustivas comparando máscaras predichas por 5 modelos contra\\nground truth anotado manualmente, con análisis geométrico avanzado usando\\nShapely y análisis textural usando Mahotas.\\n\\nDEPENDENCIAS DE DATOS:\\n- Requiere Fase 1 completada (índice maestro + configuraciones)\\n- Utiliza máscaras NPZ de modelos en ubicaciones originales\\n- Utiliza ground truth desde anotaciones CVAT\\n- Utiliza características fotográficas del Notebook 00\\n\\nMODELOS EVALUADOS:\\n1. Mask2Former (Swin-Large/Tiny, ADE20K/COCO) - 19 configuraciones\\n2. OneFormer (task-conditioned) - 36 configuraciones\\n3. SAM 2.0 (con/sin prompts) - 44 configuraciones\\n4. YOLOv8-seg (nano a xlarge) - 20 configuraciones\\n5. BodyPix (MobileNetV1) - 8 configuraciones\\nTotal: 127 configuraciones únicas\\n\\nDATASET:\\n- 20 fotografías de retrato manualmente anotadas\\n- Resoluciones variables (típicamente 6016×4016 px)\\n- Ground truth binario en formato NPZ\\n- Total evaluaciones: 20 fotos × 127 configs = 2,540 combinaciones\\n\\nMÉTRICAS CALCULADAS:\\n\\nA. Métricas Clásicas de Segmentación (5 métricas):\\n   - IoU (Intersection over Union) - Métrica estándar\\n   - Dice Coefficient - Solapamiento normalizado\\n   - Precision - Tasa de verdaderos positivos\\n   - Recall - Cobertura del ground truth\\n   - F1-Score - Media armónica precision-recall\\n\\nB. Métricas Geométricas con Shapely (25 métricas):\\n   \\n   B1. Geometría Básica:\\n       - Área (pixels)\\n       - Perímetro (pixels)\\n       - Bounding box (xmin, ymin, xmax, ymax)\\n       - Centroide (x, y)\\n       - Aspect ratio (ancho/alto)\\n       - Orientación (grados)\\n   \\n   B2. Forma Avanzada:\\n       - Convex hull (envolvente convexa)\\n       - Solidity (área / área_convex_hull)\\n       - Compacidad (4π×área / perímetro²)\\n       - Circularity\\n       - Elongation (ratio ejes)\\n       - Rectangularity (área / área_bbox)\\n   \\n   B3. Contorno:\\n       - Boundary IoU (solo bordes)\\n       - Hausdorff Distance (error máximo)\\n       - Chamfer Distance (error promedio)\\n       - Smoothness (varianza curvatura)\\n       - Número de vértices\\n   \\n   B4. Posición Compositiva:\\n       - Distancia a centro imagen\\n       - Zona regla de tercios (1-9)\\n       - Recortes por bordes (%)\\n       - Espacio negativo\\n   \\n   B5. Fragmentación:\\n       - Número componentes desconectadas\\n       - Área componente principal\\n       - Ratio fragmentación\\n   \\n   B6. Comparación vs Ground Truth:\\n       - Desplazamiento centroide (Euclidean)\\n       - Diferencia orientación (grados)\\n       - Ratio solidity (pred/GT)\\n       - Diferencia compacidad\\n       - Symmetric difference area\\n\\nC. Métricas Texturales con Mahotas (30 métricas):\\n   \\n   C1. Texturas Haralick - Región Interior (13 features):\\n       - Angular Second Moment\\n       - Contrast\\n       - Correlation\\n       - Sum of Squares Variance\\n       - Inverse Difference Moment\\n       - Sum Average\\n       - Sum Variance\\n       - Sum Entropy\\n       - Entropy\\n       - Difference Variance\\n       - Difference Entropy\\n       - Information Measure Correlation 1\\n       - Information Measure Correlation 2\\n   \\n   C2. Texturas Haralick - Región Borde (13 features):\\n       - Mismas features calculadas en borde de 5px\\n       - Evalúa calidad de separación persona-fondo\\n   \\n   C3. Estadísticas Básicas (4 métricas):\\n       - Media, std, min, max de intensidad\\n\\nTOTAL MÉTRICAS POR CONFIGURACIÓN: ~60 métricas\\n\\nPROCESAMIENTO:\\n- Incremental con sistema de checkpoint resumible\\n- Guardado automático después de cada fotografía procesada\\n- Gestión optimizada de memoria para Google Colab free tier\\n- Manejo robusto de configuraciones faltantes\\n- Logging detallado para trazabilidad\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/3_Analisis/fase2_evaluacion/\\n├── metricas_individuales/\\n│   ├── _DSC0036_metricas_completas.json\\n│   ├── _DSC0592_metricas_completas.json\\n│   └── ... (20 archivos JSON)\\n│\\n├── metricas_agregadas/\\n│   ├── todas_metricas.csv                  # Tabla plana: 2540 filas × ~65 columnas\\n│   ├── ranking_configuraciones.csv         # TOP-10 configs ordenadas por IoU\\n│   ├── estadisticas_por_modelo.json        # Media, std, min, max por modelo\\n│   ├── configuraciones_omitidas.json       # Registro de omisiones\\n│   └── datos_visualizaciones.json          # Datos pre-formateados para plots\\n│\\n├── checkpoint_fase2a.json                  # Estado de procesamiento\\n└── INFORME_FASE2A.md                       # Documento narrativo académico\\n\\nREFERENCIAS METODOLÓGICAS:\\n- Lin, T.Y., et al. (2014). Microsoft COCO: Common Objects in Context\\n- Kirillov, A., et al. (2023). Segment Anything\\n- Shapely Documentation (2024). Geometric Operations\\n- Haralick, R.M., et al. (1973). Textural Features for Image Classification\\n- Gonzalez, R.C. & Woods, R.E. (2018). Digital Image Processing (4th ed.)\\n\\nCOMPATIBILIDAD:\\n- Google Colab Free Tier\\n- Python 3.10+\\n- Requiere: numpy, pandas, opencv-python, shapely, mahotas, Pillow, scikit-image\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2A - EVALUACIÓN CUANTITATIVA Y ANÁLISIS GEOMÉTRICO\n",
        "================================================================================\n",
        "Trabajo Fin de Máster: Evaluación Comparativa de Técnicas de Segmentación\n",
        "en Fotografía de Retrato\n",
        "\n",
        "Autor: Jesús Lévano Lévano\n",
        "Universidad: Universidad Oberta de Catalunya (UOC)\n",
        "Tutor: Miguel Alejandro Ponce Proaño\n",
        "Fecha: Noviembre 2025\n",
        "\n",
        "DESCRIPCIÓN:\n",
        "Fase 2A del análisis comparativo de modelos de segmentación. Calcula métricas\n",
        "cuantitativas exhaustivas comparando máscaras predichas por 5 modelos contra\n",
        "ground truth anotado manualmente, con análisis geométrico avanzado usando\n",
        "Shapely y análisis textural usando Mahotas.\n",
        "\n",
        "DEPENDENCIAS DE DATOS:\n",
        "- Requiere Fase 1 completada (índice maestro + configuraciones)\n",
        "- Utiliza máscaras NPZ de modelos en ubicaciones originales\n",
        "- Utiliza ground truth desde anotaciones CVAT\n",
        "- Utiliza características fotográficas del Notebook 00\n",
        "\n",
        "MODELOS EVALUADOS:\n",
        "1. Mask2Former (Swin-Large/Tiny, ADE20K/COCO) - 19 configuraciones\n",
        "2. OneFormer (task-conditioned) - 36 configuraciones\n",
        "3. SAM 2.0 (con/sin prompts) - 44 configuraciones\n",
        "4. YOLOv8-seg (nano a xlarge) - 20 configuraciones\n",
        "5. BodyPix (MobileNetV1) - 8 configuraciones\n",
        "Total: 127 configuraciones únicas\n",
        "\n",
        "DATASET:\n",
        "- 20 fotografías de retrato manualmente anotadas\n",
        "- Resoluciones variables (típicamente 6016×4016 px)\n",
        "- Ground truth binario en formato NPZ\n",
        "- Total evaluaciones: 20 fotos × 127 configs = 2,540 combinaciones\n",
        "\n",
        "MÉTRICAS CALCULADAS:\n",
        "\n",
        "A. Métricas Clásicas de Segmentación (5 métricas):\n",
        "   - IoU (Intersection over Union) - Métrica estándar\n",
        "   - Dice Coefficient - Solapamiento normalizado\n",
        "   - Precision - Tasa de verdaderos positivos\n",
        "   - Recall - Cobertura del ground truth\n",
        "   - F1-Score - Media armónica precision-recall\n",
        "\n",
        "B. Métricas Geométricas con Shapely (25 métricas):\n",
        "\n",
        "   B1. Geometría Básica:\n",
        "       - Área (pixels)\n",
        "       - Perímetro (pixels)\n",
        "       - Bounding box (xmin, ymin, xmax, ymax)\n",
        "       - Centroide (x, y)\n",
        "       - Aspect ratio (ancho/alto)\n",
        "       - Orientación (grados)\n",
        "\n",
        "   B2. Forma Avanzada:\n",
        "       - Convex hull (envolvente convexa)\n",
        "       - Solidity (área / área_convex_hull)\n",
        "       - Compacidad (4π×área / perímetro²)\n",
        "       - Circularity\n",
        "       - Elongation (ratio ejes)\n",
        "       - Rectangularity (área / área_bbox)\n",
        "\n",
        "   B3. Contorno:\n",
        "       - Boundary IoU (solo bordes)\n",
        "       - Hausdorff Distance (error máximo)\n",
        "       - Chamfer Distance (error promedio)\n",
        "       - Smoothness (varianza curvatura)\n",
        "       - Número de vértices\n",
        "\n",
        "   B4. Posición Compositiva:\n",
        "       - Distancia a centro imagen\n",
        "       - Zona regla de tercios (1-9)\n",
        "       - Recortes por bordes (%)\n",
        "       - Espacio negativo\n",
        "\n",
        "   B5. Fragmentación:\n",
        "       - Número componentes desconectadas\n",
        "       - Área componente principal\n",
        "       - Ratio fragmentación\n",
        "\n",
        "   B6. Comparación vs Ground Truth:\n",
        "       - Desplazamiento centroide (Euclidean)\n",
        "       - Diferencia orientación (grados)\n",
        "       - Ratio solidity (pred/GT)\n",
        "       - Diferencia compacidad\n",
        "       - Symmetric difference area\n",
        "\n",
        "C. Métricas Texturales con Mahotas (30 métricas):\n",
        "\n",
        "   C1. Texturas Haralick - Región Interior (13 features):\n",
        "       - Angular Second Moment\n",
        "       - Contrast\n",
        "       - Correlation\n",
        "       - Sum of Squares Variance\n",
        "       - Inverse Difference Moment\n",
        "       - Sum Average\n",
        "       - Sum Variance\n",
        "       - Sum Entropy\n",
        "       - Entropy\n",
        "       - Difference Variance\n",
        "       - Difference Entropy\n",
        "       - Information Measure Correlation 1\n",
        "       - Information Measure Correlation 2\n",
        "\n",
        "   C2. Texturas Haralick - Región Borde (13 features):\n",
        "       - Mismas features calculadas en borde de 5px\n",
        "       - Evalúa calidad de separación persona-fondo\n",
        "\n",
        "   C3. Estadísticas Básicas (4 métricas):\n",
        "       - Media, std, min, max de intensidad\n",
        "\n",
        "TOTAL MÉTRICAS POR CONFIGURACIÓN: ~60 métricas\n",
        "\n",
        "PROCESAMIENTO:\n",
        "- Incremental con sistema de checkpoint resumible\n",
        "- Guardado automático después de cada fotografía procesada\n",
        "- Gestión optimizada de memoria para Google Colab free tier\n",
        "- Manejo robusto de configuraciones faltantes\n",
        "- Logging detallado para trazabilidad\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/3_Analisis/fase2_evaluacion/\n",
        "├── metricas_individuales/\n",
        "│   ├── _DSC0036_metricas_completas.json\n",
        "│   ├── _DSC0592_metricas_completas.json\n",
        "│   └── ... (20 archivos JSON)\n",
        "│\n",
        "├── metricas_agregadas/\n",
        "│   ├── todas_metricas.csv                  # Tabla plana: 2540 filas × ~65 columnas\n",
        "│   ├── ranking_configuraciones.csv         # TOP-10 configs ordenadas por IoU\n",
        "│   ├── estadisticas_por_modelo.json        # Media, std, min, max por modelo\n",
        "│   ├── configuraciones_omitidas.json       # Registro de omisiones\n",
        "│   └── datos_visualizaciones.json          # Datos pre-formateados para plots\n",
        "│\n",
        "├── checkpoint_fase2a.json                  # Estado de procesamiento\n",
        "└── INFORME_FASE2A.md                       # Documento narrativo académico\n",
        "\n",
        "REFERENCIAS METODOLÓGICAS:\n",
        "- Lin, T.Y., et al. (2014). Microsoft COCO: Common Objects in Context\n",
        "- Kirillov, A., et al. (2023). Segment Anything\n",
        "- Shapely Documentation (2024). Geometric Operations\n",
        "- Haralick, R.M., et al. (1973). Textural Features for Image Classification\n",
        "- Gonzalez, R.C. & Woods, R.E. (2018). Digital Image Processing (4th ed.)\n",
        "\n",
        "COMPATIBILIDAD:\n",
        "- Google Colab Free Tier\n",
        "- Python 3.10+\n",
        "- Requiere: numpy, pandas, opencv-python, shapely, mahotas, Pillow, scikit-image\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q shapely mahotas scikit-image"
      ],
      "metadata": {
        "id": "sRofP5deEaa4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQVbP_dlISz9",
        "outputId": "73c42e12-37f9-4cca-aeb6-ec93954e287b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIÓN DE LIBRERÍAS\n",
        "# =============================================================================\n",
        "\n",
        "# Librerías estándar de Python\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple, Any, Set\n",
        "\n",
        "# Librerías de procesamiento numérico y datos\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Librerías de procesamiento de imágenes\n",
        "import cv2\n",
        "import mahotas\n",
        "from PIL import Image\n",
        "from scipy.ndimage import distance_transform_edt\n",
        "from scipy.spatial.distance import directed_hausdorff\n",
        "from skimage import measure\n",
        "\n",
        "# Shapely para análisis geométrico\n",
        "from shapely.geometry import Polygon, MultiPolygon, Point\n",
        "from shapely.validation import make_valid"
      ],
      "metadata": {
        "id": "U5WCqXLBEVqD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DEFINICIÓN DE ESTRUCTURAS DE DATOS\n",
        "# =============================================================================\n",
        "\n",
        "class NivelLogging(Enum):\n",
        "    \"\"\"\n",
        "    Enumeración de niveles de logging para control de verbosidad.\n",
        "\n",
        "    Niveles:\n",
        "    - MINIMAL: Solo resumen por fotografía\n",
        "    - NORMAL: Progreso con detalle moderado (recomendado)\n",
        "    - DETAILED: Información detallada por configuración\n",
        "    - DEBUG: Máximo detalle para debugging\n",
        "    \"\"\"\n",
        "    MINIMAL = \"minimal\"\n",
        "    NORMAL = \"normal\"\n",
        "    DETAILED = \"detailed\"\n",
        "    DEBUG = \"debug\""
      ],
      "metadata": {
        "id": "3ku_C7RyElnQ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ConfiguracionFase2A:\n",
        "    \"\"\"\n",
        "    Dataclass para configuración global de Fase 2A.\n",
        "\n",
        "    Attributes:\n",
        "        ruta_base_tfm: Directorio raíz del proyecto TFM\n",
        "        max_dimension_mahotas: Redimensión para Mahotas (optimización)\n",
        "        ancho_borde_px: Ancho del borde para análisis textural\n",
        "        usar_checkpoint: Habilita sistema de checkpoint resumible\n",
        "        guardar_json_individuales: Guardar JSON por fotografía\n",
        "        guardar_csv_consolidado: Guardar CSV con todas las métricas\n",
        "        guardar_estadisticas: Calcular estadísticas por modelo\n",
        "        nivel_logging: Nivel de verbosidad del logging\n",
        "    \"\"\"\n",
        "    ruta_base_tfm: Path\n",
        "    max_dimension_mahotas: int = 1024\n",
        "    ancho_borde_px: int = 5\n",
        "    usar_checkpoint: bool = True\n",
        "    guardar_json_individuales: bool = True\n",
        "    guardar_csv_consolidado: bool = True\n",
        "    guardar_estadisticas: bool = True\n",
        "    nivel_logging: NivelLogging = NivelLogging.NORMAL\n",
        "\n",
        "    @property\n",
        "    def ruta_fase1(self) -> Path:\n",
        "        \"\"\"Ruta al directorio de resultados de Fase 1.\"\"\"\n",
        "        return self.ruta_base_tfm / \"3_Analisis\" / \"fase1_integracion\"\n",
        "\n",
        "    @property\n",
        "    def ruta_salida(self) -> Path:\n",
        "        \"\"\"Ruta al directorio de salida de Fase 2A.\"\"\"\n",
        "        return self.ruta_base_tfm / \"3_Analisis\" / \"fase2_evaluacion\"\n",
        "\n",
        "    @property\n",
        "    def ruta_ground_truth(self) -> Path:\n",
        "        \"\"\"Ruta al directorio de ground truth.\"\"\"\n",
        "        return self.ruta_base_tfm / \"0_Imagenes_CVAT\" / \"ground_truth_masks\"\n",
        "\n",
        "    @property\n",
        "    def ruta_caracteristicas(self) -> Path:\n",
        "        \"\"\"Ruta al directorio de características fotográficas.\"\"\"\n",
        "        return self.ruta_base_tfm / \"1_Caracteristicas\" / \"json\"\n",
        "\n",
        "    def crear_directorios(self) -> None:\n",
        "        \"\"\"Crea la estructura de directorios de salida.\"\"\"\n",
        "        (self.ruta_salida / \"metricas_individuales\").mkdir(parents=True, exist_ok=True)\n",
        "        (self.ruta_salida / \"metricas_agregadas\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CheckpointFase2A:\n",
        "    \"\"\"\n",
        "    Dataclass para gestión de checkpoint de procesamiento.\n",
        "\n",
        "    Permite reanudar el procesamiento desde el punto de interrupción,\n",
        "    evitando reprocesar fotografías ya completadas.\n",
        "\n",
        "    Attributes:\n",
        "        fotos_procesadas: Conjunto de códigos de fotografías completadas\n",
        "        fotos_pendientes: Lista de códigos de fotografías por procesar\n",
        "        configuraciones_totales: Número total de configuraciones\n",
        "        ultima_actualizacion: Timestamp de última actualización\n",
        "    \"\"\"\n",
        "    fotos_procesadas: Set[str] = field(default_factory=set)\n",
        "    fotos_pendientes: List[str] = field(default_factory=list)\n",
        "    configuraciones_totales: int = 0\n",
        "    ultima_actualizacion: Optional[str] = None\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        \"\"\"Serializa checkpoint a diccionario JSON-compatible.\"\"\"\n",
        "        return {\n",
        "            \"fotos_procesadas\": list(self.fotos_procesadas),\n",
        "            \"fotos_pendientes\": self.fotos_pendientes,\n",
        "            \"configuraciones_totales\": self.configuraciones_totales,\n",
        "            \"ultima_actualizacion\": self.ultima_actualizacion\n",
        "        }\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, data: Dict[str, Any]) -> 'CheckpointFase2A':\n",
        "        \"\"\"Reconstruye checkpoint desde diccionario.\"\"\"\n",
        "        return cls(\n",
        "            fotos_procesadas=set(data.get(\"fotos_procesadas\", [])),\n",
        "            fotos_pendientes=data.get(\"fotos_pendientes\", []),\n",
        "            configuraciones_totales=data.get(\"configuraciones_totales\", 0),\n",
        "            ultima_actualizacion=data.get(\"ultima_actualizacion\")\n",
        "        )"
      ],
      "metadata": {
        "id": "IwQ-zxneEmnZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIONES AUXILIARES\n",
        "# =============================================================================\n",
        "\n",
        "def configurar_logging(nivel: NivelLogging, nombre_modulo: str = \"Fase2A\") -> logging.Logger:\n",
        "    \"\"\"\n",
        "    Configuración del sistema de logging con formato académico.\n",
        "\n",
        "    Args:\n",
        "        nivel: Nivel de logging deseado\n",
        "        nombre_modulo: Nombre del módulo para identificación\n",
        "\n",
        "    Returns:\n",
        "        Logger configurado\n",
        "    \"\"\"\n",
        "    logger = logging.getLogger(nombre_modulo)\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    if logger.handlers:\n",
        "        logger.handlers.clear()\n",
        "\n",
        "    handler = logging.StreamHandler(sys.stdout)\n",
        "\n",
        "    if nivel == NivelLogging.MINIMAL:\n",
        "        handler.setLevel(logging.WARNING)\n",
        "    elif nivel == NivelLogging.NORMAL:\n",
        "        handler.setLevel(logging.INFO)\n",
        "    elif nivel == NivelLogging.DETAILED:\n",
        "        handler.setLevel(logging.INFO)\n",
        "    else:\n",
        "        handler.setLevel(logging.DEBUG)\n",
        "\n",
        "    formatter = logging.Formatter(\n",
        "        fmt='[%(asctime)s] %(levelname)-8s | %(message)s',\n",
        "        datefmt='%H:%M:%S'\n",
        "    )\n",
        "\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "\n",
        "def guardar_json_seguro(datos: Any, ruta_archivo: Path, logger: logging.Logger) -> bool:\n",
        "    \"\"\"\n",
        "    Guarda datos en formato JSON con manejo robusto de errores.\n",
        "\n",
        "    Incluye conversión automática de tipos NumPy y sets a formatos JSON-compatibles.\n",
        "\n",
        "    Args:\n",
        "        datos: Datos a serializar\n",
        "        ruta_archivo: Path donde guardar el JSON\n",
        "        logger: Logger para registrar operaciones\n",
        "\n",
        "    Returns:\n",
        "        True si guardado exitoso, False en caso contrario\n",
        "    \"\"\"\n",
        "    try:\n",
        "        class NumpyEncoder(json.JSONEncoder):\n",
        "            \"\"\"Encoder personalizado para tipos NumPy y estructuras complejas.\"\"\"\n",
        "            def default(self, obj):\n",
        "                if isinstance(obj, np.integer):\n",
        "                    return int(obj)\n",
        "                if isinstance(obj, np.floating):\n",
        "                    return float(obj)\n",
        "                if isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                if isinstance(obj, set):\n",
        "                    return list(obj)\n",
        "                if isinstance(obj, Path):\n",
        "                    return str(obj)\n",
        "                return super().default(obj)\n",
        "\n",
        "        ruta_archivo.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False, cls=NumpyEncoder)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error guardando JSON en {ruta_archivo}: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def cargar_mascara_npz(ruta_npz: Path, umbral: Optional[float] = None, logger: Optional[logging.Logger] = None) -> Optional[np.ndarray]:\n",
        "    \"\"\"\n",
        "    Carga máscara desde archivo NPZ con manejo de múltiples estructuras.\n",
        "\n",
        "    Soporta tres estructuras:\n",
        "    1. Unificada: clave 'person_mask' (SAM, Mask2Former, OneFormer, YOLO)\n",
        "    2. Por umbral: claves 'mask_X.XX' (BodyPix)\n",
        "    3. Ground Truth CVAT: clave 'masks' con array 3D [1, H, W]\n",
        "\n",
        "    Args:\n",
        "        ruta_npz: Path al archivo NPZ\n",
        "        umbral: Umbral específico para modelos por-umbral (ej: 0.50)\n",
        "        logger: Logger para debugging\n",
        "\n",
        "    Returns:\n",
        "        Array booleano 2D con la máscara, o None si error\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si el archivo no existe\n",
        "        ValueError: Si estructura NPZ inválida o clave faltante\n",
        "    \"\"\"\n",
        "    if not ruta_npz.exists():\n",
        "        if logger:\n",
        "            logger.warning(f\"Archivo NPZ no encontrado: {ruta_npz}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        with np.load(ruta_npz, allow_pickle=False) as data:\n",
        "            claves_disponibles = list(data.keys())\n",
        "\n",
        "            if logger:\n",
        "                logger.debug(f\"Claves en NPZ: {claves_disponibles}\")\n",
        "\n",
        "            # Caso 1: Estructura unificada (modelos)\n",
        "            if 'person_mask' in claves_disponibles:\n",
        "                mascara = data['person_mask']\n",
        "\n",
        "                if logger:\n",
        "                    logger.debug(f\"Cargada máscara unificada, shape: {mascara.shape}\")\n",
        "\n",
        "            # Caso 2: Ground Truth CVAT (estructura con 'masks')\n",
        "            elif 'masks' in claves_disponibles:\n",
        "                mascara = data['masks']\n",
        "\n",
        "                if logger:\n",
        "                    logger.debug(f\"Cargada máscara Ground Truth CVAT, shape: {mascara.shape}\")\n",
        "\n",
        "                # El ground truth de CVAT suele venir como [1, H, W] o [H, W]\n",
        "                if mascara.ndim == 3:\n",
        "                    # Tomar el primer canal\n",
        "                    mascara = mascara[0]\n",
        "                    if logger:\n",
        "                        logger.debug(f\"Reducida dimensión: {mascara.shape}\")\n",
        "\n",
        "            # Caso 3: Estructura por-umbral (BodyPix)\n",
        "            else:\n",
        "                claves_mascara = [k for k in claves_disponibles if k.startswith('mask_')]\n",
        "\n",
        "                if not claves_mascara:\n",
        "                    if logger:\n",
        "                        logger.error(f\"No se encontró 'person_mask', 'masks' ni 'mask_X.XX' en {ruta_npz}\")\n",
        "                    return None\n",
        "\n",
        "                if umbral is not None:\n",
        "                    clave_objetivo = f\"mask_{umbral:.2f}\"\n",
        "\n",
        "                    if clave_objetivo not in claves_disponibles:\n",
        "                        if logger:\n",
        "                            logger.warning(f\"Umbral {umbral:.2f} no encontrado. Disponibles: {claves_mascara}\")\n",
        "                        return None\n",
        "\n",
        "                    mascara = data[clave_objetivo]\n",
        "\n",
        "                    if logger:\n",
        "                        logger.debug(f\"Cargada máscara por umbral {clave_objetivo}, shape: {mascara.shape}\")\n",
        "\n",
        "                else:\n",
        "                    if logger:\n",
        "                        logger.error(f\"Estructura por-umbral requiere especificar 'umbral'. Disponibles: {claves_mascara}\")\n",
        "                    return None\n",
        "\n",
        "            # Validación de dimensiones\n",
        "            if mascara.ndim != 2:\n",
        "                if logger:\n",
        "                    logger.error(f\"Máscara con dimensiones inválidas: {mascara.shape}\")\n",
        "                return None\n",
        "\n",
        "            mascara_bool = mascara.astype(bool)\n",
        "\n",
        "            return mascara_bool\n",
        "\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error cargando NPZ {ruta_npz}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def mascara_a_shapely(mascara: np.ndarray, logger: Optional[logging.Logger] = None) -> Optional[Polygon | MultiPolygon]:\n",
        "    \"\"\"\n",
        "    Convierte máscara binaria a polígonos Shapely.\n",
        "\n",
        "    Utiliza find_contours de scikit-image para detectar contornos y los\n",
        "    convierte en geometrías Shapely válidas. Maneja múltiples componentes\n",
        "    desconectadas y aplica validación geométrica.\n",
        "\n",
        "    Args:\n",
        "        mascara: Array 2D booleano con la máscara\n",
        "        logger: Logger opcional para debugging\n",
        "\n",
        "    Returns:\n",
        "        Polygon o MultiPolygon válido, o None si error\n",
        "\n",
        "    Notes:\n",
        "        - Invierte coordenadas Y debido a convención imagen vs Shapely\n",
        "        - Filtra polígonos con menos de 3 vértices\n",
        "        - Aplica make_valid() para corregir auto-intersecciones\n",
        "        - Une polígonos múltiples usando unary_union para evitar errores\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Asegurar que la máscara es binaria\n",
        "        mascara_binaria = mascara.astype(np.uint8)\n",
        "\n",
        "        # Encontrar contornos\n",
        "        contornos = measure.find_contours(mascara_binaria, level=0.5)\n",
        "\n",
        "        if len(contornos) == 0:\n",
        "            if logger:\n",
        "                logger.debug(\"No se encontraron contornos en la máscara\")\n",
        "            return None\n",
        "\n",
        "        poligonos_validos = []\n",
        "\n",
        "        for contorno in contornos:\n",
        "            # Invertir coordenadas Y (convención imagen vs Shapely)\n",
        "            coordenadas = [(x, mascara.shape[0] - y) for y, x in contorno]\n",
        "\n",
        "            # Filtrar contornos con muy pocos puntos\n",
        "            if len(coordenadas) < 3:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # Crear polígono\n",
        "                poligono = Polygon(coordenadas)\n",
        "\n",
        "                # Validar y corregir si es necesario\n",
        "                if not poligono.is_valid:\n",
        "                    poligono = make_valid(poligono)\n",
        "\n",
        "                # Verificar que sigue siendo válido después de make_valid\n",
        "                if poligono.is_valid and not poligono.is_empty:\n",
        "                    # Si make_valid devolvió un MultiPolygon, extraer polígonos individuales\n",
        "                    if isinstance(poligono, MultiPolygon):\n",
        "                        for poly in poligono.geoms:\n",
        "                            if poly.is_valid and not poly.is_empty:\n",
        "                                poligonos_validos.append(poly)\n",
        "                    else:\n",
        "                        poligonos_validos.append(poligono)\n",
        "\n",
        "            except Exception as e_poly:\n",
        "                if logger:\n",
        "                    logger.debug(f\"Error creando polígono individual: {e_poly}\")\n",
        "                continue\n",
        "\n",
        "        if len(poligonos_validos) == 0:\n",
        "            if logger:\n",
        "                logger.debug(\"No se generaron polígonos válidos\")\n",
        "            return None\n",
        "\n",
        "        # Si hay un solo polígono, retornarlo directamente\n",
        "        if len(poligonos_validos) == 1:\n",
        "            return poligonos_validos[0]\n",
        "\n",
        "        # Si hay múltiples polígonos, usar unary_union para combinarlos correctamente\n",
        "        try:\n",
        "            geometria_unida = unary_union(poligonos_validos)\n",
        "\n",
        "            # Validar el resultado final\n",
        "            if not geometria_unida.is_valid:\n",
        "                geometria_unida = make_valid(geometria_unida)\n",
        "\n",
        "            if geometria_unida.is_empty:\n",
        "                if logger:\n",
        "                    logger.warning(\"La unión de polígonos resultó vacía\")\n",
        "                return None\n",
        "\n",
        "            return geometria_unida\n",
        "\n",
        "        except Exception as e_union:\n",
        "            if logger:\n",
        "                logger.error(f\"Error en unary_union: {e_union}\")\n",
        "\n",
        "            # Fallback: retornar MultiPolygon directamente\n",
        "            try:\n",
        "                return MultiPolygon(poligonos_validos)\n",
        "            except Exception as e_mp:\n",
        "                if logger:\n",
        "                    logger.error(f\"Error creando MultiPolygon: {e_mp}\")\n",
        "                return None\n",
        "\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error convirtiendo máscara a Shapely: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "LRjKBF9wFPoP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CALCULADORAS DE MÉTRICAS\n",
        "# =============================================================================\n",
        "\n",
        "def calcular_metricas_clasicas(mascara_pred: np.ndarray, mascara_gt: np.ndarray) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula métricas clásicas de segmentación.\n",
        "\n",
        "    Métricas calculadas:\n",
        "    - IoU (Intersection over Union): |A ∩ B| / |A ∪ B|\n",
        "    - Dice Coefficient: 2|A ∩ B| / (|A| + |B|)\n",
        "    - Precision: TP / (TP + FP)\n",
        "    - Recall: TP / (TP + FN)\n",
        "    - F1-Score: 2 × (Precision × Recall) / (Precision + Recall)\n",
        "\n",
        "    Args:\n",
        "        mascara_pred: Máscara predicha (booleano 2D)\n",
        "        mascara_gt: Ground truth (booleano 2D)\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con las 5 métricas, o dict con NaN si error\n",
        "\n",
        "    References:\n",
        "        Lin et al. (2014). Microsoft COCO: Common Objects in Context\n",
        "    \"\"\"\n",
        "    try:\n",
        "        interseccion = np.logical_and(mascara_pred, mascara_gt).sum()\n",
        "        union = np.logical_or(mascara_pred, mascara_gt).sum()\n",
        "\n",
        "        tp = interseccion\n",
        "        fp = mascara_pred.sum() - interseccion\n",
        "        fn = mascara_gt.sum() - interseccion\n",
        "\n",
        "        iou = interseccion / union if union > 0 else 0.0\n",
        "\n",
        "        suma_areas = mascara_pred.sum() + mascara_gt.sum()\n",
        "        dice = (2 * interseccion) / suma_areas if suma_areas > 0 else 0.0\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "        return {\n",
        "            \"iou\": float(iou),\n",
        "            \"dice\": float(dice),\n",
        "            \"precision\": float(precision),\n",
        "            \"recall\": float(recall),\n",
        "            \"f1_score\": float(f1)\n",
        "        }\n",
        "\n",
        "    except Exception:\n",
        "        return {\n",
        "            \"iou\": np.nan,\n",
        "            \"dice\": np.nan,\n",
        "            \"precision\": np.nan,\n",
        "            \"recall\": np.nan,\n",
        "            \"f1_score\": np.nan\n",
        "        }\n",
        "\n",
        "\n",
        "def calcular_metricas_shapely(geometria: Polygon | MultiPolygon, dimensiones_imagen: Tuple[int, int], logger: Optional[logging.Logger] = None) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula métricas geométricas usando Shapely.\n",
        "\n",
        "    Métricas de forma (13):\n",
        "    - área, perímetro, centroide, bounding box\n",
        "    - aspect_ratio, orientación\n",
        "    - solidity, compacidad, circularity\n",
        "    - elongation, rectangularity\n",
        "    - num_componentes, ratio_componente_principal\n",
        "\n",
        "    Métricas compositivas (4):\n",
        "    - distancia_centro, zona_tercios\n",
        "    - recorte_bordes, espacio_negativo\n",
        "\n",
        "    Args:\n",
        "        geometria: Polygon o MultiPolygon de Shapely\n",
        "        dimensiones_imagen: Tupla (altura, ancho) de la imagen\n",
        "        logger: Logger opcional\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con ~17 métricas geométricas\n",
        "\n",
        "    Notes:\n",
        "        - Solidity: compacidad considerando concavidades\n",
        "        - Compacidad: círculo perfecto = 1.0\n",
        "        - Zona tercios: 1-9 según regla fotográfica de tercios\n",
        "    \"\"\"\n",
        "    try:\n",
        "        altura_img, ancho_img = dimensiones_imagen\n",
        "\n",
        "        # Métricas básicas\n",
        "        area = geometria.area\n",
        "        perimetro = geometria.length\n",
        "        centroide = geometria.centroid\n",
        "        bbox = geometria.bounds  # (minx, miny, maxx, maxy)\n",
        "\n",
        "        ancho_bbox = bbox[2] - bbox[0]\n",
        "        alto_bbox = bbox[3] - bbox[1]\n",
        "        aspect_ratio = ancho_bbox / alto_bbox if alto_bbox > 0 else 0.0\n",
        "\n",
        "        # Orientación\n",
        "        try:\n",
        "            coords = np.array(geometria.exterior.coords if isinstance(geometria, Polygon) else geometria.geoms[0].exterior.coords)\n",
        "            orientacion = np.arctan2(coords[-1, 1] - coords[0, 1], coords[-1, 0] - coords[0, 0]) * 180 / np.pi\n",
        "        except:\n",
        "            orientacion = 0.0\n",
        "\n",
        "        # Solidity\n",
        "        convex_hull = geometria.convex_hull\n",
        "        solidity = area / convex_hull.area if convex_hull.area > 0 else 0.0\n",
        "\n",
        "        # Compacidad\n",
        "        compacidad = (4 * np.pi * area) / (perimetro ** 2) if perimetro > 0 else 0.0\n",
        "\n",
        "        circularity = compacidad\n",
        "\n",
        "        # Elongation\n",
        "        elongation = max(ancho_bbox, alto_bbox) / min(ancho_bbox, alto_bbox) if min(ancho_bbox, alto_bbox) > 0 else 1.0\n",
        "\n",
        "        # Rectangularity\n",
        "        area_bbox = ancho_bbox * alto_bbox\n",
        "        rectangularity = area / area_bbox if area_bbox > 0 else 0.0\n",
        "\n",
        "        # Fragmentación\n",
        "        if isinstance(geometria, MultiPolygon):\n",
        "            num_componentes = len(geometria.geoms)\n",
        "            areas_componentes = [g.area for g in geometria.geoms]\n",
        "            area_principal = max(areas_componentes)\n",
        "            ratio_componente_principal = area_principal / area if area > 0 else 1.0\n",
        "        else:\n",
        "            num_componentes = 1\n",
        "            area_principal = area\n",
        "            ratio_componente_principal = 1.0\n",
        "\n",
        "        # Posición compositiva\n",
        "        centro_imagen = Point(ancho_img / 2, altura_img / 2)\n",
        "        distancia_centro = centroide.distance(centro_imagen)\n",
        "\n",
        "        # Zona de tercios\n",
        "        tercio_ancho = ancho_img / 3\n",
        "        tercio_alto = altura_img / 3\n",
        "\n",
        "        col_tercio = int(centroide.x // tercio_ancho)\n",
        "        fila_tercio = int(centroide.y // tercio_alto)\n",
        "\n",
        "        col_tercio = min(col_tercio, 2)\n",
        "        fila_tercio = min(fila_tercio, 2)\n",
        "\n",
        "        zona_tercios = fila_tercio * 3 + col_tercio + 1\n",
        "\n",
        "        # Recorte por bordes\n",
        "        margen = 10\n",
        "        recorte_izq = max(0, margen - bbox[0])\n",
        "        recorte_der = max(0, bbox[2] - (ancho_img - margen))\n",
        "        recorte_sup = max(0, margen - bbox[1])\n",
        "        recorte_inf = max(0, bbox[3] - (altura_img - margen))\n",
        "\n",
        "        recorte_total = recorte_izq + recorte_der + recorte_sup + recorte_inf\n",
        "        perimetro_bbox = 2 * (ancho_bbox + alto_bbox)\n",
        "        porcentaje_recorte = recorte_total / perimetro_bbox if perimetro_bbox > 0 else 0.0\n",
        "\n",
        "        # Espacio negativo\n",
        "        area_imagen_total = altura_img * ancho_img\n",
        "        espacio_negativo = 1.0 - (area / area_imagen_total)\n",
        "\n",
        "        return {\n",
        "            \"area_px\": float(area),\n",
        "            \"perimetro_px\": float(perimetro),\n",
        "            \"centroide_x\": float(centroide.x),\n",
        "            \"centroide_y\": float(centroide.y),\n",
        "            \"bbox_xmin\": float(bbox[0]),\n",
        "            \"bbox_ymin\": float(bbox[1]),\n",
        "            \"bbox_xmax\": float(bbox[2]),\n",
        "            \"bbox_ymax\": float(bbox[3]),\n",
        "            \"aspect_ratio\": float(aspect_ratio),\n",
        "            \"orientacion_grados\": float(orientacion),\n",
        "            \"solidity\": float(solidity),\n",
        "            \"compacidad\": float(compacidad),\n",
        "            \"circularity\": float(circularity),\n",
        "            \"elongation\": float(elongation),\n",
        "            \"rectangularity\": float(rectangularity),\n",
        "            \"num_componentes\": int(num_componentes),\n",
        "            \"ratio_componente_principal\": float(ratio_componente_principal),\n",
        "            \"distancia_centro_px\": float(distancia_centro),\n",
        "            \"zona_tercios\": int(zona_tercios),\n",
        "            \"recorte_bordes_porcentaje\": float(porcentaje_recorte),\n",
        "            \"espacio_negativo\": float(espacio_negativo)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error calculando métricas Shapely: {e}\")\n",
        "\n",
        "        return {k: np.nan for k in [\n",
        "            \"area_px\", \"perimetro_px\", \"centroide_x\", \"centroide_y\",\n",
        "            \"bbox_xmin\", \"bbox_ymin\", \"bbox_xmax\", \"bbox_ymax\",\n",
        "            \"aspect_ratio\", \"orientacion_grados\", \"solidity\", \"compacidad\",\n",
        "            \"circularity\", \"elongation\", \"rectangularity\", \"num_componentes\",\n",
        "            \"ratio_componente_principal\", \"distancia_centro_px\", \"zona_tercios\",\n",
        "            \"recorte_bordes_porcentaje\", \"espacio_negativo\"\n",
        "        ]}\n",
        "\n",
        "\n",
        "def calcular_metricas_comparativas(geom_pred: Polygon | MultiPolygon, geom_gt: Polygon | MultiPolygon, mascara_pred: np.ndarray, mascara_gt: np.ndarray, logger: Optional[logging.Logger] = None) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula métricas de comparación entre predicción y ground truth.\n",
        "\n",
        "    Métricas de contorno (3):\n",
        "    - boundary_iou: IoU calculado solo sobre bordes\n",
        "    - hausdorff_distance: Máxima desviación entre contornos\n",
        "    - chamfer_distance: Desviación promedio\n",
        "\n",
        "    Métricas de forma (4):\n",
        "    - desplazamiento_centroide: Distancia Euclidiana entre centroides\n",
        "    - diferencia_orientacion: Diferencia angular en grados\n",
        "    - ratio_solidity: pred_solidity / gt_solidity\n",
        "    - diferencia_compacidad: Diferencia absoluta\n",
        "\n",
        "    Métricas de área (1):\n",
        "    - symmetric_difference_area: Área de diferencia simétrica\n",
        "\n",
        "    Args:\n",
        "        geom_pred: Geometría predicha\n",
        "        geom_gt: Geometría ground truth\n",
        "        mascara_pred: Máscara predicha (para boundary IoU)\n",
        "        mascara_gt: Máscara GT (para boundary IoU)\n",
        "        logger: Logger opcional\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con 8 métricas comparativas\n",
        "\n",
        "    Notes:\n",
        "        - Boundary IoU: Evalúa específicamente calidad de bordes\n",
        "        - Hausdorff: Detecta outliers en la segmentación\n",
        "        - Chamfer: Métrica más robusta a outliers que Hausdorff\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Boundary IoU\n",
        "        boundary_pred = cv2.Canny(mascara_pred.astype(np.uint8) * 255, 100, 200) > 0\n",
        "        boundary_gt = cv2.Canny(mascara_gt.astype(np.uint8) * 255, 100, 200) > 0\n",
        "\n",
        "        boundary_interseccion = np.logical_and(boundary_pred, boundary_gt).sum()\n",
        "        boundary_union = np.logical_or(boundary_pred, boundary_gt).sum()\n",
        "\n",
        "        boundary_iou = boundary_interseccion / boundary_union if boundary_union > 0 else 0.0\n",
        "\n",
        "        # Hausdorff y Chamfer Distance\n",
        "        coords_pred = np.column_stack(np.where(boundary_pred))\n",
        "        coords_gt = np.column_stack(np.where(boundary_gt))\n",
        "\n",
        "        if len(coords_pred) > 0 and len(coords_gt) > 0:\n",
        "            hausdorff_dist = max(\n",
        "                directed_hausdorff(coords_pred, coords_gt)[0],\n",
        "                directed_hausdorff(coords_gt, coords_pred)[0]\n",
        "            )\n",
        "\n",
        "            dist_pred_to_gt = distance_transform_edt(~boundary_gt)[boundary_pred]\n",
        "            dist_gt_to_pred = distance_transform_edt(~boundary_pred)[boundary_gt]\n",
        "\n",
        "            chamfer_dist = (dist_pred_to_gt.sum() + dist_gt_to_pred.sum()) / (len(dist_pred_to_gt) + len(dist_gt_to_pred))\n",
        "        else:\n",
        "            hausdorff_dist = np.nan\n",
        "            chamfer_dist = np.nan\n",
        "\n",
        "        # Desplazamiento centroide\n",
        "        centroide_pred = geom_pred.centroid\n",
        "        centroide_gt = geom_gt.centroid\n",
        "        desplazamiento_centroide = centroide_pred.distance(centroide_gt)\n",
        "\n",
        "        # Diferencia orientación\n",
        "        try:\n",
        "            coords_pred_poly = np.array(geom_pred.exterior.coords if isinstance(geom_pred, Polygon) else geom_pred.geoms[0].exterior.coords)\n",
        "            coords_gt_poly = np.array(geom_gt.exterior.coords if isinstance(geom_gt, Polygon) else geom_gt.geoms[0].exterior.coords)\n",
        "\n",
        "            orient_pred = np.arctan2(coords_pred_poly[-1, 1] - coords_pred_poly[0, 1], coords_pred_poly[-1, 0] - coords_pred_poly[0, 0]) * 180 / np.pi\n",
        "            orient_gt = np.arctan2(coords_gt_poly[-1, 1] - coords_gt_poly[0, 1], coords_gt_poly[-1, 0] - coords_gt_poly[0, 0]) * 180 / np.pi\n",
        "\n",
        "            diferencia_orientacion = abs(orient_pred - orient_gt)\n",
        "        except:\n",
        "            diferencia_orientacion = np.nan\n",
        "\n",
        "        # Ratio solidity\n",
        "        solidity_pred = geom_pred.area / geom_pred.convex_hull.area if geom_pred.convex_hull.area > 0 else 0.0\n",
        "        solidity_gt = geom_gt.area / geom_gt.convex_hull.area if geom_gt.convex_hull.area > 0 else 0.0\n",
        "\n",
        "        ratio_solidity = solidity_pred / solidity_gt if solidity_gt > 0 else np.nan\n",
        "\n",
        "        # Diferencia compacidad\n",
        "        perimetro_pred = geom_pred.length\n",
        "        perimetro_gt = geom_gt.length\n",
        "\n",
        "        compacidad_pred = (4 * np.pi * geom_pred.area) / (perimetro_pred ** 2) if perimetro_pred > 0 else 0.0\n",
        "        compacidad_gt = (4 * np.pi * geom_gt.area) / (perimetro_gt ** 2) if perimetro_gt > 0 else 0.0\n",
        "\n",
        "        diferencia_compacidad = abs(compacidad_pred - compacidad_gt)\n",
        "\n",
        "        # Symmetric difference\n",
        "        sym_diff = geom_pred.symmetric_difference(geom_gt)\n",
        "        symmetric_difference_area = sym_diff.area\n",
        "\n",
        "        return {\n",
        "            \"boundary_iou\": float(boundary_iou),\n",
        "            \"hausdorff_distance\": float(hausdorff_dist),\n",
        "            \"chamfer_distance\": float(chamfer_dist),\n",
        "            \"desplazamiento_centroide_px\": float(desplazamiento_centroide),\n",
        "            \"diferencia_orientacion_grados\": float(diferencia_orientacion),\n",
        "            \"ratio_solidity\": float(ratio_solidity),\n",
        "            \"diferencia_compacidad\": float(diferencia_compacidad),\n",
        "            \"symmetric_difference_area_px\": float(symmetric_difference_area)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error calculando métricas comparativas: {e}\")\n",
        "\n",
        "        return {k: np.nan for k in [\n",
        "            \"boundary_iou\", \"hausdorff_distance\", \"chamfer_distance\",\n",
        "            \"desplazamiento_centroide_px\", \"diferencia_orientacion_grados\",\n",
        "            \"ratio_solidity\", \"diferencia_compacidad\", \"symmetric_difference_area_px\"\n",
        "        ]}\n",
        "\n",
        "\n",
        "def calcular_metricas_mahotas(imagen_rgb: np.ndarray, mascara: np.ndarray, ancho_borde: int = 5, max_dimension: int = 1024, logger: Optional[logging.Logger] = None) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Calcula métricas texturales usando Mahotas.\n",
        "\n",
        "    Extrae 3 tipos de métricas:\n",
        "    1. Texturas Haralick interior (13 features)\n",
        "    2. Texturas Haralick borde (13 features)\n",
        "    3. Estadísticas básicas (4 valores)\n",
        "\n",
        "    Args:\n",
        "        imagen_rgb: Imagen original en RGB\n",
        "        mascara: Máscara binaria de la región\n",
        "        ancho_borde: Ancho del borde en pixels\n",
        "        max_dimension: Redimensión máxima (optimización)\n",
        "        logger: Logger opcional\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con 30 métricas texturales\n",
        "\n",
        "    Notes:\n",
        "        - Haralick: Calcula co-ocurrencia de grises\n",
        "        - Borde: Evalúa calidad de transición persona-fondo\n",
        "        - Redimensión: Trade-off velocidad vs precisión\n",
        "\n",
        "    References:\n",
        "        Haralick et al. (1973). Textural Features for Image Classification\n",
        "    \"\"\"\n",
        "    try:\n",
        "        altura, ancho = imagen_rgb.shape[:2]\n",
        "        factor_escala = 1.0\n",
        "\n",
        "        # Redimensionar si excede límite\n",
        "        if max(altura, ancho) > max_dimension:\n",
        "            factor_escala = max_dimension / max(altura, ancho)\n",
        "            nuevo_ancho = int(ancho * factor_escala)\n",
        "            nuevo_alto = int(altura * factor_escala)\n",
        "\n",
        "            imagen_rgb = cv2.resize(imagen_rgb, (nuevo_ancho, nuevo_alto), interpolation=cv2.INTER_AREA)\n",
        "            mascara = cv2.resize(mascara.astype(np.uint8), (nuevo_ancho, nuevo_alto), interpolation=cv2.INTER_NEAREST).astype(bool)\n",
        "\n",
        "        # Convertir a escala de grises\n",
        "        imagen_gris = cv2.cvtColor(imagen_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Región interior\n",
        "        region_persona = imagen_gris * mascara\n",
        "\n",
        "        if region_persona[mascara].size == 0:\n",
        "            raise ValueError(\"Región de persona vacía\")\n",
        "\n",
        "        haralick_interior = mahotas.features.haralick(region_persona, ignore_zeros=True).mean(axis=0)\n",
        "\n",
        "        # Región borde\n",
        "        kernel = np.ones((ancho_borde * 2 + 1, ancho_borde * 2 + 1), np.uint8)\n",
        "        mascara_dilatada = cv2.dilate(mascara.astype(np.uint8), kernel, iterations=1).astype(bool)\n",
        "        mascara_erosionada = cv2.erode(mascara.astype(np.uint8), kernel, iterations=1).astype(bool)\n",
        "\n",
        "        mascara_borde = np.logical_and(mascara_dilatada, ~mascara_erosionada)\n",
        "\n",
        "        region_borde = imagen_gris * mascara_borde\n",
        "\n",
        "        if region_borde[mascara_borde].size == 0:\n",
        "            haralick_borde = np.full(13, np.nan)\n",
        "        else:\n",
        "            haralick_borde = mahotas.features.haralick(region_borde, ignore_zeros=True).mean(axis=0)\n",
        "\n",
        "        # Estadísticas básicas\n",
        "        intensidades = region_persona[mascara]\n",
        "\n",
        "        media_intensidad = float(np.mean(intensidades))\n",
        "        std_intensidad = float(np.std(intensidades))\n",
        "        min_intensidad = float(np.min(intensidades))\n",
        "        max_intensidad = float(np.max(intensidades))\n",
        "\n",
        "        # Construir diccionario de resultados\n",
        "        nombres_haralick = [\n",
        "            \"angular_second_moment\", \"contrast\", \"correlation\",\n",
        "            \"sum_of_squares_variance\", \"inverse_difference_moment\",\n",
        "            \"sum_average\", \"sum_variance\", \"sum_entropy\",\n",
        "            \"entropy\", \"difference_variance\", \"difference_entropy\",\n",
        "            \"information_measure_correlation_1\", \"information_measure_correlation_2\"\n",
        "        ]\n",
        "\n",
        "        resultado = {}\n",
        "\n",
        "        for i, nombre in enumerate(nombres_haralick):\n",
        "            resultado[f\"haralick_interior_{nombre}\"] = float(haralick_interior[i])\n",
        "            resultado[f\"haralick_borde_{nombre}\"] = float(haralick_borde[i])\n",
        "\n",
        "        resultado.update({\n",
        "            \"intensidad_media\": media_intensidad,\n",
        "            \"intensidad_std\": std_intensidad,\n",
        "            \"intensidad_min\": min_intensidad,\n",
        "            \"intensidad_max\": max_intensidad\n",
        "        })\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    except Exception as e:\n",
        "        if logger:\n",
        "            logger.error(f\"Error calculando métricas Mahotas: {e}\")\n",
        "\n",
        "        nombres_haralick = [\n",
        "            \"angular_second_moment\", \"contrast\", \"correlation\",\n",
        "            \"sum_of_squares_variance\", \"inverse_difference_moment\",\n",
        "            \"sum_average\", \"sum_variance\", \"sum_entropy\",\n",
        "            \"entropy\", \"difference_variance\", \"difference_entropy\",\n",
        "            \"information_measure_correlation_1\", \"information_measure_correlation_2\"\n",
        "        ]\n",
        "\n",
        "        resultado = {}\n",
        "        for nombre in nombres_haralick:\n",
        "            resultado[f\"haralick_interior_{nombre}\"] = np.nan\n",
        "            resultado[f\"haralick_borde_{nombre}\"] = np.nan\n",
        "\n",
        "        resultado.update({\n",
        "            \"intensidad_media\": np.nan,\n",
        "            \"intensidad_std\": np.nan,\n",
        "            \"intensidad_min\": np.nan,\n",
        "            \"intensidad_max\": np.nan\n",
        "        })\n",
        "\n",
        "        return resultado"
      ],
      "metadata": {
        "id": "Ily7HYh9FbYe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SISTEMA DE SELECCIÓN INTERACTIVA\n",
        "# =============================================================================\n",
        "\n",
        "class SelectorModelos:\n",
        "    \"\"\"\n",
        "    Sistema de selección interactiva de familias de modelos a evaluar.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, indice_maestro: Dict, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el selector.\n",
        "\n",
        "        Args:\n",
        "            indice_maestro: Índice maestro consolidado de Fase 1\n",
        "            logger: Sistema de logging\n",
        "        \"\"\"\n",
        "        self.indice = indice_maestro\n",
        "        self.logger = logger\n",
        "        self.modelos_por_familia = self._extraer_familias()\n",
        "\n",
        "    def _extraer_familias(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"\n",
        "        Extrae configuraciones agrupadas por familia desde índice maestro.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario {familia: [lista_de_codigos_config]}\n",
        "        \"\"\"\n",
        "        familias = {}\n",
        "\n",
        "        # Iterar sobre todas las fotos\n",
        "        for foto_id, datos_foto in self.indice.items():\n",
        "            modelos_disponibles = datos_foto.get('modelos_disponibles', {})\n",
        "\n",
        "            # Iterar sobre todas las configuraciones de esta foto\n",
        "            for codigo_config in modelos_disponibles.keys():\n",
        "                # Extraer familia del código\n",
        "                familia = self._extraer_familia_de_codigo(codigo_config)\n",
        "\n",
        "                if familia not in familias:\n",
        "                    familias[familia] = set()\n",
        "\n",
        "                familias[familia].add(codigo_config)\n",
        "\n",
        "        # Convertir sets a listas ordenadas\n",
        "        familias_listas = {\n",
        "            familia: sorted(list(configs))\n",
        "            for familia, configs in familias.items()\n",
        "        }\n",
        "\n",
        "        return familias_listas\n",
        "\n",
        "    @staticmethod\n",
        "    def _extraer_familia_de_codigo(codigo_config: str) -> str:\n",
        "        \"\"\"\n",
        "        Extrae el nombre de la familia del modelo desde el código de configuración.\n",
        "\n",
        "        Ejemplos reales de tu índice:\n",
        "        - \"mask2former_large_ade_baja_sensibilidad\" -> \"mask2former\"\n",
        "        - \"bodypix_mobilenet_050_estandar\" -> \"bodypix\"\n",
        "        - \"sam2_hiera_large_auto_generacion\" -> \"sam2\"\n",
        "        - \"sam2_hiera_large_box_prompts\" -> \"sam2_prompts\"\n",
        "        - \"yolov8_nano_estandar\" -> \"yolov8\"\n",
        "        - \"oneformer_dinat_large_semantic\" -> \"oneformer\"\n",
        "\n",
        "        Args:\n",
        "            codigo_config: Código de configuración completo\n",
        "\n",
        "        Returns:\n",
        "            Nombre de la familia del modelo\n",
        "        \"\"\"\n",
        "        # Casos especiales: SAM2 con prompts\n",
        "        if codigo_config.startswith('sam2'):\n",
        "            # Si contiene palabras clave de prompts, es sam2_prompts\n",
        "            if any(palabra in codigo_config for palabra in ['box', 'point', 'combined', 'prompts']):\n",
        "                return 'sam2_prompts'\n",
        "            else:\n",
        "                # Es SAM2 auto (sin prompts)\n",
        "                return 'sam2'\n",
        "\n",
        "        # Caso general: primera palabra antes del primer guión bajo\n",
        "        return codigo_config.split('_')[0]\n",
        "\n",
        "    def mostrar_menu(self) -> int:\n",
        "        \"\"\"\n",
        "        Muestra menú interactivo de selección.\n",
        "\n",
        "        Returns:\n",
        "            Índice de opción seleccionada, o -1 si cancela\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SELECCIÓN DE MODELOS PARA PROCESAMIENTO\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        if not self.modelos_por_familia:\n",
        "            print(\"\\n¡ERROR! No se encontraron configuraciones en el índice maestro\")\n",
        "            return -1\n",
        "\n",
        "        # Orden preferido de familias\n",
        "        familias_ordenadas = ['bodypix', 'mask2former', 'oneformer', 'sam2', 'sam2_prompts', 'yolov8']\n",
        "        familias_disponibles = [f for f in familias_ordenadas if f in self.modelos_por_familia]\n",
        "\n",
        "        # Agregar familias que no estén en el orden preferido (por si acaso)\n",
        "        for familia in sorted(self.modelos_por_familia.keys()):\n",
        "            if familia not in familias_disponibles:\n",
        "                familias_disponibles.append(familia)\n",
        "\n",
        "        print(\"\\nModelos disponibles:\\n\")\n",
        "\n",
        "        for idx, familia in enumerate(familias_disponibles, start=1):\n",
        "            num_configs = len(self.modelos_por_familia[familia])\n",
        "            nombre_display = familia.upper().replace('_', ' ')\n",
        "            print(f\"{idx}. {nombre_display}\")\n",
        "            print(f\"   Configuraciones: {num_configs}\\n\")\n",
        "\n",
        "        print(f\"{len(familias_disponibles) + 1}. TODOS LOS MODELOS\")\n",
        "        total_configs = sum(len(configs) for configs in self.modelos_por_familia.values())\n",
        "        print(f\"   Total: {total_configs} configuraciones\\n\")\n",
        "\n",
        "        print(f\"{len(familias_disponibles) + 2}. SELECCIÓN MÚLTIPLE (separar con comas)\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                seleccion = input(f\"\\nSeleccione opción [1-{len(familias_disponibles) + 2}]: \").strip()\n",
        "\n",
        "                if not seleccion:\n",
        "                    print(\"Selección vacía. Cancelando...\")\n",
        "                    return -1\n",
        "\n",
        "                opcion = int(seleccion)\n",
        "\n",
        "                if 1 <= opcion <= len(familias_disponibles) + 2:\n",
        "                    return opcion\n",
        "                else:\n",
        "                    print(f\"Por favor ingrese un número entre 1 y {len(familias_disponibles) + 2}\")\n",
        "\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor ingrese un número\")\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                print(\"\\n\\nSelección cancelada por el usuario\")\n",
        "                return -1\n",
        "\n",
        "    def seleccion_multiple(self) -> List[str]:\n",
        "        \"\"\"\n",
        "        Permite selección múltiple de familias.\n",
        "\n",
        "        Returns:\n",
        "            Lista de familias seleccionadas\n",
        "        \"\"\"\n",
        "        familias_ordenadas = ['bodypix', 'mask2former', 'oneformer', 'sam2', 'sam2_prompts', 'yolov8']\n",
        "        familias_disponibles = [f for f in familias_ordenadas if f in self.modelos_por_familia]\n",
        "\n",
        "        # Agregar familias adicionales no ordenadas\n",
        "        for familia in sorted(self.modelos_por_familia.keys()):\n",
        "            if familia not in familias_disponibles:\n",
        "                familias_disponibles.append(familia)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SELECCIÓN MÚLTIPLE\")\n",
        "        print(\"=\"*80)\n",
        "        print(\"\\nIngrese los números separados por comas (ej: 1,3,5)\\n\")\n",
        "\n",
        "        for idx, familia in enumerate(familias_disponibles, start=1):\n",
        "            nombre_display = familia.upper().replace('_', ' ')\n",
        "            num_configs = len(self.modelos_por_familia[familia])\n",
        "            print(f\"{idx}. {nombre_display} ({num_configs} configs)\")\n",
        "\n",
        "        seleccion = input(\"\\nSelección: \").strip()\n",
        "\n",
        "        if not seleccion:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            indices = [int(x.strip()) for x in seleccion.split(',')]\n",
        "            familias_sel = []\n",
        "\n",
        "            for idx in indices:\n",
        "                if 1 <= idx <= len(familias_disponibles):\n",
        "                    familias_sel.append(familias_disponibles[idx - 1])\n",
        "                else:\n",
        "                    print(f\"Advertencia: índice {idx} fuera de rango, ignorado\")\n",
        "\n",
        "            return familias_sel\n",
        "\n",
        "        except ValueError:\n",
        "            print(\"Error: formato inválido\")\n",
        "            return []\n",
        "\n",
        "    def expandir_seleccion(self, familias_seleccionadas: List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Expande familias seleccionadas a lista completa de configuraciones.\n",
        "\n",
        "        Args:\n",
        "            familias_seleccionadas: Lista de códigos de familia\n",
        "\n",
        "        Returns:\n",
        "            Lista completa de códigos de configuración\n",
        "        \"\"\"\n",
        "        if 'TODAS' in familias_seleccionadas:\n",
        "            configs = []\n",
        "            for familia_configs in self.modelos_por_familia.values():\n",
        "                configs.extend(familia_configs)\n",
        "            return sorted(configs)\n",
        "\n",
        "        configs = []\n",
        "        for familia in familias_seleccionadas:\n",
        "            if familia in self.modelos_por_familia:\n",
        "                configs.extend(self.modelos_por_familia[familia])\n",
        "\n",
        "        return sorted(configs)\n",
        "\n",
        "    def confirmar_seleccion(self, configuraciones: List[str]) -> bool:\n",
        "        \"\"\"\n",
        "        Muestra resumen y solicita confirmación.\n",
        "\n",
        "        Args:\n",
        "            configuraciones: Lista de configuraciones seleccionadas\n",
        "\n",
        "        Returns:\n",
        "            True si usuario confirma, False si cancela\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RESUMEN DE SELECCIÓN\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"\\nTotal de configuraciones seleccionadas: {len(configuraciones)}\")\n",
        "\n",
        "        if len(configuraciones) <= 20:\n",
        "            print(\"\\nConfiguraciones:\")\n",
        "            for config in configuraciones:\n",
        "                print(f\"  - {config}\")\n",
        "        else:\n",
        "            print(\"\\nPrimeras 10 configuraciones:\")\n",
        "            for config in configuraciones[:10]:\n",
        "                print(f\"  - {config}\")\n",
        "            print(f\"  ... y {len(configuraciones) - 10} más\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "        while True:\n",
        "            confirmacion = input(\"\\n¿Continuar con esta selección? [S/n]: \").strip().lower()\n",
        "\n",
        "            if confirmacion in ['s', 'si', 'yes', '']:\n",
        "                return True\n",
        "            elif confirmacion in ['n', 'no']:\n",
        "                return False\n",
        "            else:\n",
        "                print(\"Por favor responda 's' o 'n'\")\n",
        "\n",
        "    def seleccionar(self) -> Optional[List[str]]:\n",
        "        \"\"\"\n",
        "        Proceso completo de selección interactiva.\n",
        "\n",
        "        Returns:\n",
        "            Lista de configuraciones seleccionadas, o None si se cancela\n",
        "        \"\"\"\n",
        "        opcion = self.mostrar_menu()\n",
        "\n",
        "        if opcion == -1:\n",
        "            return None\n",
        "\n",
        "        familias_ordenadas = ['bodypix', 'mask2former', 'oneformer', 'sam2', 'sam2_prompts', 'yolov8']\n",
        "        familias_disponibles = [f for f in familias_ordenadas if f in self.modelos_por_familia]\n",
        "\n",
        "        # Agregar familias adicionales\n",
        "        for familia in sorted(self.modelos_por_familia.keys()):\n",
        "            if familia not in familias_disponibles:\n",
        "                familias_disponibles.append(familia)\n",
        "\n",
        "        if opcion == len(familias_disponibles) + 1:\n",
        "            # TODAS\n",
        "            familias_sel = ['TODAS']\n",
        "        elif opcion == len(familias_disponibles) + 2:\n",
        "            # SELECCIÓN MÚLTIPLE\n",
        "            familias_sel = self.seleccion_multiple()\n",
        "            if not familias_sel:\n",
        "                print(\"\\nSelección cancelada\")\n",
        "                return None\n",
        "        else:\n",
        "            # FAMILIA INDIVIDUAL\n",
        "            familias_sel = [familias_disponibles[opcion - 1]]\n",
        "\n",
        "        configuraciones = self.expandir_seleccion(familias_sel)\n",
        "\n",
        "        if not configuraciones:\n",
        "            print(\"\\nError: No se seleccionaron configuraciones válidas\")\n",
        "            return None\n",
        "\n",
        "        if self.confirmar_seleccion(configuraciones):\n",
        "            return configuraciones\n",
        "        else:\n",
        "            print(\"\\nSelección cancelada\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "BVQqT5MOFrFI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ORQUESTADOR PRINCIPAL DE FASE 2A\n",
        "# =============================================================================\n",
        "\n",
        "class OrquestadorFase2A:\n",
        "    \"\"\"\n",
        "    Orquestador principal para ejecución de Fase 2A.\n",
        "\n",
        "    Coordina el pipeline completo de evaluación cuantitativa:\n",
        "    - Gestión de checkpoint para procesamiento resumible\n",
        "    - Carga de ground truth y máscaras predichas\n",
        "    - Cálculo de métricas clásicas, geométricas y texturales\n",
        "    - Consolidación de resultados en múltiples formatos\n",
        "    - Generación de estadísticas y rankings\n",
        "\n",
        "    Attributes:\n",
        "        config: Configuración global de Fase 2A\n",
        "        configuraciones_seleccionadas: Lista de códigos de configuración a procesar\n",
        "        logger: Logger configurado según nivel de verbosidad\n",
        "        checkpoint: Sistema de checkpoint para reanudar procesamiento\n",
        "        resultados_consolidados: Lista acumulativa de resultados para CSV\n",
        "        estadisticas_omisiones: Registro de configuraciones omitidas por foto\n",
        "        indice_maestro: Índice maestro cargado desde Fase 1\n",
        "        fotografias_disponibles: Lista de estructuras con información de fotografías\n",
        "\n",
        "    Notes:\n",
        "        - Las configuraciones con ruta_mascara=null se omiten automáticamente\n",
        "        - El checkpoint se actualiza después de cada fotografía procesada\n",
        "        - Los errores en cálculo de métricas se registran como NaN sin detener ejecución\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2A, configuraciones: List[str]):\n",
        "        \"\"\"\n",
        "        Inicializa el orquestador con configuración y lista de configuraciones.\n",
        "\n",
        "        Args:\n",
        "            config: Configuración global del sistema\n",
        "            configuraciones: Lista de códigos de configuración seleccionados por el usuario\n",
        "\n",
        "        Raises:\n",
        "            FileNotFoundError: Si no existe el índice maestro de Fase 1\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.configuraciones_seleccionadas = configuraciones\n",
        "        self.logger = configurar_logging(config.nivel_logging, \"OrquestadorFase2A\")\n",
        "\n",
        "        config.crear_directorios()\n",
        "\n",
        "        self.checkpoint: Optional[CheckpointFase2A] = None\n",
        "        self.resultados_consolidados: List[Dict] = []\n",
        "        self.estadisticas_omisiones: Dict[str, List[str]] = {}\n",
        "\n",
        "        # Cargar índice maestro de Fase 1\n",
        "        ruta_indice = config.ruta_fase1 / \"indice_maestro.json\"\n",
        "\n",
        "        if not ruta_indice.exists():\n",
        "            raise FileNotFoundError(f\"Índice maestro no encontrado: {ruta_indice}\")\n",
        "\n",
        "        with open(ruta_indice, 'r', encoding='utf-8') as f:\n",
        "            self.indice_maestro = json.load(f)\n",
        "\n",
        "        # Extraer información de fotografías disponibles\n",
        "        self.fotografias_disponibles = []\n",
        "\n",
        "        for foto_id in sorted(self.indice_maestro.keys()):\n",
        "            datos_foto = self.indice_maestro[foto_id]\n",
        "\n",
        "            foto_info = {\n",
        "                \"codigo_foto\": foto_id,\n",
        "                \"ruta_imagen\": datos_foto[\"rutas\"][\"imagen\"],\n",
        "                \"ruta_ground_truth\": datos_foto[\"rutas\"][\"ground_truth\"],\n",
        "                \"ruta_caracteristicas\": datos_foto[\"rutas\"][\"caracteristicas\"],\n",
        "                \"modelos_disponibles\": datos_foto[\"modelos_disponibles\"]\n",
        "            }\n",
        "\n",
        "            self.fotografias_disponibles.append(foto_info)\n",
        "\n",
        "        self.logger.info(f\"Índice maestro cargado: {len(self.fotografias_disponibles)} fotografías\")\n",
        "\n",
        "    def cargar_checkpoint(self) -> None:\n",
        "        \"\"\"\n",
        "        Carga checkpoint existente si está habilitado.\n",
        "\n",
        "        Permite reanudar procesamiento desde fotografía interrumpida.\n",
        "        Actualiza la lista de fotografías pendientes basándose en fotos ya procesadas.\n",
        "        \"\"\"\n",
        "        ruta_checkpoint = self.config.ruta_salida / \"checkpoint_fase2a.json\"\n",
        "\n",
        "        if self.config.usar_checkpoint and ruta_checkpoint.exists():\n",
        "            try:\n",
        "                with open(ruta_checkpoint, 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "                    self.checkpoint = CheckpointFase2A.from_dict(data)\n",
        "\n",
        "                self.logger.info(f\"Checkpoint cargado: {len(self.checkpoint.fotos_procesadas)} fotos ya procesadas\")\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.warning(f\"Error cargando checkpoint: {e}. Iniciando desde cero\")\n",
        "                self.checkpoint = CheckpointFase2A()\n",
        "        else:\n",
        "            self.checkpoint = CheckpointFase2A()\n",
        "\n",
        "        # Actualizar fotos pendientes\n",
        "        codigos_fotos = [f[\"codigo_foto\"] for f in self.fotografias_disponibles]\n",
        "\n",
        "        self.checkpoint.fotos_pendientes = [\n",
        "            codigo for codigo in codigos_fotos\n",
        "            if codigo not in self.checkpoint.fotos_procesadas\n",
        "        ]\n",
        "\n",
        "        self.checkpoint.configuraciones_totales = len(self.configuraciones_seleccionadas)\n",
        "\n",
        "    def guardar_checkpoint(self) -> None:\n",
        "        \"\"\"\n",
        "        Guarda estado actual del checkpoint.\n",
        "\n",
        "        Se ejecuta después de cada fotografía procesada para permitir\n",
        "        reanudación en caso de interrupción.\n",
        "        \"\"\"\n",
        "        if not self.config.usar_checkpoint:\n",
        "            return\n",
        "\n",
        "        self.checkpoint.ultima_actualizacion = datetime.now().isoformat()\n",
        "\n",
        "        ruta_checkpoint = self.config.ruta_salida / \"checkpoint_fase2a.json\"\n",
        "\n",
        "        guardar_json_seguro(self.checkpoint.to_dict(), ruta_checkpoint, self.logger)\n",
        "\n",
        "    def procesar_fotografia(self, info_foto: Dict) -> None:\n",
        "        \"\"\"\n",
        "        Procesa una fotografía completa con todas sus configuraciones seleccionadas.\n",
        "\n",
        "        Pipeline de procesamiento:\n",
        "        1. Carga ground truth\n",
        "        2. Convierte GT a geometría Shapely\n",
        "        3. Calcula métricas base del GT\n",
        "        4. Para cada configuración seleccionada disponible:\n",
        "           - Verifica existencia de máscara NPZ\n",
        "           - Carga máscara predicha\n",
        "           - Calcula métricas clásicas (IoU, Dice, Precision, Recall, F1)\n",
        "           - Calcula métricas geométricas Shapely\n",
        "           - Calcula métricas comparativas\n",
        "           - Calcula métricas texturales Mahotas\n",
        "        5. Guarda resultados individuales en JSON\n",
        "        6. Actualiza checkpoint\n",
        "\n",
        "        Args:\n",
        "            info_foto: Diccionario con información de la fotografía:\n",
        "                - codigo_foto: Identificador único\n",
        "                - ruta_imagen: Path a imagen original\n",
        "                - ruta_ground_truth: Path a máscara GT\n",
        "                - ruta_caracteristicas: Path a JSON de características\n",
        "                - modelos_disponibles: Dict de configuraciones disponibles\n",
        "\n",
        "        Notes:\n",
        "            - Configuraciones sin máscara NPZ (ruta_mascara=null) se omiten\n",
        "            - Errores en conversión a Shapely se registran como omisiones\n",
        "            - Mahotas se omite si no existe imagen original RGB\n",
        "        \"\"\"\n",
        "        codigo_foto = info_foto[\"codigo_foto\"]\n",
        "\n",
        "        if self.config.nivel_logging in [NivelLogging.NORMAL, NivelLogging.DETAILED, NivelLogging.DEBUG]:\n",
        "            self.logger.info(f\"\\n{'='*80}\")\n",
        "            self.logger.info(f\"Procesando fotografía: {codigo_foto}\")\n",
        "            self.logger.info(f\"{'='*80}\")\n",
        "\n",
        "        # Cargar ground truth\n",
        "        ruta_gt = Path(info_foto[\"ruta_ground_truth\"])\n",
        "\n",
        "        if not ruta_gt.exists():\n",
        "            self.logger.error(f\"Ground truth no encontrado para {codigo_foto}. Omitiendo fotografía\")\n",
        "            return\n",
        "\n",
        "        mascara_gt = cargar_mascara_npz(ruta_gt, logger=self.logger)\n",
        "\n",
        "        if mascara_gt is None:\n",
        "            self.logger.error(f\"Error cargando ground truth de {codigo_foto}. Omitiendo fotografía\")\n",
        "            return\n",
        "\n",
        "        # Convertir GT a Shapely\n",
        "        geom_gt = mascara_a_shapely(mascara_gt, self.logger)\n",
        "\n",
        "        if geom_gt is None:\n",
        "            self.logger.error(f\"Error convirtiendo GT a Shapely para {codigo_foto}. Omitiendo fotografía\")\n",
        "            return\n",
        "\n",
        "        # Dimensiones de la imagen\n",
        "        dimensiones_imagen = (mascara_gt.shape[0], mascara_gt.shape[1])\n",
        "\n",
        "        # Métricas del ground truth\n",
        "        metricas_gt = calcular_metricas_shapely(geom_gt, dimensiones_imagen, self.logger)\n",
        "\n",
        "        # Cargar imagen original para Mahotas\n",
        "        ruta_imagen_original = Path(info_foto[\"ruta_imagen\"])\n",
        "\n",
        "        if ruta_imagen_original.exists():\n",
        "            imagen_rgb = np.array(Image.open(ruta_imagen_original).convert(\"RGB\"))\n",
        "        else:\n",
        "            self.logger.warning(f\"Imagen original no encontrada: {ruta_imagen_original}. Mahotas omitido\")\n",
        "            imagen_rgb = None\n",
        "\n",
        "        # Estructura de resultados\n",
        "        resultados_foto = {\n",
        "            \"codigo_foto\": codigo_foto,\n",
        "            \"dimensiones_imagen\": {\n",
        "                \"altura\": dimensiones_imagen[0],\n",
        "                \"ancho\": dimensiones_imagen[1]\n",
        "            },\n",
        "            \"ground_truth_metricas\": metricas_gt,\n",
        "            \"configuraciones\": []\n",
        "        }\n",
        "\n",
        "        configs_procesadas = 0\n",
        "        configs_omitidas = 0\n",
        "\n",
        "        # Iterar sobre configuraciones seleccionadas que existen en esta foto\n",
        "        modelos_disponibles_foto = info_foto[\"modelos_disponibles\"]\n",
        "\n",
        "        for config_codigo in self.configuraciones_seleccionadas:\n",
        "            # Verificar si esta configuración existe para esta foto\n",
        "            if config_codigo not in modelos_disponibles_foto:\n",
        "                if self.config.nivel_logging == NivelLogging.DEBUG:\n",
        "                    self.logger.debug(f\"  Config {config_codigo} no disponible para {codigo_foto}\")\n",
        "                configs_omitidas += 1\n",
        "\n",
        "                # Registrar omisión\n",
        "                modelo = config_codigo.split('_')[0]\n",
        "                clave_omision = f\"{codigo_foto}_{config_codigo}\"\n",
        "                if modelo not in self.estadisticas_omisiones:\n",
        "                    self.estadisticas_omisiones[modelo] = []\n",
        "                self.estadisticas_omisiones[modelo].append(clave_omision)\n",
        "                continue\n",
        "\n",
        "            if self.config.nivel_logging == NivelLogging.DEBUG:\n",
        "                self.logger.debug(f\"  Procesando config: {config_codigo}\")\n",
        "\n",
        "            # Obtener información de la configuración\n",
        "            config_info = modelos_disponibles_foto[config_codigo]\n",
        "\n",
        "            # Verificar si tiene máscara NPZ (puede ser null)\n",
        "            if config_info.get(\"ruta_mascara\") is None:\n",
        "                if self.config.nivel_logging == NivelLogging.DEBUG:\n",
        "                    self.logger.debug(f\"    Config {config_codigo} no tiene máscara NPZ (solo metadata)\")\n",
        "                configs_omitidas += 1\n",
        "\n",
        "                # Registrar omisión\n",
        "                modelo = config_codigo.split('_')[0]\n",
        "                clave_omision = f\"{codigo_foto}_{config_codigo}\"\n",
        "                if modelo not in self.estadisticas_omisiones:\n",
        "                    self.estadisticas_omisiones[modelo] = []\n",
        "                self.estadisticas_omisiones[modelo].append(clave_omision)\n",
        "                continue\n",
        "\n",
        "            ruta_mascara = Path(config_info[\"ruta_mascara\"])\n",
        "\n",
        "            if not ruta_mascara.exists():\n",
        "                self.logger.warning(f\"    Máscara no encontrada: {ruta_mascara}\")\n",
        "                configs_omitidas += 1\n",
        "                continue\n",
        "\n",
        "            # Cargar máscara predicha\n",
        "            mascara_pred = cargar_mascara_npz(ruta_mascara, logger=self.logger)\n",
        "\n",
        "            if mascara_pred is None:\n",
        "                self.logger.warning(f\"    Error cargando máscara {config_codigo} para {codigo_foto}\")\n",
        "                configs_omitidas += 1\n",
        "                continue\n",
        "\n",
        "            # Calcular métricas clásicas\n",
        "            metricas_clasicas = calcular_metricas_clasicas(mascara_pred, mascara_gt)\n",
        "\n",
        "            # Convertir predicción a Shapely\n",
        "            geom_pred = mascara_a_shapely(mascara_pred, self.logger)\n",
        "\n",
        "            if geom_pred is None:\n",
        "                self.logger.warning(f\"    Error convirtiendo predicción a Shapely: {config_codigo}\")\n",
        "                configs_omitidas += 1\n",
        "                continue\n",
        "\n",
        "            # Métricas Shapely de predicción\n",
        "            metricas_shapely_pred = calcular_metricas_shapely(geom_pred, dimensiones_imagen, self.logger)\n",
        "\n",
        "            # Métricas comparativas\n",
        "            metricas_comparativas = calcular_metricas_comparativas(\n",
        "                geom_pred, geom_gt, mascara_pred, mascara_gt, self.logger\n",
        "            )\n",
        "\n",
        "            # Métricas Mahotas\n",
        "            if imagen_rgb is not None:\n",
        "                metricas_mahotas = calcular_metricas_mahotas(\n",
        "                    imagen_rgb, mascara_pred,\n",
        "                    ancho_borde=self.config.ancho_borde_px,\n",
        "                    max_dimension=self.config.max_dimension_mahotas,\n",
        "                    logger=self.logger\n",
        "                )\n",
        "            else:\n",
        "                metricas_mahotas = {}\n",
        "\n",
        "            # Consolidar resultados de configuración\n",
        "            resultado_config = {\n",
        "                \"config_codigo\": config_codigo,\n",
        "                \"modelo\": config_codigo.split('_')[0],\n",
        "                \"metricas_clasicas\": metricas_clasicas,\n",
        "                \"metricas_shapely\": metricas_shapely_pred,\n",
        "                \"metricas_comparativas\": metricas_comparativas,\n",
        "                \"metricas_mahotas\": metricas_mahotas\n",
        "            }\n",
        "\n",
        "            resultados_foto[\"configuraciones\"].append(resultado_config)\n",
        "\n",
        "            # Agregar a consolidado para CSV\n",
        "            fila_csv = {\n",
        "                \"codigo_foto\": codigo_foto,\n",
        "                \"config_codigo\": config_codigo,\n",
        "                \"modelo\": config_codigo.split('_')[0],\n",
        "                **metricas_clasicas,\n",
        "                **metricas_shapely_pred,\n",
        "                **metricas_comparativas,\n",
        "                **metricas_mahotas\n",
        "            }\n",
        "\n",
        "            self.resultados_consolidados.append(fila_csv)\n",
        "\n",
        "            configs_procesadas += 1\n",
        "\n",
        "        # Guardar JSON individual\n",
        "        if self.config.guardar_json_individuales:\n",
        "            ruta_json_individual = self.config.ruta_salida / \"metricas_individuales\" / f\"{codigo_foto}_metricas_completas.json\"\n",
        "            guardar_json_seguro(resultados_foto, ruta_json_individual, self.logger)\n",
        "\n",
        "        # Actualizar checkpoint\n",
        "        self.checkpoint.fotos_procesadas.add(codigo_foto)\n",
        "\n",
        "        if codigo_foto in self.checkpoint.fotos_pendientes:\n",
        "            self.checkpoint.fotos_pendientes.remove(codigo_foto)\n",
        "\n",
        "        self.guardar_checkpoint()\n",
        "\n",
        "        if self.config.nivel_logging in [NivelLogging.NORMAL, NivelLogging.DETAILED]:\n",
        "            self.logger.info(f\"  Configuraciones procesadas: {configs_procesadas}\")\n",
        "            self.logger.info(f\"  Configuraciones omitidas: {configs_omitidas}\")\n",
        "\n",
        "    def ejecutar(self) -> None:\n",
        "        \"\"\"\n",
        "        Ejecuta el pipeline completo de Fase 2A.\n",
        "\n",
        "        Procesa todas las fotografías pendientes y genera archivos de salida:\n",
        "        - JSONs individuales por fotografía (opcional)\n",
        "        - CSV consolidado con todas las métricas\n",
        "        - Estadísticas por modelo\n",
        "        - Ranking TOP-10 de configuraciones\n",
        "        - Reporte de configuraciones omitidas\n",
        "\n",
        "        El procesamiento es resumible mediante checkpoint si está habilitado.\n",
        "        \"\"\"\n",
        "        self.logger.info(\"\\nIniciando Fase 2A - Evaluación Cuantitativa\")\n",
        "        self.logger.info(f\"Configuraciones a evaluar: {len(self.configuraciones_seleccionadas)}\")\n",
        "        self.logger.info(f\"Fotografías disponibles: {len(self.fotografias_disponibles)}\")\n",
        "\n",
        "        self.cargar_checkpoint()\n",
        "\n",
        "        self.logger.info(f\"Fotografías pendientes: {len(self.checkpoint.fotos_pendientes)}\")\n",
        "        self.logger.info(f\"Fotografías ya procesadas: {len(self.checkpoint.fotos_procesadas)}\\n\")\n",
        "\n",
        "        # Procesar cada fotografía\n",
        "        for info_foto in self.fotografias_disponibles:\n",
        "            codigo_foto = info_foto[\"codigo_foto\"]\n",
        "\n",
        "            if codigo_foto in self.checkpoint.fotos_procesadas:\n",
        "                if self.config.nivel_logging == NivelLogging.DEBUG:\n",
        "                    self.logger.debug(f\"Omitiendo {codigo_foto} (ya procesada)\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                self.procesar_fotografia(info_foto)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error procesando {codigo_foto}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        self.logger.info(\"\\nProcesamiento de fotografías completado\")\n",
        "\n",
        "        # Generar archivos consolidados\n",
        "        if self.config.guardar_csv_consolidado:\n",
        "            self.generar_csv_consolidado()\n",
        "\n",
        "        if self.config.guardar_estadisticas:\n",
        "            self.generar_estadisticas_por_modelo()\n",
        "\n",
        "        self.generar_ranking_top10()\n",
        "\n",
        "        self.guardar_reporte_omisiones()\n",
        "\n",
        "        self.logger.info(\"\\nFase 2A completada exitosamente\")\n",
        "\n",
        "    def generar_csv_consolidado(self) -> None:\n",
        "        \"\"\"\n",
        "        Genera CSV consolidado con todas las métricas.\n",
        "\n",
        "        Formato: Una fila por combinación foto-configuración.\n",
        "        Columnas: código_foto, config_codigo, modelo + ~60 métricas\n",
        "\n",
        "        Output: metricas_agregadas/todas_metricas.csv\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(self.resultados_consolidados) == 0:\n",
        "                self.logger.warning(\"No hay datos para consolidar en CSV\")\n",
        "                return\n",
        "\n",
        "            df = pd.DataFrame(self.resultados_consolidados)\n",
        "\n",
        "            ruta_csv = self.config.ruta_salida / \"metricas_agregadas\" / \"todas_metricas.csv\"\n",
        "\n",
        "            df.to_csv(ruta_csv, index=False, encoding='utf-8')\n",
        "\n",
        "            self.logger.info(f\"CSV consolidado guardado: {ruta_csv}\")\n",
        "            self.logger.info(f\"  Filas: {len(df)}\")\n",
        "            self.logger.info(f\"  Columnas: {len(df.columns)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando CSV consolidado: {e}\")\n",
        "\n",
        "    def generar_ranking_top10(self) -> None:\n",
        "        \"\"\"\n",
        "        Genera ranking TOP-10 de configuraciones ordenadas por IoU medio.\n",
        "\n",
        "        Para cada configuración calcula:\n",
        "        - IoU medio, desviación estándar, mínimo, máximo\n",
        "        - Número de fotografías evaluadas\n",
        "        - Modelo al que pertenece\n",
        "\n",
        "        Output: metricas_agregadas/ranking_configuraciones.csv\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(self.resultados_consolidados) == 0:\n",
        "                self.logger.warning(\"No hay datos para generar ranking\")\n",
        "                return\n",
        "\n",
        "            df = pd.DataFrame(self.resultados_consolidados)\n",
        "\n",
        "            # Agrupar por configuración y calcular estadísticas de IoU\n",
        "            ranking = df.groupby('config_codigo').agg({\n",
        "                'iou': ['mean', 'std', 'min', 'max', 'count'],\n",
        "                'modelo': 'first'\n",
        "            }).reset_index()\n",
        "\n",
        "            ranking.columns = ['config_codigo', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'num_fotos', 'modelo']\n",
        "\n",
        "            # Ordenar por IoU medio descendente\n",
        "            ranking = ranking.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "            # TOP-10\n",
        "            top10 = ranking.head(10)\n",
        "\n",
        "            ruta_ranking = self.config.ruta_salida / \"metricas_agregadas\" / \"ranking_configuraciones.csv\"\n",
        "\n",
        "            top10.to_csv(ruta_ranking, index=False, encoding='utf-8')\n",
        "\n",
        "            self.logger.info(f\"Ranking TOP-10 guardado: {ruta_ranking}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando ranking: {e}\")\n",
        "\n",
        "    def generar_estadisticas_por_modelo(self) -> None:\n",
        "        \"\"\"\n",
        "        Genera estadísticas agregadas por modelo.\n",
        "\n",
        "        Para cada modelo calcula:\n",
        "        - Número de configuraciones únicas\n",
        "        - Número total de evaluaciones\n",
        "        - Estadísticas de IoU: media, desviación, min, max, mediana\n",
        "\n",
        "        Output: metricas_agregadas/estadisticas_por_modelo.json\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(self.resultados_consolidados) == 0:\n",
        "                self.logger.warning(\"No hay datos suficientes para generar estadísticas\")\n",
        "                return\n",
        "\n",
        "            df = pd.DataFrame(self.resultados_consolidados)\n",
        "\n",
        "            ruta_stats = self.config.ruta_salida / \"metricas_agregadas\" / \"estadisticas_por_modelo.json\"\n",
        "\n",
        "            stats_por_modelo = {}\n",
        "\n",
        "            for modelo in df['modelo'].unique():\n",
        "                df_modelo = df[df['modelo'] == modelo]\n",
        "\n",
        "                stats_por_modelo[modelo] = {\n",
        "                    'num_configuraciones': int(df_modelo['config_codigo'].nunique()),\n",
        "                    'num_evaluaciones': int(len(df_modelo)),\n",
        "                    'iou': {\n",
        "                        'mean': float(df_modelo['iou'].mean()),\n",
        "                        'std': float(df_modelo['iou'].std()),\n",
        "                        'min': float(df_modelo['iou'].min()),\n",
        "                        'max': float(df_modelo['iou'].max()),\n",
        "                        'median': float(df_modelo['iou'].median())\n",
        "                    }\n",
        "                }\n",
        "\n",
        "            guardar_json_seguro(stats_por_modelo, ruta_stats, self.logger)\n",
        "\n",
        "            self.logger.info(f\"Estadísticas por modelo guardadas: {ruta_stats}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando estadísticas: {e}\")\n",
        "\n",
        "    def guardar_reporte_omisiones(self) -> None:\n",
        "        \"\"\"\n",
        "        Guarda reporte detallado de configuraciones omitidas.\n",
        "\n",
        "        Útil para debugging y auditoría del proceso de evaluación.\n",
        "        Incluye:\n",
        "        - Total de omisiones\n",
        "        - Omisiones por modelo\n",
        "        - Lista detallada de combinaciones foto-config omitidas\n",
        "\n",
        "        Output: metricas_agregadas/configuraciones_omitidas.json\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if len(self.estadisticas_omisiones) == 0:\n",
        "                self.logger.info(\"No hay omisiones para reportar\")\n",
        "                return\n",
        "\n",
        "            ruta_omisiones = self.config.ruta_salida / \"metricas_agregadas\" / \"configuraciones_omitidas.json\"\n",
        "\n",
        "            reporte = {\n",
        "                \"total_omisiones\": sum(len(v) for v in self.estadisticas_omisiones.values()),\n",
        "                \"por_modelo\": {\n",
        "                    modelo: {\n",
        "                        \"count\": len(omisiones),\n",
        "                        \"combinaciones\": omisiones\n",
        "                    }\n",
        "                    for modelo, omisiones in self.estadisticas_omisiones.items()\n",
        "                }\n",
        "            }\n",
        "\n",
        "            guardar_json_seguro(reporte, ruta_omisiones, self.logger)\n",
        "\n",
        "            self.logger.info(f\"Reporte de omisiones guardado: {ruta_omisiones}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error guardando reporte de omisiones: {e}\")"
      ],
      "metadata": {
        "id": "WM0bng7tF7af"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN PRINCIPAL DE EJECUCIÓN INTERACTIVA\n",
        "# =============================================================================\n",
        "\n",
        "def ejecutar_fase2a_interactivo(ruta_base_tfm: str = \"/content/drive/MyDrive/TFM\") -> Optional[OrquestadorFase2A]:\n",
        "    \"\"\"\n",
        "    Ejecuta el pipeline completo de Fase 2A con selección interactiva.\n",
        "\n",
        "    Args:\n",
        "        ruta_base_tfm: Ruta base del proyecto TFM\n",
        "\n",
        "    Returns:\n",
        "        OrquestadorFase2A con resultados, o None si cancelado\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"FASE 2A - EVALUACIÓN CUANTITATIVA Y ANÁLISIS GEOMÉTRICO\")\n",
        "    print(\"Trabajo Fin de Máster - Universidad Oberta de Catalunya\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Configuración\n",
        "    config = ConfiguracionFase2A(\n",
        "        ruta_base_tfm=Path(ruta_base_tfm),\n",
        "        max_dimension_mahotas=1024,\n",
        "        ancho_borde_px=5,\n",
        "        usar_checkpoint=True,\n",
        "        guardar_json_individuales=True,\n",
        "        guardar_csv_consolidado=True,\n",
        "        guardar_estadisticas=True,\n",
        "        nivel_logging=NivelLogging.NORMAL\n",
        "    )\n",
        "\n",
        "    # Cargar índice maestro\n",
        "    ruta_indice = config.ruta_fase1 / \"indice_maestro.json\"\n",
        "\n",
        "    if not ruta_indice.exists():\n",
        "        raise FileNotFoundError(f\"Índice maestro no encontrado: {ruta_indice}\")\n",
        "\n",
        "    with open(ruta_indice, 'r', encoding='utf-8') as f:\n",
        "        indice_maestro = json.load(f)\n",
        "\n",
        "    # Selección de modelos\n",
        "    logger_temp = logging.getLogger('Selector')\n",
        "    logger_temp.setLevel(logging.INFO)\n",
        "\n",
        "    selector = SelectorModelos(indice_maestro, logger_temp)\n",
        "\n",
        "    configuraciones_seleccionadas = selector.seleccionar()\n",
        "\n",
        "    if configuraciones_seleccionadas is None:\n",
        "        print(\"\\nEjecución cancelada por el usuario\")\n",
        "        return None\n",
        "\n",
        "    # Configuración de nivel de logging\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CONFIGURACIÓN DE NIVEL DE LOGGING\")\n",
        "    print(\"=\"*80)\n",
        "    print(\"\\n1. MINIMAL - Solo resumen por foto\")\n",
        "    print(\"2. NORMAL - Progreso con detalle moderado (recomendado)\")\n",
        "    print(\"3. DETAILED - Información detallada por configuración\")\n",
        "    print(\"4. DEBUG - Máximo detalle para debugging\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            nivel_input = input(\"\\nSeleccione nivel [1-4, default=2]: \").strip()\n",
        "\n",
        "            if nivel_input == '' or nivel_input == '2':\n",
        "                config.nivel_logging = NivelLogging.NORMAL\n",
        "                break\n",
        "            elif nivel_input == '1':\n",
        "                config.nivel_logging = NivelLogging.MINIMAL\n",
        "                break\n",
        "            elif nivel_input == '3':\n",
        "                config.nivel_logging = NivelLogging.DETAILED\n",
        "                break\n",
        "            elif nivel_input == '4':\n",
        "                config.nivel_logging = NivelLogging.DEBUG\n",
        "                break\n",
        "            else:\n",
        "                print(\"Por favor ingrese un número entre 1 y 4\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nEjecución cancelada por el usuario\")\n",
        "            return None\n",
        "\n",
        "    # Resumen de configuración\n",
        "    print(f\"\\nConfiguración:\")\n",
        "    print(f\"  - Ruta base: {config.ruta_base_tfm}\")\n",
        "    print(f\"  - Ruta Fase 1: {config.ruta_fase1}\")\n",
        "    print(f\"  - Ruta salida: {config.ruta_salida}\")\n",
        "    print(f\"  - Configuraciones a procesar: {len(configuraciones_seleccionadas)}\")\n",
        "    print(f\"  - Nivel logging: {config.nivel_logging.value}\")\n",
        "    print(f\"  - Checkpoint: {config.usar_checkpoint}\")\n",
        "    print()\n",
        "\n",
        "    # Crear orquestador y ejecutar\n",
        "    orquestador = OrquestadorFase2A(config, configuraciones_seleccionadas)\n",
        "\n",
        "    orquestador.ejecutar()\n",
        "\n",
        "    return orquestador"
      ],
      "metadata": {
        "id": "0m5YJv7zGI19"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PUNTO DE ENTRADA\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    RUTA_BASE_TFM = \"/content/drive/MyDrive/TFM\"\n",
        "\n",
        "    try:\n",
        "        orquestador = ejecutar_fase2a_interactivo(RUTA_BASE_TFM)\n",
        "\n",
        "        if orquestador is None:\n",
        "            print(\"\\nEjecución cancelada\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        # Resumen final\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"RESUMEN DE EJECUCIÓN\")\n",
        "        print(\"=\"*80)\n",
        "        print(f\"Fotografías procesadas: {len(orquestador.checkpoint.fotos_procesadas) if orquestador.checkpoint else 'N/A'}\")\n",
        "        print(f\"Evaluaciones exitosas: {len(orquestador.resultados_consolidados)}\")\n",
        "\n",
        "        if orquestador.estadisticas_omisiones:\n",
        "            total_omisiones = sum(len(v) for v in orquestador.estadisticas_omisiones.values())\n",
        "            print(f\"Configuraciones omitidas: {total_omisiones}\")\n",
        "\n",
        "        print(f\"\\nResultados disponibles en:\")\n",
        "        print(f\"  - JSONs individuales: {orquestador.config.ruta_salida / 'metricas_individuales'}\")\n",
        "        print(f\"  - CSV consolidado: {orquestador.config.ruta_salida / 'metricas_agregadas' / 'todas_metricas.csv'}\")\n",
        "        print(f\"  - Ranking TOP-10: {orquestador.config.ruta_salida / 'metricas_agregadas' / 'ranking_configuraciones.csv'}\")\n",
        "        print(f\"  - Estadísticas: {orquestador.config.ruta_salida / 'metricas_agregadas' / 'estadisticas_por_modelo.json'}\")\n",
        "        print(f\"  - Reporte omisiones: {orquestador.config.ruta_salida / 'metricas_agregadas' / 'configuraciones_omitidas.json'}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"FASE 2A COMPLETADA EXITOSAMENTE\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n\\nEjecución interrumpida por el usuario\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nERROR DURANTE EJECUCIÓN: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gcytrk9ZGPZP",
        "outputId": "96a7a341-c027-423c-9493-6cba7d8fac06"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FASE 2A - EVALUACIÓN CUANTITATIVA Y ANÁLISIS GEOMÉTRICO\n",
            "Trabajo Fin de Máster - Universidad Oberta de Catalunya\n",
            "================================================================================\n",
            "\n",
            "\n",
            "================================================================================\n",
            "SELECCIÓN DE MODELOS PARA PROCESAMIENTO\n",
            "================================================================================\n",
            "\n",
            "Modelos disponibles:\n",
            "\n",
            "1. BODYPIX\n",
            "   Configuraciones: 24\n",
            "\n",
            "2. MASK2FORMER\n",
            "   Configuraciones: 19\n",
            "\n",
            "3. ONEFORMER\n",
            "   Configuraciones: 36\n",
            "\n",
            "4. SAM2\n",
            "   Configuraciones: 12\n",
            "\n",
            "5. SAM2 PROMPTS\n",
            "   Configuraciones: 32\n",
            "\n",
            "6. YOLOV8\n",
            "   Configuraciones: 20\n",
            "\n",
            "7. TODOS LOS MODELOS\n",
            "   Total: 143 configuraciones\n",
            "\n",
            "8. SELECCIÓN MÚLTIPLE (separar con comas)\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Seleccione opción [1-8]: 1\n",
            "\n",
            "================================================================================\n",
            "RESUMEN DE SELECCIÓN\n",
            "================================================================================\n",
            "\n",
            "Total de configuraciones seleccionadas: 24\n",
            "\n",
            "Primeras 10 configuraciones:\n",
            "  - bodypix_mobilenet_v1_050_baja_sensibilidad_t0_3\n",
            "  - bodypix_mobilenet_v1_050_baja_sensibilidad_t0_4\n",
            "  - bodypix_mobilenet_v1_050_baja_sensibilidad_t0_5\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_alta_t0_15\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_alta_t0_2\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_alta_t0_25\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_media_t0_2\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_media_t0_3\n",
            "  - bodypix_mobilenet_v1_050_sensibilidad_media_t0_4\n",
            "  - bodypix_mobilenet_v1_050_ultra_sensible_t0_1\n",
            "  ... y 14 más\n",
            "\n",
            "================================================================================\n",
            "\n",
            "¿Continuar con esta selección? [S/n]: s\n",
            "\n",
            "================================================================================\n",
            "CONFIGURACIÓN DE NIVEL DE LOGGING\n",
            "================================================================================\n",
            "\n",
            "1. MINIMAL - Solo resumen por foto\n",
            "2. NORMAL - Progreso con detalle moderado (recomendado)\n",
            "3. DETAILED - Información detallada por configuración\n",
            "4. DEBUG - Máximo detalle para debugging\n",
            "\n",
            "Seleccione nivel [1-4, default=2]: 4\n",
            "\n",
            "Configuración:\n",
            "  - Ruta base: /content/drive/MyDrive/TFM\n",
            "  - Ruta Fase 1: /content/drive/MyDrive/TFM/3_Analisis/fase1_integracion\n",
            "  - Ruta salida: /content/drive/MyDrive/TFM/3_Analisis/fase2_evaluacion\n",
            "  - Configuraciones a procesar: 24\n",
            "  - Nivel logging: debug\n",
            "  - Checkpoint: True\n",
            "\n",
            "[20:51:55] INFO     | Índice maestro cargado: 20 fotografías\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Índice maestro cargado: 20 fotografías\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | \n",
            "Iniciando Fase 2A - Evaluación Cuantitativa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:\n",
            "Iniciando Fase 2A - Evaluación Cuantitativa\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | Configuraciones a evaluar: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Configuraciones a evaluar: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | Fotografías disponibles: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Fotografías disponibles: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | Fotografías pendientes: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Fotografías pendientes: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | Fotografías ya procesadas: 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Fotografías ya procesadas: 0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | \n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | Procesando fotografía: _DSC0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:Procesando fotografía: _DSC0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] INFO     | ================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OrquestadorFase2A:================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] DEBUG    | Claves en NPZ: ['masks', 'scores', 'metadata']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['masks', 'scores', 'metadata']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:55] DEBUG    | Cargada máscara Ground Truth CVAT, shape: (6000, 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara Ground Truth CVAT, shape: (6000, 4000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:56] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:56] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:56] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:57] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:57] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:57] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:58] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:58] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:58] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:59] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:51:59] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:00] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_baja_sensibilidad_t0_5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:00] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:00] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:01] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:01] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:02] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:02] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:02] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:02] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:02] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:03] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:03] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:03] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:03] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:03] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:04] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_sensibilidad_alta_t0_25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:04] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:04] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:04] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:04] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:05] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_sensibilidad_media_t0_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_sensibilidad_media_t0_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:05] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:05] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:05] ERROR    | Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error en unary_union: name 'unary_union' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:05] ERROR    | Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:OrquestadorFase2A:Error calculando métricas comparativas: operands could not be broadcast together with shapes (4096,2734) (6000,4000) \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:06] DEBUG    |   Procesando config: bodypix_mobilenet_v1_050_sensibilidad_media_t0_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:  Procesando config: bodypix_mobilenet_v1_050_sensibilidad_media_t0_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:06] DEBUG    | Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Claves en NPZ: ['person_mask', 'probability_mask', 'threshold_value', 'body_parts_mask', 'grupo_cara', 'grupo_torso', 'grupo_brazos', 'grupo_manos', 'grupo_piernas', 'grupo_pies']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20:52:06] DEBUG    | Cargada máscara unificada, shape: (4096, 2734)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:OrquestadorFase2A:Cargada máscara unificada, shape: (4096, 2734)\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Ejecución interrumpida por el usuario\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2135785638.py\", line 10, in <cell line: 0>\n",
            "    orquestador = ejecutar_fase2a_interactivo(RUTA_BASE_TFM)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-4285730203.py\", line 98, in ejecutar_fase2a_interactivo\n",
            "    orquestador.ejecutar()\n",
            "  File \"/tmp/ipython-input-2093944007.py\", line 375, in ejecutar\n",
            "    self.procesar_fotografia(info_foto)\n",
            "  File \"/tmp/ipython-input-2093944007.py\", line 273, in procesar_fotografia\n",
            "    geom_pred = mascara_a_shapely(mascara_pred, self.logger)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1528737909.py\", line 209, in mascara_a_shapely\n",
            "    contornos = measure.find_contours(mascara_binaria, level=0.5)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/skimage/measure/_find_contours.py\", line 149, in find_contours\n",
            "    contours = _assemble_contours(segments)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/skimage/measure/_find_contours.py\", line 188, in _assemble_contours\n",
            "    ends[head[-1]] = (head, head_num)\n",
            "    ~~~~^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-2135785638.py\", line 40, in <cell line: 0>\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2135785638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0morquestador\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mejecutar_fase2a_interactivo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUTA_BASE_TFM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4285730203.py\u001b[0m in \u001b[0;36mejecutar_fase2a_interactivo\u001b[0;34m(ruta_base_tfm)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0morquestador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mejecutar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2093944007.py\u001b[0m in \u001b[0;36mejecutar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocesar_fotografia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_foto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2093944007.py\u001b[0m in \u001b[0;36mprocesar_fotografia\u001b[0;34m(self, info_foto)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;31m# Convertir predicción a Shapely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mgeom_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmascara_a_shapely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmascara_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1528737909.py\u001b[0m in \u001b[0;36mmascara_a_shapely\u001b[0;34m(mascara, logger)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Encontrar contornos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontornos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeasure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmascara_binaria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/skimage/measure/_find_contours.py\u001b[0m in \u001b[0;36mfind_contours\u001b[0;34m(image, level, fully_connected, positive_orientation, mask)\u001b[0m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mcontours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_assemble_contours\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpositive_orientation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'high'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/skimage/measure/_find_contours.py\u001b[0m in \u001b[0;36m_assemble_contours\u001b[0;34m(segments)\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mstarts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                     \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# tail_num <= head_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2135785638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nEjecución interrumpida por el usuario\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYJOVMCkPKrU"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}