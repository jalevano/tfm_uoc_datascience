{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMt+df7WRbMGKdaU7H6ecEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/01_Mask2Former_Recopilacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluador Mask2Former para recolecci√≥n de M√©tricas\n",
        "**Recopilaci√≥n de todas las m√©tricas posibles sin ground truth.**\n",
        "\n",
        "- Autor: Jes√∫s L.\n",
        "- Proyecto: TFM. Evaluaci√≥n comparativa de t√©cnicas de segmentaci√≥n."
      ],
      "metadata": {
        "id": "a8lOSAZmzYlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2pdz2A9tsSqk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation\n",
        "from PIL import Image, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import measure\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. Montar Google Drive\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta a tu dataset en Google Drive\n",
        "DATASET_PATH = \"/content/drive/MyDrive/TFM/mask2former/imagenes\"\n",
        "# Carpeta donde se guardar√°n los resultados\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/TFM/mask2former/resultados\"\n",
        "\n",
        "# Crear carpeta de resultados si no existe\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "os.makedirs(f\"{OUTPUT_PATH}/debug_visualizations\", exist_ok=True)\n",
        "\n",
        "# Lista de modelos a evaluar\n",
        "MODELOS = [\n",
        "    \"facebook/mask2former-swin-large-coco-instance\",\n",
        "    \"facebook/mask2former-swin-base-ade-semantic\",\n",
        "    \"facebook/mask2former-swin-small-coco-instance\"\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qqQBwP7t_vDN",
        "outputId": "208a07a1-f289-4ebc-915b-6be80f9c59df"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RecolectorMetricasCompletas:\n",
        "    \"\"\"\n",
        "    Recolecta todas las m√©tricas posibles de una segmentaci√≥n sin ground truth.\n",
        "    Versi√≥n mejorada con debug y detecci√≥n forzada.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.debug_mode = config.get('debug', True)\n",
        "        self.forzar_deteccion = config.get('forzar_deteccion', True)\n",
        "\n",
        "        # Usar AutoModelForUniversalSegmentation para todos los modelos mask2former\n",
        "        try:\n",
        "            self.processor = AutoImageProcessor.from_pretrained(config['model_name'])\n",
        "            self.model = AutoModelForUniversalSegmentation.from_pretrained(config['model_name'])\n",
        "            print(f\"Modelo cargado exitosamente: {config['model_name']}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error cargando modelo {config['model_name']}: {e}\")\n",
        "            raise\n",
        "\n",
        "        self.device = torch.device(config['device'])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Crear directorios\n",
        "        self.output_dir = Path(config['output_dir'])\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        (self.output_dir / 'datos_completos').mkdir(exist_ok=True)\n",
        "        (self.output_dir / 'debug_visualizations').mkdir(exist_ok=True)\n",
        "\n",
        "        self.resultados = []\n",
        "        print(f\"Modelo cargado en {self.device}\")\n",
        "        print(f\"Debug mode: {self.debug_mode}\")\n",
        "        print(f\"Forzar detecci√≥n: {self.forzar_deteccion}\")\n",
        "\n",
        "    def preprocesar_imagen(self, ruta, max_size=1024):\n",
        "        \"\"\"Preprocesa la imagen redimension√°ndola si es necesario.\"\"\"\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "        original_size = img.size\n",
        "        img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
        "        if self.debug_mode:\n",
        "            print(f\"  Imagen redimensionada de {original_size} a {img.size}\")\n",
        "        return img\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen):\n",
        "        \"\"\"Procesa una imagen y recolecta TODAS las m√©tricas posibles.\"\"\"\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # 1. CARGA Y AN√ÅLISIS B√ÅSICO DE IMAGEN\n",
        "            imagen_pil = self.preprocesar_imagen(ruta_imagen)\n",
        "            imagen_np = np.array(imagen_pil)\n",
        "            h, w = imagen_np.shape[:2]\n",
        "\n",
        "            # Hash √∫nico para la imagen\n",
        "            ruta_imagen = Path(ruta_imagen)\n",
        "            hash_img = hashlib.md5(open(ruta_imagen, 'rb').read()).hexdigest()[:12]\n",
        "\n",
        "            if self.debug_mode:\n",
        "                print(f\"  Procesando imagen: {h}x{w} pixels\")\n",
        "\n",
        "            # Estad√≠sticas b√°sicas de la imagen\n",
        "            stat = ImageStat.Stat(imagen_pil)\n",
        "            gray = cv2.cvtColor(imagen_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # 2. AN√ÅLISIS VISUAL DE LA IMAGEN (sin modelo)\n",
        "            metricas_imagen = {\n",
        "                'archivo': os.path.basename(ruta_imagen),\n",
        "                'hash': hash_img,\n",
        "                'resolucion_w': w,\n",
        "                'resolucion_h': h,\n",
        "                'aspect_ratio': w/h,\n",
        "                'area_total': w*h,\n",
        "                'brillo_promedio': float(np.mean(gray)),\n",
        "                'brillo_std': float(np.std(gray)),\n",
        "                'rgb_mean_r': float(stat.mean[0]),\n",
        "                'rgb_mean_g': float(stat.mean[1]),\n",
        "                'rgb_mean_b': float(stat.mean[2]),\n",
        "                'rgb_std_r': float(stat.stddev[0]),\n",
        "                'rgb_std_g': float(stat.stddev[1]),\n",
        "                'rgb_std_b': float(stat.stddev[2]),\n",
        "                'varianza_laplacian': float(cv2.Laplacian(gray, cv2.CV_64F).var()),\n",
        "                'entropia': self._calcular_entropia(gray),\n",
        "                'densidad_bordes': self._calcular_densidad_bordes(gray),\n",
        "                'saturacion_media': float(np.mean(cv2.cvtColor(imagen_np, cv2.COLOR_RGB2HSV)[:,:,1])),\n",
        "                'saturacion_std': float(np.std(cv2.cvtColor(imagen_np, cv2.COLOR_RGB2HSV)[:,:,1])),\n",
        "                'contraste_local_std': float(np.std([cv2.Laplacian(gray[i:i+32, j:j+32], cv2.CV_64F).var()\n",
        "                                                   for i in range(0, h-32, 32)\n",
        "                                                   for j in range(0, w-32, 32) if i+32<h and j+32<w]))\n",
        "            }\n",
        "\n",
        "            # 3. RECURSOS ANTES DE INFERENCIA\n",
        "            recursos_antes = self._obtener_recursos()\n",
        "\n",
        "            # 4. INFERENCIA DEL MODELO\n",
        "            inputs = self.processor(images=imagen_pil, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            tiempo_inferencia_inicio = time.time()\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "\n",
        "            tiempo_inferencia = (time.time() - tiempo_inferencia_inicio) * 1000\n",
        "\n",
        "            if self.debug_mode:\n",
        "                print(f\"  Inferencia completada en {tiempo_inferencia:.1f}ms\")\n",
        "\n",
        "            # 5. POST-PROCESAMIENTO CON M√öLTIPLES UMBRALES Y DEBUG\n",
        "            umbrales = [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7]\n",
        "            resultados_por_umbral = {}\n",
        "\n",
        "            debug_info = {\n",
        "                'todas_las_detecciones': {},\n",
        "                'clases_detectadas': set(),\n",
        "                'scores_por_clase': {}\n",
        "            }\n",
        "\n",
        "            for umbral in umbrales:\n",
        "                try:\n",
        "                    # POST-PROCESAMIENTO PRINCIPAL\n",
        "                    resultado = self.processor.post_process_instance_segmentation(\n",
        "                        outputs, target_sizes=[(h, w)], threshold=umbral\n",
        "                    )[0]\n",
        "\n",
        "                    if self.debug_mode:\n",
        "                        total_detecciones = len(resultado.get(\"labels\", []))\n",
        "                        print(f\"    Umbral {umbral}: {total_detecciones} detecciones totales\")\n",
        "\n",
        "                        # Debug: mostrar todas las clases detectadas\n",
        "                        if \"labels\" in resultado and \"scores\" in resultado:\n",
        "                            for label, score in zip(resultado[\"labels\"], resultado[\"scores\"]):\n",
        "                                clase = int(label.item())\n",
        "                                score_val = float(score.item())\n",
        "                                debug_info['clases_detectadas'].add(clase)\n",
        "                                debug_info['scores_por_clase'].setdefault(clase, []).append(score_val)\n",
        "\n",
        "                                if self.debug_mode and umbral == 0.1:  # Solo mostrar para un umbral\n",
        "                                    print(f\"      Clase {clase}: score {score_val:.3f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    if self.debug_mode:\n",
        "                        print(f\"    Error en post-processing para umbral {umbral}: {e}\")\n",
        "                    try:\n",
        "                        # Fallback: segmentaci√≥n sem√°ntica\n",
        "                        resultado = self.processor.post_process_semantic_segmentation(\n",
        "                            outputs, target_sizes=[(h, w)]\n",
        "                        )[0]\n",
        "                        resultado = self._convertir_semantico_a_instancia(resultado, umbral)\n",
        "                    except:\n",
        "                        resultado = {'labels': [], 'masks': [], 'scores': []}\n",
        "\n",
        "                # Extraer TODAS las detecciones (no solo personas)\n",
        "                todas_detecciones = []\n",
        "                mascaras_personas = []\n",
        "                scores_personas = []\n",
        "\n",
        "                if 'labels' in resultado and 'masks' in resultado:\n",
        "                    labels = resultado.get(\"labels\", [])\n",
        "                    scores = resultado.get(\"scores\", [1.0] * len(labels))\n",
        "                    masks = resultado.get(\"masks\", [])\n",
        "\n",
        "                    for i, (label, score) in enumerate(zip(labels, scores)):\n",
        "                        clase = int(label.item() if hasattr(label, 'item') else label)\n",
        "                        score_val = float(score.item() if hasattr(score, 'item') else score)\n",
        "\n",
        "                        todas_detecciones.append({\n",
        "                            'clase': clase,\n",
        "                            'score': score_val,\n",
        "                            'area': int(torch.sum(masks[i]).item()) if i < len(masks) else 0\n",
        "                        })\n",
        "\n",
        "                        # Personas (clase 0)\n",
        "                        if clase == 0:\n",
        "                            if i < len(masks):\n",
        "                                mask = masks[i].cpu().numpy().squeeze() > 0.5\n",
        "                                mascaras_personas.append(mask)\n",
        "                                scores_personas.append(score_val)\n",
        "\n",
        "                # FORZAR DETECCI√ìN: Si no hay personas pero hay otras detecciones humanas\n",
        "                if self.forzar_deteccion and len(mascaras_personas) == 0:\n",
        "                    # Buscar clases que podr√≠an ser personas (0=person en COCO)\n",
        "                    # Si no hay clase 0, buscar la detecci√≥n con mayor score que pueda ser humana\n",
        "                    clases_humanas = [0]  # person\n",
        "                    detecciones_candidatas = [d for d in todas_detecciones if d['clase'] in clases_humanas]\n",
        "\n",
        "                    if not detecciones_candidatas and len(todas_detecciones) > 0:\n",
        "                        # Si no hay detecciones de personas, usar la detecci√≥n con mayor score\n",
        "                        mejor_deteccion = max(todas_detecciones, key=lambda x: x['score'])\n",
        "                        if mejor_deteccion['score'] > 0.01:  # Umbral muy bajo\n",
        "                            if self.debug_mode:\n",
        "                                print(f\"    FORZANDO: Usando clase {mejor_deteccion['clase']} como persona (score: {mejor_deteccion['score']:.3f})\")\n",
        "                            # Crear m√°scara ficticia basada en la mejor detecci√≥n\n",
        "                            idx_mejor = next(i for i, d in enumerate(todas_detecciones) if d == mejor_deteccion)\n",
        "                            if idx_mejor < len(masks):\n",
        "                                mask = masks[idx_mejor].cpu().numpy().squeeze() > 0.5\n",
        "                                mascaras_personas.append(mask)\n",
        "                                scores_personas.append(mejor_deteccion['score'])\n",
        "\n",
        "                # M√°scara combinada de todas las personas\n",
        "                if mascaras_personas:\n",
        "                    mascara_combinada = np.logical_or.reduce(mascaras_personas)\n",
        "                else:\n",
        "                    mascara_combinada = np.zeros((h, w), dtype=bool)\n",
        "\n",
        "                # M√©tricas por umbral\n",
        "                resultados_por_umbral[f'umbral_{umbral}'] = {\n",
        "                    'num_detecciones': len(mascaras_personas),\n",
        "                    'num_detecciones_totales': len(todas_detecciones),\n",
        "                    'todas_las_clases': [d['clase'] for d in todas_detecciones],\n",
        "                    'todos_los_scores': [d['score'] for d in todas_detecciones],\n",
        "                    'scores_personas': scores_personas,\n",
        "                    'area_segmentada': int(np.sum(mascara_combinada)),\n",
        "                    'porcentaje_imagen': float(np.sum(mascara_combinada) / (h*w) * 100),\n",
        "                    'coherencia': self._metricas_coherencia(mascara_combinada)\n",
        "                }\n",
        "\n",
        "                debug_info['todas_las_detecciones'][f'umbral_{umbral}'] = todas_detecciones\n",
        "\n",
        "            # 6. CREAR VISUALIZACI√ìN DEBUG\n",
        "            if self.debug_mode:\n",
        "                self._crear_visualizacion_debug(imagen_np, resultados_por_umbral, hash_img)\n",
        "\n",
        "            # 7. AN√ÅLISIS PAN√ìPTICO\n",
        "            metricas_panoptico = {}\n",
        "            try:\n",
        "                resultado_panoptico = self.processor.post_process_panoptic_segmentation(\n",
        "                    outputs, target_sizes=[(h, w)]\n",
        "                )[0]\n",
        "\n",
        "                if 'segments_info' in resultado_panoptico:\n",
        "                    segmentos = resultado_panoptico['segments_info']\n",
        "                    categorias = [seg.get('category_id', -1) for seg in segmentos]\n",
        "\n",
        "                    metricas_panoptico = {\n",
        "                        'total_segmentos': len(segmentos),\n",
        "                        'categorias_unicas': len(set(categorias)),\n",
        "                        'areas_segmentos': [seg.get('area', 0) for seg in segmentos],\n",
        "                        'distribucion_categorias': {str(k): categorias.count(k) for k in set(categorias)},\n",
        "                        'segmentos_persona': sum(1 for seg in segmentos if seg.get('category_id') == 0)\n",
        "                    }\n",
        "\n",
        "                    if self.debug_mode:\n",
        "                        print(f\"  Pan√≥ptico: {len(segmentos)} segmentos, categor√≠as: {set(categorias)}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                metricas_panoptico = {'error': f'Pan√≥ptico no disponible: {str(e)}'}\n",
        "\n",
        "            # 8. RECURSOS DESPU√âS DE INFERENCIA\n",
        "            recursos_despues = self._obtener_recursos()\n",
        "            tiempo_total = (time.time() - inicio) * 1000\n",
        "\n",
        "            # 9. AN√ÅLISIS DE LA MEJOR DETECCI√ìN\n",
        "            mejor_resultado = resultados_por_umbral.get('umbral_0.1', resultados_por_umbral.get('umbral_0.5', {}))\n",
        "\n",
        "            # 10. CLASIFICACI√ìN AUTOM√ÅTICA DE CONTEXTO\n",
        "            contexto = self._clasificar_contexto_automatico(\n",
        "                imagen_np,\n",
        "                mejor_resultado.get('num_detecciones', 0),\n",
        "                metricas_imagen\n",
        "            )\n",
        "\n",
        "            # 11. RESULTADO FINAL COMPLETO\n",
        "            resultado_completo = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'id_procesamiento': f\"{hash_img}_{int(time.time())}\",\n",
        "                'imagen': metricas_imagen,\n",
        "                'rendimiento': {\n",
        "                    'tiempo_inferencia_ms': tiempo_inferencia,\n",
        "                    'tiempo_total_ms': tiempo_total,\n",
        "                    'memoria_antes_mb': recursos_antes.get('memoria_usada_mb', 0),\n",
        "                    'memoria_despues_mb': recursos_despues.get('memoria_usada_mb', 0),\n",
        "                    'memoria_gpu_mb': recursos_despues.get('gpu_memoria_mb', 0),\n",
        "                    'cpu_percent': recursos_despues.get('cpu_percent', 0)\n",
        "                },\n",
        "                'segmentacion': resultados_por_umbral,\n",
        "                'panoptico': metricas_panoptico,\n",
        "                'contexto': contexto,\n",
        "                'debug_info': debug_info,\n",
        "                'modelo': {\n",
        "                    'nombre': self.config['model_name'],\n",
        "                    'device': str(self.device),\n",
        "                    'confianza_umbral_principal': 0.1,\n",
        "                    'forzar_deteccion': self.forzar_deteccion\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Debug final\n",
        "            if self.debug_mode:\n",
        "                personas_detectadas = mejor_resultado.get('num_detecciones', 0)\n",
        "                total_detectado = mejor_resultado.get('num_detecciones_totales', 0)\n",
        "                print(f\"  RESULTADO FINAL: {personas_detectadas} personas, {total_detectado} detecciones totales\")\n",
        "                print(f\"  Clases detectadas: {sorted(list(debug_info['clases_detectadas']))}\")\n",
        "\n",
        "            del inputs, outputs, imagen_pil, imagen_np\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            return resultado_completo\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error procesando {ruta_imagen}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {'archivo': os.path.basename(ruta_imagen)},\n",
        "                'error': str(e),\n",
        "                'procesamiento_fallido': True\n",
        "            }\n",
        "\n",
        "    def _crear_visualizacion_debug(self, imagen_np, resultados_por_umbral, hash_img):\n",
        "        \"\"\"Crea visualizaciones para debug.\"\"\"\n",
        "        try:\n",
        "            fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "            axes = axes.flatten()\n",
        "\n",
        "            # Imagen original\n",
        "            axes[0].imshow(imagen_np)\n",
        "            axes[0].set_title('Imagen Original')\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # Resultados por umbral\n",
        "            umbrales_viz = [0.01, 0.1, 0.3, 0.5, 0.9]\n",
        "            for i, umbral in enumerate(umbrales_viz):\n",
        "                if i+1 < len(axes):\n",
        "                    resultado = resultados_por_umbral.get(f'umbral_{umbral}', {})\n",
        "                    num_personas = resultado.get('num_detecciones', 0)\n",
        "                    num_total = resultado.get('num_detecciones_totales', 0)\n",
        "\n",
        "                    axes[i+1].imshow(imagen_np)\n",
        "                    axes[i+1].set_title(f'Umbral {umbral}\\n{num_personas} personas, {num_total} total')\n",
        "                    axes[i+1].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            debug_path = self.output_dir / 'debug_visualizations' / f'debug_{hash_img}.png'\n",
        "            plt.savefig(debug_path, dpi=150, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            print(f\"  Debug viz guardada: {debug_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error creando visualizaci√≥n debug: {e}\")\n",
        "\n",
        "    def _convertir_semantico_a_instancia(self, resultado_semantico, umbral):\n",
        "        \"\"\"Convierte resultado de segmentaci√≥n sem√°ntica a formato de instancia.\"\"\"\n",
        "        if hasattr(resultado_semantico, 'cpu'):\n",
        "            mask = resultado_semantico.cpu().numpy()\n",
        "        else:\n",
        "            mask = resultado_semantico\n",
        "\n",
        "        # Encontrar p√≠xeles de personas (asumiendo que la clase 0 es persona)\n",
        "        persona_mask = (mask == 0)\n",
        "\n",
        "        if np.any(persona_mask):\n",
        "            return {\n",
        "                'labels': [0],\n",
        "                'masks': [torch.from_numpy(persona_mask.astype(np.float32))],\n",
        "                'scores': [1.0]\n",
        "            }\n",
        "        else:\n",
        "            return {'labels': [], 'masks': [], 'scores': []}\n",
        "\n",
        "    def _calcular_entropia(self, imagen_gray):\n",
        "        \"\"\"Calcula la entrop√≠a de Shannon de la imagen.\"\"\"\n",
        "        histogram, _ = np.histogram(imagen_gray, bins=256, range=(0, 256))\n",
        "        histogram = histogram + 1e-7  # Evitar log(0)\n",
        "        prob = histogram / np.sum(histogram)\n",
        "        return float(-np.sum(prob * np.log2(prob)))\n",
        "\n",
        "    def _calcular_densidad_bordes(self, imagen_gray):\n",
        "        \"\"\"Calcula densidad de bordes usando Canny.\"\"\"\n",
        "        edges = cv2.Canny(imagen_gray, 50, 150)\n",
        "        return float(np.sum(edges > 0) / edges.size)\n",
        "\n",
        "    def _metricas_coherencia(self, mascara):\n",
        "        \"\"\"M√©tricas de coherencia espacial de una m√°scara.\"\"\"\n",
        "        if np.sum(mascara) == 0:\n",
        "            return {\n",
        "                'area': 0,\n",
        "                'componentes': 0,\n",
        "                'compacidad': 0.0,\n",
        "                'solidez': 0.0\n",
        "            }\n",
        "\n",
        "        # Componentes conectados\n",
        "        labeled = measure.label(mascara)\n",
        "        num_componentes = int(labeled.max())\n",
        "\n",
        "        # Contornos para otras m√©tricas\n",
        "        contours, _ = cv2.findContours(mascara.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            contorno_principal = max(contours, key=cv2.contourArea)\n",
        "            area = cv2.contourArea(contorno_principal)\n",
        "            perimetro = cv2.arcLength(contorno_principal, True)\n",
        "\n",
        "            # Convex hull\n",
        "            hull = cv2.convexHull(contorno_principal)\n",
        "            area_hull = cv2.contourArea(hull)\n",
        "\n",
        "            # M√©tricas\n",
        "            compacidad = (4 * np.pi * area) / (perimetro ** 2) if perimetro > 0 else 0\n",
        "            solidez = area / area_hull if area_hull > 0 else 0\n",
        "\n",
        "            return {\n",
        "                'area': int(area),\n",
        "                'componentes': num_componentes,\n",
        "                'compacidad': float(compacidad),\n",
        "                'solidez': float(solidez),\n",
        "                'perimetro': float(perimetro)\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'area': int(np.sum(mascara)),\n",
        "            'componentes': num_componentes,\n",
        "            'compacidad': 0.0,\n",
        "            'solidez': 0.0\n",
        "        }\n",
        "\n",
        "    def _obtener_recursos(self):\n",
        "        \"\"\"Obtiene informaci√≥n de recursos del sistema.\"\"\"\n",
        "        try:\n",
        "            mem = psutil.virtual_memory()\n",
        "            recursos = {\n",
        "                'memoria_usada_mb': mem.used / (1024*1024),\n",
        "                'cpu_percent': psutil.cpu_percent()\n",
        "            }\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                recursos['gpu_memoria_mb'] = torch.cuda.memory_allocated() / (1024*1024)\n",
        "\n",
        "            return recursos\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _clasificar_contexto_automatico(self, imagen, num_personas, metricas_img):\n",
        "        \"\"\"Clasificaci√≥n autom√°tica de contexto basada en m√©tricas.\"\"\"\n",
        "\n",
        "        # Reglas simples de clasificaci√≥n\n",
        "        if num_personas == 0:\n",
        "            categoria = 'sin_personas'\n",
        "        elif num_personas == 1:\n",
        "            if metricas_img['densidad_bordes'] < 0.1:\n",
        "                categoria = 'retrato_simple'\n",
        "            else:\n",
        "                categoria = 'retrato_complejo'\n",
        "        else:\n",
        "            categoria = 'multiples_personas'\n",
        "\n",
        "        # An√°lisis de complejidad\n",
        "        complejidad = (\n",
        "            metricas_img['densidad_bordes'] * 0.4 +\n",
        "            min(metricas_img['varianza_laplacian'] / 1000, 1.0) * 0.3 +\n",
        "            (metricas_img['contraste_local_std'] / 100) * 0.3\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'categoria': categoria,\n",
        "            'complejidad_score': float(min(complejidad, 1.0)),\n",
        "            'num_personas_detectadas': num_personas,\n",
        "            'iluminacion': 'baja' if metricas_img['brillo_promedio'] < 80 else\n",
        "                         'alta' if metricas_img['brillo_promedio'] > 180 else 'normal'\n",
        "        }\n",
        "\n",
        "    def evaluar_dataset(self, rutas_imagenes):\n",
        "        \"\"\"Eval√∫a un conjunto de im√°genes completo.\"\"\"\n",
        "        print(f\"Iniciando evaluaci√≥n de {len(rutas_imagenes)} im√°genes\")\n",
        "\n",
        "        self.resultados = []\n",
        "        exitosas = 0\n",
        "\n",
        "        for i, ruta in enumerate(rutas_imagenes):\n",
        "            print(f\"[{i+1:4d}/{len(rutas_imagenes)}] {os.path.basename(ruta)}\")\n",
        "\n",
        "            resultado = self.procesar_imagen(ruta)\n",
        "            self.resultados.append(resultado)\n",
        "\n",
        "            if not resultado.get('procesamiento_fallido', False):\n",
        "                exitosas += 1\n",
        "                num_personas = resultado.get('segmentacion', {}).get('umbral_0.1', {}).get('num_detecciones', 0)\n",
        "                num_total = resultado.get('segmentacion', {}).get('umbral_0.1', {}).get('num_detecciones_totales', 0)\n",
        "                tiempo = resultado.get('rendimiento', {}).get('tiempo_total_ms', 0)\n",
        "                print(f\"  ‚úì {num_personas} personas ({num_total} total), {tiempo:.1f}ms\")\n",
        "            else:\n",
        "                print(f\"  ‚úó Error: {resultado.get('error', 'unknown')}\")\n",
        "\n",
        "            # Limpieza peri√≥dica de memoria\n",
        "            if (i + 1) % 10 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"\\nResumen: {exitosas}/{len(rutas_imagenes)} exitosas\")\n",
        "        return self.resultados\n",
        "\n",
        "    def guardar_resultados(self, nombre_archivo=None):\n",
        "        \"\"\"Guarda todos los resultados en formato JSON.\"\"\"\n",
        "        if not nombre_archivo:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            nombre_archivo = f\"evaluacion_mask2former_debug_{timestamp}.json\"\n",
        "\n",
        "        ruta_archivo = self.output_dir / 'datos_completos' / nombre_archivo\n",
        "\n",
        "        # Preparar datos para JSON\n",
        "        datos_exportacion = {\n",
        "            'resumen': {\n",
        "                'total_imagenes': len(self.resultados),\n",
        "                'exitosas': sum(1 for r in self.resultados if not r.get('procesamiento_fallido', False)),\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo': self.config['model_name']\n",
        "            },\n",
        "            'configuracion': self.config,\n",
        "            'resultados': self.resultados\n",
        "        }\n",
        "\n",
        "        with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos_exportacion, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Resultados guardados en: {ruta_archivo}\")\n",
        "        print(f\"Tama√±o del archivo: {os.path.getsize(ruta_archivo) / (1024*1024):.2f} MB\")\n",
        "\n",
        "        return str(ruta_archivo)"
      ],
      "metadata": {
        "id": "zwsRY9gBCXOn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Funciones auxiliares (sin cambios)\n",
        "# ==========================================\n",
        "def cargar_dataset(ruta_dataset, extensiones=(\".jpg\", \".png\", \".jpeg\")):\n",
        "    ruta = Path(ruta_dataset)\n",
        "    imagenes = [str(p) for p in ruta.glob(\"**/*\") if p.suffix.lower() in extensiones]\n",
        "    print(f\"Dataset cargado: {len(imagenes)} im√°genes encontradas.\")\n",
        "    return imagenes\n",
        "\n",
        "def procesar_por_lotes(evaluador, imagenes, tam_lote=5):\n",
        "    print(\"Procesando por lotes...\")\n",
        "    resultados_totales = []\n",
        "    for i in tqdm(range(0, len(imagenes), tam_lote), desc=\"Procesando lotes\"):\n",
        "        lote = imagenes[i:i+tam_lote]\n",
        "        resultados_lote = evaluador.evaluar_dataset(lote)\n",
        "        resultados_totales.extend(resultados_lote)\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "    return resultados_totales\n",
        "\n",
        "def generar_resumen(resultados):\n",
        "    resumen = {}\n",
        "    for r in resultados:\n",
        "        for clave, valor in r.items():\n",
        "            if isinstance(valor, (int, float)):\n",
        "                resumen.setdefault(clave, []).append(valor)\n",
        "    return {k: sum(v)/len(v) for k, v in resumen.items() if v}\n",
        "\n",
        "def ejecutar_multi_modelo_debug(modelos, dataset_path, drive_output_path, tam_lote=1):\n",
        "    imagenes = cargar_dataset(dataset_path)\n",
        "    resumen_global = {}\n",
        "\n",
        "    for modelo in modelos:\n",
        "        print(f\"\\n=========================\")\n",
        "        print(f\"Ejecutando modelo: {modelo}\")\n",
        "        print(f\"=========================\")\n",
        "\n",
        "        try:\n",
        "            config = {\n",
        "                'model_name': modelo,\n",
        "                'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "                'output_dir': drive_output_path,\n",
        "                'debug': True,\n",
        "                'forzar_deteccion': True\n",
        "            }\n",
        "\n",
        "            evaluador = RecolectorMetricasCompletas(config)\n",
        "            resultados = procesar_por_lotes(evaluador, imagenes, tam_lote)\n",
        "\n",
        "            # Guardar resultados por modelo\n",
        "            nombre_archivo = f\"resultados_debug_{modelo.replace('/', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "            ruta_archivo = Path(drive_output_path) / nombre_archivo\n",
        "            with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
        "                json.dump(resultados, f, indent=2, ensure_ascii=False)\n",
        "            print(f\"Resultados guardados en: {ruta_archivo}\")\n",
        "\n",
        "            resumen_global[modelo] = generar_resumen(resultados)\n",
        "\n",
        "            # Limpieza de memoria entre modelos\n",
        "            del evaluador\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error con el modelo {modelo}: {e}\")\n",
        "            continue\n",
        "\n",
        "    # Guardar resumen global\n",
        "    archivo_resumen = Path(drive_output_path) / f\"resumen_global_debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(archivo_resumen, 'w', encoding='utf-8') as f:\n",
        "        json.dump(resumen_global, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"\\nResumen global guardado en: {archivo_resumen}\")\n",
        "\n",
        "    # Mostrar resumen de detecciones\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"RESUMEN DE DETECCIONES POR MODELO\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for modelo, datos in resumen_global.items():\n",
        "        print(f\"\\nModelo: {modelo}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Buscar m√©tricas de personas detectadas en los resultados originales\n",
        "        resultados_modelo = []\n",
        "        for resultado in [r for r in resultados if r.get('modelo', {}).get('nombre') == modelo]:\n",
        "            if not resultado.get('procesamiento_fallido', False):\n",
        "                segmentacion = resultado.get('segmentacion', {})\n",
        "                for umbral, datos_umbral in segmentacion.items():\n",
        "                    if 'num_detecciones' in datos_umbral:\n",
        "                        resultados_modelo.append({\n",
        "                            'umbral': umbral,\n",
        "                            'personas': datos_umbral.get('num_detecciones', 0),\n",
        "                            'total': datos_umbral.get('num_detecciones_totales', 0),\n",
        "                            'clases': datos_umbral.get('todas_las_clases', [])\n",
        "                        })\n",
        "\n",
        "        if resultados_modelo:\n",
        "            # Mostrar mejor resultado por umbral\n",
        "            for umbral in ['umbral_0.01', 'umbral_0.1', 'umbral_0.5']:\n",
        "                datos_umbral = next((r for r in resultados_modelo if r['umbral'] == umbral), None)\n",
        "                if datos_umbral:\n",
        "                    print(f\"  {umbral}: {datos_umbral['personas']} personas, {datos_umbral['total']} total\")\n",
        "                    if datos_umbral['clases']:\n",
        "                        clases_unicas = list(set(datos_umbral['clases']))\n",
        "                        print(f\"    Clases detectadas: {clases_unicas}\")\n",
        "        else:\n",
        "            print(\"  No hay datos de detecci√≥n disponibles\")\n",
        "\n",
        "def analizar_resultados_detallado(ruta_resultados_json):\n",
        "    \"\"\"\n",
        "    Analiza en detalle los resultados de un archivo JSON para diagnosticar\n",
        "    por qu√© no se detectan personas.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"AN√ÅLISIS DETALLADO DE RESULTADOS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        with open(ruta_resultados_json, 'r', encoding='utf-8') as f:\n",
        "            datos = json.load(f)\n",
        "\n",
        "        if isinstance(datos, list):\n",
        "            resultados = datos\n",
        "        else:\n",
        "            resultados = datos.get('resultados', [])\n",
        "\n",
        "        for i, resultado in enumerate(resultados):\n",
        "            if resultado.get('procesamiento_fallido', False):\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nImagen {i+1}: {resultado.get('imagen', {}).get('archivo', 'unknown')}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "            # Informaci√≥n del modelo\n",
        "            modelo_info = resultado.get('modelo', {})\n",
        "            print(f\"Modelo: {modelo_info.get('nombre', 'unknown')}\")\n",
        "\n",
        "            # Informaci√≥n de la imagen\n",
        "            imagen_info = resultado.get('imagen', {})\n",
        "            print(f\"Resoluci√≥n: {imagen_info.get('resolucion_w', 0)}x{imagen_info.get('resolucion_h', 0)}\")\n",
        "            print(f\"Brillo promedio: {imagen_info.get('brillo_promedio', 0):.1f}\")\n",
        "\n",
        "            # An√°lisis por umbral\n",
        "            segmentacion = resultado.get('segmentacion', {})\n",
        "            print(\"\\nDetecciones por umbral:\")\n",
        "\n",
        "            for umbral in ['umbral_0.01', 'umbral_0.1', 'umbral_0.5', 'umbral_0.9']:\n",
        "                datos_umbral = segmentacion.get(umbral, {})\n",
        "                personas = datos_umbral.get('num_detecciones', 0)\n",
        "                total = datos_umbral.get('num_detecciones_totales', 0)\n",
        "                clases = datos_umbral.get('todas_las_clases', [])\n",
        "                scores = datos_umbral.get('todos_los_scores', [])\n",
        "\n",
        "                print(f\"  {umbral}: {personas} personas de {total} detecciones totales\")\n",
        "\n",
        "                if clases and scores:\n",
        "                    # Mostrar las 3 mejores detecciones\n",
        "                    detecciones_con_score = list(zip(clases, scores))\n",
        "                    detecciones_ordenadas = sorted(detecciones_con_score, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "                    print(f\"    Top 3 detecciones:\")\n",
        "                    for j, (clase, score) in enumerate(detecciones_ordenadas[:3]):\n",
        "                        print(f\"      {j+1}. Clase {clase}: {score:.4f}\")\n",
        "\n",
        "            # Debug info si est√° disponible\n",
        "            debug_info = resultado.get('debug_info', {})\n",
        "            if debug_info:\n",
        "                clases_detectadas = debug_info.get('clases_detectadas', set())\n",
        "                if clases_detectadas:\n",
        "                    print(f\"\\nTodas las clases detectadas: {sorted(list(clases_detectadas))}\")\n",
        "\n",
        "                scores_por_clase = debug_info.get('scores_por_clase', {})\n",
        "                if scores_por_clase:\n",
        "                    print(\"Scores promedio por clase:\")\n",
        "                    for clase, scores_lista in scores_por_clase.items():\n",
        "                        avg_score = sum(scores_lista) / len(scores_lista)\n",
        "                        max_score = max(scores_lista)\n",
        "                        print(f\"  Clase {clase}: promedio={avg_score:.4f}, m√°ximo={max_score:.4f}\")\n",
        "\n",
        "            # Contexto autom√°tico\n",
        "            contexto = resultado.get('contexto', {})\n",
        "            if contexto:\n",
        "                print(f\"\\nContexto: {contexto.get('categoria', 'unknown')}\")\n",
        "                print(f\"Complejidad: {contexto.get('complejidad_score', 0):.3f}\")\n",
        "                print(f\"Iluminaci√≥n: {contexto.get('iluminacion', 'unknown')}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error analizando resultados: {e}\")\n",
        "\n",
        "def crear_modelo_personalizado_personas():\n",
        "    \"\"\"\n",
        "    Crea un evaluador espec√≠fico optimizado para detectar personas\n",
        "    con configuraciones m√°s agresivas.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"CREANDO MODELO OPTIMIZADO PARA PERSONAS\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Configuraci√≥n optimizada\n",
        "    config_optimizada = {\n",
        "        'model_name': \"facebook/mask2former-swin-large-coco-instance\",\n",
        "        'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "        'output_dir': OUTPUT_PATH,\n",
        "        'debug': True,\n",
        "        'forzar_deteccion': True,\n",
        "        'umbrales_personalizados': [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
        "        'optimizado_personas': True\n",
        "    }\n",
        "\n",
        "    return RecolectorMetricasCompletas(config_optimizada)\n",
        "\n",
        "def test_deteccion_simple(ruta_imagen):\n",
        "    \"\"\"\n",
        "    Prueba simple y directa de detecci√≥n en una imagen espec√≠fica.\n",
        "    \"\"\"\n",
        "    print(f\"\\n\" + \"=\"*60)\n",
        "    print(f\"TEST DE DETECCI√ìN SIMPLE\")\n",
        "    print(f\"Imagen: {os.path.basename(ruta_imagen)}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        # Cargar modelo m√°s simple\n",
        "        processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-coco-instance\")\n",
        "        model = AutoModelForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-coco-instance\")\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        # Cargar imagen\n",
        "        image = Image.open(ruta_imagen).convert(\"RGB\")\n",
        "        print(f\"Imagen cargada: {image.size}\")\n",
        "\n",
        "        # Redimensionar si es muy grande\n",
        "        if max(image.size) > 800:\n",
        "            image.thumbnail((800, 800), Image.Resampling.LANCZOS)\n",
        "            print(f\"Imagen redimensionada a: {image.size}\")\n",
        "\n",
        "        # Procesar\n",
        "        inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
        "        print(\"Imagen procesada por el processor\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        print(\"Inferencia completada\")\n",
        "\n",
        "        # Probar m√∫ltiples umbrales\n",
        "        umbrales = [0.001, 0.01, 0.05, 0.1, 0.3, 0.5, 0.7]\n",
        "\n",
        "        for umbral in umbrales_test:\n",
        "            try:\n",
        "                resultado = processor.post_process_instance_segmentation(\n",
        "                    outputs, target_sizes=[image.size[::-1]], threshold=umbral\n",
        "                )[0]\n",
        "\n",
        "                if \"labels\" in resultado:\n",
        "                    labels = resultado[\"labels\"]\n",
        "                    scores = resultado.get(\"scores\", [])\n",
        "\n",
        "                    print(f\"\\nUmbral {umbral}:\")\n",
        "                    print(f\"  Total detecciones: {len(labels)}\")\n",
        "\n",
        "                    # Contar personas (clase 0)\n",
        "                    personas = sum(1 for label in labels if label.item() == 0)\n",
        "                    print(f\"  Personas detectadas: {personas}\")\n",
        "\n",
        "                    # Mostrar todas las detecciones\n",
        "                    if len(labels) > 0:\n",
        "                        print(\"  Todas las detecciones:\")\n",
        "                        detecciones = []\n",
        "                        for i, (label, score) in enumerate(zip(labels, scores)):\n",
        "                            clase = label.item()\n",
        "                            score_val = score.item()\n",
        "                            detecciones.append((clase, score_val))\n",
        "\n",
        "                        # Ordenar por score\n",
        "                        detecciones.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "                        for i, (clase, score) in enumerate(detecciones[:10]):  # Top 10\n",
        "                            marca = \"üë§\" if clase == 0 else \"üî∏\"\n",
        "                            print(f\"    {i+1:2d}. {marca} Clase {clase:2d}: {score:.4f}\")\n",
        "\n",
        "                    if personas == 0 and len(labels) > 0:\n",
        "                        print(\"  ‚ö†Ô∏è  No se detectaron personas, pero s√≠ otros objetos\")\n",
        "                        mejor_deteccion = max([(l.item(), s.item()) for l, s in zip(labels, scores)], key=lambda x: x[1])\n",
        "                        print(f\"  üí° Mejor detecci√≥n: Clase {mejor_deteccion[0]} con score {mejor_deteccion[1]:.4f}\")\n",
        "\n",
        "                        # ¬øPodr√≠amos forzar esta detecci√≥n como persona?\n",
        "                        if mejor_deteccion[1] > 0.1:\n",
        "                            print(f\"  üîÑ Se podr√≠a considerar como persona con forzado\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"Umbral {umbral}: Sin resultados de labels\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error con umbral {umbral}: {e}\")\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*60)\n",
        "        print(\"RECOMENDACIONES:\")\n",
        "\n",
        "        # An√°lisis de la imagen\n",
        "        img_array = np.array(image)\n",
        "        brillo_promedio = np.mean(cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY))\n",
        "\n",
        "        print(f\"1. Brillo promedio de la imagen: {brillo_promedio:.1f}\")\n",
        "        if brillo_promedio < 50:\n",
        "            print(\"   ‚Üí Imagen muy oscura, podr√≠a afectar la detecci√≥n\")\n",
        "        elif brillo_promedio > 200:\n",
        "            print(\"   ‚Üí Imagen muy brillante, podr√≠a causar sobreexposici√≥n\")\n",
        "        else:\n",
        "            print(\"   ‚Üí Brillo adecuado para detecci√≥n\")\n",
        "\n",
        "        print(\"2. Para mejorar la detecci√≥n:\")\n",
        "        print(\"   ‚Üí Usar umbrales m√°s bajos (0.01 - 0.1)\")\n",
        "        print(\"   ‚Üí Activar forzado de detecci√≥n\")\n",
        "        print(\"   ‚Üí Probar con diferentes modelos\")\n",
        "        print(\"   ‚Üí Verificar que la resoluci√≥n no sea excesiva\")\n",
        "\n",
        "        del model, processor, inputs, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error en test simple: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "qFb3434hbkoM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. Configuraci√≥n y ejecuci√≥n principal\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Ejecutando evaluaci√≥n con debug mejorado...\")\n",
        "\n",
        "    # Ejecutar evaluaci√≥n completa\n",
        "    ejecutar_multi_modelo_debug(MODELOS, DATASET_PATH, OUTPUT_PATH, tam_lote=1)\n",
        "\n",
        "    # Test adicional en la primera imagen encontrada\n",
        "    imagenes = cargar_dataset(DATASET_PATH)\n",
        "    if imagenes:\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(\"EJECUTANDO TEST ADICIONAL EN LA PRIMERA IMAGEN\")\n",
        "        print(f\"{'='*60}\")\n",
        "        test_deteccion_simple(imagenes[0])\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"EVALUACI√ìN COMPLETADA\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(\"Archivos generados:\")\n",
        "    print(\"- Resultados JSON por cada modelo\")\n",
        "    print(\"- Resumen global\")\n",
        "    print(\"- Visualizaciones debug en /debug_visualizations/\")\n",
        "    print(\"- Logs detallados en consola\")\n",
        "\n",
        "    # Instrucciones para an√°lisis posterior\n",
        "    print(f\"\\nPara an√°lizar resultados detallados, ejecuta:\")\n",
        "    print(f\"analizar_resultados_detallado('/path/to/results.json')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aDD0PmTPctiZ",
        "outputId": "37b1ed31-33b4-4b32-cfe7-736e39f8b582"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando evaluaci√≥n con debug mejorado...\n",
            "Dataset cargado: 1 im√°genes encontradas.\n",
            "\n",
            "=========================\n",
            "Ejecutando modelo: facebook/mask2former-swin-large-coco-instance\n",
            "=========================\n",
            "Modelo cargado exitosamente: facebook/mask2former-swin-large-coco-instance\n",
            "Modelo cargado en cuda\n",
            "Debug mode: True\n",
            "Forzar detecci√≥n: True\n",
            "Procesando por lotes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando lotes:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando evaluaci√≥n de 1 im√°genes\n",
            "[   1/1] _DSC0442.jpg\n",
            "  Imagen redimensionada de (3849, 5774) a (683, 1024)\n",
            "  Procesando imagen: 1024x683 pixels\n",
            "  Inferencia completada en 177.7ms\n",
            "    Umbral 0.001: 0 detecciones totales\n",
            "    Umbral 0.01: 0 detecciones totales\n",
            "    Umbral 0.05: 0 detecciones totales\n",
            "    Umbral 0.1: 0 detecciones totales\n",
            "    Umbral 0.3: 0 detecciones totales\n",
            "    Umbral 0.5: 0 detecciones totales\n",
            "    Umbral 0.7: 0 detecciones totales\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`label_ids_to_fuse` unset. No instance will be fused.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Debug viz guardada: /content/drive/MyDrive/TFM/mask2former/resultados/debug_visualizations/debug_b11eece7179a.png\n",
            "  Pan√≥ptico: 1 segmentos, categor√≠as: {-1}\n",
            "  RESULTADO FINAL: 0 personas, 0 detecciones totales\n",
            "  Clases detectadas: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando lotes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚úì 0 personas (0 total), 1995.6ms\n",
            "\n",
            "Resumen: 1/1 exitosas\n",
            "Error con el modelo facebook/mask2former-swin-large-coco-instance: Object of type set is not JSON serializable\n",
            "\n",
            "=========================\n",
            "Ejecutando modelo: facebook/mask2former-swin-base-ade-semantic\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente: facebook/mask2former-swin-base-ade-semantic\n",
            "Modelo cargado en cuda\n",
            "Debug mode: True\n",
            "Forzar detecci√≥n: True\n",
            "Procesando por lotes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando lotes:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando evaluaci√≥n de 1 im√°genes\n",
            "[   1/1] _DSC0442.jpg\n",
            "  Imagen redimensionada de (3849, 5774) a (683, 1024)\n",
            "  Procesando imagen: 1024x683 pixels\n",
            "  Inferencia completada en 125.3ms\n",
            "    Umbral 0.001: 0 detecciones totales\n",
            "    Umbral 0.01: 0 detecciones totales\n",
            "    Umbral 0.05: 0 detecciones totales\n",
            "    Umbral 0.1: 0 detecciones totales\n",
            "    Umbral 0.3: 0 detecciones totales\n",
            "    Umbral 0.5: 0 detecciones totales\n",
            "    Umbral 0.7: 0 detecciones totales\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`label_ids_to_fuse` unset. No instance will be fused.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Debug viz guardada: /content/drive/MyDrive/TFM/mask2former/resultados/debug_visualizations/debug_b11eece7179a.png\n",
            "  Pan√≥ptico: 3 segmentos, categor√≠as: {-1}\n",
            "  RESULTADO FINAL: 0 personas, 0 detecciones totales\n",
            "  Clases detectadas: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando lotes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ‚úì 0 personas (0 total), 1998.9ms\n",
            "\n",
            "Resumen: 1/1 exitosas\n",
            "Error con el modelo facebook/mask2former-swin-base-ade-semantic: Object of type set is not JSON serializable\n",
            "\n",
            "=========================\n",
            "Ejecutando modelo: facebook/mask2former-swin-small-coco-instance\n",
            "=========================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente: facebook/mask2former-swin-small-coco-instance\n",
            "Modelo cargado en cuda\n",
            "Debug mode: True\n",
            "Forzar detecci√≥n: True\n",
            "Procesando por lotes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando lotes:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando evaluaci√≥n de 1 im√°genes\n",
            "[   1/1] _DSC0442.jpg\n",
            "  Imagen redimensionada de (3849, 5774) a (683, 1024)\n",
            "  Procesando imagen: 1024x683 pixels\n",
            "  Inferencia completada en 109.9ms\n",
            "    Umbral 0.001: 0 detecciones totales\n",
            "    Umbral 0.01: 0 detecciones totales\n",
            "    Umbral 0.05: 0 detecciones totales\n",
            "    Umbral 0.1: 0 detecciones totales\n",
            "    Umbral 0.3: 0 detecciones totales\n",
            "    Umbral 0.5: 0 detecciones totales\n",
            "    Umbral 0.7: 0 detecciones totales\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`label_ids_to_fuse` unset. No instance will be fused.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Debug viz guardada: /content/drive/MyDrive/TFM/mask2former/resultados/debug_visualizations/debug_b11eece7179a.png\n",
            "  Pan√≥ptico: 1 segmentos, categor√≠as: {-1}\n",
            "  RESULTADO FINAL: 0 personas, 0 detecciones totales\n",
            "  Clases detectadas: []\n",
            "  ‚úì 0 personas (0 total), 1960.7ms\n",
            "\n",
            "Resumen: 1/1 exitosas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando lotes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error con el modelo facebook/mask2former-swin-small-coco-instance: Object of type set is not JSON serializable\n",
            "\n",
            "Resumen global guardado en: /content/drive/MyDrive/TFM/mask2former/resultados/resumen_global_debug_20250901_181213.json\n",
            "\n",
            "==================================================\n",
            "RESUMEN DE DETECCIONES POR MODELO\n",
            "==================================================\n",
            "Dataset cargado: 1 im√°genes encontradas.\n",
            "\n",
            "============================================================\n",
            "EJECUTANDO TEST ADICIONAL EN LA PRIMERA IMAGEN\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "TEST DE DETECCI√ìN SIMPLE\n",
            "Imagen: _DSC0442.jpg\n",
            "============================================================\n",
            "Imagen cargada: (3849, 5774)\n",
            "Imagen redimensionada a: (533, 800)\n",
            "Imagen procesada por el processor\n",
            "Inferencia completada\n",
            "Error en test simple: name 'umbrales_test' is not defined\n",
            "\n",
            "============================================================\n",
            "EVALUACI√ìN COMPLETADA\n",
            "============================================================\n",
            "Archivos generados:\n",
            "- Resultados JSON por cada modelo\n",
            "- Resumen global\n",
            "- Visualizaciones debug en /debug_visualizations/\n",
            "- Logs detallados en consola\n",
            "\n",
            "Para an√°lizar resultados detallados, ejecuta:\n",
            "analizar_resultados_detallado('/path/to/results.json')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1266062792.py\", line 250, in test_deteccion_simple\n",
            "    for umbral in umbrales_test:\n",
            "                  ^^^^^^^^^^^^^\n",
            "NameError: name 'umbrales_test' is not defined\n"
          ]
        }
      ]
    }
  ]
}