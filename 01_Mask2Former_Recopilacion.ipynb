{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfIslnm71BEK8yjqAw9SZV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/01_Mask2Former_Recopilacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluador Mask2Former para recolección de Métricas\n",
        "**Recopilación de todas las métricas posibles sin ground truth.**\n",
        "\n",
        "- Autor: Jesús L.\n",
        "- Proyecto: TFM. Evaluación comparativa de técnicas de segmentación."
      ],
      "metadata": {
        "id": "a8lOSAZmzYlh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2pdz2A9tsSqk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import hashlib\n",
        "\n",
        "from transformers import Mask2FormerImageProcessor, Mask2FormerForUniversalSegmentation\n",
        "from PIL import Image, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import measure"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. Montar Google Drive\n",
        "# ==========================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Ruta a tu dataset en Google Drive\n",
        "DATASET_PATH = \"/content/drive/MyDrive/mask2former/imagenes\"\n",
        "# Carpeta donde se guardarán los resultados\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/mask2former/resultados\"\n",
        "\n",
        "# Crear carpeta de resultados si no existe\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "# Lista de modelos a evaluar\n",
        "MODELOS = [\n",
        "    \"facebook/mask2former-swin-large-coco-instance\",\n",
        "    \"facebook/maskformer-swin-base-coco\",\n",
        "    \"facebook/mask2former-swin-base-ade-semantic\"\n",
        "]"
      ],
      "metadata": {
        "id": "qqQBwP7t_vDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RecolectorMetricasCompletas:\n",
        "    \"\"\"\n",
        "    Recolecta todas las métricas posibles de una segmentación sin ground truth.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.processor = Mask2FormerImageProcessor.from_pretrained(config['model_name'])\n",
        "        self.model = Mask2FormerForUniversalSegmentation.from_pretrained(config['model_name'])\n",
        "        self.device = torch.device(config['device'])\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        # Crear directorios\n",
        "        self.output_dir = Path(config['output_dir'])\n",
        "        self.output_dir.mkdir(exist_ok=True)\n",
        "        (self.output_dir / 'datos_completos').mkdir(exist_ok=True)\n",
        "\n",
        "        self.resultados = []\n",
        "        print(f\"Modelo cargado en {self.device}\")\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen):\n",
        "        \"\"\"Procesa una imagen y recolecta TODAS las métricas posibles.\"\"\"\n",
        "\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # 1. CARGA Y ANÁLISIS BÁSICO DE IMAGEN\n",
        "            imagen_pil = Image.open(ruta_imagen).convert(\"RGB\")\n",
        "            imagen_np = np.array(imagen_pil)\n",
        "            h, w = imagen_np.shape[:2]\n",
        "\n",
        "            # Hash único para la imagen\n",
        "            hash_img = hashlib.md5(open(ruta_imagen, 'rb').read()).hexdigest()[:12]\n",
        "\n",
        "            # Estadísticas básicas de la imagen\n",
        "            stat = ImageStat.Stat(imagen_pil)\n",
        "            gray = cv2.cvtColor(imagen_np, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "            # 2. ANÁLISIS VISUAL DE LA IMAGEN (sin modelo)\n",
        "            metricas_imagen = {\n",
        "                # Básicas\n",
        "                'archivo': os.path.basename(ruta_imagen),\n",
        "                'hash': hash_img,\n",
        "                'resolucion_w': w,\n",
        "                'resolucion_h': h,\n",
        "                'aspect_ratio': w/h,\n",
        "                'area_total': w*h,\n",
        "\n",
        "                # Color y brillo\n",
        "                'brillo_promedio': float(np.mean(gray)),\n",
        "                'brillo_std': float(np.std(gray)),\n",
        "                'rgb_mean_r': float(stat.mean[0]),\n",
        "                'rgb_mean_g': float(stat.mean[1]),\n",
        "                'rgb_mean_b': float(stat.mean[2]),\n",
        "                'rgb_std_r': float(stat.stddev[0]),\n",
        "                'rgb_std_g': float(stat.stddev[1]),\n",
        "                'rgb_std_b': float(stat.stddev[2]),\n",
        "\n",
        "                # Textura y complejidad\n",
        "                'varianza_laplacian': float(cv2.Laplacian(gray, cv2.CV_64F).var()),\n",
        "                'entropia': self._calcular_entropia(gray),\n",
        "                'densidad_bordes': self._calcular_densidad_bordes(gray),\n",
        "\n",
        "                # HSV\n",
        "                'saturacion_media': float(np.mean(cv2.cvtColor(imagen_np, cv2.COLOR_RGB2HSV)[:,:,1])),\n",
        "                'saturacion_std': float(np.std(cv2.cvtColor(imagen_np, cv2.COLOR_RGB2HSV)[:,:,1])),\n",
        "\n",
        "                # Contraste local\n",
        "                'contraste_local_std': float(np.std([cv2.Laplacian(gray[i:i+32, j:j+32], cv2.CV_64F).var()\n",
        "                                                   for i in range(0, h-32, 32)\n",
        "                                                   for j in range(0, w-32, 32) if i+32<h and j+32<w]))\n",
        "            }\n",
        "\n",
        "            # 3. RECURSOS ANTES DE INFERENCIA\n",
        "            recursos_antes = self._obtener_recursos()\n",
        "\n",
        "            # 4. INFERENCIA DEL MODELO\n",
        "            inputs = self.processor(images=imagen_pil, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            tiempo_inferencia_inicio = time.time()\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            tiempo_inferencia = (time.time() - tiempo_inferencia_inicio) * 1000\n",
        "\n",
        "            # 5. POST-PROCESAMIENTO CON MÚLTIPLES UMBRALES\n",
        "            umbrales = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "            resultados_por_umbral = {}\n",
        "\n",
        "            for umbral in umbrales:\n",
        "                resultado = self.processor.post_process_instance_segmentation(\n",
        "                    outputs, target_sizes=[(h, w)], threshold=umbral\n",
        "                )[0]\n",
        "\n",
        "                # Extraer personas (clase 0)\n",
        "                mascaras_personas = []\n",
        "                scores_personas = []\n",
        "\n",
        "                if 'labels' in resultado and 'masks' in resultado:\n",
        "                    for i, (label, score) in enumerate(zip(resultado[\"labels\"], resultado[\"scores\"])):\n",
        "                        if label == 0:  # persona\n",
        "                            mask = resultado[\"masks\"][i].cpu().numpy().squeeze() > 0.5\n",
        "                            mascaras_personas.append(mask)\n",
        "                            scores_personas.append(float(score.item()))\n",
        "\n",
        "                # Máscara combinada de todas las personas\n",
        "                if mascaras_personas:\n",
        "                    mascara_combinada = np.logical_or.reduce(mascaras_personas)\n",
        "                else:\n",
        "                    mascara_combinada = np.zeros((h, w), dtype=bool)\n",
        "\n",
        "                # Métricas por umbral\n",
        "                resultados_por_umbral[f'umbral_{umbral}'] = {\n",
        "                    'num_detecciones': len(mascaras_personas),\n",
        "                    'scores': scores_personas,\n",
        "                    'area_segmentada': int(np.sum(mascara_combinada)),\n",
        "                    'porcentaje_imagen': float(np.sum(mascara_combinada) / (h*w) * 100),\n",
        "                    'coherencia': self._metricas_coherencia(mascara_combinada)\n",
        "                }\n",
        "\n",
        "            # 6. ANÁLISIS PANÓPTICO\n",
        "            metricas_panoptico = {}\n",
        "            try:\n",
        "                resultado_panoptico = self.processor.post_process_panoptic_segmentation(\n",
        "                    outputs, target_sizes=[(h, w)]\n",
        "                )[0]\n",
        "\n",
        "                if 'segments_info' in resultado_panoptico:\n",
        "                    segmentos = resultado_panoptico['segments_info']\n",
        "                    categorias = [seg.get('category_id', -1) for seg in segmentos]\n",
        "\n",
        "                    metricas_panoptico = {\n",
        "                        'total_segmentos': len(segmentos),\n",
        "                        'categorias_unicas': len(set(categorias)),\n",
        "                        'areas_segmentos': [seg.get('area', 0) for seg in segmentos],\n",
        "                        'distribucion_categorias': {str(k): categorias.count(k) for k in set(categorias)},\n",
        "                        'segmentos_persona': sum(1 for seg in segmentos if seg.get('category_id') == 0)\n",
        "                    }\n",
        "            except:\n",
        "                metricas_panoptico = {'error': 'Panóptico no disponible'}\n",
        "\n",
        "            # 7. RECURSOS DESPUÉS DE INFERENCIA\n",
        "            recursos_despues = self._obtener_recursos()\n",
        "            tiempo_total = (time.time() - inicio) * 1000\n",
        "\n",
        "            # 8. ANÁLISIS DE LA MEJOR DETECCIÓN (umbral 0.5 como referencia)\n",
        "            mejor_resultado = resultados_por_umbral.get('umbral_0.5', {})\n",
        "\n",
        "            # 9. CLASIFICACIÓN AUTOMÁTICA DE CONTEXTO\n",
        "            contexto = self._clasificar_contexto_automatico(\n",
        "                imagen_np,\n",
        "                mejor_resultado.get('num_detecciones', 0),\n",
        "                metricas_imagen\n",
        "            )\n",
        "\n",
        "            # 10. RESULTADO FINAL COMPLETO\n",
        "            resultado_completo = {\n",
        "                # Metadatos\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'id_procesamiento': f\"{hash_img}_{int(time.time())}\",\n",
        "\n",
        "                # Datos de la imagen\n",
        "                'imagen': metricas_imagen,\n",
        "\n",
        "                # Rendimiento\n",
        "                'rendimiento': {\n",
        "                    'tiempo_inferencia_ms': tiempo_inferencia,\n",
        "                    'tiempo_total_ms': tiempo_total,\n",
        "                    'memoria_antes_mb': recursos_antes.get('memoria_usada_mb', 0),\n",
        "                    'memoria_despues_mb': recursos_despues.get('memoria_usada_mb', 0),\n",
        "                    'memoria_gpu_mb': recursos_despues.get('gpu_memoria_mb', 0),\n",
        "                    'cpu_percent': recursos_despues.get('cpu_percent', 0)\n",
        "                },\n",
        "\n",
        "                # Resultados por umbral\n",
        "                'segmentacion': resultados_por_umbral,\n",
        "\n",
        "                # Análisis panóptico\n",
        "                'panoptico': metricas_panoptico,\n",
        "\n",
        "                # Contexto automático\n",
        "                'contexto': contexto,\n",
        "\n",
        "                # Modelo info\n",
        "                'modelo': {\n",
        "                    'nombre': self.config['model_name'],\n",
        "                    'device': str(self.device),\n",
        "                    'confianza_umbral_principal': 0.5\n",
        "                }\n",
        "            }\n",
        "\n",
        "            return resultado_completo\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {'archivo': os.path.basename(ruta_imagen)},\n",
        "                'error': str(e),\n",
        "                'procesamiento_fallido': True\n",
        "            }\n",
        "\n",
        "    def _calcular_entropia(self, imagen_gray):\n",
        "        \"\"\"Calcula la entropía de Shannon de la imagen.\"\"\"\n",
        "        histogram, _ = np.histogram(imagen_gray, bins=256, range=(0, 256))\n",
        "        histogram = histogram + 1e-7  # Evitar log(0)\n",
        "        prob = histogram / np.sum(histogram)\n",
        "        return float(-np.sum(prob * np.log2(prob)))\n",
        "\n",
        "    def _calcular_densidad_bordes(self, imagen_gray):\n",
        "        \"\"\"Calcula densidad de bordes usando Canny.\"\"\"\n",
        "        edges = cv2.Canny(imagen_gray, 50, 150)\n",
        "        return float(np.sum(edges > 0) / edges.size)\n",
        "\n",
        "    def _metricas_coherencia(self, mascara):\n",
        "        \"\"\"Métricas de coherencia espacial de una máscara.\"\"\"\n",
        "        if np.sum(mascara) == 0:\n",
        "            return {\n",
        "                'area': 0,\n",
        "                'componentes': 0,\n",
        "                'compacidad': 0.0,\n",
        "                'solidez': 0.0\n",
        "            }\n",
        "\n",
        "        # Componentes conectados\n",
        "        labeled = measure.label(mascara)\n",
        "        num_componentes = int(labeled.max())\n",
        "\n",
        "        # Contornos para otras métricas\n",
        "        contours, _ = cv2.findContours(mascara.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        if contours:\n",
        "            contorno_principal = max(contours, key=cv2.contourArea)\n",
        "            area = cv2.contourArea(contorno_principal)\n",
        "            perimetro = cv2.arcLength(contorno_principal, True)\n",
        "\n",
        "            # Convex hull\n",
        "            hull = cv2.convexHull(contorno_principal)\n",
        "            area_hull = cv2.contourArea(hull)\n",
        "\n",
        "            # Métricas\n",
        "            compacidad = (4 * np.pi * area) / (perimetro ** 2) if perimetro > 0 else 0\n",
        "            solidez = area / area_hull if area_hull > 0 else 0\n",
        "\n",
        "            return {\n",
        "                'area': int(area),\n",
        "                'componentes': num_componentes,\n",
        "                'compacidad': float(compacidad),\n",
        "                'solidez': float(solidez),\n",
        "                'perimetro': float(perimetro)\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'area': int(np.sum(mascara)),\n",
        "            'componentes': num_componentes,\n",
        "            'compacidad': 0.0,\n",
        "            'solidez': 0.0\n",
        "        }\n",
        "\n",
        "    def _obtener_recursos(self):\n",
        "        \"\"\"Obtiene información de recursos del sistema.\"\"\"\n",
        "        try:\n",
        "            mem = psutil.virtual_memory()\n",
        "            recursos = {\n",
        "                'memoria_usada_mb': mem.used / (1024*1024),\n",
        "                'cpu_percent': psutil.cpu_percent()\n",
        "            }\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                recursos['gpu_memoria_mb'] = torch.cuda.memory_allocated() / (1024*1024)\n",
        "\n",
        "            return recursos\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _clasificar_contexto_automatico(self, imagen, num_personas, metricas_img):\n",
        "        \"\"\"Clasificación automática de contexto basada en métricas.\"\"\"\n",
        "\n",
        "        # Reglas simples de clasificación\n",
        "        if num_personas == 0:\n",
        "            categoria = 'sin_personas'\n",
        "        elif num_personas == 1:\n",
        "            if metricas_img['densidad_bordes'] < 0.1:\n",
        "                categoria = 'retrato_simple'\n",
        "            else:\n",
        "                categoria = 'retrato_complejo'\n",
        "        else:\n",
        "            categoria = 'multiples_personas'\n",
        "\n",
        "        # Análisis de complejidad\n",
        "        complejidad = (\n",
        "            metricas_img['densidad_bordes'] * 0.4 +\n",
        "            min(metricas_img['varianza_laplacian'] / 1000, 1.0) * 0.3 +\n",
        "            (metricas_img['contraste_local_std'] / 100) * 0.3\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'categoria': categoria,\n",
        "            'complejidad_score': float(min(complejidad, 1.0)),\n",
        "            'num_personas_detectadas': num_personas,\n",
        "            'iluminacion': 'baja' if metricas_img['brillo_promedio'] < 80 else\n",
        "                         'alta' if metricas_img['brillo_promedio'] > 180 else 'normal'\n",
        "        }\n",
        "\n",
        "    def evaluar_dataset(self, rutas_imagenes):\n",
        "        \"\"\"Evalúa un conjunto de imágenes completo.\"\"\"\n",
        "        print(f\"Iniciando evaluación de {len(rutas_imagenes)} imágenes\")\n",
        "\n",
        "        self.resultados = []\n",
        "        exitosas = 0\n",
        "\n",
        "        for i, ruta in enumerate(rutas_imagenes):\n",
        "            print(f\"[{i+1:4d}/{len(rutas_imagenes)}] {os.path.basename(ruta)}\")\n",
        "\n",
        "            resultado = self.procesar_imagen(ruta)\n",
        "            self.resultados.append(resultado)\n",
        "\n",
        "            if not resultado.get('procesamiento_fallido', False):\n",
        "                exitosas += 1\n",
        "                num_personas = resultado.get('segmentacion', {}).get('umbral_0.5', {}).get('num_detecciones', 0)\n",
        "                tiempo = resultado.get('rendimiento', {}).get('tiempo_total_ms', 0)\n",
        "                print(f\"  {num_personas} personas, {tiempo:.1f}ms\")\n",
        "            else:\n",
        "                print(f\"  Error: {resultado.get('error', 'unknown')}\")\n",
        "\n",
        "            # Limpieza periódica de memoria\n",
        "            if (i + 1) % 10 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        print(f\"\\nResumen: {exitosas}/{len(rutas_imagenes)} exitosas\")\n",
        "        return self.resultados\n",
        "\n",
        "    def guardar_resultados(self, nombre_archivo=None):\n",
        "        \"\"\"Guarda todos los resultados en formato JSON.\"\"\"\n",
        "        if not nombre_archivo:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            nombre_archivo = f\"evaluacion_mask2former_{timestamp}.json\"\n",
        "\n",
        "        ruta_archivo = self.output_dir / 'datos_completos' / nombre_archivo\n",
        "\n",
        "        # Preparar datos para JSON\n",
        "        datos_exportacion = {\n",
        "            'resumen': {\n",
        "                'total_imagenes': len(self.resultados),\n",
        "                'exitosas': sum(1 for r in self.resultados if not r.get('procesamiento_fallido', False)),\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo': self.config['model_name']\n",
        "            },\n",
        "            'configuracion': self.config,\n",
        "            'resultados': self.resultados\n",
        "        }\n",
        "\n",
        "        with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos_exportacion, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Resultados guardados en: {ruta_archivo}\")\n",
        "        print(f\"Tamaño del archivo: {os.path.getsize(ruta_archivo) / (1024*1024):.2f} MB\")\n",
        "\n",
        "        return str(ruta_archivo)"
      ],
      "metadata": {
        "id": "zwsRY9gBCXOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. Función para cargar dataset desde carpeta\n",
        "# ==========================================\n",
        "def cargar_dataset(ruta_dataset, extensiones=(\".jpg\", \".png\", \".jpeg\")):\n",
        "    ruta = Path(ruta_dataset)\n",
        "    imagenes = [str(p) for p in ruta.glob(\"**/*\") if p.suffix.lower() in extensiones]\n",
        "    print(f\"Dataset cargado: {len(imagenes)} imágenes encontradas.\")\n",
        "    return imagenes"
      ],
      "metadata": {
        "id": "X8VYJDQVAhz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 3. Ejecutor por lotes con limpieza de GPU\n",
        "# ==========================================\n",
        "def procesar_por_lotes(evaluador, imagenes, tam_lote=5):\n",
        "    resultados_totales = []\n",
        "    for i in range(0, len(imagenes), tam_lote):\n",
        "        lote = imagenes[i:i+tam_lote]\n",
        "        print(f\"\\nProcesando lote {i//tam_lote + 1} ({len(lote)} imágenes)\")\n",
        "        resultados_lote = evaluador.evaluar_dataset(lote)\n",
        "        resultados_totales.extend(resultados_lote)\n",
        "        torch.cuda.empty_cache()\n",
        "    return resultados_totales"
      ],
      "metadata": {
        "id": "dI0ttYONAksY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. Ejecución sobre múltiples modelos\n",
        "# ==========================================\n",
        "from RecolectorMetricasCompletas import RecolectorMetricasCompletas\n",
        "\n",
        "def ejecutar_multi_modelo(modelos, dataset_path, drive_output_path, tam_lote=5):\n",
        "    imagenes = cargar_dataset(dataset_path)\n",
        "\n",
        "    for modelo in modelos:\n",
        "        print(f\"\\n=========================\")\n",
        "        print(f\"Ejecutando modelo: {modelo}\")\n",
        "        print(f\"=========================\")\n",
        "\n",
        "        config = {\n",
        "            'model_name': modelo,\n",
        "            'device': \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "            'output_dir': drive_output_path\n",
        "        }\n",
        "\n",
        "        evaluador = RecolectorMetricasCompletas(config)\n",
        "        resultados = procesar_por_lotes(evaluador, imagenes, tam_lote)\n",
        "\n",
        "        nombre_archivo = f\"resultados_{modelo.replace('/', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        ruta_archivo = Path(drive_output_path) / nombre_archivo\n",
        "\n",
        "        with open(ruta_archivo, 'w', encoding='utf-8') as f:\n",
        "            json.dump(resultados, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"Resultados guardados en: {ruta_archivo}\")"
      ],
      "metadata": {
        "id": "CSANdR_yBOk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. Configuración y ejecución principal\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    ejecutar_multi_modelo(MODELOS, DATASET_PATH, OUTPUT_PATH, tam_lote=5)"
      ],
      "metadata": {
        "id": "eAJL4CxFBVn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ei_U5B79acV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}