{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+IGw6EvJvmutAjvbFiDnm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f7049b6cb4b4c9dbe76c6af96eac526": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5500f20be31545079aab8b3904cc50ad",
              "IPY_MODEL_860f63cc599b426ab15dcecb05a3fd64",
              "IPY_MODEL_7f12e20663ae487896b1c81dd72f4cc0"
            ],
            "layout": "IPY_MODEL_6e73d7b9a0f54617b68a738a5551ca6f"
          }
        },
        "5500f20be31545079aab8b3904cc50ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b4cbd240f6469bb7e4d52f6becf682",
            "placeholder": "​",
            "style": "IPY_MODEL_18b6469e4a3342bfad422154348c338b",
            "value": "Fetching 1 files: 100%"
          }
        },
        "860f63cc599b426ab15dcecb05a3fd64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af05ca74308c4aec86af2ff2aa9ad213",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87346c5d976b436f8a43a6a876c7b575",
            "value": 1
          }
        },
        "7f12e20663ae487896b1c81dd72f4cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48922a184e374786a20d09c398e2896b",
            "placeholder": "​",
            "style": "IPY_MODEL_876c1d4bc01146bcb697c99118a37d4c",
            "value": " 1/1 [00:00&lt;00:00, 101.40it/s]"
          }
        },
        "6e73d7b9a0f54617b68a738a5551ca6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b4cbd240f6469bb7e4d52f6becf682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b6469e4a3342bfad422154348c338b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af05ca74308c4aec86af2ff2aa9ad213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87346c5d976b436f8a43a6a876c7b575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48922a184e374786a20d09c398e2896b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876c1d4bc01146bcb697c99118a37d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "120b5196c1444147afc90e208af98818": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13d34ebfe13c473ab621485bc78a389b",
              "IPY_MODEL_301a43ce27e34dab886424fc8ce25e73",
              "IPY_MODEL_d355b402f7184a919ad07b9843838f4c"
            ],
            "layout": "IPY_MODEL_8e52fc85ac434dc9ab8ad49673f8a3b2"
          }
        },
        "13d34ebfe13c473ab621485bc78a389b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5f3d480099488a915166ad76a0adcc",
            "placeholder": "​",
            "style": "IPY_MODEL_baee498ce3b841ff8127baaebc777727",
            "value": "Fetching 1 files: 100%"
          }
        },
        "301a43ce27e34dab886424fc8ce25e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa1fe7f219a543608d92bc8b3826c7c8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f9f7e500e474beaa6afd2edc7dbf73b",
            "value": 1
          }
        },
        "d355b402f7184a919ad07b9843838f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92429ddefe694bdf814d0ed93a754231",
            "placeholder": "​",
            "style": "IPY_MODEL_b14efcd3e67243b4a450a2c50fd1be4c",
            "value": " 1/1 [00:00&lt;00:00, 93.15it/s]"
          }
        },
        "8e52fc85ac434dc9ab8ad49673f8a3b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5f3d480099488a915166ad76a0adcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baee498ce3b841ff8127baaebc777727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa1fe7f219a543608d92bc8b3826c7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f9f7e500e474beaa6afd2edc7dbf73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92429ddefe694bdf814d0ed93a754231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14efcd3e67243b4a450a2c50fd1be4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a28cdf4a2f44acebaed532858639508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d62f20cc143a427c8ca7b13c0b518bce",
              "IPY_MODEL_b07de3510bb44b45a40f3ac7b4cd3666",
              "IPY_MODEL_dc5f127f7f6645d290bf72f6d6761d9a"
            ],
            "layout": "IPY_MODEL_907c45ba5e6b4666852b030cd02a1a0e"
          }
        },
        "d62f20cc143a427c8ca7b13c0b518bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df887ae542a40968adad709bdb6b34e",
            "placeholder": "​",
            "style": "IPY_MODEL_d6a541a17f98446b91b47f73184f9a4a",
            "value": "Fetching 1 files: 100%"
          }
        },
        "b07de3510bb44b45a40f3ac7b4cd3666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac4183a8afe42f39b19516930c4d6cd",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_266f4b9a3f7e4525a9e1dc810a26a024",
            "value": 1
          }
        },
        "dc5f127f7f6645d290bf72f6d6761d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3bb151055154957aae8196751f7da38",
            "placeholder": "​",
            "style": "IPY_MODEL_2df9d79f0e5b4288b091ed1259941ed8",
            "value": " 1/1 [00:00&lt;00:00, 119.29it/s]"
          }
        },
        "907c45ba5e6b4666852b030cd02a1a0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df887ae542a40968adad709bdb6b34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a541a17f98446b91b47f73184f9a4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ac4183a8afe42f39b19516930c4d6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266f4b9a3f7e4525a9e1dc810a26a024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3bb151055154957aae8196751f7da38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2df9d79f0e5b4288b091ed1259941ed8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b10ce620eb4be98e4848f43920eeb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d1b0f7473394756a619aa6ffc6001dc",
              "IPY_MODEL_bd49114ab8124b29ba6a3bbf8b628fda",
              "IPY_MODEL_ad86013674e44aa880c05103038ed393"
            ],
            "layout": "IPY_MODEL_c21530f252544d3ea3dabd52d04d3e25"
          }
        },
        "0d1b0f7473394756a619aa6ffc6001dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62a8dbc70be343f8915055950329dd10",
            "placeholder": "​",
            "style": "IPY_MODEL_7f01c954d69f4910aa4b57db8c988f92",
            "value": "Fetching 1 files: 100%"
          }
        },
        "bd49114ab8124b29ba6a3bbf8b628fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00165f1cbf5647768a63b8203058a7b4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b32ab4ff0644d390f20609594cbba6",
            "value": 1
          }
        },
        "ad86013674e44aa880c05103038ed393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa752631b5b495985cbe4f57777384a",
            "placeholder": "​",
            "style": "IPY_MODEL_a586265e8349430aaf0dbb3405c2a6ab",
            "value": " 1/1 [00:00&lt;00:00, 118.60it/s]"
          }
        },
        "c21530f252544d3ea3dabd52d04d3e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a8dbc70be343f8915055950329dd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f01c954d69f4910aa4b57db8c988f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00165f1cbf5647768a63b8203058a7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b32ab4ff0644d390f20609594cbba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa752631b5b495985cbe4f57777384a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a586265e8349430aaf0dbb3405c2a6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c04c2cf071b3491dadde552e79a117aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_735eda7a7ec24d0cb5ea2451ffd6ca00",
              "IPY_MODEL_c07907c67c0b4b5a81fd54e984066036",
              "IPY_MODEL_76f44cd7349b45f287bca09a8ecdd3cb"
            ],
            "layout": "IPY_MODEL_aec8cb7803ac43b398c395156cd98534"
          }
        },
        "735eda7a7ec24d0cb5ea2451ffd6ca00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4ee83644f3447debf43ed82009e580f",
            "placeholder": "​",
            "style": "IPY_MODEL_41a589737b7a43e88606341999bca766",
            "value": "Fetching 1 files: 100%"
          }
        },
        "c07907c67c0b4b5a81fd54e984066036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44193d2bcc6b4ab19c543389551baca8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18dd87020adc4a14b9fe0f3937252eb3",
            "value": 1
          }
        },
        "76f44cd7349b45f287bca09a8ecdd3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1e28fc850af417fac03c0f4d0a7f90b",
            "placeholder": "​",
            "style": "IPY_MODEL_8e0ec62e84ad487a8ab67bfd9af350c4",
            "value": " 1/1 [00:00&lt;00:00, 102.23it/s]"
          }
        },
        "aec8cb7803ac43b398c395156cd98534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ee83644f3447debf43ed82009e580f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41a589737b7a43e88606341999bca766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44193d2bcc6b4ab19c543389551baca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18dd87020adc4a14b9fe0f3937252eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1e28fc850af417fac03c0f4d0a7f90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e0ec62e84ad487a8ab67bfd9af350c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ed769e83a54005b0b38f99aa4892fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e8b2a7f4f9445fd90df3a4568893186",
              "IPY_MODEL_d8b7bc70b0af405a9b07e4fc732ff31d",
              "IPY_MODEL_060d6e7f52de4368b82b062a6f48b5d9"
            ],
            "layout": "IPY_MODEL_9926001a05fb4b648b1e71697544391e"
          }
        },
        "6e8b2a7f4f9445fd90df3a4568893186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48985b0e4c4a4ecf83255d25ddaf3a6a",
            "placeholder": "​",
            "style": "IPY_MODEL_54cc88a6dd2b45baa894760f9fa9933b",
            "value": "Fetching 1 files: 100%"
          }
        },
        "d8b7bc70b0af405a9b07e4fc732ff31d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c3427bc15a409889672e7d8c991d02",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d8e0241c9864ec295e08aabb7de7c5e",
            "value": 1
          }
        },
        "060d6e7f52de4368b82b062a6f48b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3512db97c4104a30ab04a73336e20a1b",
            "placeholder": "​",
            "style": "IPY_MODEL_404d1ba265ae436f9e1633a969c1ee55",
            "value": " 1/1 [00:00&lt;00:00, 102.80it/s]"
          }
        },
        "9926001a05fb4b648b1e71697544391e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48985b0e4c4a4ecf83255d25ddaf3a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54cc88a6dd2b45baa894760f9fa9933b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c3427bc15a409889672e7d8c991d02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d8e0241c9864ec295e08aabb7de7c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3512db97c4104a30ab04a73336e20a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "404d1ba265ae436f9e1633a969c1ee55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "044fb81c95a6402aaffe43a0d1f96ee8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87b49f76061f4c31ac60ba7bc8945b58",
              "IPY_MODEL_a19c6d72b56a482cb29099f76ef61719",
              "IPY_MODEL_a2228d2e0b2140abab6f30828b27ef60"
            ],
            "layout": "IPY_MODEL_a6a70ddc851040698c3dbc353edf4d80"
          }
        },
        "87b49f76061f4c31ac60ba7bc8945b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8a6aa08bb1546b4a8059f5c7e619094",
            "placeholder": "​",
            "style": "IPY_MODEL_12dbfee44ae84a9592649e1e15447626",
            "value": "Fetching 1 files: 100%"
          }
        },
        "a19c6d72b56a482cb29099f76ef61719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f0ada9780684aa7b12c7d20c031e942",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b64cdd605c4a4a059c3c0eea1d42906f",
            "value": 1
          }
        },
        "a2228d2e0b2140abab6f30828b27ef60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1040c0952c44d778c73ab5b340526f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8fad99f096ca4bb6ad5211891b3fedc7",
            "value": " 1/1 [00:00&lt;00:00, 124.88it/s]"
          }
        },
        "a6a70ddc851040698c3dbc353edf4d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8a6aa08bb1546b4a8059f5c7e619094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dbfee44ae84a9592649e1e15447626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0ada9780684aa7b12c7d20c031e942": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64cdd605c4a4a059c3c0eea1d42906f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1040c0952c44d778c73ab5b340526f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fad99f096ca4bb6ad5211891b3fedc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7b3efa916944379bb8363b77eebb51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5f540f77c59493ea704da7edd2d8b10",
              "IPY_MODEL_e84918fec4254cdca70b371471076ef5",
              "IPY_MODEL_a73ef68ea28e46f8bdcfb9cdd1438ca2"
            ],
            "layout": "IPY_MODEL_1afc762966ae41b882700c549b619a34"
          }
        },
        "c5f540f77c59493ea704da7edd2d8b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf0a509ed9834a51852ada97072cb43a",
            "placeholder": "​",
            "style": "IPY_MODEL_e38399aec54f41ecac4c7f91e654f920",
            "value": "Fetching 1 files: 100%"
          }
        },
        "e84918fec4254cdca70b371471076ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd7a46868e1433b92b90542385bd428",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_604156ec04614e42ae54f7d41ff5f813",
            "value": 1
          }
        },
        "a73ef68ea28e46f8bdcfb9cdd1438ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03aa4cf18cf84cc48aa91e5a3d7abb32",
            "placeholder": "​",
            "style": "IPY_MODEL_9d789dab41044ed48e945afbc84294c1",
            "value": " 1/1 [00:00&lt;00:00, 119.21it/s]"
          }
        },
        "1afc762966ae41b882700c549b619a34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf0a509ed9834a51852ada97072cb43a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38399aec54f41ecac4c7f91e654f920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd7a46868e1433b92b90542385bd428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604156ec04614e42ae54f7d41ff5f813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03aa4cf18cf84cc48aa91e5a3d7abb32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d789dab41044ed48e945afbc84294c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f302129eac44636912c552b008964b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7dff668b71b4ff6bb01218ef32e13f6",
              "IPY_MODEL_085403b326394c35937f28cc1dd6500c",
              "IPY_MODEL_3d3e43ada429452e9a2da1e7da5d9b04"
            ],
            "layout": "IPY_MODEL_b8738d6cbb0b461387b3f1e921dc82b6"
          }
        },
        "f7dff668b71b4ff6bb01218ef32e13f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2896c9df9a4c495a8554080674835f17",
            "placeholder": "​",
            "style": "IPY_MODEL_0add7c5159a84b23864585f9686ebfc8",
            "value": "Fetching 1 files: 100%"
          }
        },
        "085403b326394c35937f28cc1dd6500c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d51efe916e4db49293f23b9dee702d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_486ed01260f340a8892ba622dbfac90f",
            "value": 1
          }
        },
        "3d3e43ada429452e9a2da1e7da5d9b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4754a021b7704a379f6ac6882121f3ad",
            "placeholder": "​",
            "style": "IPY_MODEL_60c145b6fff6487caa69009a8eb85e66",
            "value": " 1/1 [00:00&lt;00:00, 114.67it/s]"
          }
        },
        "b8738d6cbb0b461387b3f1e921dc82b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2896c9df9a4c495a8554080674835f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0add7c5159a84b23864585f9686ebfc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7d51efe916e4db49293f23b9dee702d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "486ed01260f340a8892ba622dbfac90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4754a021b7704a379f6ac6882121f3ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c145b6fff6487caa69009a8eb85e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9dcb59c97d324e5b9d6d7dc93d018cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ac539d3f4904232bffb9bfc1f40d2b7",
              "IPY_MODEL_e1cd12c51ee34b12b8d84f0a860ed8eb",
              "IPY_MODEL_1a64f233165d4049a529567d1130c93b"
            ],
            "layout": "IPY_MODEL_00f2cddc92754ce3b9006f6a7c828833"
          }
        },
        "7ac539d3f4904232bffb9bfc1f40d2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32b9cd65b23486f80ff60a986aad30c",
            "placeholder": "​",
            "style": "IPY_MODEL_1730339408004fd88a9f8464591d459d",
            "value": "Fetching 1 files: 100%"
          }
        },
        "e1cd12c51ee34b12b8d84f0a860ed8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d56e167ad5434390ad41faa793ba718b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f961d0395e5849a189b4a738c93cfb4e",
            "value": 1
          }
        },
        "1a64f233165d4049a529567d1130c93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0ef5b5d99a43f0b96dff999ca1c784",
            "placeholder": "​",
            "style": "IPY_MODEL_ab5e4d1de1aa4554a53e8f73fc6fc018",
            "value": " 1/1 [00:00&lt;00:00, 123.80it/s]"
          }
        },
        "00f2cddc92754ce3b9006f6a7c828833": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b32b9cd65b23486f80ff60a986aad30c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1730339408004fd88a9f8464591d459d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d56e167ad5434390ad41faa793ba718b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f961d0395e5849a189b4a738c93cfb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f0ef5b5d99a43f0b96dff999ca1c784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5e4d1de1aa4554a53e8f73fc6fc018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "507d738e60cd4df68e35bd343e553208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2dc1a46cd28e4468b0571310455eacca",
              "IPY_MODEL_41331be1eac64e14ba570c38917da072",
              "IPY_MODEL_8a6ab991809c4555a9d8185070624940"
            ],
            "layout": "IPY_MODEL_088a00f46961401f9d26ee2981006a28"
          }
        },
        "2dc1a46cd28e4468b0571310455eacca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_689e995b7afe4c678d954b8d21310faf",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf37048d72643afae9f2434bf19f0af",
            "value": "Fetching 1 files: 100%"
          }
        },
        "41331be1eac64e14ba570c38917da072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_407493e75b56409ba35ab65889033e36",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a961cad573844d62bdd5ea601378cfa7",
            "value": 1
          }
        },
        "8a6ab991809c4555a9d8185070624940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6909cea8fe574c238b22d7154ca907f2",
            "placeholder": "​",
            "style": "IPY_MODEL_9db0fdc365fe45fe851abda8d601dbcb",
            "value": " 1/1 [00:00&lt;00:00, 120.80it/s]"
          }
        },
        "088a00f46961401f9d26ee2981006a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689e995b7afe4c678d954b8d21310faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf37048d72643afae9f2434bf19f0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "407493e75b56409ba35ab65889033e36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a961cad573844d62bdd5ea601378cfa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6909cea8fe574c238b22d7154ca907f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db0fdc365fe45fe851abda8d601dbcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe2bd87b3394da9b268e62c904e156c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c64427d7300b4d42b8009a2f89ea2e63",
              "IPY_MODEL_4c233243e94649f1bef2a0acecbf5b50",
              "IPY_MODEL_432a62847d8d4a7fa683e8a4bb6463f6"
            ],
            "layout": "IPY_MODEL_102842ab7bdc4e459245966b041020cb"
          }
        },
        "c64427d7300b4d42b8009a2f89ea2e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b06ef0569ed476086657b34fc828097",
            "placeholder": "​",
            "style": "IPY_MODEL_54945cbff9044903bc0a3700d5f4a7f5",
            "value": "Fetching 1 files: 100%"
          }
        },
        "4c233243e94649f1bef2a0acecbf5b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_206d73569da34fd695672f0ac8c1f7c8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0d976955efd4c138fd3ba50994c60a8",
            "value": 1
          }
        },
        "432a62847d8d4a7fa683e8a4bb6463f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21c041843ac442e0ac6d60bd6a24e920",
            "placeholder": "​",
            "style": "IPY_MODEL_d250f1f7786c4ed1834ad6796524478d",
            "value": " 1/1 [00:00&lt;00:00, 97.42it/s]"
          }
        },
        "102842ab7bdc4e459245966b041020cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b06ef0569ed476086657b34fc828097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54945cbff9044903bc0a3700d5f4a7f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206d73569da34fd695672f0ac8c1f7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d976955efd4c138fd3ba50994c60a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21c041843ac442e0ac6d60bd6a24e920": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d250f1f7786c4ed1834ad6796524478d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/01_Mask2Former_Evaluador_Master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "058HNFKWwyqn",
        "outputId": "29efac33-4d42-4e69-e8f2-04629b51771d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSistema de Evaluación Avanzado Mask2Former\\n==============================================================\\n\\nFramework completo para evaluación sistemática de modelos Mask2Former\\ncon análisis de características avanzadas usando librerías especializadas.\\n\\nCaracterísticas principales:\\n- Análisis geométrico con Shapely\\n- Características de textura con Mahotas y Scikit-image\\n- Exportación dual: JSON propio + formato COCO\\n- Sistema de logging estructurado\\n- Organización automática de directorios\\n\\nAutor: Jesús L.\\nProyecto: TFM - Evaluación Comparativa de Técnicas de Segmentación\\nUniversidad: Universidad Oberta de Cataluña\\nFecha: 2025\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Sistema de Evaluación Avanzado Mask2Former\n",
        "==============================================================\n",
        "\n",
        "Framework completo para evaluación sistemática de modelos Mask2Former\n",
        "con análisis de características avanzadas usando librerías especializadas.\n",
        "\n",
        "Características principales:\n",
        "- Análisis geométrico con Shapely\n",
        "- Características de textura con Mahotas y Scikit-image\n",
        "- Exportación dual: JSON propio + formato COCO\n",
        "- Sistema de logging estructurado\n",
        "- Organización automática de directorios\n",
        "\n",
        "Autor: Jesús L.\n",
        "Proyecto: TFM - Evaluación Comparativa de Técnicas de Segmentación\n",
        "Universidad: Universidad Oberta de Cataluña\n",
        "Fecha: 2025\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Librerías principales que necesitas instalar\n",
        "!pip install shapely\n",
        "!pip install mahotas\n",
        "!pip install scikit-image\n",
        "\n",
        "# Librerías adicionales que podrían no estar actualizadas\n",
        "!pip install opencv-python\n",
        "!pip install psutil\n",
        "\n",
        "# Si tienes problemas con versiones específicas, usa estas versiones estables:\n",
        "!pip install shapely>=1.8.0\n",
        "!pip install mahotas>=1.4.0\n",
        "!pip install scikit-image>=0.19.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZWMRAGsDDIX",
        "outputId": "bf6d937b-a86a-4e21-b499-7e48ce7cbe5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shapely in /usr/local/lib/python3.12/dist-packages (2.1.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.12/dist-packages (from shapely) (2.0.2)\n",
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mahotas) (2.0.2)\n",
            "Downloading mahotas-1.4.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.18\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (5.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import psutil\n",
        "import logging\n",
        "import hashlib\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "\n",
        "# Librerías especializadas para análisis avanzado\n",
        "import mahotas as mh\n",
        "from shapely.geometry import Polygon, Point\n",
        "from shapely.ops import unary_union\n",
        "from shapely import affinity\n",
        "from skimage import measure, morphology, feature, filters, segmentation\n",
        "from skimage.color import rgb2gray, rgb2hsv, rgb2lab\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from transformers import AutoImageProcessor, AutoModelForUniversalSegmentation\n",
        "from PIL import Image, ImageStat\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuración para entorno Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Suprimir warnings para salida más limpia\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlrFPQ1l5T5D",
        "outputId": "31960c9d-bb0f-46bf-b304-72a398b92259"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN Y ESTRUCTURAS DE DATOS\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloInfo:\n",
        "    \"\"\"Información completa de un modelo Mask2Former\"\"\"\n",
        "    nombre_hf: str\n",
        "    nombre_corto: str\n",
        "    tipo: str  # 'instancia' o 'semantico'\n",
        "    dataset: str  # 'COCO', 'ADE20K', etc.\n",
        "    arquitectura: str  # 'Swin-Large', 'Swin-Base', etc.\n",
        "    descripcion: str\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionUmbrales:\n",
        "    \"\"\"Configuración de umbrales con metadatos\"\"\"\n",
        "    nombre: str\n",
        "    valores: List[float]\n",
        "    descripcion: str\n",
        "\n",
        "@dataclass\n",
        "class ConfigEvaluacion:\n",
        "    \"\"\"Configuración centralizada del sistema de evaluación avanzado\"\"\"\n",
        "\n",
        "    # Rutas base\n",
        "    BASE_PATH: Path = Path(\"/content/drive/MyDrive/TFM/mask2former\")\n",
        "    DATASET_PATH: Path = BASE_PATH / \"imagenes\"\n",
        "\n",
        "    # Parámetros de procesamiento\n",
        "    MAX_SIZE_IMAGEN: int = 1024\n",
        "    MAX_IMAGENES_LOTE: int = 50\n",
        "    GUARDAR_VISUALIZACIONES: bool = True\n",
        "    LIMPIAR_CACHE_CADA: int = 25\n",
        "    GENERAR_FORMATO_COCO: bool = True\n",
        "\n",
        "    # Modelos disponibles\n",
        "    MODELOS: List[ModeloInfo] = None\n",
        "\n",
        "    # Configuraciones de umbrales\n",
        "    UMBRALES: Dict[str, ConfiguracionUmbrales] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.MODELOS is None:\n",
        "            self.MODELOS = [\n",
        "                ModeloInfo(\n",
        "                    nombre_hf=\"facebook/mask2former-swin-large-coco-instance\",\n",
        "                    nombre_corto=\"swin-large-coco-instance\",\n",
        "                    tipo='instancia',\n",
        "                    dataset='COCO',\n",
        "                    arquitectura='Swin-Large',\n",
        "                    descripcion='Segmentación por instancia - Mayor precisión'\n",
        "                ),\n",
        "                ModeloInfo(\n",
        "                    nombre_hf=\"facebook/mask2former-swin-base-ade-semantic\",\n",
        "                    nombre_corto=\"swin-base-ade-semantic\",\n",
        "                    tipo='semantico',\n",
        "                    dataset='ADE20K',\n",
        "                    arquitectura='Swin-Base',\n",
        "                    descripcion='Segmentación semántica - Balance eficiencia/precisión'\n",
        "                ),\n",
        "                ModeloInfo(\n",
        "                    nombre_hf=\"facebook/mask2former-swin-small-coco-instance\",\n",
        "                    nombre_corto=\"swin-small-coco-instance\",\n",
        "                    tipo='instancia',\n",
        "                    dataset='COCO',\n",
        "                    arquitectura='Swin-Small',\n",
        "                    descripcion='Segmentación por instancia - Más rápido'\n",
        "                )\n",
        "            ]\n",
        "\n",
        "        if self.UMBRALES is None:\n",
        "            self.UMBRALES = {\n",
        "                'ultra_sensible': ConfiguracionUmbrales(\n",
        "                    nombre='ultra_sensible',\n",
        "                    valores=[0.0001, 0.001, 0.01, 0.1],\n",
        "                    descripcion='Detecta cambios mínimos - Máxima sensibilidad'\n",
        "                ),\n",
        "                'alta_sensibilidad': ConfiguracionUmbrales(\n",
        "                    nombre='alta_sensibilidad',\n",
        "                    valores=[0.001, 0.01, 0.05, 0.1, 0.3],\n",
        "                    descripcion='Sensibilidad alta para detección temprana'\n",
        "                ),\n",
        "                'sensibilidad_media': ConfiguracionUmbrales(\n",
        "                    nombre='sensibilidad_media',\n",
        "                    valores=[0.01, 0.1, 0.3, 0.5],\n",
        "                    descripcion='Balance entre precisión y recall'\n",
        "                ),\n",
        "                'baja_sensibilidad': ConfiguracionUmbrales(\n",
        "                    nombre='baja_sensibilidad',\n",
        "                    valores=[0.3, 0.5, 0.7],\n",
        "                    descripcion='Solo detecciones muy confiables'\n",
        "                )\n",
        "            }\n",
        "\n",
        "    def crear_directorio_ejecucion(self) -> Path:\n",
        "        \"\"\"Crea directorio único para cada ejecución con timestamp\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        directorio_ejecucion = self.BASE_PATH / \"resultados\" / f\"ejecucion_{timestamp}\"\n",
        "\n",
        "        subdirectorios = [\n",
        "            \"logs\",\n",
        "            \"resultados_json\",\n",
        "            \"formato_coco\",\n",
        "            \"caracteristicas_avanzadas\",\n",
        "            \"visualizaciones\",\n",
        "            \"resumenes\"\n",
        "        ]\n",
        "\n",
        "        for subdir in subdirectorios:\n",
        "            (directorio_ejecucion / subdir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        return directorio_ejecucion"
      ],
      "metadata": {
        "id": "ZTEoGGef5YXy"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SISTEMA DE LOGGING ESTRUCTURADO\n",
        "# =============================================================================\n",
        "\n",
        "class LoggerManager:\n",
        "    \"\"\"Gestor centralizado de logging para diferentes componentes del sistema\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_logs: Path):\n",
        "        self.directorio_logs = directorio_logs\n",
        "        self.loggers = {}\n",
        "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            datefmt='%Y-%m-%d %H:%M:%S'\n",
        "        )\n",
        "\n",
        "    def crear_logger(self, nombre: str, archivo_log: str = None) -> logging.Logger:\n",
        "        \"\"\"Crea un logger específico para un componente\"\"\"\n",
        "        if nombre in self.loggers:\n",
        "            return self.loggers[nombre]\n",
        "\n",
        "        logger = logging.getLogger(nombre)\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        if logger.handlers:\n",
        "            logger.handlers.clear()\n",
        "\n",
        "        if archivo_log is None:\n",
        "            archivo_log = f\"{nombre.lower()}_{self.timestamp}.log\"\n",
        "\n",
        "        archivo_path = self.directorio_logs / archivo_log\n",
        "        handler_archivo = logging.FileHandler(archivo_path, encoding='utf-8')\n",
        "\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s - %(levelname)-8s - %(message)s',\n",
        "            datefmt='%H:%M:%S'\n",
        "        )\n",
        "        handler_archivo.setFormatter(formatter)\n",
        "\n",
        "        logger.addHandler(handler_archivo)\n",
        "        self.loggers[nombre] = logger\n",
        "\n",
        "        return logger"
      ],
      "metadata": {
        "id": "tWhBQMN85zeG"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ANALIZADOR DE MÁSCARAS CON SHAPELY\n",
        "# =============================================================================\n",
        "\n",
        "class MaskAnalyzer:\n",
        "    \"\"\"Analizador especializado de máscaras de segmentación usando Shapely\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.epsilon_factor = 0.02\n",
        "\n",
        "    def analizar_mascaras_completo(self, masks: np.ndarray, scores: List[float],\n",
        "                                  imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"Análisis completo de todas las máscaras detectadas\"\"\"\n",
        "        if len(masks) == 0:\n",
        "            return self._resultado_vacio()\n",
        "\n",
        "        resultado = {\n",
        "            'metadatos': {\n",
        "                'num_mascaras': len(masks),\n",
        "                'imagen_shape': imagen_shape,\n",
        "                'total_pixels': imagen_shape[0] * imagen_shape[1]\n",
        "            },\n",
        "            'mascaras_individuales': [],\n",
        "            'analisis_conjunto': {},\n",
        "            'estadisticas_globales': {}\n",
        "        }\n",
        "\n",
        "        polygons_validos = []\n",
        "\n",
        "        # Análisis individual de cada máscara\n",
        "        for i, (mask, score) in enumerate(zip(masks, scores)):\n",
        "            analisis_individual = self._analizar_mascara_individual(\n",
        "                mask, score, i, imagen_shape\n",
        "            )\n",
        "            resultado['mascaras_individuales'].append(analisis_individual)\n",
        "\n",
        "            if analisis_individual['shapely_geometry']['polygon_valido']:\n",
        "                polygons_validos.append(analisis_individual['shapely_geometry']['polygon'])\n",
        "\n",
        "        # Análisis conjunto\n",
        "        if polygons_validos:\n",
        "            resultado['analisis_conjunto'] = self._analizar_conjunto_mascaras(\n",
        "                polygons_validos, imagen_shape\n",
        "            )\n",
        "\n",
        "        # Estadísticas globales\n",
        "        resultado['estadisticas_globales'] = self._calcular_estadisticas_globales(\n",
        "            resultado['mascaras_individuales']\n",
        "        )\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def _analizar_mascara_individual(self, mask: np.ndarray, score: float,\n",
        "                                   indice: int, imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"Análisis completo de una máscara individual\"\"\"\n",
        "        mask_binary = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "        resultado = {\n",
        "            'indice': indice,\n",
        "            'score_confianza': float(score),\n",
        "            'caracteristicas_geometricas': {},\n",
        "            'caracteristicas_forma': {},\n",
        "            'caracteristicas_contextuales': {},\n",
        "            'shapely_geometry': {}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            resultado['caracteristicas_geometricas'] = self._extraer_geometricas_basicas(\n",
        "                mask_binary, imagen_shape\n",
        "            )\n",
        "            resultado['shapely_geometry'] = self._analizar_con_shapely(mask_binary)\n",
        "            resultado['caracteristicas_forma'] = self._extraer_forma_calidad(mask_binary)\n",
        "            resultado['caracteristicas_contextuales'] = self._extraer_contextuales(\n",
        "                mask_binary, imagen_shape\n",
        "            )\n",
        "        except Exception as e:\n",
        "            resultado['error'] = str(e)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def _extraer_geometricas_basicas(self, mask: np.ndarray,\n",
        "                                   imagen_shape: Tuple[int, int]) -> Dict[str, float]:\n",
        "        \"\"\"Extrae características geométricas básicas usando scikit-image\"\"\"\n",
        "        props = measure.regionprops(mask.astype(int))[0] if np.any(mask) else None\n",
        "\n",
        "        if props is None:\n",
        "            return self._geometricas_vacias()\n",
        "\n",
        "        total_pixels = imagen_shape[0] * imagen_shape[1]\n",
        "\n",
        "        return {\n",
        "            'area_pixels': float(props.area),\n",
        "            'area_percentage': float(props.area / total_pixels * 100),\n",
        "            'perimeter': float(props.perimeter),\n",
        "            'compactness': float(4 * np.pi * props.area / (props.perimeter ** 2)) if props.perimeter > 0 else 0.0,\n",
        "            'aspect_ratio': float(props.major_axis_length / props.minor_axis_length) if props.minor_axis_length > 0 else 0.0,\n",
        "            'orientation_angle': float(np.degrees(props.orientation)),\n",
        "            'centroid_y': float(props.centroid[0]),\n",
        "            'centroid_x': float(props.centroid[1]),\n",
        "            'solidity': float(props.solidity),\n",
        "            'extent': float(props.extent),\n",
        "            'eccentricity': float(props.eccentricity),\n",
        "            'major_axis_length': float(props.major_axis_length),\n",
        "            'minor_axis_length': float(props.minor_axis_length)\n",
        "        }\n",
        "\n",
        "    def _analizar_con_shapely(self, mask: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Análisis geométrico avanzado usando Shapely\"\"\"\n",
        "        try:\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if not contours:\n",
        "                return self._shapely_vacio()\n",
        "\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            epsilon = self.epsilon_factor * cv2.arcLength(contour, True)\n",
        "            contour_simplified = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            if len(contour_simplified) < 3:\n",
        "                return self._shapely_vacio()\n",
        "\n",
        "            coords = [(point[0][0], point[0][1]) for point in contour_simplified]\n",
        "            if coords[0] != coords[-1]:\n",
        "                coords.append(coords[0])\n",
        "\n",
        "            polygon = Polygon(coords)\n",
        "\n",
        "            if not polygon.is_valid:\n",
        "                polygon = polygon.buffer(0)\n",
        "\n",
        "            if not polygon.is_valid:\n",
        "                return self._shapely_vacio()\n",
        "\n",
        "            convex_hull = polygon.convex_hull\n",
        "\n",
        "            return {\n",
        "                'polygon_valido': True,\n",
        "                'polygon': polygon,\n",
        "                'area_shapely': float(polygon.area),\n",
        "                'perimeter_shapely': float(polygon.length),\n",
        "                'convex_hull_area': float(convex_hull.area),\n",
        "                'convexity_ratio': float(polygon.area / convex_hull.area),\n",
        "                'is_simple': bool(polygon.is_simple),\n",
        "                'num_vertices': len(coords) - 1,\n",
        "                'bounds': polygon.bounds,\n",
        "                'centroid_shapely': (float(polygon.centroid.x), float(polygon.centroid.y))\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'polygon_valido': False,\n",
        "                'error_shapely': str(e),\n",
        "                **self._shapely_vacio()\n",
        "            }\n",
        "\n",
        "    def _extraer_forma_calidad(self, mask: np.ndarray) -> Dict[str, float]:\n",
        "        \"\"\"Características de forma y calidad de la máscara\"\"\"\n",
        "        try:\n",
        "            labeled_mask = measure.label(mask)\n",
        "            num_components = labeled_mask.max()\n",
        "\n",
        "            edges = cv2.Canny(mask.astype(np.uint8) * 255, 50, 150)\n",
        "            edge_pixels = np.sum(edges > 0)\n",
        "\n",
        "            grad_x = cv2.Sobel(mask.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)\n",
        "            grad_y = cv2.Sobel(mask.astype(np.float32), cv2.CV_32F, 0, 1, ksize=3)\n",
        "            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "            edge_smoothness = float(np.std(gradient_magnitude[gradient_magnitude > 0]))\n",
        "\n",
        "            filled = morphology.binary_fill_holes(mask)\n",
        "            holes_area = np.sum(filled) - np.sum(mask)\n",
        "\n",
        "            if np.sum(mask) > 0:\n",
        "                equivalent_diameter = np.sqrt(4 * np.sum(mask) / np.pi)\n",
        "                ideal_perimeter = np.pi * equivalent_diameter\n",
        "                actual_perimeter = float(measure.perimeter(mask))\n",
        "                roughness = actual_perimeter / ideal_perimeter if ideal_perimeter > 0 else 0.0\n",
        "            else:\n",
        "                roughness = 0.0\n",
        "\n",
        "            return {\n",
        "                'num_components': int(num_components),\n",
        "                'edge_pixels': int(edge_pixels),\n",
        "                'edge_smoothness': edge_smoothness,\n",
        "                'holes_area': int(holes_area),\n",
        "                'holes_percentage': float(holes_area / np.sum(filled) * 100) if np.sum(filled) > 0 else 0.0,\n",
        "                'roughness_factor': roughness,\n",
        "                'is_single_component': bool(num_components == 1)\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error_forma': str(e),\n",
        "                'num_components': 0,\n",
        "                'edge_pixels': 0,\n",
        "                'edge_smoothness': 0.0,\n",
        "                'holes_area': 0,\n",
        "                'holes_percentage': 0.0,\n",
        "                'roughness_factor': 0.0,\n",
        "                'is_single_component': False\n",
        "            }\n",
        "\n",
        "    def _extraer_contextuales(self, mask: np.ndarray,\n",
        "                            imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"Características contextuales de posición y distribución\"\"\"\n",
        "        h, w = imagen_shape\n",
        "        props = measure.regionprops(mask.astype(int))[0] if np.any(mask) else None\n",
        "\n",
        "        if props is None:\n",
        "            return self._contextuales_vacios()\n",
        "\n",
        "        cy, cx = props.centroid\n",
        "        pos_y_rel = cy / h\n",
        "        pos_x_rel = cx / w\n",
        "\n",
        "        position_region = self._clasificar_posicion(pos_x_rel, pos_y_rel)\n",
        "\n",
        "        dist_top = cy\n",
        "        dist_bottom = h - cy\n",
        "        dist_left = cx\n",
        "        dist_right = w - cx\n",
        "\n",
        "        center_x, center_y = w / 2, h / 2\n",
        "        dist_to_center = np.sqrt((cx - center_x)**2 + (cy - center_y)**2)\n",
        "        dist_to_center_normalized = dist_to_center / np.sqrt(center_x**2 + center_y**2)\n",
        "\n",
        "        bbox = props.bbox\n",
        "        bbox_area = (bbox[2] - bbox[0]) * (bbox[3] - bbox[1])\n",
        "        bbox_coverage = float(bbox_area / (h * w))\n",
        "\n",
        "        return {\n",
        "            'centroid_relative': {'x': float(pos_x_rel), 'y': float(pos_y_rel)},\n",
        "            'position_region': position_region,\n",
        "            'distances_to_edges': {\n",
        "                'top': float(dist_top),\n",
        "                'bottom': float(dist_bottom),\n",
        "                'left': float(dist_left),\n",
        "                'right': float(dist_right)\n",
        "            },\n",
        "            'distance_to_center': float(dist_to_center),\n",
        "            'distance_to_center_normalized': float(dist_to_center_normalized),\n",
        "            'bbox_coverage_percentage': float(bbox_coverage * 100),\n",
        "            'aspect_vs_image': float((bbox[3] - bbox[1]) / (bbox[2] - bbox[0])) if (bbox[2] - bbox[0]) > 0 else 0.0\n",
        "        }\n",
        "\n",
        "    def _analizar_conjunto_mascaras(self, polygons: List[Polygon],\n",
        "                                  imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"Análisis de relaciones entre múltiples máscaras\"\"\"\n",
        "        if len(polygons) < 2:\n",
        "            return {'num_mascaras': len(polygons), 'analisis_conjunto': 'insuficientes_mascaras'}\n",
        "\n",
        "        union_polygon = unary_union(polygons)\n",
        "        overlaps = []\n",
        "        distances = []\n",
        "\n",
        "        for i in range(len(polygons)):\n",
        "            for j in range(i + 1, len(polygons)):\n",
        "                poly1, poly2 = polygons[i], polygons[j]\n",
        "\n",
        "                intersection = poly1.intersection(poly2)\n",
        "                overlap_area = intersection.area if hasattr(intersection, 'area') else 0\n",
        "                overlap_percentage = (overlap_area / min(poly1.area, poly2.area)) * 100\n",
        "                overlaps.append(overlap_percentage)\n",
        "\n",
        "                distance = poly1.distance(poly2)\n",
        "                distances.append(distance)\n",
        "\n",
        "        centroids = [poly.centroid for poly in polygons]\n",
        "        centroid_distances = []\n",
        "\n",
        "        for i in range(len(centroids)):\n",
        "            for j in range(i + 1, len(centroids)):\n",
        "                dist = centroids[i].distance(centroids[j])\n",
        "                centroid_distances.append(dist)\n",
        "\n",
        "        return {\n",
        "            'num_mascaras': len(polygons),\n",
        "            'area_total_union': float(union_polygon.area),\n",
        "            'coverage_percentage': float(union_polygon.area / (imagen_shape[0] * imagen_shape[1]) * 100),\n",
        "            'overlaps': {\n",
        "                'mean_overlap_percentage': float(np.mean(overlaps)),\n",
        "                'max_overlap_percentage': float(np.max(overlaps)),\n",
        "                'num_overlapping_pairs': int(np.sum(np.array(overlaps) > 0))\n",
        "            },\n",
        "            'distances': {\n",
        "                'mean_distance': float(np.mean(distances)),\n",
        "                'min_distance': float(np.min(distances)),\n",
        "                'max_distance': float(np.max(distances))\n",
        "            },\n",
        "            'spatial_distribution': {\n",
        "                'mean_centroid_distance': float(np.mean(centroid_distances)),\n",
        "                'centroid_spread': float(np.std(centroid_distances))\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _calcular_estadisticas_globales(self, mascaras_individuales: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Estadísticas globales del conjunto de máscaras\"\"\"\n",
        "        if not mascaras_individuales:\n",
        "            return {}\n",
        "\n",
        "        areas = []\n",
        "        compactness = []\n",
        "        scores = []\n",
        "        roughness = []\n",
        "\n",
        "        for mask_data in mascaras_individuales:\n",
        "            if 'error' not in mask_data:\n",
        "                geom = mask_data.get('caracteristicas_geometricas', {})\n",
        "                forma = mask_data.get('caracteristicas_forma', {})\n",
        "\n",
        "                areas.append(geom.get('area_percentage', 0))\n",
        "                compactness.append(geom.get('compactness', 0))\n",
        "                scores.append(mask_data.get('score_confianza', 0))\n",
        "                roughness.append(forma.get('roughness_factor', 0))\n",
        "\n",
        "        def safe_stats(values):\n",
        "            if not values:\n",
        "                return {'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}\n",
        "            return {\n",
        "                'mean': float(np.mean(values)),\n",
        "                'std': float(np.std(values)),\n",
        "                'min': float(np.min(values)),\n",
        "                'max': float(np.max(values))\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'areas_estadisticas': safe_stats(areas),\n",
        "            'compactness_estadisticas': safe_stats(compactness),\n",
        "            'scores_estadisticas': safe_stats(scores),\n",
        "            'roughness_estadisticas': safe_stats(roughness),\n",
        "            'mascaras_exitosas': len([m for m in mascaras_individuales if 'error' not in m])\n",
        "        }\n",
        "\n",
        "    # Métodos auxiliares\n",
        "    def _resultado_vacio(self):\n",
        "        return {\n",
        "            'metadatos': {'num_mascaras': 0},\n",
        "            'mascaras_individuales': [],\n",
        "            'analisis_conjunto': {},\n",
        "            'estadisticas_globales': {}\n",
        "        }\n",
        "\n",
        "    def _geometricas_vacias(self):\n",
        "        return {k: 0.0 for k in ['area_pixels', 'area_percentage', 'perimeter',\n",
        "                                'compactness', 'aspect_ratio', 'orientation_angle',\n",
        "                                'centroid_y', 'centroid_x', 'solidity', 'extent',\n",
        "                                'eccentricity', 'major_axis_length', 'minor_axis_length']}\n",
        "\n",
        "    def _shapely_vacio(self):\n",
        "        return {\n",
        "            'polygon_valido': False,\n",
        "            'polygon': None,\n",
        "            'area_shapely': 0.0,\n",
        "            'perimeter_shapely': 0.0,\n",
        "            'convex_hull_area': 0.0,\n",
        "            'convexity_ratio': 0.0,\n",
        "            'is_simple': False,\n",
        "            'num_vertices': 0,\n",
        "            'bounds': (0, 0, 0, 0),\n",
        "            'centroid_shapely': (0.0, 0.0)\n",
        "        }\n",
        "\n",
        "    def _contextuales_vacios(self):\n",
        "        return {\n",
        "            'centroid_relative': {'x': 0.0, 'y': 0.0},\n",
        "            'position_region': 'desconocida',\n",
        "            'distances_to_edges': {'top': 0.0, 'bottom': 0.0, 'left': 0.0, 'right': 0.0},\n",
        "            'distance_to_center': 0.0,\n",
        "            'distance_to_center_normalized': 0.0,\n",
        "            'bbox_coverage_percentage': 0.0,\n",
        "            'aspect_vs_image': 0.0\n",
        "        }\n",
        "\n",
        "    def _clasificar_posicion(self, x_rel: float, y_rel: float) -> str:\n",
        "        \"\"\"Clasifica la posición de la máscara en la imagen\"\"\"\n",
        "        if y_rel < 0.33:\n",
        "            if x_rel < 0.33:\n",
        "                return 'superior_izquierda'\n",
        "            elif x_rel < 0.67:\n",
        "                return 'superior_centro'\n",
        "            else:\n",
        "                return 'superior_derecha'\n",
        "        elif y_rel < 0.67:\n",
        "            if x_rel < 0.33:\n",
        "                return 'centro_izquierda'\n",
        "            elif x_rel < 0.67:\n",
        "                return 'centro'\n",
        "            else:\n",
        "                return 'centro_derecha'\n",
        "        else:\n",
        "            if x_rel < 0.33:\n",
        "                return 'inferior_izquierda'\n",
        "            elif x_rel < 0.67:\n",
        "                return 'inferior_centro'\n",
        "            else:\n",
        "                return 'inferior_derecha'"
      ],
      "metadata": {
        "id": "URL3dy-X57yH"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXTRACTOR DE CARACTERÍSTICAS AVANZADAS\n",
        "# =============================================================================\n",
        "\n",
        "class ExtractorCaracteristicasAvanzado:\n",
        "    \"\"\"Extractor de características usando librerías especializadas\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = None\n",
        "\n",
        "    def set_logger(self, logger: logging.Logger):\n",
        "        \"\"\"Asigna logger para el extractor\"\"\"\n",
        "        self.logger = logger\n",
        "\n",
        "    def analizar_imagen_completa(self, imagen: Image.Image, ruta: str) -> Dict[str, Any]:\n",
        "        \"\"\"Análisis completo usando librerías especializadas\"\"\"\n",
        "        img_array = np.array(imagen)\n",
        "        img_gray = rgb2gray(img_array)\n",
        "        img_hsv = rgb2hsv(img_array)\n",
        "        img_lab = rgb2lab(img_array)\n",
        "\n",
        "        img_gray_uint8 = (img_gray * 255).astype(np.uint8)\n",
        "\n",
        "        caracteristicas = {\n",
        "            'metadatos_basicos': self._extraer_metadatos_basicos(imagen, ruta),\n",
        "            'color_y_paleta': self._analizar_color_avanzado(img_array, img_hsv, img_lab),\n",
        "            'texturas_mahotas': self._extraer_texturas_mahotas(img_gray_uint8),\n",
        "            'texturas_skimage': self._extraer_texturas_skimage(img_gray),\n",
        "            'caracteristicas_geometricas': self._analizar_geometria_avanzada(img_gray_uint8),\n",
        "            'multiscale_features': self._extraer_multiscale_features(img_gray),\n",
        "            'propiedades_regionales': self._analizar_propiedades_regionales(img_gray),\n",
        "            'descriptores_locales': self._extraer_descriptores_locales(img_gray_uint8)\n",
        "        }\n",
        "\n",
        "        return caracteristicas\n",
        "\n",
        "    def _extraer_metadatos_basicos(self, imagen: Image.Image, ruta: str) -> Dict:\n",
        "        \"\"\"Metadatos básicos de la imagen\"\"\"\n",
        "        w, h = imagen.size\n",
        "        return {\n",
        "            'dimensiones': {'ancho': w, 'alto': h},\n",
        "            'aspecto_ratio': round(w / h, 3),\n",
        "            'megapixeles': round((w * h) / 1000000, 2),\n",
        "            'orientacion': 'horizontal' if w > h else 'vertical' if h > w else 'cuadrada',\n",
        "            'formato': ruta.split('.')[-1].lower() if '.' in ruta else 'desconocido'\n",
        "        }\n",
        "\n",
        "    def _analizar_color_avanzado(self, img_rgb: np.ndarray, img_hsv: np.ndarray, img_lab: np.ndarray) -> Dict:\n",
        "        \"\"\"Análisis de color usando sklearn para paleta dominante\"\"\"\n",
        "        pixels = img_rgb.reshape(-1, 3)\n",
        "        kmeans = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
        "        kmeans.fit(pixels)\n",
        "\n",
        "        colores_dominantes = kmeans.cluster_centers_.astype(int).tolist()\n",
        "        proporciones = np.bincount(kmeans.labels_) / len(kmeans.labels_)\n",
        "\n",
        "        return {\n",
        "            'paleta_dominante': colores_dominantes,\n",
        "            'proporciones_colores': proporciones.tolist(),\n",
        "            'estadisticas_rgb': {\n",
        "                'media': np.mean(img_rgb, axis=(0,1)).tolist(),\n",
        "                'std': np.std(img_rgb, axis=(0,1)).tolist(),\n",
        "                'rango': {\n",
        "                    'min': np.min(img_rgb, axis=(0,1)).tolist(),\n",
        "                    'max': np.max(img_rgb, axis=(0,1)).tolist()\n",
        "                }\n",
        "            },\n",
        "            'hsv_global': {\n",
        "                'hue_medio': float(np.mean(img_hsv[:,:,0])),\n",
        "                'saturacion_media': float(np.mean(img_hsv[:,:,1])),\n",
        "                'valor_medio': float(np.mean(img_hsv[:,:,2]))\n",
        "            },\n",
        "            'lab_luminancia': {\n",
        "                'L_medio': float(np.mean(img_lab[:,:,0])),\n",
        "                'a_medio': float(np.mean(img_lab[:,:,1])),\n",
        "                'b_medio': float(np.mean(img_lab[:,:,2]))\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _extraer_texturas_mahotas(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Extracción de características de textura usando Mahotas\"\"\"\n",
        "        try:\n",
        "            haralick_features = mh.features.haralick(img_gray, return_mean=True)\n",
        "            lbp = mh.features.lbp(img_gray, radius=1, points=8, ignore_zeros=False)\n",
        "\n",
        "            try:\n",
        "                zernike_features = mh.features.zernike_moments(img_gray, radius=21)\n",
        "            except:\n",
        "                zernike_features = np.zeros(25)\n",
        "\n",
        "            otsu_threshold = mh.otsu(img_gray)\n",
        "            pftas = mh.features.pftas(img_gray)\n",
        "\n",
        "            return {\n",
        "                'haralick_features': haralick_features.tolist(),\n",
        "                'lbp_histogram': np.histogram(lbp, bins=50)[0].tolist(),\n",
        "                'zernike_moments': zernike_features.tolist(),\n",
        "                'otsu_threshold': float(otsu_threshold),\n",
        "                'pftas': pftas.tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en Mahotas: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en Mahotas: {str(e)}\",\n",
        "                'haralick_features': [],\n",
        "                'lbp_histogram': [],\n",
        "                'zernike_moments': [],\n",
        "                'otsu_threshold': 0.0,\n",
        "                'pftas': []\n",
        "            }\n",
        "\n",
        "    def _extraer_texturas_skimage(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Extracción de características de textura usando Scikit-image\"\"\"\n",
        "        try:\n",
        "            lbp_skimage = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')\n",
        "\n",
        "            img_scaled = (img_gray * 255).astype(np.uint8)\n",
        "            glcm = feature.graycomatrix(img_scaled, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
        "                                      levels=256, symmetric=True, normed=True)\n",
        "\n",
        "            contrast = feature.graycoprops(glcm, 'contrast').mean()\n",
        "            dissimilarity = feature.graycoprops(glcm, 'dissimilarity').mean()\n",
        "            homogeneity = feature.graycoprops(glcm, 'homogeneity').mean()\n",
        "            energy = feature.graycoprops(glcm, 'energy').mean()\n",
        "            correlation = feature.graycoprops(glcm, 'correlation').mean()\n",
        "\n",
        "            return {\n",
        "                'lbp_uniform_histogram': np.histogram(lbp_skimage, bins=10)[0].tolist(),\n",
        "                'glcm_properties': {\n",
        "                    'contrast': float(contrast),\n",
        "                    'dissimilarity': float(dissimilarity),\n",
        "                    'homogeneity': float(homogeneity),\n",
        "                    'energy': float(energy),\n",
        "                    'correlation': float(correlation)\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en Scikit-image: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en Scikit-image: {str(e)}\",\n",
        "                'lbp_uniform_histogram': [],\n",
        "                'glcm_properties': {}\n",
        "            }\n",
        "\n",
        "    def _analizar_geometria_avanzada(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Análisis geométrico usando mahotas y scikit-image\"\"\"\n",
        "        try:\n",
        "            edges_canny = feature.canny(img_gray / 255.0)\n",
        "            edges_sobel = mh.sobel(img_gray)\n",
        "\n",
        "            corners = feature.corner_harris(img_gray / 255.0)\n",
        "            corner_peaks = feature.corner_peaks(corners, min_distance=5)\n",
        "\n",
        "            moments = measure.moments(img_gray)\n",
        "            centroid = measure.centroid(img_gray)\n",
        "\n",
        "            return {\n",
        "                'bordes_canny': float(np.sum(edges_canny)),\n",
        "                'bordes_sobel_intensidad': float(np.mean(edges_sobel)),\n",
        "                'num_corners': len(corner_peaks),\n",
        "                'centroide': [float(centroid[0]), float(centroid[1])],\n",
        "                'momentos_hu': measure.moments_hu(moments).tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en análisis geométrico: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en análisis geométrico: {str(e)}\",\n",
        "                'bordes_canny': 0.0,\n",
        "                'bordes_sobel_intensidad': 0.0,\n",
        "                'num_corners': 0,\n",
        "                'centroide': [0.0, 0.0],\n",
        "                'momentos_hu': []\n",
        "            }\n",
        "\n",
        "    def _extraer_multiscale_features(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Características multi-escala usando scikit-image\"\"\"\n",
        "        try:\n",
        "            features_multiscale = feature.multiscale_basic_features(\n",
        "                img_gray,\n",
        "                intensity=True,\n",
        "                edges=True,\n",
        "                texture=True,\n",
        "                sigma_min=0.5,\n",
        "                sigma_max=8\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'num_features': features_multiscale.shape[-1],\n",
        "                'feature_means': np.mean(features_multiscale, axis=(0,1)).tolist(),\n",
        "                'feature_stds': np.std(features_multiscale, axis=(0,1)).tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en features multiscale: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en features multiscale: {str(e)}\",\n",
        "                'num_features': 0,\n",
        "                'feature_means': [],\n",
        "                'feature_stds': []\n",
        "            }\n",
        "\n",
        "    def _analizar_propiedades_regionales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Análisis de propiedades regionales usando segmentación\"\"\"\n",
        "        try:\n",
        "            # Especificar explícitamente que es imagen en escala de grises\n",
        "            segments = segmentation.slic(img_gray, n_segments=100, compactness=10, channel_axis=None)\n",
        "            regions = measure.regionprops(segments, intensity_image=img_gray)\n",
        "\n",
        "            if regions:\n",
        "                areas = [r.area for r in regions]\n",
        "                eccentricities = [r.eccentricity for r in regions]\n",
        "                intensities = [r.mean_intensity for r in regions]\n",
        "\n",
        "                return {\n",
        "                    'num_regiones': len(regions),\n",
        "                    'area_promedio': float(np.mean(areas)),\n",
        "                    'excentricidad_promedio': float(np.mean(eccentricities)),\n",
        "                    'intensidad_promedio_regiones': float(np.mean(intensities)),\n",
        "                    'variabilidad_areas': float(np.std(areas)),\n",
        "                    'variabilidad_intensidades': float(np.std(intensities))\n",
        "                }\n",
        "            else:\n",
        "                return {'num_regiones': 0}\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en análisis regional: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en análisis regional: {str(e)}\",\n",
        "                'num_regiones': 0\n",
        "            }\n",
        "\n",
        "    def _extraer_descriptores_locales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Descriptores locales usando OpenCV\"\"\"\n",
        "        try:\n",
        "            img_cv = img_gray.copy()\n",
        "\n",
        "            orb = cv2.ORB_create(nfeatures=100)\n",
        "            keypoints_orb = orb.detect(img_cv, None)\n",
        "\n",
        "            fast = cv2.FastFeatureDetector_create()\n",
        "            keypoints_fast = fast.detect(img_cv, None)\n",
        "\n",
        "            return {\n",
        "                'orb_keypoints': len(keypoints_orb),\n",
        "                'fast_keypoints': len(keypoints_fast),\n",
        "                'keypoint_density': (len(keypoints_orb) + len(keypoints_fast)) / (img_gray.shape[0] * img_gray.shape[1])\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error en descriptores locales: {str(e)}\")\n",
        "            return {\n",
        "                'error': f\"Error en descriptores locales: {str(e)}\",\n",
        "                'orb_keypoints': 0,\n",
        "                'fast_keypoints': 0,\n",
        "                'keypoint_density': 0.0\n",
        "            }"
      ],
      "metadata": {
        "id": "CGzdFC588JxH"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneradorVisualizaciones:\n",
        "    \"\"\"Genera visualizaciones comparativas imagen original vs detecciones\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_salida: Path, logger: logging.Logger = None):\n",
        "        self.directorio_salida = directorio_salida\n",
        "        self.logger = logger\n",
        "\n",
        "    def generar_visualizacion_completa(self, imagen_original: Image.Image,\n",
        "                                     nombre_archivo: str, resultados_deteccion: Dict,\n",
        "                                     umbral_principal: float = None,\n",
        "                                     modelo_nombre: str = \"modelo\") -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Genera visualización completa: original + máscaras + overlay\n",
        "\n",
        "        Args:\n",
        "            imagen_original: Imagen PIL original\n",
        "            nombre_archivo: Nombre del archivo de imagen\n",
        "            resultados_deteccion: Resultados de detección del modelo\n",
        "            umbral_principal: Umbral a usar para visualización (usa el primero si es None)\n",
        "            modelo_nombre: Nombre del modelo para el archivo\n",
        "\n",
        "        Returns:\n",
        "            Ruta del archivo de visualización generado\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Seleccionar umbral para visualización\n",
        "            detecciones_umbral = resultados_deteccion.get('detecciones_por_umbral', {})\n",
        "            if not detecciones_umbral:\n",
        "                return None\n",
        "\n",
        "            if umbral_principal is None:\n",
        "                # Usar el primer umbral disponible\n",
        "                umbral_key = list(detecciones_umbral.keys())[0]\n",
        "            else:\n",
        "                umbral_key = f'umbral_{umbral_principal}'\n",
        "\n",
        "            if umbral_key not in detecciones_umbral:\n",
        "                return None\n",
        "\n",
        "            datos_umbral = detecciones_umbral[umbral_key]\n",
        "\n",
        "            # Crear figura con subplots\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "            fig.suptitle(f'Detección de Personas - {nombre_archivo}', fontsize=16, fontweight='bold')\n",
        "\n",
        "            # 1. Imagen original\n",
        "            axes[0].imshow(imagen_original)\n",
        "            axes[0].set_title('Imagen Original', fontsize=14)\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # 2. Máscaras detectadas\n",
        "            self._generar_visualizacion_mascaras(axes[1], imagen_original, datos_umbral, umbral_key)\n",
        "\n",
        "            # 3. Overlay (original + máscaras superpuestas)\n",
        "            self._generar_overlay(axes[2], imagen_original, datos_umbral, umbral_key)\n",
        "\n",
        "            # Información adicional\n",
        "            personas = datos_umbral.get('personas_detectadas', 0)\n",
        "            total = datos_umbral.get('total_detecciones', 0)\n",
        "            umbral_val = umbral_key.replace('umbral_', '')\n",
        "\n",
        "            fig.text(0.5, 0.02, f'Personas detectadas: {personas} | Total detecciones: {total} | Umbral: {umbral_val}',\n",
        "                    ha='center', fontsize=12, style='italic')\n",
        "\n",
        "            # Guardar visualización\n",
        "            umbral_str = f\"umbral_{umbral_principal:.4f}\".replace('.', '')\n",
        "            nombre_vis = f\"vis_{modelo_nombre}_{umbral_str}_{nombre_archivo.replace('.jpg', '').replace('.png', '').replace('.jpeg', '')}.png\"\n",
        "            archivo_salida = self.directorio_salida / nombre_vis\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(archivo_salida, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "            plt.close()\n",
        "\n",
        "            if self.logger:\n",
        "                self.logger.info(f\"Visualización guardada: {nombre_vis}\")\n",
        "\n",
        "            return str(archivo_salida)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.error(f\"Error generando visualización para {nombre_archivo}: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _generar_visualizacion_mascaras(self, ax, imagen_original: Image.Image,\n",
        "                                       datos_umbral: Dict, umbral_key: str):\n",
        "        \"\"\"Genera visualización de máscaras detectadas\"\"\"\n",
        "\n",
        "        # Crear imagen base en escala de grises\n",
        "        img_gray = np.array(imagen_original.convert('L'))\n",
        "        h, w = img_gray.shape\n",
        "        mask_combined = np.zeros_like(img_gray, dtype=np.float32)\n",
        "\n",
        "        # Intentar usar máscaras reales guardadas\n",
        "        mascaras_raw = datos_umbral.get('mascaras_raw')\n",
        "        num_mascaras = 0\n",
        "\n",
        "        if mascaras_raw and len(mascaras_raw) > 0:\n",
        "            # Usar máscaras reales de Mask2Former\n",
        "            for i, mask in enumerate(mascaras_raw):\n",
        "                if mask is not None and mask.size > 0:\n",
        "                    # Convertir máscara a binario\n",
        "                    mask_binary = (mask > 0.5).astype(np.float32)\n",
        "\n",
        "                    # Redimensionar si es necesario\n",
        "                    if mask_binary.shape != (h, w):\n",
        "                        mask_binary = cv2.resize(mask_binary, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "                    # Agregar con diferentes intensidades para cada máscara\n",
        "                    mask_combined += mask_binary * (0.3 + (i * 0.2))\n",
        "                    num_mascaras += 1\n",
        "\n",
        "        # Si no hay máscaras raw, intentar desde análisis Shapely\n",
        "        if num_mascaras == 0:\n",
        "            analisis_mascaras = datos_umbral.get('analisis_mascaras_avanzado')\n",
        "            if analisis_mascaras and analisis_mascaras.get('mascaras_individuales'):\n",
        "                for i, mascara_data in enumerate(analisis_mascaras['mascaras_individuales']):\n",
        "                    if 'error' not in mascara_data:\n",
        "                        geom = mascara_data.get('caracteristicas_geometricas', {})\n",
        "\n",
        "                        # Crear máscara desde bbox si está disponible\n",
        "                        if all(key in geom for key in ['bbox_min_col', 'bbox_min_row', 'bbox_max_col', 'bbox_max_row']):\n",
        "                            x1 = int(geom['bbox_min_col'])\n",
        "                            y1 = int(geom['bbox_min_row'])\n",
        "                            x2 = int(geom['bbox_max_col'])\n",
        "                            y2 = int(geom['bbox_max_row'])\n",
        "\n",
        "                            # Crear máscara rectangular básica\n",
        "                            if x2 > x1 and y2 > y1 and x2 <= w and y2 <= h:\n",
        "                                mask_region = np.zeros((h, w))\n",
        "                                mask_region[y1:y2, x1:x2] = (i + 1) * 0.3\n",
        "                                mask_combined += mask_region\n",
        "                                num_mascaras += 1\n",
        "\n",
        "        # Si aún no hay máscaras, crear visualización dummy\n",
        "        if num_mascaras == 0:\n",
        "            personas = datos_umbral.get('personas_detectadas', 0)\n",
        "            if personas > 0:\n",
        "                # Crear máscara dummy en el centro\n",
        "                center_h, center_w = h // 2, w // 2\n",
        "                size = min(h, w) // 4\n",
        "                mask_combined[center_h-size:center_h+size, center_w-size:center_w+size] = 0.5\n",
        "                num_mascaras = personas\n",
        "\n",
        "        # Visualizar máscaras\n",
        "        if num_mascaras > 0:\n",
        "            # Mostrar imagen base + máscaras coloreadas\n",
        "            ax.imshow(img_gray, cmap='gray', alpha=0.7)\n",
        "            mask_colored = np.ma.masked_where(mask_combined == 0, mask_combined)\n",
        "            ax.imshow(mask_colored, cmap='Reds', alpha=0.8, vmin=0, vmax=1)\n",
        "            ax.set_title(f'Máscaras Detectadas ({num_mascaras})', fontsize=14)\n",
        "        else:\n",
        "            ax.imshow(img_gray, cmap='gray')\n",
        "            ax.set_title('No se detectaron personas', fontsize=14)\n",
        "\n",
        "        ax.axis('off')\n",
        "\n",
        "    def _generar_overlay(self, ax, imagen_original: Image.Image,\n",
        "                        datos_umbral: Dict, umbral_key: str):\n",
        "        \"\"\"Genera overlay de imagen original con detecciones superpuestas\"\"\"\n",
        "\n",
        "        img_array = np.array(imagen_original)\n",
        "\n",
        "        # Usar máscaras reales si están disponibles\n",
        "        mascaras_raw = datos_umbral.get('mascaras_raw')\n",
        "        analisis_mascaras = datos_umbral.get('analisis_mascaras_avanzado')\n",
        "\n",
        "        contornos_dibujados = 0\n",
        "\n",
        "        # Intentar dibujar contornos de máscaras reales\n",
        "        if mascaras_raw and len(mascaras_raw) > 0:\n",
        "            for i, mask in enumerate(mascaras_raw):\n",
        "                if mask is not None and mask.size > 0:\n",
        "                    # Convertir máscara a binario\n",
        "                    mask_binary = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "                    # Redimensionar si es necesario\n",
        "                    h, w = img_array.shape[:2]\n",
        "                    if mask_binary.shape != (h, w):\n",
        "                        mask_binary = cv2.resize(mask_binary, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "                    # Encontrar contornos\n",
        "                    contours, _ = cv2.findContours(mask_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                    for contour in contours:\n",
        "                        if cv2.contourArea(contour) > 100:  # Filtrar contornos muy pequeños\n",
        "                            # Dibujar contorno\n",
        "                            from matplotlib.patches import Polygon as MplPolygon\n",
        "                            contour_points = contour.reshape(-1, 2)\n",
        "                            polygon = MplPolygon(contour_points, linewidth=2,\n",
        "                                               edgecolor='red', facecolor='red', alpha=0.3)\n",
        "                            ax.add_patch(polygon)\n",
        "\n",
        "                            # Añadir etiqueta\n",
        "                            x, y, w_bbox, h_bbox = cv2.boundingRect(contour)\n",
        "                            score = datos_umbral.get('confianza_scores', [1.0])[min(i, len(datos_umbral.get('confianza_scores', [1.0]))-1)]\n",
        "                            ax.text(x, y-5, f'Persona {i+1}\\nScore: {score:.3f}',\n",
        "                                   bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.8),\n",
        "                                   fontsize=9, verticalalignment='top')\n",
        "                            contornos_dibujados += 1\n",
        "\n",
        "        # Si no hay máscaras raw, usar bounding boxes desde análisis Shapely\n",
        "        if contornos_dibujados == 0 and analisis_mascaras and analisis_mascaras.get('mascaras_individuales'):\n",
        "            for i, mascara_data in enumerate(analisis_mascaras['mascaras_individuales']):\n",
        "                if 'error' not in mascara_data:\n",
        "                    geom = mascara_data.get('caracteristicas_geometricas', {})\n",
        "                    score = mascara_data.get('score_confianza', 0.0)\n",
        "\n",
        "                    # Dibujar bounding box\n",
        "                    if all(key in geom for key in ['bbox_min_col', 'bbox_min_row', 'bbox_max_col', 'bbox_max_row']):\n",
        "                        x1 = int(geom['bbox_min_col'])\n",
        "                        y1 = int(geom['bbox_min_row'])\n",
        "                        x2 = int(geom['bbox_max_col'])\n",
        "                        y2 = int(geom['bbox_max_row'])\n",
        "\n",
        "                        # Dibujar rectángulo\n",
        "                        from matplotlib.patches import Rectangle\n",
        "                        rect = Rectangle((x1, y1), x2-x1, y2-y1,\n",
        "                                       linewidth=3, edgecolor='red', facecolor='none')\n",
        "                        ax.add_patch(rect)\n",
        "\n",
        "                        # Añadir texto con score\n",
        "                        ax.text(x1, y1-5, f'Persona {i+1}\\nScore: {score:.3f}',\n",
        "                               bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7),\n",
        "                               fontsize=10, verticalalignment='top')\n",
        "                        contornos_dibujados += 1\n",
        "\n",
        "        ax.imshow(img_array)\n",
        "        personas = datos_umbral.get('personas_detectadas', 0)\n",
        "        ax.set_title(f'Overlay - {personas} Persona(s) - {contornos_dibujados} Visualizadas', fontsize=14)\n",
        "        ax.axis('off')\n",
        "\n",
        "    def generar_resumen_visual(self, resultados_procesamiento: List[Dict],\n",
        "                              nombre_modelo: str) -> Optional[str]:\n",
        "        \"\"\"Genera un resumen visual con múltiples imágenes procesadas\"\"\"\n",
        "        try:\n",
        "            # Filtrar resultados exitosos\n",
        "            exitosos = [r for r in resultados_procesamiento if r.get('metadatos', {}).get('exitoso', False)]\n",
        "            if len(exitosos) == 0:\n",
        "                return None\n",
        "\n",
        "            # Tomar una muestra representativa (máximo 12 imágenes)\n",
        "            muestra = exitosos[:12] if len(exitosos) > 12 else exitosos\n",
        "\n",
        "            # Calcular grid\n",
        "            n_imgs = len(muestra)\n",
        "            cols = min(4, n_imgs)\n",
        "            rows = (n_imgs + cols - 1) // cols\n",
        "\n",
        "            fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 4*rows))\n",
        "            fig.suptitle(f'Resumen Visual - {nombre_modelo}', fontsize=16, fontweight='bold')\n",
        "\n",
        "            # MANEJO CORREGIDO DE AXES\n",
        "            if n_imgs == 1:\n",
        "                axes_list = [axes]\n",
        "            elif rows == 1:\n",
        "                axes_list = axes if hasattr(axes, '__len__') else [axes]\n",
        "            elif cols == 1:\n",
        "                axes_list = axes if hasattr(axes, '__len__') else [axes]\n",
        "            else:\n",
        "                axes_list = axes.flatten()\n",
        "\n",
        "            for i, resultado in enumerate(muestra):\n",
        "                ax = axes_list[i]\n",
        "\n",
        "                # Información de la imagen\n",
        "                info_img = resultado['imagen']\n",
        "                nombre_archivo = info_img['archivo']\n",
        "\n",
        "                # Estadísticas de detección (primer umbral)\n",
        "                detecciones = resultado['deteccion'].get('detecciones_por_umbral', {})\n",
        "                if detecciones:\n",
        "                    primer_umbral = list(detecciones.values())[0]\n",
        "                    personas = primer_umbral.get('personas_detectadas', 0)\n",
        "                    score_max = primer_umbral.get('score_maximo', 0)\n",
        "\n",
        "                    # Color según detección\n",
        "                    color = 'green' if personas > 0 else 'gray'\n",
        "\n",
        "                    ax.text(0.5, 0.7, nombre_archivo, ha='center', va='center',\n",
        "                           fontsize=10, weight='bold', transform=ax.transAxes)\n",
        "                    ax.text(0.5, 0.5, f'Personas: {personas}', ha='center', va='center',\n",
        "                           fontsize=12, color=color, weight='bold', transform=ax.transAxes)\n",
        "                    ax.text(0.5, 0.3, f'Score máx: {score_max:.3f}', ha='center', va='center',\n",
        "                           fontsize=10, transform=ax.transAxes)\n",
        "\n",
        "                    ax.set_facecolor('lightgreen' if personas > 0 else 'lightgray')\n",
        "                else:\n",
        "                    ax.text(0.5, 0.5, f'{nombre_archivo}\\nError de procesamiento',\n",
        "                           ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
        "                    ax.set_facecolor('lightcoral')\n",
        "\n",
        "                ax.set_xticks([])\n",
        "                ax.set_yticks([])\n",
        "                ax.set_aspect('equal')\n",
        "\n",
        "            # Ocultar axes sobrantes\n",
        "            for i in range(n_imgs, len(axes_list)):\n",
        "                axes_list[i].set_visible(False)\n",
        "\n",
        "            # Estadísticas generales\n",
        "            total_personas = sum(\n",
        "                list(r['deteccion']['detecciones_por_umbral'].values())[0].get('personas_detectadas', 0)\n",
        "                for r in exitosos if r['deteccion'].get('detecciones_por_umbral')\n",
        "            )\n",
        "\n",
        "            imagenes_con_personas = sum(\n",
        "                1 for r in exitosos\n",
        "                if r['deteccion'].get('detecciones_por_umbral') and\n",
        "                list(r['deteccion']['detecciones_por_umbral'].values())[0].get('personas_detectadas', 0) > 0\n",
        "            )\n",
        "\n",
        "            fig.text(0.5, 0.02,\n",
        "                    f'Total procesadas: {len(exitosos)} | Con personas: {imagenes_con_personas} | Total personas: {total_personas}',\n",
        "                    ha='center', fontsize=12, style='italic')\n",
        "\n",
        "            # Guardar resumen\n",
        "            nombre_resumen = f\"resumen_visual_{nombre_modelo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
        "            archivo_resumen = self.directorio_salida / nombre_resumen\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(archivo_resumen, dpi=150, bbox_inches='tight', facecolor='white')\n",
        "            plt.close()\n",
        "\n",
        "            if self.logger:\n",
        "                self.logger.info(f\"Resumen visual guardado: {nombre_resumen}\")\n",
        "\n",
        "            return str(archivo_resumen)\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.error(f\"Error generando resumen visual: {str(e)}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "pjMK3DfBP_jg"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXPORTADOR FORMATO COCO\n",
        "# =============================================================================\n",
        "\n",
        "class ExportadorCOCO:\n",
        "    \"\"\"Exportador de resultados a formato COCO\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger = None):\n",
        "        self.logger = logger\n",
        "        self.coco_data = {\n",
        "            \"info\": {\n",
        "                \"description\": \"Mask2Former Evaluation Results\",\n",
        "                \"version\": \"1.0\",\n",
        "                \"year\": datetime.now().year,\n",
        "                \"contributor\": \"TFM Evaluation Framework\",\n",
        "                \"date_created\": datetime.now().isoformat()\n",
        "            },\n",
        "            \"images\": [],\n",
        "            \"annotations\": [],\n",
        "            \"categories\": [\n",
        "                {\n",
        "                    \"id\": 1,\n",
        "                    \"name\": \"person\",\n",
        "                    \"supercategory\": \"person\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "        self.image_id = 1\n",
        "        self.annotation_id = 1\n",
        "\n",
        "    def agregar_imagen(self, nombre_archivo: str, ancho: int, alto: int) -> int:\n",
        "        \"\"\"Agrega una imagen al dataset COCO\"\"\"\n",
        "        imagen_info = {\n",
        "            \"id\": self.image_id,\n",
        "            \"file_name\": nombre_archivo,\n",
        "            \"width\": ancho,\n",
        "            \"height\": alto\n",
        "        }\n",
        "        self.coco_data[\"images\"].append(imagen_info)\n",
        "\n",
        "        current_id = self.image_id\n",
        "        self.image_id += 1\n",
        "        return current_id\n",
        "\n",
        "    def agregar_anotacion(self, image_id: int, mascara: np.ndarray, score: float, bbox: List[int]):\n",
        "        \"\"\"Agrega una anotación de segmentación al formato COCO\"\"\"\n",
        "        try:\n",
        "            # Convertir máscara a RLE (Run Length Encoding) simplificado\n",
        "            # En un sistema completo usarías pycocotools, aquí una versión simplificada\n",
        "            area = int(np.sum(mascara > 0.5))\n",
        "\n",
        "            if area == 0:\n",
        "                return\n",
        "\n",
        "            anotacion = {\n",
        "                \"id\": self.annotation_id,\n",
        "                \"image_id\": image_id,\n",
        "                \"category_id\": 1,  # person\n",
        "                \"bbox\": bbox,  # [x, y, width, height]\n",
        "                \"area\": area,\n",
        "                \"iscrowd\": 0,\n",
        "                \"score\": float(score)\n",
        "            }\n",
        "\n",
        "            self.coco_data[\"annotations\"].append(anotacion)\n",
        "            self.annotation_id += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.warning(f\"Error agregando anotación COCO: {str(e)}\")\n",
        "\n",
        "    def exportar(self, archivo_salida: Path) -> None:\n",
        "        \"\"\"Exporta los datos en formato COCO\"\"\"\n",
        "        try:\n",
        "            with open(archivo_salida, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.coco_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            if self.logger:\n",
        "                self.logger.info(f\"Archivo COCO exportado: {archivo_salida.name}\")\n",
        "                self.logger.info(f\"Imágenes: {len(self.coco_data['images'])}, Anotaciones: {len(self.coco_data['annotations'])}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            if self.logger:\n",
        "                self.logger.error(f\"Error exportando COCO: {str(e)}\")"
      ],
      "metadata": {
        "id": "qUCJLlMr8SmL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utils:\n",
        "    \"\"\"Funciones utilitarias reutilizables\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagenes(ruta: str, extensiones: Tuple[str, ...] = (\".jpg\", \".png\", \".jpeg\")) -> List[str]:\n",
        "        \"\"\"Carga todas las imágenes desde una ruta recursivamente\"\"\"\n",
        "        path = Path(ruta)\n",
        "        imagenes = [\n",
        "            str(p) for p in path.glob(\"**/*\")\n",
        "            if p.suffix.lower() in extensiones and p.is_file()\n",
        "        ]\n",
        "        return sorted(imagenes)\n",
        "\n",
        "    @staticmethod\n",
        "    def preparar_imagen(ruta: str, max_size: int = 1024) -> Image.Image:\n",
        "        \"\"\"Prepara una imagen para procesamiento\"\"\"\n",
        "        try:\n",
        "            img = Image.open(ruta).convert(\"RGB\")\n",
        "            if max(img.size) > max_size:\n",
        "                img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)\n",
        "            return img\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error cargando imagen {ruta}: {str(e)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash_imagen(ruta: str) -> str:\n",
        "        \"\"\"Calcula hash MD5 para identificación única de imagen\"\"\"\n",
        "        try:\n",
        "            with open(ruta, 'rb') as f:\n",
        "                return hashlib.md5(f.read()).hexdigest()[:12]\n",
        "        except Exception:\n",
        "            return \"hash_error\"\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Any, archivo: Path, indent: int = 2) -> None:\n",
        "        \"\"\"Guarda datos en formato JSON con manejo de errores\"\"\"\n",
        "        try:\n",
        "            with open(archivo, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos, f, indent=indent, ensure_ascii=False, default=str)\n",
        "        except Exception as e:\n",
        "            raise IOError(f\"Error guardando JSON en {archivo}: {str(e)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def crear_nombre_archivo(modelo_info: ModeloInfo, config_umbral: str, timestamp: str) -> str:\n",
        "        \"\"\"Crea nombres de archivo descriptivos y únicos\"\"\"\n",
        "        return f\"mask2former_{modelo_info.tipo}_{modelo_info.dataset.lower()}_{modelo_info.arquitectura.lower().replace('-', '')}_{config_umbral}_{timestamp}.json\""
      ],
      "metadata": {
        "id": "w2j765y08r-i"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DETECTOR DE PERSONAS\n",
        "# =============================================================================\n",
        "\n",
        "class DetectorPersonas:\n",
        "    \"\"\"Detector de personas usando modelos Mask2Former con análisis avanzado\"\"\"\n",
        "\n",
        "    def __init__(self, modelo_info: ModeloInfo, logger: logging.Logger,\n",
        "                 extractor: ExtractorCaracteristicasAvanzado, mask_analyzer: MaskAnalyzer):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.logger = logger\n",
        "        self.extractor = extractor\n",
        "        self.mask_analyzer = mask_analyzer\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.logger.info(\"=\"*60)\n",
        "        self.logger.info(f\"🤖 INICIALIZANDO MODELO: {modelo_info.nombre_corto}\")\n",
        "        self.logger.info(f\"📌 Tipo: {modelo_info.tipo.upper()}\")\n",
        "        self.logger.info(f\"🏗️ Arquitectura: {modelo_info.arquitectura}\")\n",
        "        self.logger.info(f\"📊 Dataset: {modelo_info.dataset}\")\n",
        "        self.logger.info(f\"💻 Dispositivo: {self.device}\")\n",
        "\n",
        "        try:\n",
        "            self.logger.info(\"⏳ Cargando procesador de imágenes...\")\n",
        "            self.processor = AutoImageProcessor.from_pretrained(modelo_info.nombre_hf)\n",
        "\n",
        "            self.logger.info(\"⏳ Cargando modelo de segmentación...\")\n",
        "            self.model = AutoModelForUniversalSegmentation.from_pretrained(modelo_info.nombre_hf)\n",
        "\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "\n",
        "            self.es_semantico = (modelo_info.tipo == 'semantico')\n",
        "            self._configurar_clases()\n",
        "\n",
        "            self.logger.info(\"✅ Modelo cargado exitosamente\")\n",
        "            self.logger.info(\"=\"*60)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"❌ Error cargando modelo: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def _configurar_clases(self) -> None:\n",
        "        \"\"\"Configura las clases y encuentra la clase 'persona'\"\"\"\n",
        "        if hasattr(self.model.config, 'id2label'):\n",
        "            self.id2label = self.model.config.id2label\n",
        "            self.logger.info(f\"🏷️ Clases disponibles: {len(self.id2label)}\")\n",
        "\n",
        "            self.clase_persona = 0\n",
        "            for clase_id, nombre in self.id2label.items():\n",
        "                if any(term in nombre.lower() for term in ['person', 'people', 'human']):\n",
        "                    self.clase_persona = clase_id\n",
        "                    self.logger.info(f\"👤 Clase persona encontrada: ID {clase_id} = '{nombre}'\")\n",
        "                    break\n",
        "            else:\n",
        "                self.logger.warning(f\"⚠️ Usando clase por defecto (ID 0) como 'persona'\")\n",
        "        else:\n",
        "            self.clase_persona = 0\n",
        "            self.logger.warning(f\"⚠️ Sin diccionario de clases, usando ID 0 como 'persona'\")\n",
        "\n",
        "    def detectar_en_imagen(self, imagen: Image.Image, umbrales: List[float]) -> Dict[str, Any]:\n",
        "        \"\"\"Ejecuta detección completa con análisis avanzado\"\"\"\n",
        "        inicio_tiempo = time.time()\n",
        "        memoria_inicial = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0\n",
        "\n",
        "        try:\n",
        "            w, h = imagen.size\n",
        "            inputs = self.processor(images=imagen, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            # Inferencia\n",
        "            inicio_inferencia = time.time()\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "            tiempo_inferencia_ms = (time.time() - inicio_inferencia) * 1000\n",
        "\n",
        "            # Métricas de memoria\n",
        "            memoria_maxima = torch.cuda.max_memory_allocated() if torch.cuda.is_available() else 0\n",
        "            memoria_usada_mb = (memoria_maxima - memoria_inicial) / (1024 ** 2)\n",
        "\n",
        "            resultados = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo_info': asdict(self.modelo_info),\n",
        "                'rendimiento': {\n",
        "                    'tiempo_inferencia_ms': tiempo_inferencia_ms,\n",
        "                    'memoria_usada_mb': memoria_usada_mb,\n",
        "                    'fps_estimado': 1000 / tiempo_inferencia_ms\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Post-procesamiento específico por tipo\n",
        "            if self.es_semantico:\n",
        "                resultados.update(self._procesar_segmentacion_semantica(outputs, (h, w), umbrales))\n",
        "            else:\n",
        "                resultados.update(self._procesar_segmentacion_instancia(outputs, (h, w), umbrales))\n",
        "\n",
        "            tiempo_total_ms = (time.time() - inicio_tiempo) * 1000\n",
        "            resultados['rendimiento']['tiempo_total_ms'] = tiempo_total_ms\n",
        "\n",
        "            return resultados\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error en detección: {str(e)}\")\n",
        "            return self._crear_resultado_error(str(e), umbrales)\n",
        "\n",
        "    def _procesar_segmentacion_semantica(self, outputs, target_size: Tuple[int, int], umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Procesa resultados de segmentación semántica con análisis avanzado\"\"\"\n",
        "        try:\n",
        "            resultado_semantico = self.processor.post_process_semantic_segmentation(\n",
        "                outputs, target_sizes=[target_size]\n",
        "            )[0]\n",
        "\n",
        "            unique_classes = torch.unique(resultado_semantico)\n",
        "            total_pixels = resultado_semantico.numel()\n",
        "\n",
        "            resultados_umbrales = {}\n",
        "\n",
        "            for umbral in umbrales:\n",
        "                persona_mask = (resultado_semantico == self.clase_persona)\n",
        "                persona_pixels = persona_mask.sum().item()\n",
        "                porcentaje_persona = (persona_pixels / total_pixels) * 100\n",
        "\n",
        "                personas_detectadas = 1 if porcentaje_persona >= (umbral * 100) and persona_pixels > 50 else 0\n",
        "\n",
        "                # Análisis avanzado de la máscara si hay detección\n",
        "                analisis_mascaras = None\n",
        "                if personas_detectadas > 0:\n",
        "                    mask_np = persona_mask.cpu().numpy().astype(np.float32)\n",
        "                    analisis_mascaras = self.mask_analyzer.analizar_mascaras_completo(\n",
        "                        [mask_np], [1.0], target_size\n",
        "                    )\n",
        "\n",
        "                resultados_umbrales[f'umbral_{umbral}'] = {\n",
        "                    'personas_detectadas': personas_detectadas,\n",
        "                    'total_clases_detectadas': len(unique_classes),\n",
        "                    'clases_presentes': unique_classes.tolist(),\n",
        "                    'estadisticas_persona': {\n",
        "                        'pixels_persona': persona_pixels,\n",
        "                        'porcentaje_imagen': round(porcentaje_persona, 3),\n",
        "                        'umbral_aplicado': umbral,\n",
        "                        'criterio_cumplido': personas_detectadas > 0\n",
        "                    },\n",
        "                    'analisis_mascaras_avanzado': analisis_mascaras,\n",
        "                    'confianza_scores': [1.0] if personas_detectadas > 0 else [],\n",
        "                    'score_maximo': 1.0 if len(unique_classes) > 0 else 0.0\n",
        "                }\n",
        "\n",
        "            return {'detecciones_por_umbral': resultados_umbrales}\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error en segmentación semántica: {str(e)}\")\n",
        "            return self._crear_resultado_error(str(e), umbrales)\n",
        "\n",
        "    def _procesar_segmentacion_instancia(self, outputs, target_size: Tuple[int, int], umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Procesa resultados de segmentación de instancia con análisis avanzado\"\"\"\n",
        "        resultados_umbrales = {}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            try:\n",
        "                resultado = self.processor.post_process_instance_segmentation(\n",
        "                    outputs, target_sizes=[target_size], threshold=umbral\n",
        "                )[0]\n",
        "\n",
        "                labels = resultado.get(\"labels\", torch.tensor([]))\n",
        "                scores = resultado.get(\"scores\", torch.tensor([]))\n",
        "                masks = resultado.get(\"masks\", torch.tensor([]))\n",
        "\n",
        "                # Filtrar detecciones de personas\n",
        "                indices_personas = [i for i, l in enumerate(labels) if int(l.item()) == self.clase_persona]\n",
        "                personas_detectadas = len(indices_personas)\n",
        "\n",
        "                scores_personas = [float(scores[i].item()) for i in indices_personas]\n",
        "\n",
        "                # Análisis avanzado de máscaras de personas\n",
        "                analisis_mascaras = None\n",
        "                if personas_detectadas > 0 and len(masks) > 0:\n",
        "                    masks_personas = [masks[i].cpu().numpy() for i in indices_personas]\n",
        "                    scores_personas_mask = [scores[i].item() for i in indices_personas]\n",
        "\n",
        "                    analisis_mascaras = self.mask_analyzer.analizar_mascaras_completo(\n",
        "                        masks_personas, scores_personas_mask, target_size\n",
        "                    )\n",
        "\n",
        "                todas_clases = [int(l.item()) for l in labels]\n",
        "                todos_scores = [float(s.item()) for s in scores]\n",
        "\n",
        "                resultados_umbrales[f'umbral_{umbral}'] = {\n",
        "                    'personas_detectadas': personas_detectadas,\n",
        "                    'total_detecciones': len(labels),\n",
        "                    'clases_detectadas': todas_clases,\n",
        "                    'estadisticas_persona': {\n",
        "                        'numero_instancias': personas_detectadas,\n",
        "                        'scores_individuales': scores_personas,\n",
        "                        'score_promedio': np.mean(scores_personas) if scores_personas else 0.0,\n",
        "                        'score_maximo_persona': max(scores_personas) if scores_personas else 0.0\n",
        "                    },\n",
        "                    'analisis_mascaras_avanzado': analisis_mascaras,\n",
        "                    'confianza_scores': scores_personas,\n",
        "                    'score_maximo': max(todos_scores) if todos_scores else 0.0,\n",
        "                    'todas_detecciones_scores': todos_scores\n",
        "                }\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"Error en umbral {umbral}: {str(e)}\")\n",
        "                resultados_umbrales[f'umbral_{umbral}'] = self._crear_resultado_error_umbral(str(e))\n",
        "\n",
        "        return {'detecciones_por_umbral': resultados_umbrales}\n",
        "\n",
        "    def _crear_resultado_error(self, error_msg: str, umbrales: List[float]) -> Dict:\n",
        "        \"\"\"Crea estructura de resultado para casos de error\"\"\"\n",
        "        resultados_umbrales = {}\n",
        "        for umbral in umbrales:\n",
        "            resultados_umbrales[f'umbral_{umbral}'] = self._crear_resultado_error_umbral(error_msg)\n",
        "\n",
        "        return {\n",
        "            'error_general': error_msg,\n",
        "            'detecciones_por_umbral': resultados_umbrales,\n",
        "            'rendimiento': {'tiempo_inferencia_ms': 0, 'error': True}\n",
        "        }\n",
        "\n",
        "    def _crear_resultado_error_umbral(self, error_msg: str) -> Dict:\n",
        "        \"\"\"Crea resultado de error para un umbral específico\"\"\"\n",
        "        return {\n",
        "            'error': error_msg,\n",
        "            'personas_detectadas': 0,\n",
        "            'total_detecciones': 0,\n",
        "            'confianza_scores': [],\n",
        "            'score_maximo': 0.0,\n",
        "            'analisis_mascaras_avanzado': None\n",
        "        }\n",
        "\n",
        "    def liberar_memoria(self) -> None:\n",
        "        \"\"\"Libera recursos del modelo\"\"\"\n",
        "        self.logger.info(f\"🧹 Liberando memoria del modelo {self.modelo_info.nombre_corto}\")\n",
        "\n",
        "        if hasattr(self, 'model'):\n",
        "            del self.model\n",
        "        if hasattr(self, 'processor'):\n",
        "            del self.processor\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        self.logger.info(\"✅ Memoria liberada\")\n"
      ],
      "metadata": {
        "id": "4uG9eAIv8y8N"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROCESADOR DE RESULTADOS AVANZADO\n",
        "# =============================================================================\n",
        "\n",
        "class ProcesadorResultadosAvanzado:\n",
        "    \"\"\"Procesador completo con análisis avanzado y exportación múltiple\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_salida: Path, logger_manager: LoggerManager):\n",
        "        self.directorio_salida = directorio_salida\n",
        "        self.logger_manager = logger_manager\n",
        "        self.logger = logger_manager.crear_logger(\"procesador\")\n",
        "\n",
        "        # Inicializar componentes especializados\n",
        "        self.extractor = ExtractorCaracteristicasAvanzado()\n",
        "        self.extractor.set_logger(self.logger)\n",
        "        self.mask_analyzer = MaskAnalyzer()\n",
        "\n",
        "        # Inicializar generador de visualizaciones\n",
        "        self.generador_vis = GeneradorVisualizaciones(\n",
        "            directorio_salida / \"visualizaciones\",\n",
        "            self.logger\n",
        "        )\n",
        "\n",
        "        # Contadores\n",
        "        self.imagenes_procesadas = 0\n",
        "        self.imagenes_exitosas = 0\n",
        "        self.tiempo_total_procesamiento = 0\n",
        "\n",
        "        # Lista para guardar resultados y generar resumen visual al final\n",
        "        self.resultados_para_resumen = []\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: str, detector: DetectorPersonas,\n",
        "                       umbrales: List[float], exportador_coco: ExportadorCOCO = None) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Procesa una imagen con análisis completo y visualizaciones\"\"\"\n",
        "        inicio_procesamiento = time.time()\n",
        "        nombre_archivo = os.path.basename(ruta_imagen)\n",
        "\n",
        "        try:\n",
        "            # Preparar imagen\n",
        "            imagen = Utils.preparar_imagen(ruta_imagen)\n",
        "            hash_imagen = Utils.calcular_hash_imagen(ruta_imagen)\n",
        "\n",
        "            # Análisis avanzado de características de imagen\n",
        "            self.logger.info(f\"📷 Extrayendo características avanzadas de {nombre_archivo}\")\n",
        "            caracteristicas_avanzadas = self.extractor.analizar_imagen_completa(imagen, ruta_imagen)\n",
        "\n",
        "            # Información completa de la imagen\n",
        "            info_imagen = {\n",
        "                'archivo': nombre_archivo,\n",
        "                'ruta_completa': ruta_imagen,\n",
        "                'hash_md5': hash_imagen,\n",
        "                'caracteristicas_avanzadas': caracteristicas_avanzadas,\n",
        "                'timestamp_procesamiento': datetime.now().isoformat()\n",
        "            }\n",
        "\n",
        "            # Detección de personas con análisis de máscaras\n",
        "            self.logger.info(f\"🔍 Ejecutando detección de personas en {nombre_archivo}\")\n",
        "            resultados_deteccion = detector.detectar_en_imagen(imagen, umbrales)\n",
        "\n",
        "            # GENERAR VISUALIZACIÓN INMEDIATAMENTE\n",
        "            self.logger.info(f\"🎨 Generando visualización para {nombre_archivo}\")\n",
        "            archivo_visualizacion = self.generador_vis.generar_visualizacion_completa(\n",
        "                imagen, nombre_archivo, resultados_deteccion, umbrales[0],\n",
        "                detector.modelo_info.nombre_corto\n",
        "            )\n",
        "\n",
        "            # Exportar a COCO si se especifica\n",
        "            if exportador_coco and resultados_deteccion.get('detecciones_por_umbral'):\n",
        "                self._exportar_a_coco(exportador_coco, nombre_archivo, imagen.size,\n",
        "                                    resultados_deteccion, umbrales[0])\n",
        "\n",
        "            # Calcular métricas de procesamiento\n",
        "            tiempo_total_ms = (time.time() - inicio_procesamiento) * 1000\n",
        "\n",
        "            resultado_completo = {\n",
        "                'metadatos': {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'version_framework': '2.0_avanzado',\n",
        "                    'librerias_usadas': ['mahotas', 'scikit-image', 'shapely', 'sklearn'],\n",
        "                    'exitoso': True\n",
        "                },\n",
        "                'imagen': info_imagen,\n",
        "                'deteccion': resultados_deteccion,\n",
        "                'visualizacion': {\n",
        "                    'archivo_generado': archivo_visualizacion,\n",
        "                    'disponible': archivo_visualizacion is not None\n",
        "                },\n",
        "                'rendimiento_total': {\n",
        "                    'tiempo_procesamiento_completo_ms': tiempo_total_ms,\n",
        "                    'memoria_sistema_mb': self._obtener_memoria_sistema()\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Estadísticas de logging\n",
        "            self._log_resultado_imagen(resultado_completo, nombre_archivo)\n",
        "\n",
        "            # Guardar para resumen visual posterior\n",
        "            self.resultados_para_resumen.append(resultado_completo)\n",
        "\n",
        "            # Actualizar contadores\n",
        "            self.imagenes_procesadas += 1\n",
        "            self.imagenes_exitosas += 1\n",
        "            self.tiempo_total_procesamiento += tiempo_total_ms\n",
        "\n",
        "            return resultado_completo\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"❌ Error procesando {nombre_archivo}: {str(e)}\")\n",
        "            self.logger_manager.log_error(\"procesador\", e, f\"Imagen: {nombre_archivo}\")\n",
        "\n",
        "            resultado_error = {\n",
        "                'metadatos': {\n",
        "                    'timestamp': datetime.now().isoformat(),\n",
        "                    'version_framework': '2.0_avanzado',\n",
        "                    'exitoso': False\n",
        "                },\n",
        "                'imagen': {'archivo': nombre_archivo, 'error': str(e)},\n",
        "                'error_detalle': str(e),\n",
        "                'visualizacion': {\n",
        "                    'archivo_generado': None,\n",
        "                    'disponible': False\n",
        "                }\n",
        "            }\n",
        "\n",
        "            self.imagenes_procesadas += 1\n",
        "            return resultado_error\n",
        "\n",
        "    def finalizar_procesamiento(self, nombre_modelo: str) -> Optional[str]:\n",
        "        \"\"\"Genera resumen visual final y limpia recursos\"\"\"\n",
        "        try:\n",
        "            # Generar resumen visual con todas las imágenes procesadas\n",
        "            self.logger.info(\"🎨 Generando resumen visual final...\")\n",
        "            archivo_resumen_visual = self.generador_vis.generar_resumen_visual(\n",
        "                self.resultados_para_resumen, nombre_modelo\n",
        "            )\n",
        "\n",
        "            # Limpiar lista para siguiente modelo\n",
        "            self.resultados_para_resumen = []\n",
        "\n",
        "            return archivo_resumen_visual\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando resumen visual final: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def _exportar_a_coco(self, exportador_coco: ExportadorCOCO, nombre_archivo: str,\n",
        "                        tamaño_imagen: Tuple[int, int], resultados_deteccion: Dict, umbral_ref: float):\n",
        "        \"\"\"Exporta detecciones al formato COCO\"\"\"\n",
        "        try:\n",
        "            ancho, alto = tamaño_imagen\n",
        "            image_id = exportador_coco.agregar_imagen(nombre_archivo, ancho, alto)\n",
        "\n",
        "            detecciones_umbral = resultados_deteccion.get('detecciones_por_umbral', {})\n",
        "            datos_umbral = detecciones_umbral.get(f'umbral_{umbral_ref}', {})\n",
        "\n",
        "            # Exportar máscaras individuales si están disponibles\n",
        "            analisis_mascaras = datos_umbral.get('analisis_mascaras_avanzado')\n",
        "            if analisis_mascaras and analisis_mascaras.get('mascaras_individuales'):\n",
        "                for mascara_data in analisis_mascaras['mascaras_individuales']:\n",
        "                    if 'error' not in mascara_data:\n",
        "                        geom = mascara_data.get('caracteristicas_geometricas', {})\n",
        "                        score = mascara_data.get('score_confianza', 0.0)\n",
        "\n",
        "                        # Crear bbox desde las características geométricas\n",
        "                        if all(key in geom for key in ['bbox_min_col', 'bbox_min_row', 'bbox_max_col', 'bbox_max_row']):\n",
        "                            x = int(geom['bbox_min_col'])\n",
        "                            y = int(geom['bbox_min_row'])\n",
        "                            w = int(geom['bbox_max_col'] - geom['bbox_min_col'])\n",
        "                            h = int(geom['bbox_max_row'] - geom['bbox_min_row'])\n",
        "                            bbox = [x, y, w, h]\n",
        "\n",
        "                            # Crear máscara dummy para COCO (en implementación real usarías la máscara real)\n",
        "                            mascara_dummy = np.zeros((alto, ancho))\n",
        "                            if x + w <= ancho and y + h <= alto:\n",
        "                                mascara_dummy[y:y+h, x:x+w] = 1\n",
        "\n",
        "                            exportador_coco.agregar_anotacion(image_id, mascara_dummy, score, bbox)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.warning(f\"Error exportando a COCO para {nombre_archivo}: {str(e)}\")\n",
        "\n",
        "    def _obtener_memoria_sistema(self) -> float:\n",
        "        \"\"\"Obtiene el uso actual de memoria del sistema\"\"\"\n",
        "        try:\n",
        "            return psutil.Process().memory_info().rss / (1024 ** 2)\n",
        "        except:\n",
        "            return 0.0\n",
        "\n",
        "    def _log_resultado_imagen(self, resultado: Dict, nombre_archivo: str) -> None:\n",
        "        \"\"\"Registra estadísticas del resultado de una imagen\"\"\"\n",
        "        if resultado['metadatos']['exitoso']:\n",
        "            deteccion = resultado['deteccion']\n",
        "            rendimiento = deteccion.get('rendimiento', {})\n",
        "\n",
        "            # Tomar el primer umbral como referencia para logging\n",
        "            primera_deteccion = None\n",
        "            for key, value in deteccion.get('detecciones_por_umbral', {}).items():\n",
        "                primera_deteccion = value\n",
        "                break\n",
        "\n",
        "            if primera_deteccion and 'error' not in primera_deteccion:\n",
        "                personas = primera_deteccion.get('personas_detectadas', 0)\n",
        "                total = primera_deteccion.get('total_detecciones', 0)\n",
        "                tiempo = rendimiento.get('tiempo_inferencia_ms', 0)\n",
        "\n",
        "                self.logger.info(f\"✅ {nombre_archivo}: {personas} personas | {total} total | {tiempo:.1f}ms | Análisis avanzado ✓\")\n",
        "\n",
        "                # Log características avanzadas si están disponibles\n",
        "                carac_avanzadas = resultado['imagen'].get('caracteristicas_avanzadas', {})\n",
        "                if carac_avanzadas:\n",
        "                    texturas_mh = carac_avanzadas.get('texturas_mahotas', {})\n",
        "                    if 'haralick_features' in texturas_mh and texturas_mh['haralick_features']:\n",
        "                        haralick_mean = np.mean(texturas_mh['haralick_features'])\n",
        "                        self.logger.info(f\"   📊 Haralick promedio: {haralick_mean:.3f}\")\n",
        "\n",
        "                    geom = carac_avanzadas.get('caracteristicas_geometricas', {})\n",
        "                    if 'num_corners' in geom:\n",
        "                        self.logger.info(f\"   🔍 Esquinas detectadas: {geom['num_corners']}\")\n",
        "        else:\n",
        "            self.logger.error(f\"❌ {nombre_archivo}: Procesamiento fallido\")\n",
        "\n",
        "    def generar_resumen_estadistico_avanzado(self, resultados: List[Dict], config_umbral: ConfiguracionUmbrales,\n",
        "                                           modelo_info: ModeloInfo) -> Dict[str, Any]:\n",
        "        \"\"\"Genera resumen estadístico completo con análisis avanzado\"\"\"\n",
        "        exitosos = [r for r in resultados if r.get('metadatos', {}).get('exitoso', False)]\n",
        "\n",
        "        resumen = {\n",
        "            'metadatos_resumen': {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo_evaluado': asdict(modelo_info),\n",
        "                'configuracion_umbrales': asdict(config_umbral),\n",
        "                'total_imagenes': len(resultados),\n",
        "                'imagenes_exitosas': len(exitosos),\n",
        "                'tasa_exito': len(exitosos) / len(resultados) if resultados else 0,\n",
        "                'version_framework': '2.0_avanzado'\n",
        "            },\n",
        "            'estadisticas_rendimiento': self._calcular_estadisticas_rendimiento(exitosos),\n",
        "            'estadisticas_deteccion': self._calcular_estadisticas_deteccion(exitosos, config_umbral.valores),\n",
        "            'estadisticas_caracteristicas_avanzadas': self._analizar_caracteristicas_avanzadas(exitosos),\n",
        "            'estadisticas_mascaras_shapely': self._analizar_estadisticas_shapely(exitosos),\n",
        "            'distribucion_caracteristicas': self._analizar_caracteristicas_imagenes(exitosos)\n",
        "        }\n",
        "\n",
        "        return resumen\n",
        "\n",
        "    def _calcular_estadisticas_rendimiento(self, resultados_exitosos: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Calcula estadísticas de rendimiento del sistema\"\"\"\n",
        "        if not resultados_exitosos:\n",
        "            return {}\n",
        "\n",
        "        tiempos_inferencia = []\n",
        "        memoria_usada = []\n",
        "\n",
        "        for resultado in resultados_exitosos:\n",
        "            rendimiento = resultado.get('deteccion', {}).get('rendimiento', {})\n",
        "            if 'tiempo_inferencia_ms' in rendimiento:\n",
        "                tiempos_inferencia.append(rendimiento['tiempo_inferencia_ms'])\n",
        "            if 'memoria_usada_mb' in rendimiento:\n",
        "                memoria_usada.append(rendimiento['memoria_usada_mb'])\n",
        "\n",
        "        estadisticas = {\n",
        "            'tiempo_inferencia': {\n",
        "                'promedio_ms': np.mean(tiempos_inferencia) if tiempos_inferencia else 0,\n",
        "                'mediana_ms': np.median(tiempos_inferencia) if tiempos_inferencia else 0,\n",
        "                'minimo_ms': np.min(tiempos_inferencia) if tiempos_inferencia else 0,\n",
        "                'maximo_ms': np.max(tiempos_inferencia) if tiempos_inferencia else 0,\n",
        "                'desviacion_std': np.std(tiempos_inferencia) if tiempos_inferencia else 0\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if memoria_usada:\n",
        "            estadisticas['memoria'] = {\n",
        "                'promedio_mb': np.mean(memoria_usada),\n",
        "                'maxima_mb': np.max(memoria_usada),\n",
        "                'minima_mb': np.min(memoria_usada)\n",
        "            }\n",
        "\n",
        "        return estadisticas\n",
        "\n",
        "    def _calcular_estadisticas_deteccion(self, resultados_exitosos: List[Dict], umbrales: List[float]) -> Dict[str, Any]:\n",
        "        \"\"\"Calcula estadísticas de detección por umbral\"\"\"\n",
        "        if not resultados_exitosos:\n",
        "            return {}\n",
        "\n",
        "        estadisticas_por_umbral = {}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            personas_detectadas = []\n",
        "            scores_maximos = []\n",
        "\n",
        "            for resultado in resultados_exitosos:\n",
        "                detecciones = resultado.get('deteccion', {}).get('detecciones_por_umbral', {})\n",
        "                umbral_data = detecciones.get(f'umbral_{umbral}', {})\n",
        "\n",
        "                if 'error' not in umbral_data:\n",
        "                    personas_detectadas.append(umbral_data.get('personas_detectadas', 0))\n",
        "                    scores_maximos.append(umbral_data.get('score_maximo', 0))\n",
        "\n",
        "            if personas_detectadas:\n",
        "                total_personas = sum(personas_detectadas)\n",
        "                imagenes_con_personas = sum(1 for p in personas_detectadas if p > 0)\n",
        "\n",
        "                estadisticas_por_umbral[f'umbral_{umbral}'] = {\n",
        "                    'total_personas_detectadas': total_personas,\n",
        "                    'imagenes_con_personas': imagenes_con_personas,\n",
        "                    'imagenes_sin_personas': len(personas_detectadas) - imagenes_con_personas,\n",
        "                    'porcentaje_imagenes_con_personas': (imagenes_con_personas / len(personas_detectadas)) * 100,\n",
        "                    'personas_promedio_por_imagen': total_personas / len(personas_detectadas),\n",
        "                    'score_promedio': np.mean(scores_maximos) if scores_maximos else 0,\n",
        "                    'score_mediano': np.median(scores_maximos) if scores_maximos else 0\n",
        "                }\n",
        "\n",
        "        return estadisticas_por_umbral\n",
        "\n",
        "    def _analizar_caracteristicas_avanzadas(self, resultados_exitosos: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Analiza las características avanzadas extraídas\"\"\"\n",
        "        if not resultados_exitosos:\n",
        "            return {}\n",
        "\n",
        "        haralick_means = []\n",
        "        glcm_contrasts = []\n",
        "        num_corners = []\n",
        "        zernike_means = []\n",
        "        num_regiones = []\n",
        "\n",
        "        for resultado in resultados_exitosos:\n",
        "            carac = resultado.get('imagen', {}).get('caracteristicas_avanzadas', {})\n",
        "\n",
        "            # Características Haralick\n",
        "            texturas_mh = carac.get('texturas_mahotas', {})\n",
        "            if 'haralick_features' in texturas_mh and texturas_mh['haralick_features']:\n",
        "                haralick_means.append(np.mean(texturas_mh['haralick_features']))\n",
        "\n",
        "            # Zernike moments\n",
        "            if 'zernike_moments' in texturas_mh and texturas_mh['zernike_moments']:\n",
        "                zernike_means.append(np.mean(texturas_mh['zernike_moments']))\n",
        "\n",
        "            # GLCM contrast\n",
        "            texturas_sk = carac.get('texturas_skimage', {})\n",
        "            glcm_props = texturas_sk.get('glcm_properties', {})\n",
        "            if 'contrast' in glcm_props:\n",
        "                glcm_contrasts.append(glcm_props['contrast'])\n",
        "\n",
        "            # Características geométricas\n",
        "            geom = carac.get('caracteristicas_geometricas', {})\n",
        "            if 'num_corners' in geom:\n",
        "                num_corners.append(geom['num_corners'])\n",
        "\n",
        "            # Regiones\n",
        "            regionales = carac.get('propiedades_regionales', {})\n",
        "            if 'num_regiones' in regionales:\n",
        "                num_regiones.append(regionales['num_regiones'])\n",
        "\n",
        "        def safe_stats(values, nombre):\n",
        "            if not values:\n",
        "                return {'count': 0, 'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}\n",
        "            return {\n",
        "                'count': len(values),\n",
        "                'mean': float(np.mean(values)),\n",
        "                'std': float(np.std(values)),\n",
        "                'min': float(np.min(values)),\n",
        "                'max': float(np.max(values))\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'haralick_estadisticas': safe_stats(haralick_means, 'Haralick'),\n",
        "            'glcm_contrast_estadisticas': safe_stats(glcm_contrasts, 'GLCM Contrast'),\n",
        "            'corners_estadisticas': safe_stats(num_corners, 'Corners'),\n",
        "            'zernike_estadisticas': safe_stats(zernike_means, 'Zernike'),\n",
        "            'regiones_estadisticas': safe_stats(num_regiones, 'Regiones'),\n",
        "            'imagenes_con_caracteristicas': len([r for r in resultados_exitosos\n",
        "                                               if r.get('imagen', {}).get('caracteristicas_avanzadas')])\n",
        "        }\n",
        "\n",
        "    def _analizar_estadisticas_shapely(self, resultados_exitosos: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Analiza estadísticas específicas de análisis con Shapely\"\"\"\n",
        "        if not resultados_exitosos:\n",
        "            return {}\n",
        "\n",
        "        compactness_values = []\n",
        "        convexity_ratios = []\n",
        "        roughness_factors = []\n",
        "        num_vertices = []\n",
        "        mascaras_validas = 0\n",
        "        total_mascaras = 0\n",
        "\n",
        "        for resultado in resultados_exitosos:\n",
        "            detecciones = resultado.get('deteccion', {}).get('detecciones_por_umbral', {})\n",
        "\n",
        "            for umbral_key, umbral_data in detecciones.items():\n",
        "                analisis_mascaras = umbral_data.get('analisis_mascaras_avanzado')\n",
        "                if analisis_mascaras and analisis_mascaras.get('mascaras_individuales'):\n",
        "                    for mascara_data in analisis_mascaras['mascaras_individuales']:\n",
        "                        total_mascaras += 1\n",
        "\n",
        "                        if 'error' not in mascara_data:\n",
        "                            # Características geométricas\n",
        "                            geom = mascara_data.get('caracteristicas_geometricas', {})\n",
        "                            if 'compactness' in geom:\n",
        "                                compactness_values.append(geom['compactness'])\n",
        "\n",
        "                            # Características Shapely\n",
        "                            shapely_geom = mascara_data.get('shapely_geometry', {})\n",
        "                            if shapely_geom.get('polygon_valido'):\n",
        "                                mascaras_validas += 1\n",
        "                                if 'convexity_ratio' in shapely_geom:\n",
        "                                    convexity_ratios.append(shapely_geom['convexity_ratio'])\n",
        "                                if 'num_vertices' in shapely_geom:\n",
        "                                    num_vertices.append(shapely_geom['num_vertices'])\n",
        "\n",
        "                            # Características de forma\n",
        "                            forma = mascara_data.get('caracteristicas_forma', {})\n",
        "                            if 'roughness_factor' in forma:\n",
        "                                roughness_factors.append(forma['roughness_factor'])\n",
        "\n",
        "        def safe_stats(values):\n",
        "            if not values:\n",
        "                return {'count': 0, 'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}\n",
        "            return {\n",
        "                'count': len(values),\n",
        "                'mean': float(np.mean(values)),\n",
        "                'std': float(np.std(values)),\n",
        "                'min': float(np.min(values)),\n",
        "                'max': float(np.max(values))\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'total_mascaras_analizadas': total_mascaras,\n",
        "            'mascaras_shapely_validas': mascaras_validas,\n",
        "            'tasa_validez_shapely': mascaras_validas / total_mascaras if total_mascaras > 0 else 0,\n",
        "            'compactness_estadisticas': safe_stats(compactness_values),\n",
        "            'convexity_ratio_estadisticas': safe_stats(convexity_ratios),\n",
        "            'roughness_estadisticas': safe_stats(roughness_factors),\n",
        "            'vertices_estadisticas': safe_stats(num_vertices)\n",
        "        }\n",
        "\n",
        "    def _analizar_caracteristicas_imagenes(self, resultados_exitosos: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"Analiza la distribución de características de las imágenes procesadas\"\"\"\n",
        "        if not resultados_exitosos:\n",
        "            return {}\n",
        "\n",
        "        anchos, altos, brillos, contrastes = [], [], [], []\n",
        "        megapixeles, aspect_ratios = [], []\n",
        "\n",
        "        for resultado in resultados_exitosos:\n",
        "            carac_avanzadas = resultado.get('imagen', {}).get('caracteristicas_avanzadas', {})\n",
        "\n",
        "            # Metadatos básicos\n",
        "            metadatos = carac_avanzadas.get('metadatos_basicos', {})\n",
        "            if metadatos:\n",
        "                dims = metadatos.get('dimensiones', {})\n",
        "                if dims:\n",
        "                    anchos.append(dims.get('ancho', 0))\n",
        "                    altos.append(dims.get('alto', 0))\n",
        "\n",
        "                if 'megapixeles' in metadatos:\n",
        "                    megapixeles.append(metadatos['megapixeles'])\n",
        "                if 'aspecto_ratio' in metadatos:\n",
        "                    aspect_ratios.append(metadatos['aspecto_ratio'])\n",
        "\n",
        "            # Características de color y luminancia\n",
        "            color = carac_avanzadas.get('color_y_paleta', {})\n",
        "            if color:\n",
        "                lab = color.get('lab_luminancia', {})\n",
        "                if 'L_medio' in lab:\n",
        "                    brillos.append(lab['L_medio'])\n",
        "\n",
        "                rgb_stats = color.get('estadisticas_rgb', {})\n",
        "                if 'std' in rgb_stats and rgb_stats['std']:\n",
        "                    # Promedio de desviación estándar RGB como medida de contraste\n",
        "                    contrastes.append(np.mean(rgb_stats['std']))\n",
        "\n",
        "        def safe_stats(values):\n",
        "            if not values:\n",
        "                return {'mean': 0.0, 'std': 0.0, 'min': 0.0, 'max': 0.0}\n",
        "            return {\n",
        "                'mean': float(np.mean(values)),\n",
        "                'std': float(np.std(values)),\n",
        "                'min': float(np.min(values)),\n",
        "                'max': float(np.max(values))\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            'dimensiones': {\n",
        "                'ancho_estadisticas': safe_stats(anchos),\n",
        "                'alto_estadisticas': safe_stats(altos),\n",
        "                'megapixeles_estadisticas': safe_stats(megapixeles),\n",
        "                'aspect_ratio_estadisticas': safe_stats(aspect_ratios)\n",
        "            },\n",
        "            'iluminacion_color': {\n",
        "                'brillo_lab_estadisticas': safe_stats(brillos),\n",
        "                'contraste_rgb_estadisticas': safe_stats(contrastes)\n",
        "            },\n",
        "            'resumen_dataset': {\n",
        "                'imagenes_analizadas': len(resultados_exitosos),\n",
        "                'resolucion_promedio_mp': np.mean(megapixeles) if megapixeles else 0,\n",
        "                'orientacion_predominante': 'horizontal' if np.mean(aspect_ratios) > 1 else 'vertical' if aspect_ratios else 'desconocida'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def mostrar_resumen_consola_avanzado(self, resumen: Dict[str, Any]) -> None:\n",
        "        \"\"\"Muestra un resumen completo en consola con características avanzadas\"\"\"\n",
        "        meta = resumen['metadatos_resumen']\n",
        "        modelo = meta['modelo_evaluado']\n",
        "\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(f\"📊 RESUMEN DE EVALUACIÓN AVANZADA\")\n",
        "        print(f\"{'='*100}\")\n",
        "        print(f\"🤖 Modelo: {modelo['nombre_corto']}\")\n",
        "        print(f\"📊 Dataset: {modelo['dataset']} | Tipo: {modelo['tipo'].upper()}\")\n",
        "        print(f\"✅ Éxito: {meta['imagenes_exitosas']}/{meta['total_imagenes']} ({meta['tasa_exito']*100:.1f}%)\")\n",
        "        print(f\"🔬 Framework: {meta['version_framework']}\")\n",
        "\n",
        "        # Estadísticas de rendimiento\n",
        "        rendimiento = resumen.get('estadisticas_rendimiento', {})\n",
        "        if 'tiempo_inferencia' in rendimiento:\n",
        "            tiempo = rendimiento['tiempo_inferencia']\n",
        "            print(f\"⚡ Tiempo promedio: {tiempo['promedio_ms']:.1f}ms (min: {tiempo['minimo_ms']:.1f}ms, max: {tiempo['maximo_ms']:.1f}ms)\")\n",
        "\n",
        "        # Estadísticas por umbral\n",
        "        deteccion = resumen.get('estadisticas_deteccion', {})\n",
        "        if deteccion:\n",
        "            print(f\"\\n🎯 RESULTADOS POR UMBRAL:\")\n",
        "            for umbral_key, stats in deteccion.items():\n",
        "                umbral_val = umbral_key.replace('umbral_', '')\n",
        "                print(f\"   {umbral_val:>8}: {stats['imagenes_con_personas']:3d}/{meta['imagenes_exitosas']} imágenes ({stats['porcentaje_imagenes_con_personas']:5.1f}%) | {stats['total_personas_detectadas']:3d} personas\")\n",
        "\n",
        "        # Características avanzadas\n",
        "        carac_avanzadas = resumen.get('estadisticas_caracteristicas_avanzadas', {})\n",
        "        if carac_avanzadas and carac_avanzadas.get('imagenes_con_caracteristicas', 0) > 0:\n",
        "            print(f\"\\n🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\")\n",
        "\n",
        "            haralick = carac_avanzadas.get('haralick_estadisticas', {})\n",
        "            if haralick.get('count', 0) > 0:\n",
        "                print(f\"   📊 Haralick (textura): {haralick['mean']:.3f} ± {haralick['std']:.3f}\")\n",
        "\n",
        "            corners = carac_avanzadas.get('corners_estadisticas', {})\n",
        "            if corners.get('count', 0) > 0:\n",
        "                print(f\"   🔍 Esquinas detectadas: {corners['mean']:.1f} ± {corners['std']:.1f}\")\n",
        "\n",
        "            glcm = carac_avanzadas.get('glcm_contrast_estadisticas', {})\n",
        "            if glcm.get('count', 0) > 0:\n",
        "                print(f\"   ⚡ GLCM Contraste: {glcm['mean']:.3f} ± {glcm['std']:.3f}\")\n",
        "\n",
        "        # Estadísticas Shapely\n",
        "        shapely_stats = resumen.get('estadisticas_mascaras_shapely', {})\n",
        "        if shapely_stats and shapely_stats.get('total_mascaras_analizadas', 0) > 0:\n",
        "            print(f\"\\n🔷 ANÁLISIS GEOMÉTRICO SHAPELY:\")\n",
        "            print(f\"   📐 Máscaras analizadas: {shapely_stats['total_mascaras_analizadas']}\")\n",
        "            print(f\"   ✅ Polígonos válidos: {shapely_stats['mascaras_shapely_validas']} ({shapely_stats['tasa_validez_shapely']*100:.1f}%)\")\n",
        "\n",
        "            compactness = shapely_stats.get('compactness_estadisticas', {})\n",
        "            if compactness.get('count', 0) > 0:\n",
        "                print(f\"   🔄 Compacidad promedio: {compactness['mean']:.3f} ± {compactness['std']:.3f}\")\n",
        "\n",
        "            convexity = shapely_stats.get('convexity_ratio_estadisticas', {})\n",
        "            if convexity.get('count', 0) > 0:\n",
        "                print(f\"   📏 Ratio convexidad: {convexity['mean']:.3f} ± {convexity['std']:.3f}\")"
      ],
      "metadata": {
        "id": "kfiovwtf9EbF"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL AVANZADO\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorMask2FormerAvanzado:\n",
        "    \"\"\"Clase principal que orquesta todo el proceso de evaluación avanzado\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfigEvaluacion):\n",
        "        self.config = config\n",
        "\n",
        "        # Crear directorio de ejecución\n",
        "        self.directorio_ejecucion = config.crear_directorio_ejecucion()\n",
        "\n",
        "        # Inicializar sistema de logging\n",
        "        self.logger_manager = LoggerManager(self.directorio_ejecucion / \"logs\")\n",
        "        self.logger = self.logger_manager.crear_logger(\"evaluador_principal\")\n",
        "\n",
        "        # Inicializar procesador avanzado\n",
        "        self.procesador = ProcesadorResultadosAvanzado(self.directorio_ejecucion, self.logger_manager)\n",
        "\n",
        "        # Log de inicialización\n",
        "        self.logger.info(\"🚀 EVALUADOR MASK2FORMER AVANZADO INICIALIZADO\")\n",
        "        self.logger.info(f\"📁 Directorio de ejecución: {self.directorio_ejecucion}\")\n",
        "        self.logger.info(f\"🎯 Modelos disponibles: {len(self.config.MODELOS)}\")\n",
        "        self.logger.info(f\"⚙️ Configuraciones de umbral: {len(self.config.UMBRALES)}\")\n",
        "        self.logger.info(f\"🔬 Análisis avanzado: Mahotas + Scikit-image + Shapely + OpenCV\")\n",
        "\n",
        "    def ejecutar_evaluacion_modelo(self, idx_modelo: int, nombre_config_umbral: str) -> Optional[str]:\n",
        "        \"\"\"Ejecuta evaluación completa para un modelo y configuración específica\"\"\"\n",
        "        # Validaciones\n",
        "        if idx_modelo >= len(self.config.MODELOS):\n",
        "            self.logger.error(f\"❌ Índice de modelo inválido: {idx_modelo}\")\n",
        "            return None\n",
        "\n",
        "        if nombre_config_umbral not in self.config.UMBRALES:\n",
        "            self.logger.error(f\"❌ Configuración de umbral inválida: {nombre_config_umbral}\")\n",
        "            return None\n",
        "\n",
        "        # Configuración actual\n",
        "        modelo_info = self.config.MODELOS[idx_modelo]\n",
        "        config_umbral = self.config.UMBRALES[nombre_config_umbral]\n",
        "\n",
        "        # Log de inicio\n",
        "        self.logger.info(\"=\"*100)\n",
        "        self.logger.info(f\"🚀 INICIANDO EVALUACIÓN AVANZADA\")\n",
        "        self.logger.info(\"=\"*100)\n",
        "        self.logger.info(f\"🤖 Modelo: {modelo_info.nombre_corto}\")\n",
        "        self.logger.info(f\"⚙️ Umbrales: {config_umbral.descripcion}\")\n",
        "        self.logger.info(f\"🎯 Valores: {config_umbral.valores}\")\n",
        "\n",
        "        try:\n",
        "            # Cargar dataset\n",
        "            imagenes = Utils.cargar_imagenes(str(self.config.DATASET_PATH))\n",
        "            if not imagenes:\n",
        "                self.logger.error(\"❌ No se encontraron imágenes en el dataset\")\n",
        "                return None\n",
        "\n",
        "            self.logger.info(f\"📸 Imágenes encontradas: {len(imagenes)}\")\n",
        "\n",
        "            # Limitar imágenes si es necesario\n",
        "            if len(imagenes) > self.config.MAX_IMAGENES_LOTE:\n",
        "                imagenes = imagenes[:self.config.MAX_IMAGENES_LOTE]\n",
        "                self.logger.info(f\"⚠️ Limitando a {self.config.MAX_IMAGENES_LOTE} imágenes para prueba\")\n",
        "\n",
        "            # Inicializar detector con componentes avanzados\n",
        "            detector_logger = self.logger_manager.crear_logger(f\"detector_{modelo_info.nombre_corto}\")\n",
        "            detector = DetectorPersonas(\n",
        "                modelo_info,\n",
        "                detector_logger,\n",
        "                self.procesador.extractor,\n",
        "                self.procesador.mask_analyzer\n",
        "            )\n",
        "\n",
        "            # Inicializar exportador COCO si está habilitado\n",
        "            exportador_coco = None\n",
        "            if self.config.GENERAR_FORMATO_COCO:\n",
        "                exportador_coco = ExportadorCOCO(self.logger)\n",
        "\n",
        "            # Procesar imágenes\n",
        "            self.logger.info(f\"🔄 INICIANDO PROCESAMIENTO AVANZADO DE {len(imagenes)} IMÁGENES\")\n",
        "            resultados = []\n",
        "            tiempo_inicio_total = time.time()\n",
        "\n",
        "            for i, ruta_imagen in enumerate(tqdm(imagenes, desc=\"Procesando con análisis avanzado\"), 1):\n",
        "                # Limpiar caché periódicamente\n",
        "                if i % self.config.LIMPIAR_CACHE_CADA == 0:\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                resultado = self.procesador.procesar_imagen(\n",
        "                    ruta_imagen, detector, config_umbral.valores, exportador_coco\n",
        "                )\n",
        "\n",
        "                if resultado:\n",
        "                    resultados.append(resultado)\n",
        "\n",
        "                # Log de progreso\n",
        "                if i % 10 == 0 or i == len(imagenes):\n",
        "                    self.logger.info(f\"📈 Progreso: {i}/{len(imagenes)} imágenes procesadas\")\n",
        "\n",
        "            tiempo_total_s = time.time() - tiempo_inicio_total\n",
        "\n",
        "            # Generar resumen estadístico avanzado\n",
        "            resumen = self.procesador.generar_resumen_estadistico_avanzado(\n",
        "                resultados, config_umbral, modelo_info\n",
        "            )\n",
        "\n",
        "            # Generar resumen visual final\n",
        "            archivo_resumen_visual = self.procesador.finalizar_procesamiento(modelo_info.nombre_corto)\n",
        "\n",
        "            # Guardar resultados en múltiples formatos\n",
        "            archivos_generados = self._guardar_resultados_multiples_formatos(\n",
        "                resultados, resumen, modelo_info, config_umbral, exportador_coco, archivo_resumen_visual\n",
        "            )\n",
        "\n",
        "            # Mostrar resumen en consola\n",
        "            self.procesador.mostrar_resumen_consola_avanzado(resumen)\n",
        "\n",
        "            # Log final\n",
        "            self.logger.info(f\"⏱️ Tiempo total: {tiempo_total_s:.1f} segundos\")\n",
        "            self.logger.info(f\"💾 Archivos generados: {len(archivos_generados)}\")\n",
        "            for formato, archivo in archivos_generados.items():\n",
        "                self.logger.info(f\"   📄 {formato}: {Path(archivo).name}\")\n",
        "\n",
        "            # Liberar memoria del detector\n",
        "            detector.liberar_memoria()\n",
        "\n",
        "            return archivos_generados.get('json_principal')\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"❌ Error durante evaluación: {str(e)}\")\n",
        "            self.logger_manager.log_error(\"evaluador_principal\", e, \"Evaluación modelo\")\n",
        "            return None\n",
        "\n",
        "    def _guardar_resultados_multiples_formatos(self, resultados: List[Dict], resumen: Dict,\n",
        "                                             modelo_info: ModeloInfo, config_umbral: ConfiguracionUmbrales,\n",
        "                                             exportador_coco: ExportadorCOCO = None,\n",
        "                                             archivo_resumen_visual: str = None) -> Dict[str, str]:\n",
        "        \"\"\"Guarda resultados en múltiples formatos\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        nombre_base = Utils.crear_nombre_archivo(modelo_info, config_umbral.nombre, timestamp)\n",
        "\n",
        "        archivos_generados = {}\n",
        "\n",
        "        # 1. Archivo JSON principal con análisis completo\n",
        "        datos_completos = {\n",
        "            'metadatos_archivo': {\n",
        "                'timestamp_creacion': datetime.now().isoformat(),\n",
        "                'version_framework': '2.0_avanzado',\n",
        "                'modelo_evaluado': asdict(modelo_info),\n",
        "                'configuracion_umbrales': asdict(config_umbral),\n",
        "                'directorio_ejecucion': str(self.directorio_ejecucion),\n",
        "                'total_imagenes_procesadas': len(resultados),\n",
        "                'librerias_usadas': ['mahotas', 'scikit-image', 'shapely', 'sklearn', 'opencv-python'],\n",
        "                'analisis_incluidos': [\n",
        "                    'caracteristicas_haralick',\n",
        "                    'texturas_lbp_glcm',\n",
        "                    'geometria_shapely',\n",
        "                    'descriptores_locales',\n",
        "                    'analisis_multiscala',\n",
        "                    'segmentacion_regional'\n",
        "                ]\n",
        "            },\n",
        "            'resumen_estadistico': resumen,\n",
        "            'resultados_detallados': resultados\n",
        "        }\n",
        "\n",
        "        archivo_principal = self.directorio_ejecucion / \"resultados_json\" / nombre_base\n",
        "        Utils.guardar_json(datos_completos, archivo_principal)\n",
        "        archivos_generados['json_principal'] = str(archivo_principal)\n",
        "\n",
        "        # 2. Resumen ejecutivo separado\n",
        "        archivo_resumen = self.directorio_ejecucion / \"resumenes\" / f\"resumen_{nombre_base}\"\n",
        "        Utils.guardar_json(resumen, archivo_resumen)\n",
        "        archivos_generados['resumen_ejecutivo'] = str(archivo_resumen)\n",
        "\n",
        "        # 3. Características avanzadas separadas\n",
        "        caracteristicas_separadas = {\n",
        "            'metadatos': {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo': asdict(modelo_info),\n",
        "                'descripcion': 'Características avanzadas extraídas con librerías especializadas'\n",
        "            },\n",
        "            'caracteristicas_por_imagen': []\n",
        "        }\n",
        "\n",
        "        for resultado in resultados:\n",
        "            if resultado.get('metadatos', {}).get('exitoso'):\n",
        "                carac_img = {\n",
        "                    'archivo': resultado['imagen']['archivo'],\n",
        "                    'caracteristicas_avanzadas': resultado['imagen'].get('caracteristicas_avanzadas', {})\n",
        "                }\n",
        "                caracteristicas_separadas['caracteristicas_por_imagen'].append(carac_img)\n",
        "\n",
        "        archivo_caracteristicas = self.directorio_ejecucion / \"caracteristicas_avanzadas\" / f\"caracteristicas_{nombre_base}\"\n",
        "        Utils.guardar_json(caracteristicas_separadas, archivo_caracteristicas)\n",
        "        archivos_generados['caracteristicas_avanzadas'] = str(archivo_caracteristicas)\n",
        "\n",
        "        # 4. Formato COCO si está habilitado\n",
        "        if exportador_coco and self.config.GENERAR_FORMATO_COCO:\n",
        "            nombre_coco = nombre_base.replace('.json', '_coco.json')\n",
        "            archivo_coco = self.directorio_ejecucion / \"formato_coco\" / nombre_coco\n",
        "            exportador_coco.exportar(archivo_coco)\n",
        "            archivos_generados['formato_coco'] = str(archivo_coco)\n",
        "\n",
        "        # 5. Resumen visual si está disponible\n",
        "        if archivo_resumen_visual:\n",
        "            archivos_generados['resumen_visual'] = archivo_resumen_visual\n",
        "\n",
        "        # Log de archivos generados\n",
        "        self.logger.info(f\"💾 Archivo principal: {Path(archivo_principal).name}\")\n",
        "        self.logger.info(f\"💾 Resumen ejecutivo: {Path(archivo_resumen).name}\")\n",
        "        self.logger.info(f\"💾 Características avanzadas: {Path(archivo_caracteristicas).name}\")\n",
        "        if 'formato_coco' in archivos_generados:\n",
        "            self.logger.info(f\"💾 Formato COCO: {Path(archivos_generados['formato_coco']).name}\")\n",
        "        if 'resumen_visual' in archivos_generados:\n",
        "            self.logger.info(f\"🎨 Resumen visual: {Path(archivos_generados['resumen_visual']).name}\")\n",
        "\n",
        "        return archivos_generados\n",
        "\n",
        "    def ejecutar_evaluacion_completa(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Ejecuta evaluación completa de todos los modelos con todas las configuraciones\"\"\"\n",
        "        total_combinaciones = len(self.config.MODELOS) * len(self.config.UMBRALES)\n",
        "        archivos_generados = {}\n",
        "\n",
        "        self.logger.info(f\"🎯 EVALUACIÓN COMPLETA AVANZADA: {total_combinaciones} combinaciones\")\n",
        "        self.logger.info(f\"🔬 Análisis incluidos: Texturas, Geometría, Color, Forma, Multi-escala\")\n",
        "\n",
        "        combinacion_actual = 0\n",
        "\n",
        "        try:\n",
        "            for i, modelo_info in enumerate(self.config.MODELOS):\n",
        "                archivos_modelo = []\n",
        "\n",
        "                for nombre_config in self.config.UMBRALES.keys():\n",
        "                    combinacion_actual += 1\n",
        "\n",
        "                    self.logger.info(f\"\\n{'='*100}\")\n",
        "                    self.logger.info(f\"📊 COMBINACIÓN {combinacion_actual}/{total_combinaciones}\")\n",
        "                    self.logger.info(f\"{'='*100}\")\n",
        "\n",
        "                    archivo_resultado = self.ejecutar_evaluacion_modelo(i, nombre_config)\n",
        "\n",
        "                    if archivo_resultado:\n",
        "                        archivos_modelo.append(archivo_resultado)\n",
        "                        self.logger.info(f\"✅ Combinación {combinacion_actual} completada exitosamente\")\n",
        "                    else:\n",
        "                        self.logger.error(f\"❌ Error en combinación {combinacion_actual}\")\n",
        "\n",
        "                    # Pausa entre combinaciones\n",
        "                    if combinacion_actual < total_combinaciones:\n",
        "                        self.logger.info(\"⏳ Pausa de 3 segundos...\")\n",
        "                        time.sleep(3)\n",
        "\n",
        "                archivos_generados[modelo_info.nombre_corto] = archivos_modelo\n",
        "\n",
        "            self.logger.info(f\"\\n🎉 EVALUACIÓN COMPLETA AVANZADA FINALIZADA\")\n",
        "            self.logger.info(f\"📁 Todos los resultados en: {self.directorio_ejecucion}\")\n",
        "            self.logger.info(f\"🔬 Análisis completo con librerías especializadas\")\n",
        "\n",
        "            return archivos_generados\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            self.logger.warning(f\"\\n⚠️ EVALUACIÓN INTERRUMPIDA POR USUARIO\")\n",
        "            self.logger.info(f\"📊 Progreso: {combinacion_actual}/{total_combinaciones}\")\n",
        "            return archivos_generados\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"\\n❌ ERROR CRÍTICO: {str(e)}\")\n",
        "            self.logger_manager.log_error(\"evaluador_principal\", e, \"Evaluación completa\")\n",
        "            return archivos_generados\n"
      ],
      "metadata": {
        "id": "_f8RDFfjAP24"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN PRINCIPAL UNIFICADA\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Función principal única del sistema de evaluación avanzado\n",
        "    Ejecuta automáticamente todos los modelos con todas las configuraciones\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Configuración inicial\n",
        "        config = ConfigEvaluacion()\n",
        "\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(f\"🎯 SISTEMA DE EVALUACIÓN MASK2FORMER AVANZADO - TFM NIVEL MÁSTER\")\n",
        "        print(f\"{'='*100}\")\n",
        "        print(f\"🔬 Análisis incluidos:\")\n",
        "        print(f\"   📊 Texturas: Haralick, LBP, GLCM, Zernike\")\n",
        "        print(f\"   🔷 Geometría: Shapely, Compacidad, Convexidad\")\n",
        "        print(f\"   🎨 Color: Paleta dominante, HSV, LAB\")\n",
        "        print(f\"   📐 Forma: Bordes, Esquinas, Momentos\")\n",
        "        print(f\"   🔍 Multi-escala: Características multi-resolución\")\n",
        "        print(f\"   🗺️  Regional: Segmentación SLIC\")\n",
        "\n",
        "        print(f\"\\n📊 Configuración de evaluación:\")\n",
        "        print(f\"   🤖 Modelos: {len(config.MODELOS)}\")\n",
        "        for i, modelo in enumerate(config.MODELOS):\n",
        "            print(f\"      [{i}] {modelo.nombre_corto} ({modelo.tipo}, {modelo.dataset})\")\n",
        "\n",
        "        print(f\"   ⚙️ Configuraciones de umbral: {len(config.UMBRALES)}\")\n",
        "        for nombre, config_umbral in config.UMBRALES.items():\n",
        "            print(f\"      {nombre}: {config_umbral.descripcion}\")\n",
        "\n",
        "        print(f\"   📄 Formatos de salida: JSON propio + COCO\")\n",
        "        print(f\"   🔬 Librerías: Mahotas, Scikit-image, Shapely, OpenCV, Sklearn\")\n",
        "\n",
        "        # Crear evaluador\n",
        "        evaluador = EvaluadorMask2FormerAvanzado(config)\n",
        "\n",
        "        # Ejecutar evaluación completa automáticamente\n",
        "        print(f\"\\n🚀 INICIANDO EVALUACIÓN AUTOMÁTICA COMPLETA...\")\n",
        "        total_combinaciones = len(config.MODELOS) * len(config.UMBRALES)\n",
        "        print(f\"📊 Total de combinaciones a procesar: {total_combinaciones}\")\n",
        "\n",
        "        archivos_resultado = evaluador.ejecutar_evaluacion_completa()\n",
        "\n",
        "        # Resumen final\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(f\"✅ EVALUACIÓN COMPLETA FINALIZADA\")\n",
        "        print(f\"{'='*100}\")\n",
        "\n",
        "        total_archivos = sum(len(archivos) for archivos in archivos_resultado.values())\n",
        "        print(f\"📁 Archivos generados: {total_archivos}\")\n",
        "        print(f\"💾 Ubicación: {evaluador.directorio_ejecucion}\")\n",
        "\n",
        "        print(f\"\\n📊 RESUMEN POR MODELO:\")\n",
        "        for modelo, archivos in archivos_resultado.items():\n",
        "            print(f\"   🤖 {modelo}: {len(archivos)} evaluaciones completadas\")\n",
        "\n",
        "        print(f\"\\n📂 ESTRUCTURA DE ARCHIVOS GENERADOS:\")\n",
        "        print(f\"   📄 resultados_json/     - Análisis completos JSON\")\n",
        "        print(f\"   📊 resumenes/           - Resúmenes ejecutivos\")\n",
        "        print(f\"   🔬 caracteristicas_avanzadas/ - Características especializadas\")\n",
        "        print(f\"   🏷️  formato_coco/       - Exportación formato COCO\")\n",
        "        print(f\"   📝 logs/               - Registros de ejecución\")\n",
        "\n",
        "        print(f\"\\n🎯 ANÁLISIS COMPLETADO CON ÉXITO\")\n",
        "        print(f\"🔬 Framework v2.0 - Análisis avanzado con librerías especializadas\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ ERROR CRÍTICO EN MAIN: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "kDdLdHTpAXy3"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PUNTO DE ENTRADA\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f7049b6cb4b4c9dbe76c6af96eac526",
            "5500f20be31545079aab8b3904cc50ad",
            "860f63cc599b426ab15dcecb05a3fd64",
            "7f12e20663ae487896b1c81dd72f4cc0",
            "6e73d7b9a0f54617b68a738a5551ca6f",
            "21b4cbd240f6469bb7e4d52f6becf682",
            "18b6469e4a3342bfad422154348c338b",
            "af05ca74308c4aec86af2ff2aa9ad213",
            "87346c5d976b436f8a43a6a876c7b575",
            "48922a184e374786a20d09c398e2896b",
            "876c1d4bc01146bcb697c99118a37d4c",
            "120b5196c1444147afc90e208af98818",
            "13d34ebfe13c473ab621485bc78a389b",
            "301a43ce27e34dab886424fc8ce25e73",
            "d355b402f7184a919ad07b9843838f4c",
            "8e52fc85ac434dc9ab8ad49673f8a3b2",
            "fa5f3d480099488a915166ad76a0adcc",
            "baee498ce3b841ff8127baaebc777727",
            "fa1fe7f219a543608d92bc8b3826c7c8",
            "3f9f7e500e474beaa6afd2edc7dbf73b",
            "92429ddefe694bdf814d0ed93a754231",
            "b14efcd3e67243b4a450a2c50fd1be4c",
            "5a28cdf4a2f44acebaed532858639508",
            "d62f20cc143a427c8ca7b13c0b518bce",
            "b07de3510bb44b45a40f3ac7b4cd3666",
            "dc5f127f7f6645d290bf72f6d6761d9a",
            "907c45ba5e6b4666852b030cd02a1a0e",
            "7df887ae542a40968adad709bdb6b34e",
            "d6a541a17f98446b91b47f73184f9a4a",
            "1ac4183a8afe42f39b19516930c4d6cd",
            "266f4b9a3f7e4525a9e1dc810a26a024",
            "b3bb151055154957aae8196751f7da38",
            "2df9d79f0e5b4288b091ed1259941ed8",
            "b6b10ce620eb4be98e4848f43920eeb5",
            "0d1b0f7473394756a619aa6ffc6001dc",
            "bd49114ab8124b29ba6a3bbf8b628fda",
            "ad86013674e44aa880c05103038ed393",
            "c21530f252544d3ea3dabd52d04d3e25",
            "62a8dbc70be343f8915055950329dd10",
            "7f01c954d69f4910aa4b57db8c988f92",
            "00165f1cbf5647768a63b8203058a7b4",
            "60b32ab4ff0644d390f20609594cbba6",
            "eaa752631b5b495985cbe4f57777384a",
            "a586265e8349430aaf0dbb3405c2a6ab",
            "c04c2cf071b3491dadde552e79a117aa",
            "735eda7a7ec24d0cb5ea2451ffd6ca00",
            "c07907c67c0b4b5a81fd54e984066036",
            "76f44cd7349b45f287bca09a8ecdd3cb",
            "aec8cb7803ac43b398c395156cd98534",
            "c4ee83644f3447debf43ed82009e580f",
            "41a589737b7a43e88606341999bca766",
            "44193d2bcc6b4ab19c543389551baca8",
            "18dd87020adc4a14b9fe0f3937252eb3",
            "a1e28fc850af417fac03c0f4d0a7f90b",
            "8e0ec62e84ad487a8ab67bfd9af350c4",
            "b9ed769e83a54005b0b38f99aa4892fa",
            "6e8b2a7f4f9445fd90df3a4568893186",
            "d8b7bc70b0af405a9b07e4fc732ff31d",
            "060d6e7f52de4368b82b062a6f48b5d9",
            "9926001a05fb4b648b1e71697544391e",
            "48985b0e4c4a4ecf83255d25ddaf3a6a",
            "54cc88a6dd2b45baa894760f9fa9933b",
            "96c3427bc15a409889672e7d8c991d02",
            "7d8e0241c9864ec295e08aabb7de7c5e",
            "3512db97c4104a30ab04a73336e20a1b",
            "404d1ba265ae436f9e1633a969c1ee55",
            "044fb81c95a6402aaffe43a0d1f96ee8",
            "87b49f76061f4c31ac60ba7bc8945b58",
            "a19c6d72b56a482cb29099f76ef61719",
            "a2228d2e0b2140abab6f30828b27ef60",
            "a6a70ddc851040698c3dbc353edf4d80",
            "b8a6aa08bb1546b4a8059f5c7e619094",
            "12dbfee44ae84a9592649e1e15447626",
            "2f0ada9780684aa7b12c7d20c031e942",
            "b64cdd605c4a4a059c3c0eea1d42906f",
            "c1040c0952c44d778c73ab5b340526f7",
            "8fad99f096ca4bb6ad5211891b3fedc7",
            "d7b3efa916944379bb8363b77eebb51a",
            "c5f540f77c59493ea704da7edd2d8b10",
            "e84918fec4254cdca70b371471076ef5",
            "a73ef68ea28e46f8bdcfb9cdd1438ca2",
            "1afc762966ae41b882700c549b619a34",
            "cf0a509ed9834a51852ada97072cb43a",
            "e38399aec54f41ecac4c7f91e654f920",
            "1dd7a46868e1433b92b90542385bd428",
            "604156ec04614e42ae54f7d41ff5f813",
            "03aa4cf18cf84cc48aa91e5a3d7abb32",
            "9d789dab41044ed48e945afbc84294c1",
            "4f302129eac44636912c552b008964b8",
            "f7dff668b71b4ff6bb01218ef32e13f6",
            "085403b326394c35937f28cc1dd6500c",
            "3d3e43ada429452e9a2da1e7da5d9b04",
            "b8738d6cbb0b461387b3f1e921dc82b6",
            "2896c9df9a4c495a8554080674835f17",
            "0add7c5159a84b23864585f9686ebfc8",
            "b7d51efe916e4db49293f23b9dee702d",
            "486ed01260f340a8892ba622dbfac90f",
            "4754a021b7704a379f6ac6882121f3ad",
            "60c145b6fff6487caa69009a8eb85e66",
            "9dcb59c97d324e5b9d6d7dc93d018cb7",
            "7ac539d3f4904232bffb9bfc1f40d2b7",
            "e1cd12c51ee34b12b8d84f0a860ed8eb",
            "1a64f233165d4049a529567d1130c93b",
            "00f2cddc92754ce3b9006f6a7c828833",
            "b32b9cd65b23486f80ff60a986aad30c",
            "1730339408004fd88a9f8464591d459d",
            "d56e167ad5434390ad41faa793ba718b",
            "f961d0395e5849a189b4a738c93cfb4e",
            "5f0ef5b5d99a43f0b96dff999ca1c784",
            "ab5e4d1de1aa4554a53e8f73fc6fc018",
            "507d738e60cd4df68e35bd343e553208",
            "2dc1a46cd28e4468b0571310455eacca",
            "41331be1eac64e14ba570c38917da072",
            "8a6ab991809c4555a9d8185070624940",
            "088a00f46961401f9d26ee2981006a28",
            "689e995b7afe4c678d954b8d21310faf",
            "5cf37048d72643afae9f2434bf19f0af",
            "407493e75b56409ba35ab65889033e36",
            "a961cad573844d62bdd5ea601378cfa7",
            "6909cea8fe574c238b22d7154ca907f2",
            "9db0fdc365fe45fe851abda8d601dbcb",
            "2fe2bd87b3394da9b268e62c904e156c",
            "c64427d7300b4d42b8009a2f89ea2e63",
            "4c233243e94649f1bef2a0acecbf5b50",
            "432a62847d8d4a7fa683e8a4bb6463f6",
            "102842ab7bdc4e459245966b041020cb",
            "1b06ef0569ed476086657b34fc828097",
            "54945cbff9044903bc0a3700d5f4a7f5",
            "206d73569da34fd695672f0ac8c1f7c8",
            "c0d976955efd4c138fd3ba50994c60a8",
            "21c041843ac442e0ac6d60bd6a24e920",
            "d250f1f7786c4ed1834ad6796524478d"
          ]
        },
        "id": "z5wW-UyvAdMb",
        "outputId": "b3b21b02-6b37-4c7d-e2b4-b4f3ae15e96a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:🚀 EVALUADOR MASK2FORMER AVANZADO INICIALIZADO\n",
            "INFO:evaluador_principal:📁 Directorio de ejecución: /content/drive/MyDrive/TFM/mask2former/resultados/ejecucion_20250927_185350\n",
            "INFO:evaluador_principal:🎯 Modelos disponibles: 3\n",
            "INFO:evaluador_principal:⚙️ Configuraciones de umbral: 4\n",
            "INFO:evaluador_principal:🔬 Análisis avanzado: Mahotas + Scikit-image + Shapely + OpenCV\n",
            "INFO:evaluador_principal:🎯 EVALUACIÓN COMPLETA AVANZADA: 12 combinaciones\n",
            "INFO:evaluador_principal:🔬 Análisis incluidos: Texturas, Geometría, Color, Forma, Multi-escala\n",
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 1/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-large-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Detecta cambios mínimos - Máxima sensibilidad\n",
            "INFO:evaluador_principal:🎯 Valores: [0.0001, 0.001, 0.01, 0.1]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:detector_swin-large-coco-instance:🤖 INICIALIZANDO MODELO: swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-large-coco-instance:🏗️ Arquitectura: Swin-Large\n",
            "INFO:detector_swin-large-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-large-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-large-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "🎯 SISTEMA DE EVALUACIÓN MASK2FORMER AVANZADO - TFM NIVEL MÁSTER\n",
            "====================================================================================================\n",
            "🔬 Análisis incluidos:\n",
            "   📊 Texturas: Haralick, LBP, GLCM, Zernike\n",
            "   🔷 Geometría: Shapely, Compacidad, Convexidad\n",
            "   🎨 Color: Paleta dominante, HSV, LAB\n",
            "   📐 Forma: Bordes, Esquinas, Momentos\n",
            "   🔍 Multi-escala: Características multi-resolución\n",
            "   🗺️  Regional: Segmentación SLIC\n",
            "\n",
            "📊 Configuración de evaluación:\n",
            "   🤖 Modelos: 3\n",
            "      [0] swin-large-coco-instance (instancia, COCO)\n",
            "      [1] swin-base-ade-semantic (semantico, ADE20K)\n",
            "      [2] swin-small-coco-instance (instancia, COCO)\n",
            "   ⚙️ Configuraciones de umbral: 4\n",
            "      ultra_sensible: Detecta cambios mínimos - Máxima sensibilidad\n",
            "      alta_sensibilidad: Sensibilidad alta para detección temprana\n",
            "      sensibilidad_media: Balance entre precisión y recall\n",
            "      baja_sensibilidad: Solo detecciones muy confiables\n",
            "   📄 Formatos de salida: JSON propio + COCO\n",
            "   🔬 Librerías: Mahotas, Scikit-image, Shapely, OpenCV, Sklearn\n",
            "\n",
            "🚀 INICIANDO EVALUACIÓN AUTOMÁTICA COMPLETA...\n",
            "📊 Total de combinaciones a procesar: 12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f7049b6cb4b4c9dbe76c6af96eac526"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-large-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-large-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-large-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-large-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00001_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 184.9ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:20, 10.28s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00001_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 191.3ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:24<00:12, 12.52s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00001_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 182.9ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:35<00:00, 11.94s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-large-coco-instance_20250927_185427.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-large-coco-instance_20250927_185427.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 35.8 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinlarge_ultra_sensible_20250927_185427_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-large-coco-instance_20250927_185427.png\n",
            "INFO:detector_swin-large-coco-instance:🧹 Liberando memoria del modelo swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 1 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-large-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 186.3ms (min: 182.9ms, max: 191.3ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "     0.0001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "      0.001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 2/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-large-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Sensibilidad alta para detección temprana\n",
            "INFO:evaluador_principal:🎯 Valores: [0.001, 0.01, 0.05, 0.1, 0.3]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:detector_swin-large-coco-instance:🤖 INICIALIZANDO MODELO: swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-large-coco-instance:🏗️ Arquitectura: Swin-Large\n",
            "INFO:detector_swin-large-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-large-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-large-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "120b5196c1444147afc90e208af98818"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-large-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-large-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-large-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-large-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00010_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 184.3ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:20, 10.27s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00010_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 183.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:23<00:12, 12.28s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00010_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 176.9ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:35<00:00, 11.72s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-large-coco-instance_20250927_185507.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-large-coco-instance_20250927_185507.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 35.2 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinlarge_alta_sensibilidad_20250927_185507_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-large-coco-instance_20250927_185507.png\n",
            "INFO:detector_swin-large-coco-instance:🧹 Liberando memoria del modelo swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 2 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-large-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 181.6ms (min: 176.9ms, max: 184.3ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "      0.001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.05:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 3/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-large-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Balance entre precisión y recall\n",
            "INFO:evaluador_principal:🎯 Valores: [0.01, 0.1, 0.3, 0.5]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:detector_swin-large-coco-instance:🤖 INICIALIZANDO MODELO: swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-large-coco-instance:🏗️ Arquitectura: Swin-Large\n",
            "INFO:detector_swin-large-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-large-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-large-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5a28cdf4a2f44acebaed532858639508"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-large-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-large-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-large-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-large-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00100_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 188.8ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:20, 10.05s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00100_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 184.7ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:23<00:12, 12.31s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_00100_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 175.6ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:35<00:00, 11.70s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-large-coco-instance_20250927_185546.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-large-coco-instance_20250927_185546.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 35.1 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinlarge_sensibilidad_media_20250927_185547_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-large-coco-instance_20250927_185546.png\n",
            "INFO:detector_swin-large-coco-instance:🧹 Liberando memoria del modelo swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 3 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-large-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 183.1ms (min: 175.6ms, max: 188.8ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.5:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 4/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-large-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Solo detecciones muy confiables\n",
            "INFO:evaluador_principal:🎯 Valores: [0.3, 0.5, 0.7]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:detector_swin-large-coco-instance:🤖 INICIALIZANDO MODELO: swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-large-coco-instance:🏗️ Arquitectura: Swin-Large\n",
            "INFO:detector_swin-large-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-large-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-large-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b10ce620eb4be98e4848f43920eeb5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-large-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-large-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-large-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-large-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-large-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_03000_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 175.1ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:20, 10.11s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_03000_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 174.7ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:23<00:12, 12.07s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-large-coco-instance_umbral_03000_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 182.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:34<00:00, 11.56s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-large-coco-instance_20250927_185626.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-large-coco-instance_20250927_185626.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 34.7 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinlarge_baja_sensibilidad_20250927_185626_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-large-coco-instance_20250927_185626.png\n",
            "INFO:detector_swin-large-coco-instance:🧹 Liberando memoria del modelo swin-large-coco-instance\n",
            "INFO:detector_swin-large-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 4 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-large-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 177.4ms (min: 174.7ms, max: 182.5ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.5:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.7:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 5/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-base-ade-semantic\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Detecta cambios mínimos - Máxima sensibilidad\n",
            "INFO:evaluador_principal:🎯 Valores: [0.0001, 0.001, 0.01, 0.1]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:detector_swin-base-ade-semantic:🤖 INICIALIZANDO MODELO: swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:📌 Tipo: SEMANTICO\n",
            "INFO:detector_swin-base-ade-semantic:🏗️ Arquitectura: Swin-Base\n",
            "INFO:detector_swin-base-ade-semantic:📊 Dataset: ADE20K\n",
            "INFO:detector_swin-base-ade-semantic:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c04c2cf071b3491dadde552e79a117aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-base-ade-semantic:🏷️ Clases disponibles: 150\n",
            "INFO:detector_swin-base-ade-semantic:👤 Clase persona encontrada: ID 12 = 'person'\n",
            "INFO:detector_swin-base-ade-semantic:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00001_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 1 personas | 0 total | 130.2ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:11<00:23, 11.60s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00001_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 1 personas | 0 total | 129.6ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:26<00:13, 13.49s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00001_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 1 personas | 0 total | 133.8ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:39<00:00, 13.07s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-base-ade-semantic_20250927_185710.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-base-ade-semantic_20250927_185710.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 39.2 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_semantico_ade20k_swinbase_ultra_sensible_20250927_185710_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-base-ade-semantic_20250927_185710.png\n",
            "INFO:detector_swin-base-ade-semantic:🧹 Liberando memoria del modelo swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 5 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-base-ade-semantic\n",
            "📊 Dataset: ADE20K | Tipo: SEMANTICO\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 131.2ms (min: 129.6ms, max: 133.8ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "     0.0001:   3/3 imágenes (100.0%) |   3 personas\n",
            "      0.001:   3/3 imágenes (100.0%) |   3 personas\n",
            "       0.01:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.1:   3/3 imágenes (100.0%) |   3 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n",
            "\n",
            "🔷 ANÁLISIS GEOMÉTRICO SHAPELY:\n",
            "   📐 Máscaras analizadas: 12\n",
            "   ✅ Polígonos válidos: 12 (100.0%)\n",
            "   🔄 Compacidad promedio: 0.378 ± 0.099\n",
            "   📏 Ratio convexidad: 0.889 ± 0.078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 6/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-base-ade-semantic\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Sensibilidad alta para detección temprana\n",
            "INFO:evaluador_principal:🎯 Valores: [0.001, 0.01, 0.05, 0.1, 0.3]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:detector_swin-base-ade-semantic:🤖 INICIALIZANDO MODELO: swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:📌 Tipo: SEMANTICO\n",
            "INFO:detector_swin-base-ade-semantic:🏗️ Arquitectura: Swin-Base\n",
            "INFO:detector_swin-base-ade-semantic:📊 Dataset: ADE20K\n",
            "INFO:detector_swin-base-ade-semantic:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9ed769e83a54005b0b38f99aa4892fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-base-ade-semantic:🏷️ Clases disponibles: 150\n",
            "INFO:detector_swin-base-ade-semantic:👤 Clase persona encontrada: ID 12 = 'person'\n",
            "INFO:detector_swin-base-ade-semantic:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00010_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 1 personas | 0 total | 122.6ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:12<00:24, 12.02s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00010_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 1 personas | 0 total | 123.0ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:27<00:13, 13.81s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00010_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 1 personas | 0 total | 123.3ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:40<00:00, 13.43s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-base-ade-semantic_20250927_185754.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-base-ade-semantic_20250927_185754.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 40.3 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_semantico_ade20k_swinbase_alta_sensibilidad_20250927_185754_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-base-ade-semantic_20250927_185754.png\n",
            "INFO:detector_swin-base-ade-semantic:🧹 Liberando memoria del modelo swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 6 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-base-ade-semantic\n",
            "📊 Dataset: ADE20K | Tipo: SEMANTICO\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 123.0ms (min: 122.6ms, max: 123.3ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "      0.001:   3/3 imágenes (100.0%) |   3 personas\n",
            "       0.01:   3/3 imágenes (100.0%) |   3 personas\n",
            "       0.05:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.1:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.3:   3/3 imágenes (100.0%) |   3 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n",
            "\n",
            "🔷 ANÁLISIS GEOMÉTRICO SHAPELY:\n",
            "   📐 Máscaras analizadas: 15\n",
            "   ✅ Polígonos válidos: 15 (100.0%)\n",
            "   🔄 Compacidad promedio: 0.378 ± 0.099\n",
            "   📏 Ratio convexidad: 0.889 ± 0.078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 7/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-base-ade-semantic\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Balance entre precisión y recall\n",
            "INFO:evaluador_principal:🎯 Valores: [0.01, 0.1, 0.3, 0.5]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:detector_swin-base-ade-semantic:🤖 INICIALIZANDO MODELO: swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:📌 Tipo: SEMANTICO\n",
            "INFO:detector_swin-base-ade-semantic:🏗️ Arquitectura: Swin-Base\n",
            "INFO:detector_swin-base-ade-semantic:📊 Dataset: ADE20K\n",
            "INFO:detector_swin-base-ade-semantic:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "044fb81c95a6402aaffe43a0d1f96ee8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-base-ade-semantic:🏷️ Clases disponibles: 150\n",
            "INFO:detector_swin-base-ade-semantic:👤 Clase persona encontrada: ID 12 = 'person'\n",
            "INFO:detector_swin-base-ade-semantic:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00100_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 1 personas | 0 total | 123.2ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:11<00:23, 11.72s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00100_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 1 personas | 0 total | 121.8ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:26<00:13, 13.58s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_00100_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 1 personas | 0 total | 124.3ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:40<00:00, 13.46s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-base-ade-semantic_20250927_185839.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-base-ade-semantic_20250927_185839.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 40.4 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_semantico_ade20k_swinbase_sensibilidad_media_20250927_185839_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-base-ade-semantic_20250927_185839.png\n",
            "INFO:detector_swin-base-ade-semantic:🧹 Liberando memoria del modelo swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 7 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-base-ade-semantic\n",
            "📊 Dataset: ADE20K | Tipo: SEMANTICO\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 123.1ms (min: 121.8ms, max: 124.3ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "       0.01:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.1:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.3:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.5:   1/3 imágenes ( 33.3%) |   1 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n",
            "\n",
            "🔷 ANÁLISIS GEOMÉTRICO SHAPELY:\n",
            "   📐 Máscaras analizadas: 10\n",
            "   ✅ Polígonos válidos: 10 (100.0%)\n",
            "   🔄 Compacidad promedio: 0.391 ± 0.102\n",
            "   📏 Ratio convexidad: 0.884 ± 0.076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 8/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-base-ade-semantic\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Solo detecciones muy confiables\n",
            "INFO:evaluador_principal:🎯 Valores: [0.3, 0.5, 0.7]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:detector_swin-base-ade-semantic:🤖 INICIALIZANDO MODELO: swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:📌 Tipo: SEMANTICO\n",
            "INFO:detector_swin-base-ade-semantic:🏗️ Arquitectura: Swin-Base\n",
            "INFO:detector_swin-base-ade-semantic:📊 Dataset: ADE20K\n",
            "INFO:detector_swin-base-ade-semantic:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7b3efa916944379bb8363b77eebb51a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-base-ade-semantic:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-base-ade-semantic:🏷️ Clases disponibles: 150\n",
            "INFO:detector_swin-base-ade-semantic:👤 Clase persona encontrada: ID 12 = 'person'\n",
            "INFO:detector_swin-base-ade-semantic:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-base-ade-semantic:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_03000_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 1 personas | 0 total | 124.4ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:11<00:22, 11.26s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_03000_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 1 personas | 0 total | 122.6ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:25<00:13, 13.24s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-base-ade-semantic_umbral_03000_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 1 personas | 0 total | 134.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:39<00:00, 13.23s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-base-ade-semantic_20250927_185923.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-base-ade-semantic_20250927_185923.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 39.7 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_semantico_ade20k_swinbase_baja_sensibilidad_20250927_185923_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-base-ade-semantic_20250927_185923.png\n",
            "INFO:detector_swin-base-ade-semantic:🧹 Liberando memoria del modelo swin-base-ade-semantic\n",
            "INFO:detector_swin-base-ade-semantic:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 8 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-base-ade-semantic\n",
            "📊 Dataset: ADE20K | Tipo: SEMANTICO\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 127.1ms (min: 122.6ms, max: 134.5ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "        0.3:   3/3 imágenes (100.0%) |   3 personas\n",
            "        0.5:   1/3 imágenes ( 33.3%) |   1 personas\n",
            "        0.7:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n",
            "\n",
            "🔷 ANÁLISIS GEOMÉTRICO SHAPELY:\n",
            "   📐 Máscaras analizadas: 4\n",
            "   ✅ Polígonos válidos: 4 (100.0%)\n",
            "   🔄 Compacidad promedio: 0.410 ± 0.102\n",
            "   📏 Ratio convexidad: 0.876 ± 0.072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 9/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-small-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Detecta cambios mínimos - Máxima sensibilidad\n",
            "INFO:evaluador_principal:🎯 Valores: [0.0001, 0.001, 0.01, 0.1]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:detector_swin-small-coco-instance:🤖 INICIALIZANDO MODELO: swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-small-coco-instance:🏗️ Arquitectura: Swin-Small\n",
            "INFO:detector_swin-small-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-small-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-small-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f302129eac44636912c552b008964b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-small-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-small-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-small-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-small-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00001_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 101.2ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:20, 10.38s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00001_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 100.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:25<00:12, 12.99s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00001_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 100.4ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:37<00:00, 12.67s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-small-coco-instance_20250927_190006.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-small-coco-instance_20250927_190006.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 38.0 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinsmall_ultra_sensible_20250927_190006_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-small-coco-instance_20250927_190006.png\n",
            "INFO:detector_swin-small-coco-instance:🧹 Liberando memoria del modelo swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 9 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-small-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 100.7ms (min: 100.4ms, max: 101.2ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "     0.0001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "      0.001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 10/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-small-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Sensibilidad alta para detección temprana\n",
            "INFO:evaluador_principal:🎯 Valores: [0.001, 0.01, 0.05, 0.1, 0.3]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:detector_swin-small-coco-instance:🤖 INICIALIZANDO MODELO: swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-small-coco-instance:🏗️ Arquitectura: Swin-Small\n",
            "INFO:detector_swin-small-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-small-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-small-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dcb59c97d324e5b9d6d7dc93d018cb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-small-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-small-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-small-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-small-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00010_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 100.1ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:21, 10.66s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00010_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 101.3ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:25<00:12, 13.00s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00010_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 99.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:37<00:00, 12.65s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-small-coco-instance_20250927_190048.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-small-coco-instance_20250927_190048.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 38.0 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinsmall_alta_sensibilidad_20250927_190048_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-small-coco-instance_20250927_190048.png\n",
            "INFO:detector_swin-small-coco-instance:🧹 Liberando memoria del modelo swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 10 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-small-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 100.3ms (min: 99.5ms, max: 101.3ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "      0.001:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "       0.05:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 11/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-small-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Balance entre precisión y recall\n",
            "INFO:evaluador_principal:🎯 Valores: [0.01, 0.1, 0.3, 0.5]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:detector_swin-small-coco-instance:🤖 INICIALIZANDO MODELO: swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-small-coco-instance:🏗️ Arquitectura: Swin-Small\n",
            "INFO:detector_swin-small-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-small-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-small-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "507d738e60cd4df68e35bd343e553208"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-small-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-small-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-small-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-small-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00100_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 100.0ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:21, 10.69s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00100_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 100.5ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:24<00:12, 12.80s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_00100_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 99.2ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:37<00:00, 12.42s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-small-coco-instance_20250927_190129.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-small-coco-instance_20250927_190129.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 37.3 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinsmall_sensibilidad_media_20250927_190129_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-small-coco-instance_20250927_190129.png\n",
            "INFO:detector_swin-small-coco-instance:🧹 Liberando memoria del modelo swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 11 completada exitosamente\n",
            "INFO:evaluador_principal:⏳ Pausa de 3 segundos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-small-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 99.9ms (min: 99.2ms, max: 100.5ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "       0.01:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.1:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.5:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:evaluador_principal:\n",
            "====================================================================================================\n",
            "INFO:evaluador_principal:📊 COMBINACIÓN 12/12\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🚀 INICIANDO EVALUACIÓN AVANZADA\n",
            "INFO:evaluador_principal:====================================================================================================\n",
            "INFO:evaluador_principal:🤖 Modelo: swin-small-coco-instance\n",
            "INFO:evaluador_principal:⚙️ Umbrales: Solo detecciones muy confiables\n",
            "INFO:evaluador_principal:🎯 Valores: [0.3, 0.5, 0.7]\n",
            "INFO:evaluador_principal:📸 Imágenes encontradas: 3\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:detector_swin-small-coco-instance:🤖 INICIALIZANDO MODELO: swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:📌 Tipo: INSTANCIA\n",
            "INFO:detector_swin-small-coco-instance:🏗️ Arquitectura: Swin-Small\n",
            "INFO:detector_swin-small-coco-instance:📊 Dataset: COCO\n",
            "INFO:detector_swin-small-coco-instance:💻 Dispositivo: cuda\n",
            "INFO:detector_swin-small-coco-instance:⏳ Cargando procesador de imágenes...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fe2bd87b3394da9b268e62c904e156c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:detector_swin-small-coco-instance:⏳ Cargando modelo de segmentación...\n",
            "INFO:detector_swin-small-coco-instance:🏷️ Clases disponibles: 80\n",
            "INFO:detector_swin-small-coco-instance:👤 Clase persona encontrada: ID 0 = 'person'\n",
            "INFO:detector_swin-small-coco-instance:✅ Modelo cargado exitosamente\n",
            "INFO:detector_swin-small-coco-instance:============================================================\n",
            "INFO:evaluador_principal:🔄 INICIANDO PROCESAMIENTO AVANZADO DE 3 IMÁGENES\n",
            "Procesando con análisis avanzado:   0%|          | 0/3 [00:00<?, ?it/s]INFO:procesador:📷 Extrayendo características avanzadas de Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Aleksandra_Retrato.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Aleksandra_Retrato.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_03000_Aleksandra_Retrato.png\n",
            "INFO:procesador:✅ Aleksandra_Retrato.jpg: 0 personas | 0 total | 108.4ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1800.431\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3622\n",
            "Procesando con análisis avanzado:  33%|███▎      | 1/3 [00:10<00:21, 10.78s/it]INFO:procesador:📷 Extrayendo características avanzadas de Anastasiia_Completo.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Anastasiia_Completo.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Anastasiia_Completo.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_03000_Anastasiia_Completo.png\n",
            "INFO:procesador:✅ Anastasiia_Completo.jpg: 0 personas | 0 total | 101.1ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1654.742\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3833\n",
            "Procesando con análisis avanzado:  67%|██████▋   | 2/3 [00:25<00:12, 12.88s/it]INFO:procesador:📷 Extrayendo características avanzadas de Celia_MedioPlano.jpg\n",
            "INFO:procesador:🔍 Ejecutando detección de personas en Celia_MedioPlano.jpg\n",
            "INFO:procesador:🎨 Generando visualización para Celia_MedioPlano.jpg\n",
            "INFO:procesador:Visualización guardada: vis_swin-small-coco-instance_umbral_03000_Celia_MedioPlano.png\n",
            "INFO:procesador:✅ Celia_MedioPlano.jpg: 0 personas | 0 total | 101.8ms | Análisis avanzado ✓\n",
            "INFO:procesador:   📊 Haralick promedio: 1008.028\n",
            "INFO:procesador:   🔍 Esquinas detectadas: 3720\n",
            "INFO:evaluador_principal:📈 Progreso: 3/3 imágenes procesadas\n",
            "Procesando con análisis avanzado: 100%|██████████| 3/3 [00:36<00:00, 12.33s/it]\n",
            "INFO:procesador:🎨 Generando resumen visual final...\n",
            "INFO:procesador:Resumen visual guardado: resumen_visual_swin-small-coco-instance_20250927_190210.png\n",
            "INFO:evaluador_principal:Archivo COCO exportado: mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211_coco.json\n",
            "INFO:evaluador_principal:Imágenes: 3, Anotaciones: 0\n",
            "INFO:evaluador_principal:💾 Archivo principal: mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:💾 Resumen ejecutivo: resumen_mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:💾 Características avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:💾 Formato COCO: mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211_coco.json\n",
            "INFO:evaluador_principal:🎨 Resumen visual: resumen_visual_swin-small-coco-instance_20250927_190210.png\n",
            "INFO:evaluador_principal:⏱️ Tiempo total: 37.0 segundos\n",
            "INFO:evaluador_principal:💾 Archivos generados: 5\n",
            "INFO:evaluador_principal:   📄 json_principal: mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:   📄 resumen_ejecutivo: resumen_mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:   📄 caracteristicas_avanzadas: caracteristicas_mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211.json\n",
            "INFO:evaluador_principal:   📄 formato_coco: mask2former_instancia_coco_swinsmall_baja_sensibilidad_20250927_190211_coco.json\n",
            "INFO:evaluador_principal:   📄 resumen_visual: resumen_visual_swin-small-coco-instance_20250927_190210.png\n",
            "INFO:detector_swin-small-coco-instance:🧹 Liberando memoria del modelo swin-small-coco-instance\n",
            "INFO:detector_swin-small-coco-instance:✅ Memoria liberada\n",
            "INFO:evaluador_principal:✅ Combinación 12 completada exitosamente\n",
            "INFO:evaluador_principal:\n",
            "🎉 EVALUACIÓN COMPLETA AVANZADA FINALIZADA\n",
            "INFO:evaluador_principal:📁 Todos los resultados en: /content/drive/MyDrive/TFM/mask2former/resultados/ejecucion_20250927_185350\n",
            "INFO:evaluador_principal:🔬 Análisis completo con librerías especializadas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "📊 RESUMEN DE EVALUACIÓN AVANZADA\n",
            "====================================================================================================\n",
            "🤖 Modelo: swin-small-coco-instance\n",
            "📊 Dataset: COCO | Tipo: INSTANCIA\n",
            "✅ Éxito: 3/3 (100.0%)\n",
            "🔬 Framework: 2.0_avanzado\n",
            "⚡ Tiempo promedio: 103.8ms (min: 101.1ms, max: 108.4ms)\n",
            "\n",
            "🎯 RESULTADOS POR UMBRAL:\n",
            "        0.3:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.5:   0/3 imágenes (  0.0%) |   0 personas\n",
            "        0.7:   0/3 imágenes (  0.0%) |   0 personas\n",
            "\n",
            "🔬 ANÁLISIS DE CARACTERÍSTICAS AVANZADAS:\n",
            "   📊 Haralick (textura): 1487.734 ± 344.378\n",
            "   🔍 Esquinas detectadas: 3725.0 ± 86.2\n",
            "   ⚡ GLCM Contraste: 54.915 ± 27.816\n",
            "\n",
            "====================================================================================================\n",
            "✅ EVALUACIÓN COMPLETA FINALIZADA\n",
            "====================================================================================================\n",
            "📁 Archivos generados: 12\n",
            "💾 Ubicación: /content/drive/MyDrive/TFM/mask2former/resultados/ejecucion_20250927_185350\n",
            "\n",
            "📊 RESUMEN POR MODELO:\n",
            "   🤖 swin-large-coco-instance: 4 evaluaciones completadas\n",
            "   🤖 swin-base-ade-semantic: 4 evaluaciones completadas\n",
            "   🤖 swin-small-coco-instance: 4 evaluaciones completadas\n",
            "\n",
            "📂 ESTRUCTURA DE ARCHIVOS GENERADOS:\n",
            "   📄 resultados_json/     - Análisis completos JSON\n",
            "   📊 resumenes/           - Resúmenes ejecutivos\n",
            "   🔬 caracteristicas_avanzadas/ - Características especializadas\n",
            "   🏷️  formato_coco/       - Exportación formato COCO\n",
            "   📝 logs/               - Registros de ejecución\n",
            "\n",
            "🎯 ANÁLISIS COMPLETADO CON ÉXITO\n",
            "🔬 Framework v2.0 - Análisis avanzado con librerías especializadas\n"
          ]
        }
      ]
    }
  ]
}