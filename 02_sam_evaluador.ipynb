{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwB0Y+9CZ5u+zs34ONI8qQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/02_sam_evaluador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7_asBwddTsQb",
        "outputId": "cf0556c7-884d-45ec-af2a-01ca6f80e3d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nEVALUADOR SAM 2.0\\n================================================================================\\nSistema de evaluacion para modelos SAM 2.0 (Segment Anything Model 2) con\\nestructura estandarizada para comparacion de modelos de segmentacion automatica.\\n\\nCARACTERISTICAS PRINCIPALES:\\n- Procesamiento incremental con sistema de checkpoint robusto\\n- Gestion optima de memoria para Google Colab gratuito\\n- Guardado automatico despues de cada imagen procesada\\n- 3 configuraciones de generacion optimizadas para fotografia de retrato\\n- Filtrado inteligente de personas basado en heuristicas del estado del arte\\n- Visualizaciones 3-panel avanzadas (Original + Todas las mascaras + Personas)\\n- NPZ completo con todos los scores de SAM 2.0 para analisis posterior\\n- JSON ligero con metricas de rendimiento (sin analisis geometrico)\\n- Soporte para 4 modelos SAM 2.0 (Tiny, Small, Base Plus, Large)\\n\\nCONFIGURACIONES DE GENERACION:\\n1. low_cost: Ultra-rapida, optimizada para modelos ligeros\\n2. balanced: Equilibrio calidad-velocidad (recomendado para retratos)\\n3. quality: Maxima calidad de segmentacion\\n\\nFILTRADO DE PERSONAS (Heuristicas del estado del arte):\\n- Ratio de aspecto: 0.3 - 1.5 (personas son mas altas que anchas)\\n- Area: 5% - 90% de la imagen (personas significativas)\\n- Confianza SAM: predicted_iou >= 0.85\\n- Posicion central: Distancia al centro <= 0.3\\n- Compacidad: Objetos compactos (no fragmentados)\\n- Sistema de scoring: Minimo 3 de 5 criterios cumplidos\\n\\nALMACENAMIENTO NPZ\\n- segmentation: Mascara binaria\\n- bbox, area: Geometria basica\\n- predicted_iou, stability_score: Scores unicos de SAM 2.0\\n- crop_box: Area de procesamiento usada\\n- person_confidence: Score de filtrado de personas\\n- criteria_met, area_ratio, aspect_ratio, center_distance: Metricas de filtrado\\n\\nVISUALIZACIONES 3-PANEL:\\n- Panel 1: Imagen original\\n- Panel 2: TODAS las mascaras generadas por SAM (overlay con colores)\\n- Panel 3: SOLO personas filtradas (bounding boxes verdes + scores)\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/2_Modelos/sam2/{modelo}/{config}/\\n├── resultados_{timestamp}.json     # Metricas y metadatos ligeros\\n├── mascaras/                        # Mascaras NPZ completas por imagen\\n└── visualizaciones/                 # PNGs 3-panel con informacion\\n\\nEntrada: Imagenes desde /TFM/0_Imagenes/\\nSalida: JSON, mascaras NPZ completas y visualizaciones en estructura organizada\\n\\nAutor: Jesús L.\\nProyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\\nUniversidad: Universidad Oberta de Cataluna (UOC)\\nFecha: Octubre 2025\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "EVALUADOR SAM 2.0\n",
        "================================================================================\n",
        "Sistema de evaluacion para modelos SAM 2.0 (Segment Anything Model 2) con\n",
        "estructura estandarizada para comparacion de modelos de segmentacion automatica.\n",
        "\n",
        "CARACTERISTICAS PRINCIPALES:\n",
        "- Procesamiento incremental con sistema de checkpoint robusto\n",
        "- Gestion optima de memoria para Google Colab gratuito\n",
        "- Guardado automatico despues de cada imagen procesada\n",
        "- 3 configuraciones de generacion optimizadas para fotografia de retrato\n",
        "- Filtrado inteligente de personas basado en heuristicas del estado del arte\n",
        "- Visualizaciones 3-panel avanzadas (Original + Todas las mascaras + Personas)\n",
        "- NPZ completo con todos los scores de SAM 2.0 para analisis posterior\n",
        "- JSON ligero con metricas de rendimiento (sin analisis geometrico)\n",
        "- Soporte para 4 modelos SAM 2.0 (Tiny, Small, Base Plus, Large)\n",
        "\n",
        "CONFIGURACIONES DE GENERACION:\n",
        "1. low_cost: Ultra-rapida, optimizada para modelos ligeros\n",
        "2. balanced: Equilibrio calidad-velocidad (recomendado para retratos)\n",
        "3. quality: Maxima calidad de segmentacion\n",
        "\n",
        "FILTRADO DE PERSONAS (Heuristicas del estado del arte):\n",
        "- Ratio de aspecto: 0.3 - 1.5 (personas son mas altas que anchas)\n",
        "- Area: 5% - 90% de la imagen (personas significativas)\n",
        "- Confianza SAM: predicted_iou >= 0.85\n",
        "- Posicion central: Distancia al centro <= 0.3\n",
        "- Compacidad: Objetos compactos (no fragmentados)\n",
        "- Sistema de scoring: Minimo 3 de 5 criterios cumplidos\n",
        "\n",
        "ALMACENAMIENTO NPZ\n",
        "- segmentation: Mascara binaria\n",
        "- bbox, area: Geometria basica\n",
        "- predicted_iou, stability_score: Scores unicos de SAM 2.0\n",
        "- crop_box: Area de procesamiento usada\n",
        "- person_confidence: Score de filtrado de personas\n",
        "- criteria_met, area_ratio, aspect_ratio, center_distance: Metricas de filtrado\n",
        "\n",
        "VISUALIZACIONES 3-PANEL:\n",
        "- Panel 1: Imagen original\n",
        "- Panel 2: TODAS las mascaras generadas por SAM (overlay con colores)\n",
        "- Panel 3: SOLO personas filtradas (bounding boxes verdes + scores)\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/2_Modelos/sam2/{modelo}/{config}/\n",
        "├── resultados_{timestamp}.json     # Metricas y metadatos ligeros\n",
        "├── mascaras/                        # Mascaras NPZ completas por imagen\n",
        "└── visualizaciones/                 # PNGs 3-panel con informacion\n",
        "\n",
        "Entrada: Imagenes desde /TFM/0_Imagenes/\n",
        "Salida: JSON, mascaras NPZ completas y visualizaciones en estructura organizada\n",
        "\n",
        "Autor: Jesús L.\n",
        "Proyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "Universidad: Universidad Oberta de Cataluna (UOC)\n",
        "Fecha: Octubre 2025\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SETUP GOOGLE COLAB Y DESCARGA DE CHECKPOINTS\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Montar Google Drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    IN_COLAB = True\n",
        "    print(\"Google Drive montado correctamente\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"No estamos en Colab\")\n",
        "\n",
        "# IMPORTANTE: Checkpoints dentro del directorio sam2\n",
        "CHECKPOINTS_DIR = Path(\"/content/drive/MyDrive/TFM/2_Modelos/sam2/checkpoints\")\n",
        "CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# URLs oficiales de Meta AI\n",
        "CHECKPOINTS = {\n",
        "    'sam2_hiera_tiny.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt',\n",
        "    'sam2_hiera_small.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt',\n",
        "    'sam2_hiera_base_plus.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt',\n",
        "    'sam2_hiera_large.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt',\n",
        "}\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"DESCARGANDO CHECKPOINTS SAM 2.0\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for filename, url in CHECKPOINTS.items():\n",
        "    checkpoint_path = CHECKPOINTS_DIR / filename\n",
        "\n",
        "    if checkpoint_path.exists():\n",
        "        size_mb = checkpoint_path.stat().st_size / (1024 * 1024)\n",
        "        print(f\"[EXISTE] {filename}: {size_mb:.1f} MB\")\n",
        "    else:\n",
        "        print(f\"[DESCARGANDO] {filename}...\")\n",
        "        !wget -q --show-progress {url} -O {checkpoint_path}\n",
        "\n",
        "        if checkpoint_path.exists():\n",
        "            size_mb = checkpoint_path.stat().st_size / (1024 * 1024)\n",
        "            print(f\"  Completado: {size_mb:.1f} MB\")\n",
        "        else:\n",
        "            print(f\"  ERROR descargando {filename}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"Checkpoints listos en: {CHECKPOINTS_DIR}\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CFL7CT-GR81",
        "outputId": "77858943-d7ae-4f9b-a889-bfe34a7b56f0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado correctamente\n",
            "================================================================================\n",
            "DESCARGANDO CHECKPOINTS SAM 2.0\n",
            "================================================================================\n",
            "[DESCARGANDO] sam2_hiera_tiny.pt...\n",
            "/content/drive/MyDr 100%[===================>] 148.68M  44.8MB/s    in 3.3s    \n",
            "  Completado: 148.7 MB\n",
            "[DESCARGANDO] sam2_hiera_small.pt...\n",
            "/content/drive/MyDr 100%[===================>] 175.77M  48.3MB/s    in 4.2s    \n",
            "  Completado: 175.8 MB\n",
            "[DESCARGANDO] sam2_hiera_base_plus.pt...\n",
            "/content/drive/MyDr 100%[===================>] 308.51M  58.0MB/s    in 5.2s    \n",
            "  Completado: 308.5 MB\n",
            "[DESCARGANDO] sam2_hiera_large.pt...\n",
            "/content/drive/MyDr 100%[===================>] 856.35M  63.4MB/s    in 16s     \n",
            "  Completado: 856.4 MB\n",
            "\n",
            "================================================================================\n",
            "Checkpoints listos en: /content/drive/MyDrive/TFM/2_Modelos/sam2/checkpoints\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# INSTALACION DE DEPENDENCIAS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Instalando dependencias...\")\n",
        "\n",
        "# Dependencias core\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q opencv-python matplotlib Pillow\n",
        "!pip install -q numpy scipy\n",
        "\n",
        "# SAM 2.0\n",
        "!pip install -q git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "\n",
        "print(\"Dependencias instaladas correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00xX3fLJVNcK",
        "outputId": "f7cc908b-a29b-4925-f62b-1d6864dbb45e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando dependencias...\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Dependencias instaladas correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import hashlib\n",
        "import warnings\n",
        "import gc\n",
        "import time\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# SAM 2.0\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar dispositivo\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if DEVICE == 'cuda':\n",
        "    print(f\"GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"Usando CPU (sera mas lento)\")\n",
        "\n",
        "print(\"Librerias importadas correctamente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71VKksM4W3dL",
        "outputId": "6c9cda5e-81b0-4694-ff28-3fc95797de31"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU disponible: Tesla T4\n",
            "VRAM total: 14.74 GB\n",
            "Librerias importadas correctamente\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION DE MODELOS Y PARAMETROS\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloSAMInfo:\n",
        "    \"\"\"Informacion completa de un modelo SAM 2.0\"\"\"\n",
        "    nombre: str\n",
        "    checkpoint: str\n",
        "    config: str\n",
        "    parametros_millones: int\n",
        "    vram_estimada_gb: float\n",
        "    descripcion: str\n",
        "\n",
        "    def obtener_nombre_sanitizado(self) -> str:\n",
        "        \"\"\"Obtiene nombre corto para archivos\"\"\"\n",
        "        return self.nombre.replace('sam2_hiera_', '')\n",
        "\n",
        "# Catalogo de modelos SAM 2.0 disponibles\n",
        "MODELOS_DISPONIBLES = {\n",
        "    'tiny': ModeloSAMInfo(\n",
        "        nombre='sam2_hiera_tiny',\n",
        "        checkpoint='sam2_hiera_tiny.pt',\n",
        "        config='sam2_hiera_t.yaml',\n",
        "        parametros_millones=39,\n",
        "        vram_estimada_gb=2.0,\n",
        "        descripcion='Modelo ultraligero optimizado para edge computing'\n",
        "    ),\n",
        "    'small': ModeloSAMInfo(\n",
        "        nombre='sam2_hiera_small',\n",
        "        checkpoint='sam2_hiera_small.pt',\n",
        "        config='sam2_hiera_s.yaml',\n",
        "        parametros_millones=46,\n",
        "        vram_estimada_gb=3.0,\n",
        "        descripcion='Balance optimo calidad-velocidad para produccion'\n",
        "    ),\n",
        "    'base_plus': ModeloSAMInfo(\n",
        "        nombre='sam2_hiera_base_plus',\n",
        "        checkpoint='sam2_hiera_base_plus.pt',\n",
        "        config='sam2_hiera_b+.yaml',\n",
        "        parametros_millones=80,\n",
        "        vram_estimada_gb=5.0,\n",
        "        descripcion='Modelo avanzado para produccion de alta calidad'\n",
        "    ),\n",
        "    'large': ModeloSAMInfo(\n",
        "        nombre='sam2_hiera_large',\n",
        "        checkpoint='sam2_hiera_large.pt',\n",
        "        config='sam2_hiera_l.yaml',\n",
        "        parametros_millones=224,\n",
        "        vram_estimada_gb=8.0,\n",
        "        descripcion='Modelo de investigacion - maxima calidad'\n",
        "    )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionSAM:\n",
        "    \"\"\"\n",
        "    Configuracion de parametros para generacion automatica de mascaras.\n",
        "\n",
        "    Parametros basados en:\n",
        "    - Meta AI SAM 2.0 documentation (2024)\n",
        "    - Best practices para fotografia de retrato\n",
        "    - Optimizacion para Google Colab gratuito\n",
        "\n",
        "    Referencias:\n",
        "    - Kirillov et al. (2024) \"Segment Anything 2\"\n",
        "    - Ravi et al. (2024) \"SAM 2: Segment Anything in Images and Videos\"\n",
        "    \"\"\"\n",
        "    nombre: str\n",
        "    descripcion: str\n",
        "\n",
        "    # Parametros de generacion de puntos\n",
        "    points_per_side: int\n",
        "    points_per_batch: int\n",
        "\n",
        "    # Umbrales de calidad\n",
        "    pred_iou_thresh: float\n",
        "    stability_score_thresh: float\n",
        "    stability_score_offset: float\n",
        "\n",
        "    # Control de mascaras y crops\n",
        "    crop_n_layers: int\n",
        "    crop_n_points_downscale_factor: int\n",
        "    min_mask_region_area: int\n",
        "\n",
        "# Configuraciones de generacion optimizadas\n",
        "CONFIGURACIONES_GENERACION = {\n",
        "    'low_cost': ConfiguracionSAM(\n",
        "        nombre='low_cost',\n",
        "        descripcion='Configuracion ultra-rapida optimizada para Tiny',\n",
        "        points_per_side=16,          # 16x16 = 256 prompts (rapido)\n",
        "        points_per_batch=64,\n",
        "        pred_iou_thresh=0.88,\n",
        "        stability_score_thresh=0.92,\n",
        "        stability_score_offset=1.0,\n",
        "        crop_n_layers=0,             # Sin crops para ahorrar memoria\n",
        "        crop_n_points_downscale_factor=1,\n",
        "        min_mask_region_area=200     # Filtrar mascaras muy pequeñas\n",
        "    ),\n",
        "    'balanced': ConfiguracionSAM(\n",
        "        nombre='balanced',\n",
        "        descripcion='Configuracion equilibrada - Recomendada para retratos',\n",
        "        points_per_side=24,          # 24x24 = 576 prompts (balance)\n",
        "        points_per_batch=64,\n",
        "        pred_iou_thresh=0.86,\n",
        "        stability_score_thresh=0.92,\n",
        "        stability_score_offset=1.0,\n",
        "        crop_n_layers=1,\n",
        "        crop_n_points_downscale_factor=2,\n",
        "        min_mask_region_area=150\n",
        "    ),\n",
        "    'quality': ConfiguracionSAM(\n",
        "        nombre='quality',\n",
        "        descripcion='Maxima calidad - Mayor precision en bordes',\n",
        "        points_per_side=32,          # 32x32 = 1024 prompts (completo)\n",
        "        points_per_batch=64,\n",
        "        pred_iou_thresh=0.86,\n",
        "        stability_score_thresh=0.92,\n",
        "        stability_score_offset=1.0,\n",
        "        crop_n_layers=1,\n",
        "        crop_n_points_downscale_factor=2,\n",
        "        min_mask_region_area=100\n",
        "    )\n",
        "}\n",
        "\n",
        "print(\"Configuraciones de modelos y parametros cargadas\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSN6AC6-W4yn",
        "outputId": "98d99aec-5653-43bb-b0a5-00065481ae74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuraciones de modelos y parametros cargadas\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utilidades:\n",
        "    \"\"\"Funciones auxiliares para procesamiento de imagenes y gestion de memoria\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def liberar_memoria():\n",
        "        \"\"\"Libera memoria GPU y RAM\"\"\"\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagen(ruta: Path, max_size: int = 1024) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Carga y redimensiona imagen manteniendo aspect ratio.\n",
        "\n",
        "        Args:\n",
        "            ruta: Path a la imagen\n",
        "            max_size: Dimension maxima permitida\n",
        "\n",
        "        Returns:\n",
        "            Imagen como array numpy RGB\n",
        "        \"\"\"\n",
        "        try:\n",
        "            imagen = cv2.imread(str(ruta))\n",
        "            if imagen is None:\n",
        "                raise ValueError(f\"No se pudo cargar la imagen: {ruta}\")\n",
        "\n",
        "            # Convertir BGR a RGB\n",
        "            imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Redimensionar si es necesario\n",
        "            h, w = imagen.shape[:2]\n",
        "            if max(h, w) > max_size:\n",
        "                escala = max_size / max(h, w)\n",
        "                nuevo_w = int(w * escala)\n",
        "                nuevo_h = int(h * escala)\n",
        "                imagen = cv2.resize(imagen, (nuevo_w, nuevo_h),\n",
        "                                  interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            return imagen\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error cargando imagen {ruta}: {str(e)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash_imagen(ruta: Path) -> str:\n",
        "        \"\"\"Calcula hash MD5 para identificacion unica de imagen\"\"\"\n",
        "        try:\n",
        "            with open(ruta, 'rb') as f:\n",
        "                return hashlib.md5(f.read()).hexdigest()[:12]\n",
        "        except Exception:\n",
        "            return \"hash_error\"\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Any, archivo: Path, indent: int = 2):\n",
        "        \"\"\"Guarda datos en formato JSON con conversion de tipos numpy\"\"\"\n",
        "        def convertir_tipos(obj):\n",
        "            if isinstance(obj, np.integer):\n",
        "                return int(obj)\n",
        "            elif isinstance(obj, np.floating):\n",
        "                return float(obj)\n",
        "            elif isinstance(obj, np.ndarray):\n",
        "                return obj.tolist()\n",
        "            elif isinstance(obj, dict):\n",
        "                return {k: convertir_tipos(v) for k, v in obj.items()}\n",
        "            elif isinstance(obj, list):\n",
        "                return [convertir_tipos(item) for item in obj]\n",
        "            return obj\n",
        "\n",
        "        try:\n",
        "            archivo.parent.mkdir(parents=True, exist_ok=True)\n",
        "            datos_convertidos = convertir_tipos(datos)\n",
        "\n",
        "            with open(archivo, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=indent,\n",
        "                         ensure_ascii=False, default=str)\n",
        "        except Exception as e:\n",
        "            raise IOError(f\"Error guardando JSON en {archivo}: {str(e)}\")\n",
        "\n",
        "print(\"Clase de utilidades definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8Fhb3HiXI5-",
        "outputId": "8360dd41-d49f-47d6-8d15-2c22619c5d4c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase de utilidades definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE CHECKPOINT (COMO ONEFORMER)\n",
        "# =============================================================================\n",
        "\n",
        "class GestorCheckpoint:\n",
        "    \"\"\"\n",
        "    Gestor de checkpoint para tracking de imagenes procesadas.\n",
        "    Similar a OneFormer: solo almacena nombres de imagenes completadas.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ruta_checkpoint: Path):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            ruta_checkpoint: Path al archivo checkpoint.json\n",
        "        \"\"\"\n",
        "        self.ruta_checkpoint = ruta_checkpoint\n",
        "        self.completadas = self._cargar_checkpoint()\n",
        "\n",
        "    def _cargar_checkpoint(self) -> set:\n",
        "        \"\"\"Carga conjunto de imagenes completadas\"\"\"\n",
        "        if self.ruta_checkpoint.exists():\n",
        "            try:\n",
        "                with open(self.ruta_checkpoint, 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "                    return set(data.get('completadas', []))\n",
        "            except Exception as e:\n",
        "                print(f\"Advertencia: Error cargando checkpoint: {str(e)}\")\n",
        "                return set()\n",
        "        return set()\n",
        "\n",
        "    def esta_completada(self, nombre_imagen: str) -> bool:\n",
        "        \"\"\"Verifica si una imagen ya fue procesada\"\"\"\n",
        "        return nombre_imagen in self.completadas\n",
        "\n",
        "    def marcar_completada(self, nombre_imagen: str):\n",
        "        \"\"\"Marca una imagen como completada y guarda checkpoint\"\"\"\n",
        "        self.completadas.add(nombre_imagen)\n",
        "        self._guardar_checkpoint()\n",
        "\n",
        "    def _guardar_checkpoint(self):\n",
        "        \"\"\"Guarda checkpoint en disco\"\"\"\n",
        "        try:\n",
        "            self.ruta_checkpoint.parent.mkdir(parents=True, exist_ok=True)\n",
        "            data = {\n",
        "                'completadas': sorted(list(self.completadas)),\n",
        "                'total': len(self.completadas),\n",
        "                'ultima_actualizacion': datetime.now().isoformat()\n",
        "            }\n",
        "            with open(self.ruta_checkpoint, 'w', encoding='utf-8') as f:\n",
        "                json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "        except Exception as e:\n",
        "            print(f\"Error guardando checkpoint: {str(e)}\")\n",
        "\n",
        "    def obtener_estadisticas(self) -> Dict[str, Any]:\n",
        "        \"\"\"Retorna estadisticas del checkpoint\"\"\"\n",
        "        return {\n",
        "            'total_completadas': len(self.completadas),\n",
        "            'imagenes': sorted(list(self.completadas))\n",
        "        }\n",
        "\n",
        "print(\"Clase gestor de checkpoint definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSKWD6HUXMok",
        "outputId": "70218f41-32c4-480c-e489-ef698a761b4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase gestor de checkpoint definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FILTRADO DE PERSONAS CON HEURISTICAS DEL ESTADO DEL ARTE\n",
        "# =============================================================================\n",
        "\n",
        "class FiltradorPersonas:\n",
        "    \"\"\"\n",
        "    Filtrado de mascaras para detectar personas en fotografia de retrato.\n",
        "\n",
        "    Implementa heuristicas basadas en investigacion del estado del arte:\n",
        "\n",
        "    Referencias:\n",
        "    - Lin et al. (2014) \"Microsoft COCO: Common Objects in Context\"\n",
        "    - Kirillov et al. (2023) \"Segment Anything\"\n",
        "    - Dollar et al. (2012) \"Pedestrian Detection: An Evaluation\"\n",
        "\n",
        "    Criterios de filtrado (minimo 3 de 5):\n",
        "    1. Area: 5%-90% de imagen\n",
        "    2. Aspect ratio: 0.3-1.5\n",
        "    3. Confianza SAM: predicted_iou >= 0.85\n",
        "    4. Posicion central: Distancia <= 0.3\n",
        "    5. Compacidad: >0.2\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.MIN_AREA_RATIO = 0.05\n",
        "        self.MAX_AREA_RATIO = 0.90\n",
        "        self.MIN_ASPECT_RATIO = 0.3\n",
        "        self.MAX_ASPECT_RATIO = 1.5\n",
        "        self.MIN_PREDICTED_IOU = 0.85\n",
        "        self.PREFERRED_CENTER_DISTANCE = 0.3\n",
        "        self.MIN_COMPACTNESS = 0.2\n",
        "\n",
        "    def filtrar_mascaras_personas(self,\n",
        "                                  mascaras: List[Dict],\n",
        "                                  imagen_shape: Tuple[int, int]) -> List[Dict]:\n",
        "        \"\"\"Filtra mascaras que probablemente son personas\"\"\"\n",
        "        if not mascaras:\n",
        "            return []\n",
        "\n",
        "        h, w = imagen_shape\n",
        "        area_total = h * w\n",
        "        centro_x, centro_y = w / 2, h / 2\n",
        "\n",
        "        mascaras_filtradas = []\n",
        "\n",
        "        for mask_data in mascaras:\n",
        "            segmentacion = mask_data['segmentation']\n",
        "            bbox = mask_data['bbox']\n",
        "            predicted_iou = mask_data.get('predicted_iou', 0)\n",
        "\n",
        "            area = np.sum(segmentacion)\n",
        "            area_ratio = area / area_total\n",
        "\n",
        "            x, y, mask_w, mask_h = bbox\n",
        "            aspect_ratio = mask_w / mask_h if mask_h > 0 else 0\n",
        "\n",
        "            mask_centro_x = x + mask_w / 2\n",
        "            mask_centro_y = y + mask_h / 2\n",
        "\n",
        "            dist_centro = np.sqrt(\n",
        "                ((mask_centro_x - centro_x) / w) ** 2 +\n",
        "                ((mask_centro_y - centro_y) / h) ** 2\n",
        "            )\n",
        "\n",
        "            criterios_cumplidos = 0\n",
        "\n",
        "            if self.MIN_AREA_RATIO <= area_ratio <= self.MAX_AREA_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            if self.MIN_ASPECT_RATIO <= aspect_ratio <= self.MAX_ASPECT_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            if predicted_iou >= self.MIN_PREDICTED_IOU:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            if dist_centro <= self.PREFERRED_CENTER_DISTANCE:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            perimetro_aprox = 2 * (mask_w + mask_h)\n",
        "            compacidad = (4 * np.pi * area) / (perimetro_aprox ** 2) if perimetro_aprox > 0 else 0\n",
        "            if compacidad > self.MIN_COMPACTNESS:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            confidence_score = criterios_cumplidos / 5.0\n",
        "\n",
        "            if criterios_cumplidos >= 3:\n",
        "                mask_data['person_confidence'] = confidence_score\n",
        "                mask_data['criteria_met'] = criterios_cumplidos\n",
        "                mask_data['area_ratio'] = float(area_ratio)\n",
        "                mask_data['aspect_ratio'] = float(aspect_ratio)\n",
        "                mask_data['center_distance'] = float(dist_centro)\n",
        "                mascaras_filtradas.append(mask_data)\n",
        "\n",
        "        mascaras_filtradas.sort(key=lambda x: x['person_confidence'], reverse=True)\n",
        "\n",
        "        return mascaras_filtradas\n",
        "\n",
        "print(\"Clase de filtrado de personas definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aatSkwnEXQcN",
        "outputId": "de9e4d1d-5ac5-4b67-c311-30765a3d65cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase de filtrado de personas definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE MASCARAS - UN NPZ POR IMAGEN CON TODAS LAS MASCARAS\n",
        "# =============================================================================\n",
        "\n",
        "class GestorMascaras:\n",
        "    \"\"\"\n",
        "    Gestiona el almacenamiento de mascaras en formato NPZ.\n",
        "    Estructura como OneFormer: UN archivo NPZ por imagen conteniendo TODAS las mascaras.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, directorio_mascaras: Path):\n",
        "        self.directorio_mascaras = directorio_mascaras\n",
        "        self.directorio_mascaras.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def guardar_mascaras(self,\n",
        "                        mascaras_personas: List[Dict],\n",
        "                        nombre_archivo: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Guarda TODAS las mascaras de una imagen en UN solo archivo NPZ.\n",
        "\n",
        "        Args:\n",
        "            mascaras_personas: Lista de mascaras filtradas\n",
        "            nombre_archivo: Nombre del archivo de imagen\n",
        "\n",
        "        Returns:\n",
        "            Metadatos para el JSON\n",
        "        \"\"\"\n",
        "        try:\n",
        "            nombre_base = Path(nombre_archivo).stem\n",
        "            archivo_npz = self.directorio_mascaras / f\"{nombre_base}.npz\"\n",
        "\n",
        "            if not mascaras_personas:\n",
        "                # Guardar NPZ vacio\n",
        "                np.savez_compressed(\n",
        "                    archivo_npz,\n",
        "                    num_mascaras=np.array(0, dtype=np.int32)\n",
        "                )\n",
        "                return {\n",
        "                    'archivo_mascaras': archivo_npz.name,\n",
        "                    'num_mascaras': 0,\n",
        "                    'mascaras': []\n",
        "                }\n",
        "\n",
        "            # Preparar arrays consolidados\n",
        "            num_mascaras = len(mascaras_personas)\n",
        "\n",
        "            # Arrays de mascaras binarias (stack de todas las mascaras)\n",
        "            primera_mascara = mascaras_personas[0]['segmentation']\n",
        "            h, w = primera_mascara.shape\n",
        "\n",
        "            mascaras_binarias = np.zeros((num_mascaras, h, w), dtype=np.uint8)\n",
        "            bboxes = np.zeros((num_mascaras, 4), dtype=np.float32)\n",
        "            areas = np.zeros(num_mascaras, dtype=np.int32)\n",
        "            predicted_ious = np.zeros(num_mascaras, dtype=np.float32)\n",
        "            stability_scores = np.zeros(num_mascaras, dtype=np.float32)\n",
        "            person_confidences = np.zeros(num_mascaras, dtype=np.float32)\n",
        "            criteria_mets = np.zeros(num_mascaras, dtype=np.int32)\n",
        "            area_ratios = np.zeros(num_mascaras, dtype=np.float32)\n",
        "            aspect_ratios = np.zeros(num_mascaras, dtype=np.float32)\n",
        "            center_distances = np.zeros(num_mascaras, dtype=np.float32)\n",
        "\n",
        "            # Llenar arrays\n",
        "            for idx, mask_data in enumerate(mascaras_personas):\n",
        "                mascaras_binarias[idx] = mask_data['segmentation'].astype(np.uint8)\n",
        "                bboxes[idx] = np.array(mask_data['bbox'], dtype=np.float32)\n",
        "                areas[idx] = mask_data['area']\n",
        "                predicted_ious[idx] = mask_data.get('predicted_iou', 0.0)\n",
        "                stability_scores[idx] = mask_data.get('stability_score', 0.0)\n",
        "                person_confidences[idx] = mask_data.get('person_confidence', 0.0)\n",
        "                criteria_mets[idx] = mask_data.get('criteria_met', 0)\n",
        "                area_ratios[idx] = mask_data.get('area_ratio', 0.0)\n",
        "                aspect_ratios[idx] = mask_data.get('aspect_ratio', 0.0)\n",
        "                center_distances[idx] = mask_data.get('center_distance', 0.0)\n",
        "\n",
        "            # Guardar TODO en un solo NPZ\n",
        "            np.savez_compressed(\n",
        "                archivo_npz,\n",
        "                num_mascaras=np.array(num_mascaras, dtype=np.int32),\n",
        "                mascaras_binarias=mascaras_binarias,\n",
        "                bboxes=bboxes,\n",
        "                areas=areas,\n",
        "                predicted_ious=predicted_ious,\n",
        "                stability_scores=stability_scores,\n",
        "                person_confidences=person_confidences,\n",
        "                criteria_mets=criteria_mets,\n",
        "                area_ratios=area_ratios,\n",
        "                aspect_ratios=aspect_ratios,\n",
        "                center_distances=center_distances\n",
        "            )\n",
        "\n",
        "            # Metadatos para JSON (resumen por mascara)\n",
        "            mascaras_info = []\n",
        "            for idx in range(num_mascaras):\n",
        "                mascaras_info.append({\n",
        "                    'indice': int(idx),\n",
        "                    'area': int(areas[idx]),\n",
        "                    'bbox': [float(x) for x in bboxes[idx]],\n",
        "                    'predicted_iou': float(predicted_ious[idx]),\n",
        "                    'stability_score': float(stability_scores[idx]),\n",
        "                    'person_confidence': float(person_confidences[idx]),\n",
        "                    'criteria_met': int(criteria_mets[idx])\n",
        "                })\n",
        "\n",
        "            return {\n",
        "                'archivo_mascaras': archivo_npz.name,\n",
        "                'num_mascaras': num_mascaras,\n",
        "                'mascaras': mascaras_info\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error guardando mascaras: {str(e)}\")\n",
        "            return {\n",
        "                'archivo_mascaras': None,\n",
        "                'num_mascaras': 0,\n",
        "                'mascaras': [],\n",
        "                'error': str(e)\n",
        "            }\n",
        "\n",
        "print(\"Clase gestor de mascaras definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmMsIgw4XWMA",
        "outputId": "a53429bd-eb3a-44b6-96d4-7933155b7dfa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase gestor de mascaras definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE VISUALIZACIONES 3-PANEL\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizacionesSAM:\n",
        "    \"\"\"Genera visualizaciones 3-panel de resultados SAM 2.0\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_visualizaciones: Path):\n",
        "        self.directorio_viz = directorio_visualizaciones\n",
        "        self.directorio_viz.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def generar_visualizacion(self,\n",
        "                             imagen_original: np.ndarray,\n",
        "                             nombre_archivo: str,\n",
        "                             resultado_generacion: Dict,\n",
        "                             titulo_modelo: str) -> Optional[str]:\n",
        "        \"\"\"Genera visualizacion 3-panel y la guarda\"\"\"\n",
        "        try:\n",
        "            mascaras_todas = resultado_generacion.get('mascaras_todas', [])\n",
        "            mascaras_personas = resultado_generacion.get('mascaras_personas', [])\n",
        "\n",
        "            if not mascaras_todas:\n",
        "                return None\n",
        "\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
        "            fig.suptitle(\n",
        "                f'{titulo_modelo} - {nombre_archivo}\\n'\n",
        "                f'Total: {len(mascaras_todas)} mascaras | Personas: {len(mascaras_personas)}',\n",
        "                fontsize=16, fontweight='bold'\n",
        "            )\n",
        "\n",
        "            # Panel 1: Original\n",
        "            axes[0].imshow(imagen_original)\n",
        "            axes[0].set_title('Imagen Original', fontsize=14)\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # Panel 2: Todas las mascaras\n",
        "            self._visualizar_mascaras(\n",
        "                axes[1], imagen_original, mascaras_todas,\n",
        "                f'Todas las Mascaras ({len(mascaras_todas)})'\n",
        "            )\n",
        "\n",
        "            # Panel 3: Solo personas\n",
        "            self._visualizar_mascaras(\n",
        "                axes[2], imagen_original, mascaras_personas,\n",
        "                f'Personas Detectadas ({len(mascaras_personas)})',\n",
        "                mostrar_confianza=True\n",
        "            )\n",
        "\n",
        "            # Guardar\n",
        "            nombre_base = Path(nombre_archivo).stem\n",
        "            ruta_salida = self.directorio_viz / f\"{nombre_base}.png\"\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(ruta_salida, dpi=150, bbox_inches='tight')\n",
        "            plt.close(fig)\n",
        "\n",
        "            return ruta_salida.name\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generando visualizacion: {str(e)}\")\n",
        "            plt.close('all')\n",
        "            return None\n",
        "\n",
        "    def _visualizar_mascaras(self, ax, imagen, mascaras, titulo, mostrar_confianza=False):\n",
        "        \"\"\"Visualiza mascaras en un eje\"\"\"\n",
        "        ax.imshow(imagen)\n",
        "\n",
        "        if not mascaras:\n",
        "            ax.set_title(f'{titulo} - Vacio', fontsize=12)\n",
        "            ax.axis('off')\n",
        "            return\n",
        "\n",
        "        overlay = np.zeros_like(imagen, dtype=np.float32)\n",
        "\n",
        "        for mask_data in mascaras:\n",
        "            seg = mask_data['segmentation']\n",
        "            color = np.random.random(3)\n",
        "\n",
        "            for c in range(3):\n",
        "                overlay[:, :, c] += seg * color[c] * 0.6\n",
        "\n",
        "        overlay = np.clip(overlay, 0, 1)\n",
        "        ax.imshow(overlay, alpha=0.5)\n",
        "\n",
        "        if mostrar_confianza:\n",
        "            for mask_data in mascaras:\n",
        "                bbox = mask_data['bbox']\n",
        "                confianza = mask_data.get('person_confidence', 0)\n",
        "\n",
        "                rect = mpatches.Rectangle(\n",
        "                    (bbox[0], bbox[1]), bbox[2], bbox[3],\n",
        "                    fill=False, edgecolor='lime', linewidth=2\n",
        "                )\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                ax.text(\n",
        "                    bbox[0], bbox[1] - 5,\n",
        "                    f'{confianza:.2f}',\n",
        "                    color='lime', fontsize=10, fontweight='bold',\n",
        "                    bbox=dict(facecolor='black', alpha=0.7, pad=2)\n",
        "                )\n",
        "\n",
        "        ax.set_title(titulo, fontsize=12)\n",
        "        ax.axis('off')\n",
        "\n",
        "print(\"Clase generador de visualizaciones definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WFbMcURXj3i",
        "outputId": "829a60e5-d902-4d19-83d9-1abebb0901b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase generador de visualizaciones definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE MASCARAS SAM 2.0\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorMascarasSAM:\n",
        "    \"\"\"Genera mascaras automaticas usando SAM 2.0\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 modelo_info: ModeloSAMInfo,\n",
        "                 config_sam: ConfiguracionSAM,\n",
        "                 checkpoints_path: Path):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config_sam = config_sam\n",
        "        self.checkpoints_path = checkpoints_path\n",
        "\n",
        "        self.modelo = None\n",
        "        self.mask_generator = None\n",
        "        self.filtrador = FiltradorPersonas()\n",
        "\n",
        "    def cargar_modelo(self):\n",
        "        \"\"\"Carga el modelo SAM 2.0\"\"\"\n",
        "        try:\n",
        "            print(f\"Cargando modelo {self.modelo_info.nombre}...\")\n",
        "\n",
        "            checkpoint_path = self.checkpoints_path / self.modelo_info.checkpoint\n",
        "\n",
        "            if not checkpoint_path.exists():\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Checkpoint no encontrado: {checkpoint_path}\"\n",
        "                )\n",
        "\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            self.modelo = build_sam2(\n",
        "                config_file=self.modelo_info.config,\n",
        "                ckpt_path=str(checkpoint_path),\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            self.mask_generator = SAM2AutomaticMaskGenerator(\n",
        "                model=self.modelo,\n",
        "                points_per_side=self.config_sam.points_per_side,\n",
        "                points_per_batch=self.config_sam.points_per_batch,\n",
        "                pred_iou_thresh=self.config_sam.pred_iou_thresh,\n",
        "                stability_score_thresh=self.config_sam.stability_score_thresh,\n",
        "                stability_score_offset=self.config_sam.stability_score_offset,\n",
        "                crop_n_layers=self.config_sam.crop_n_layers,\n",
        "                crop_n_points_downscale_factor=self.config_sam.crop_n_points_downscale_factor,\n",
        "                min_mask_region_area=self.config_sam.min_mask_region_area,\n",
        "            )\n",
        "\n",
        "            print(f\"Modelo cargado correctamente\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error cargando modelo: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generar_mascaras(self, imagen: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"Genera mascaras automaticas y filtra personas\"\"\"\n",
        "        try:\n",
        "            inicio = time.time()\n",
        "\n",
        "            mascaras_todas = self.mask_generator.generate(imagen)\n",
        "\n",
        "            tiempo_generacion = (time.time() - inicio) * 1000\n",
        "\n",
        "            mascaras_personas = self.filtrador.filtrar_mascaras_personas(\n",
        "                mascaras_todas,\n",
        "                imagen.shape[:2]\n",
        "            )\n",
        "\n",
        "            resultado = {\n",
        "                'total_mascaras_generadas': len(mascaras_todas),\n",
        "                'personas_detectadas': len(mascaras_personas),\n",
        "                'mascaras_personas': mascaras_personas,\n",
        "                'mascaras_todas': mascaras_todas,\n",
        "                'tiempo_generacion_ms': tiempo_generacion,\n",
        "                'imagen_shape': imagen.shape[:2],\n",
        "            }\n",
        "\n",
        "            return resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generando mascaras: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def liberar_memoria(self):\n",
        "        \"\"\"Libera memoria del modelo\"\"\"\n",
        "        del self.modelo\n",
        "        del self.mask_generator\n",
        "        self.modelo = None\n",
        "        self.mask_generator = None\n",
        "        Utilidades.liberar_memoria()\n",
        "\n",
        "print(\"Clase generador de mascaras definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjZBCPZsXqhk",
        "outputId": "bde83ea3-c429-4b8f-8f20-7b68c74a6781"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase generador de mascaras definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROCESADOR DE IMAGENES\n",
        "# =============================================================================\n",
        "\n",
        "class ProcesadorImagenes:\n",
        "    \"\"\"Procesador principal que coordina la generacion, guardado y visualizacion\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 modelo_info: ModeloSAMInfo,\n",
        "                 config_sam: ConfiguracionSAM,\n",
        "                 checkpoints_path: Path,\n",
        "                 directorio_salida: Path,\n",
        "                 max_size: int = 1024,\n",
        "                 generar_visualizaciones: bool = True):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config_sam = config_sam\n",
        "        self.max_size = max_size\n",
        "        self.generar_vis = generar_visualizaciones\n",
        "\n",
        "        # Crear estructura de directorios\n",
        "        self.dir_mascaras = directorio_salida / \"mascaras\"\n",
        "        self.dir_json = directorio_salida / \"json\"\n",
        "        self.dir_viz = directorio_salida / \"visualizaciones\"\n",
        "\n",
        "        self.dir_mascaras.mkdir(parents=True, exist_ok=True)\n",
        "        self.dir_json.mkdir(parents=True, exist_ok=True)\n",
        "        if generar_visualizaciones:\n",
        "            self.dir_viz.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Componentes\n",
        "        self.generador = GeneradorMascarasSAM(\n",
        "            modelo_info, config_sam, checkpoints_path\n",
        "        )\n",
        "        self.gestor_mascaras = GestorMascaras(self.dir_mascaras)\n",
        "\n",
        "        if generar_visualizaciones:\n",
        "            self.visualizador = GeneradorVisualizacionesSAM(self.dir_viz)\n",
        "        else:\n",
        "            self.visualizador = None\n",
        "\n",
        "    def inicializar(self):\n",
        "        \"\"\"Inicializa el generador cargando el modelo\"\"\"\n",
        "        self.generador.cargar_modelo()\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: Path) -> Dict[str, Any]:\n",
        "        \"\"\"Procesa una imagen completa\"\"\"\n",
        "        nombre_archivo = ruta_imagen.name\n",
        "        nombre_base = ruta_imagen.stem\n",
        "\n",
        "        try:\n",
        "            # Cargar imagen\n",
        "            tiempo_inicio = time.time()\n",
        "            imagen = Utilidades.cargar_imagen(ruta_imagen, self.max_size)\n",
        "            hash_imagen = Utilidades.calcular_hash_imagen(ruta_imagen)\n",
        "            tiempo_carga = (time.time() - tiempo_inicio) * 1000\n",
        "\n",
        "            # Generar mascaras\n",
        "            resultado_generacion = self.generador.generar_mascaras(imagen)\n",
        "\n",
        "            # Guardar mascaras en NPZ (UN archivo con todas las mascaras)\n",
        "            metadatos_mascaras = self.gestor_mascaras.guardar_mascaras(\n",
        "                resultado_generacion['mascaras_personas'],\n",
        "                nombre_archivo\n",
        "            )\n",
        "\n",
        "            # Generar visualizacion\n",
        "            archivo_viz = None\n",
        "            if self.visualizador and resultado_generacion['personas_detectadas'] > 0:\n",
        "                modelo_nombre = self.modelo_info.obtener_nombre_sanitizado().upper()\n",
        "                titulo = f\"{modelo_nombre}-{self.config_sam.nombre}\"\n",
        "                archivo_viz = self.visualizador.generar_visualizacion(\n",
        "                    imagen,\n",
        "                    nombre_archivo,\n",
        "                    resultado_generacion,\n",
        "                    titulo\n",
        "                )\n",
        "\n",
        "            # Construir JSON individual para esta imagen\n",
        "            tiempo_total = tiempo_carga + resultado_generacion['tiempo_generacion_ms']\n",
        "\n",
        "            resultado = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'nombre_imagen': nombre_archivo,\n",
        "                'modelo': self.modelo_info.obtener_nombre_sanitizado(),\n",
        "                'dataset': 'SAM2',\n",
        "                'configuracion': self.config_sam.nombre,\n",
        "                'arquitectura': self.modelo_info.nombre,\n",
        "                'hash': hash_imagen,\n",
        "                'dimensiones': {\n",
        "                    'alto': int(imagen.shape[0]),\n",
        "                    'ancho': int(imagen.shape[1])\n",
        "                },\n",
        "                'resultados': {\n",
        "                    'personas_detectadas': resultado_generacion['personas_detectadas'],\n",
        "                    'mascaras_totales': resultado_generacion['total_mascaras_generadas'],\n",
        "                    'mascaras': metadatos_mascaras\n",
        "                },\n",
        "                'procesamiento': {\n",
        "                    'tiempo_carga_ms': round(tiempo_carga, 2),\n",
        "                    'tiempo_generacion_ms': round(resultado_generacion['tiempo_generacion_ms'], 2),\n",
        "                    'tiempo_total_ms': round(tiempo_total, 2)\n",
        "                },\n",
        "                'archivos': {\n",
        "                    'visualizacion': archivo_viz\n",
        "                }\n",
        "            }\n",
        "\n",
        "            # Guardar JSON individual para esta imagen\n",
        "            ruta_json = self.dir_json / f\"{nombre_base}.json\"\n",
        "            Utilidades.guardar_json(resultado, ruta_json)\n",
        "\n",
        "            return resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR procesando {nombre_archivo}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # JSON de error\n",
        "            resultado_error = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'nombre_imagen': nombre_archivo,\n",
        "                'modelo': self.modelo_info.obtener_nombre_sanitizado(),\n",
        "                'configuracion': self.config_sam.nombre,\n",
        "                'error': str(e),\n",
        "                'exito': False\n",
        "            }\n",
        "\n",
        "            ruta_json = self.dir_json / f\"{nombre_base}.json\"\n",
        "            Utilidades.guardar_json(resultado_error, ruta_json)\n",
        "\n",
        "            return resultado_error\n",
        "\n",
        "    def liberar_recursos(self):\n",
        "        \"\"\"Libera recursos del procesador\"\"\"\n",
        "        self.generador.liberar_memoria()\n",
        "\n",
        "print(\"Clase procesador de imagenes definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxk0WY-PX_Fk",
        "outputId": "71fd1857-7069-4959-b8b0-a716ff5e1fb2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase procesador de imagenes definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL SAM 2.0\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorSAM2:\n",
        "    \"\"\"Evaluador principal que coordina todo el proceso de evaluacion\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 ruta_imagenes: Path,\n",
        "                 ruta_salida_base: Path,\n",
        "                 ruta_checkpoints: Path,\n",
        "                 modelos_evaluar: List[str],\n",
        "                 configs_evaluar: List[str],\n",
        "                 max_size: int = 1024,\n",
        "                 generar_visualizaciones: bool = True,\n",
        "                 pausa_entre_imagenes: float = 2.0):\n",
        "        self.ruta_imagenes = ruta_imagenes\n",
        "        self.ruta_salida_base = ruta_salida_base\n",
        "        self.ruta_checkpoints = ruta_checkpoints\n",
        "        self.modelos_evaluar = modelos_evaluar\n",
        "        self.configs_evaluar = configs_evaluar\n",
        "        self.max_size = max_size\n",
        "        self.generar_vis = generar_visualizaciones\n",
        "        self.pausa = pausa_entre_imagenes\n",
        "\n",
        "    def evaluar_combinacion(self, modelo_key: str, config_key: str):\n",
        "        \"\"\"Evalua una combinacion modelo + configuracion\"\"\"\n",
        "        modelo_info = MODELOS_DISPONIBLES[modelo_key]\n",
        "        config_sam = CONFIGURACIONES_GENERACION[config_key]\n",
        "\n",
        "        modelo_nombre = modelo_info.obtener_nombre_sanitizado()\n",
        "        config_nombre = config_sam.nombre\n",
        "\n",
        "        # Nombre de directorio: modelo_config (como OneFormer)\n",
        "        config_id = f\"{modelo_nombre}_{config_nombre}\"\n",
        "        dir_salida = self.ruta_salida_base / config_id\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"EVALUANDO: {config_id}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Checkpoint\n",
        "        checkpoint_path = dir_salida / \"checkpoint.json\"\n",
        "        checkpoint = GestorCheckpoint(checkpoint_path)\n",
        "\n",
        "        print(f\"Imagenes ya completadas: {checkpoint.obtener_estadisticas()['total_completadas']}\")\n",
        "\n",
        "        # Obtener imagenes\n",
        "        extensiones = ['*.jpg', '*.JPG', '*.png', '*.PNG', '*.jpeg', '*.JPEG']\n",
        "        imagenes = []\n",
        "        for ext in extensiones:\n",
        "            imagenes.extend(self.ruta_imagenes.glob(ext))\n",
        "        imagenes = sorted(set(imagenes))\n",
        "\n",
        "        # Filtrar pendientes\n",
        "        imagenes_pendientes = [\n",
        "            img for img in imagenes\n",
        "            if not checkpoint.esta_completada(img.name)\n",
        "        ]\n",
        "\n",
        "        print(f\"Total imagenes: {len(imagenes)}\")\n",
        "        print(f\"Pendientes: {len(imagenes_pendientes)}\")\n",
        "\n",
        "        if not imagenes_pendientes:\n",
        "            print(\"Todas las imagenes ya fueron procesadas\")\n",
        "            return\n",
        "\n",
        "        # Inicializar procesador\n",
        "        print(f\"\\nInicializando procesador...\")\n",
        "        procesador = ProcesadorImagenes(\n",
        "            modelo_info=modelo_info,\n",
        "            config_sam=config_sam,\n",
        "            checkpoints_path=self.ruta_checkpoints,\n",
        "            directorio_salida=dir_salida,\n",
        "            max_size=self.max_size,\n",
        "            generar_visualizaciones=self.generar_vis\n",
        "        )\n",
        "\n",
        "        procesador.inicializar()\n",
        "\n",
        "        print(f\"\\nProcesando {len(imagenes_pendientes)} imagenes...\")\n",
        "\n",
        "        # Procesar imagenes\n",
        "        for idx, imagen_path in enumerate(imagenes_pendientes, 1):\n",
        "            print(f\"\\n[{idx}/{len(imagenes_pendientes)}] {imagen_path.name}\")\n",
        "\n",
        "            try:\n",
        "                resultado = procesador.procesar_imagen(imagen_path)\n",
        "\n",
        "                if resultado.get('exito', True):\n",
        "                    print(f\"  Personas: {resultado['resultados']['personas_detectadas']}\")\n",
        "                    print(f\"  Tiempo: {resultado['procesamiento']['tiempo_total_ms']:.1f} ms\")\n",
        "\n",
        "                # Marcar como completada\n",
        "                checkpoint.marcar_completada(imagen_path.name)\n",
        "                print(f\"  Checkpoint actualizado\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ERROR: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "            finally:\n",
        "                Utilidades.liberar_memoria()\n",
        "                if idx < len(imagenes_pendientes):\n",
        "                    time.sleep(self.pausa)\n",
        "\n",
        "        # Limpiar\n",
        "        print(f\"\\nLiberando recursos...\")\n",
        "        procesador.liberar_recursos()\n",
        "        del procesador\n",
        "        Utilidades.liberar_memoria()\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"COMBINACION COMPLETADA: {config_id}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "    def ejecutar_evaluacion_completa(self):\n",
        "        \"\"\"Ejecuta evaluacion completa de todas las combinaciones\"\"\"\n",
        "        print(f\"\\n{'#'*80}\")\n",
        "        print(\"INICIO DE EVALUACION SAM 2.0\")\n",
        "        print(f\"{'#'*80}\")\n",
        "        print(f\"\\nConfiguracion:\")\n",
        "        print(f\"  Modelos: {self.modelos_evaluar}\")\n",
        "        print(f\"  Configuraciones: {self.configs_evaluar}\")\n",
        "        print(f\"  Imagenes: {self.ruta_imagenes}\")\n",
        "        print(f\"  Salida: {self.ruta_salida_base}\")\n",
        "\n",
        "        total_combinaciones = len(self.modelos_evaluar) * len(self.configs_evaluar)\n",
        "        combinacion_actual = 0\n",
        "\n",
        "        for modelo_key in self.modelos_evaluar:\n",
        "            for config_key in self.configs_evaluar:\n",
        "                combinacion_actual += 1\n",
        "\n",
        "                print(f\"\\n{'#'*80}\")\n",
        "                print(f\"COMBINACION {combinacion_actual}/{total_combinaciones}\")\n",
        "                print(f\"{'#'*80}\")\n",
        "\n",
        "                try:\n",
        "                    self.evaluar_combinacion(modelo_key, config_key)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"\\nERROR FATAL: {str(e)}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "                    print(f\"\\nContinuando con siguiente combinacion...\")\n",
        "                    continue\n",
        "\n",
        "                finally:\n",
        "                    Utilidades.liberar_memoria()\n",
        "                    time.sleep(5)\n",
        "\n",
        "        print(f\"\\n{'#'*80}\")\n",
        "        print(\"EVALUACION COMPLETA FINALIZADA\")\n",
        "        print(f\"{'#'*80}\")\n",
        "\n",
        "print(\"Clase evaluador principal definida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0wGIIU0YF0E",
        "outputId": "4a4c276a-5d2a-46f5-9a3a-c5bf991932e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clase evaluador principal definida\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCION MAIN PARA EJECUCION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Funcion principal para ejecutar la evaluacion\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CONFIGURACION DEL EVALUADOR SAM 2.0\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # CONFIGURACION DE RUTAS\n",
        "    ruta_imagenes = Path(\"/content/drive/MyDrive/TFM/0_Imagenes\")\n",
        "    ruta_salida_base = Path(\"/content/drive/MyDrive/TFM/2_Modelos/sam2\")\n",
        "    ruta_checkpoints = Path(\"/content/drive/MyDrive/TFM/2_Modelos/sam2/checkpoints\")\n",
        "\n",
        "    # CONFIGURACION DE EVALUACION\n",
        "    # Empezar con prueba rapida\n",
        "    modelos_evaluar = ['tiny', 'small', 'base_plus', 'large']\n",
        "    configs_evaluar = ['low_cost', 'balanced', 'quality']\n",
        "\n",
        "    # Parametros\n",
        "    max_size = 1024\n",
        "    generar_visualizaciones = True\n",
        "    pausa_entre_imagenes = 2.0\n",
        "\n",
        "    # Validar configuracion\n",
        "    print(\"\\nValidando configuracion...\")\n",
        "    try:\n",
        "        if not ruta_imagenes.exists():\n",
        "            raise FileNotFoundError(f\"Imagenes no encontradas: {ruta_imagenes}\")\n",
        "\n",
        "        if not ruta_checkpoints.exists():\n",
        "            raise FileNotFoundError(f\"Checkpoints no encontrados: {ruta_checkpoints}\")\n",
        "\n",
        "        for modelo_key in modelos_evaluar:\n",
        "            modelo_info = MODELOS_DISPONIBLES[modelo_key]\n",
        "            checkpoint_path = ruta_checkpoints / modelo_info.checkpoint\n",
        "            if not checkpoint_path.exists():\n",
        "                raise FileNotFoundError(f\"Checkpoint no encontrado: {checkpoint_path}\")\n",
        "\n",
        "        print(\"Configuracion validada\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Resumen\n",
        "    print(f\"\\nRESUMEN:\")\n",
        "    print(f\"  Modelos: {modelos_evaluar}\")\n",
        "    print(f\"  Configuraciones: {configs_evaluar}\")\n",
        "    print(f\"  Combinaciones: {len(modelos_evaluar) * len(configs_evaluar)}\")\n",
        "    print(f\"  Dataset: {ruta_imagenes}\")\n",
        "    print(f\"  Salida: {ruta_salida_base}\")\n",
        "    print(f\"  Checkpoints: {ruta_checkpoints}\")\n",
        "\n",
        "    # Crear evaluador\n",
        "    evaluador = EvaluadorSAM2(\n",
        "        ruta_imagenes=ruta_imagenes,\n",
        "        ruta_salida_base=ruta_salida_base,\n",
        "        ruta_checkpoints=ruta_checkpoints,\n",
        "        modelos_evaluar=modelos_evaluar,\n",
        "        configs_evaluar=configs_evaluar,\n",
        "        max_size=max_size,\n",
        "        generar_visualizaciones=generar_visualizaciones,\n",
        "        pausa_entre_imagenes=pausa_entre_imagenes\n",
        "    )\n",
        "\n",
        "    # Ejecutar\n",
        "    print(f\"\\nINICIANDO EVALUACION...\")\n",
        "    evaluador.ejecutar_evaluacion_completa()\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"EVALUACION FINALIZADA\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "print(\"Funcion main definida\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LISTO PARA EJECUTAR\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nPara iniciar la evaluacion, ejecuta:\")\n",
        "print(\">>> main()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xzh22VIGYMjQ",
        "outputId": "860d1320-8d52-4d0d-c085-eb71b38ffb4a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funcion main definida\n",
            "\n",
            "================================================================================\n",
            "LISTO PARA EJECUTAR\n",
            "================================================================================\n",
            "\n",
            "Para iniciar la evaluacion, ejecuta:\n",
            ">>> main()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TlaNK5QZNWp",
        "outputId": "d68b51c5-95dd-4ee3-89ed-cfe5cc106c27"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CONFIGURACION DEL EVALUADOR SAM 2.0\n",
            "================================================================================\n",
            "\n",
            "Validando configuracion...\n",
            "Configuracion validada\n",
            "\n",
            "RESUMEN:\n",
            "  Modelos: ['tiny', 'small', 'base_plus', 'large']\n",
            "  Configuraciones: ['low_cost', 'balanced', 'quality']\n",
            "  Combinaciones: 12\n",
            "  Dataset: /content/drive/MyDrive/TFM/0_Imagenes\n",
            "  Salida: /content/drive/MyDrive/TFM/2_Modelos/sam2\n",
            "  Checkpoints: /content/drive/MyDrive/TFM/2_Modelos/sam2/checkpoints\n",
            "\n",
            "INICIANDO EVALUACION...\n",
            "\n",
            "################################################################################\n",
            "INICIO DE EVALUACION SAM 2.0\n",
            "################################################################################\n",
            "\n",
            "Configuracion:\n",
            "  Modelos: ['tiny', 'small', 'base_plus', 'large']\n",
            "  Configuraciones: ['low_cost', 'balanced', 'quality']\n",
            "  Imagenes: /content/drive/MyDrive/TFM/0_Imagenes\n",
            "  Salida: /content/drive/MyDrive/TFM/2_Modelos/sam2\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 1/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: tiny_low_cost\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_tiny...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 3481.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 1951.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 1855.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 1\n",
            "  Tiempo: 1791.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 1818.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 1914.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 1679.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 16\n",
            "  Tiempo: 1947.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 1704.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 1681.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 1914.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 2027.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 1759.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 1783.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 1873.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 1764.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 1835.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 1833.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 2174.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 1892.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: tiny_low_cost\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 2/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: tiny_balanced\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_tiny...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 6888.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 6633.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 6498.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 6454.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 6597.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 6747.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 6541.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 6843.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 6480.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 6417.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 6434.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 7130.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 6732.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 6685.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 6810.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 25\n",
            "  Tiempo: 6592.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 22\n",
            "  Tiempo: 6712.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 6679.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 6865.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 6909.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: tiny_balanced\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 3/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: tiny_quality\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_tiny...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 11374.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 11239.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 11086.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 10677.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 11095.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 11388.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 10983.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 11368.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 10829.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 10811.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 10990.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 11752.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 10811.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 16\n",
            "  Tiempo: 10823.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 11227.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 37\n",
            "  Tiempo: 11118.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 32\n",
            "  Tiempo: 10812.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 10932.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 11301.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 10953.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: tiny_quality\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 4/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: small_low_cost\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_small...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 1898.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 1929.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 1905.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 1905.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 1904.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 1963.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 1735.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 2022.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 1799.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 1853.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 1\n",
            "  Tiempo: 1844.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 2202.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 1845.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 1949.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 2014.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 1923.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 2027.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 2014.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 1938.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 1940.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: small_low_cost\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 5/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: small_balanced\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_small...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 6822.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 6873.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 20\n",
            "  Tiempo: 6981.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 6840.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 6816.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 7141.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 6888.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 7071.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 6884.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 17\n",
            "  Tiempo: 6813.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 6672.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 7260.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 6742.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 6973.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 7166.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 27\n",
            "  Tiempo: 6983.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 27\n",
            "  Tiempo: 6984.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 6914.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 7003.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 6875.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: small_balanced\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 6/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: small_quality\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_small...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 11087.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 11269.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 24\n",
            "  Tiempo: 11393.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 10889.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 11190.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 11701.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 11211.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 23\n",
            "  Tiempo: 11344.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 11134.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 16\n",
            "  Tiempo: 11105.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 10903.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 12114.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 10976.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 11017.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 11206.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 40\n",
            "  Tiempo: 11088.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 32\n",
            "  Tiempo: 11276.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 11398.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 11407.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 11077.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: small_quality\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 7/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: base_plus_low_cost\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_base_plus...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 2062.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 2218.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 2069.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 2213.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 2019.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 2105.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 1868.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 2176.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 1996.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 1977.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 1981.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 2328.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 2025.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 2070.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 2087.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 2035.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 2157.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 2107.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 2200.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 2133.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: base_plus_low_cost\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 8/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: base_plus_balanced\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_base_plus...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 7541.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 7514.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 21\n",
            "  Tiempo: 7596.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 7587.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 7327.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 7533.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 17\n",
            "  Tiempo: 7368.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 26\n",
            "  Tiempo: 7578.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 7412.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 23\n",
            "  Tiempo: 7311.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 7305.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 7830.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 7390.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 7477.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 7528.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 30\n",
            "  Tiempo: 7519.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 37\n",
            "  Tiempo: 7498.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 7425.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 7676.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 5\n",
            "  Tiempo: 7528.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: base_plus_balanced\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 9/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: base_plus_quality\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_base_plus...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 11947.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 11998.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 11919.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 12023.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 22\n",
            "  Tiempo: 11754.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 11975.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 20\n",
            "  Tiempo: 11805.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 29\n",
            "  Tiempo: 12010.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 11824.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 25\n",
            "  Tiempo: 11606.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 11693.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 12762.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 11784.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 16\n",
            "  Tiempo: 11858.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 12164.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 50\n",
            "  Tiempo: 11927.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 53\n",
            "  Tiempo: 11936.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 11923.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 12181.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 11881.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: base_plus_quality\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 10/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: large_low_cost\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_large...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 2519.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 2420.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 2467.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 2\n",
            "  Tiempo: 2415.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 2611.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 2401.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 2306.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 2464.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 2290.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 2269.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 2334.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 6\n",
            "  Tiempo: 2686.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 2336.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 2601.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 2406.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 2603.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 2413.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 8\n",
            "  Tiempo: 2390.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 2450.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 3\n",
            "  Tiempo: 2469.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: large_low_cost\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 11/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: large_balanced\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_large...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 10\n",
            "  Tiempo: 9858.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 9689.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 25\n",
            "  Tiempo: 9365.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 9465.3 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 20\n",
            "  Tiempo: 9375.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 13\n",
            "  Tiempo: 9424.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 9321.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 24\n",
            "  Tiempo: 9511.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 9346.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 24\n",
            "  Tiempo: 9272.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 9390.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 9717.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 9335.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 9351.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 9367.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 42\n",
            "  Tiempo: 9347.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 36\n",
            "  Tiempo: 9384.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 17\n",
            "  Tiempo: 9614.6 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 9476.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 9456.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: large_balanced\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 12/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUANDO: large_quality\n",
            "================================================================================\n",
            "Imagenes ya completadas: 0\n",
            "Total imagenes: 20\n",
            "Pendientes: 20\n",
            "\n",
            "Inicializando procesador...\n",
            "Cargando modelo sam2_hiera_large...\n",
            "Modelo cargado correctamente\n",
            "\n",
            "Procesando 20 imagenes...\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Personas: 11\n",
            "  Tiempo: 13914.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Personas: 18\n",
            "  Tiempo: 14066.7 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Personas: 27\n",
            "  Tiempo: 13696.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 13786.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Personas: 29\n",
            "  Tiempo: 13670.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Personas: 14\n",
            "  Tiempo: 14082.4 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Personas: 20\n",
            "  Tiempo: 13687.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Personas: 30\n",
            "  Tiempo: 13913.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Personas: 12\n",
            "  Tiempo: 13539.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Personas: 26\n",
            "  Tiempo: 13498.9 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Personas: 9\n",
            "  Tiempo: 13827.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Personas: 7\n",
            "  Tiempo: 14372.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Personas: 23\n",
            "  Tiempo: 13920.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 13628.0 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 13888.2 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Personas: 52\n",
            "  Tiempo: 13593.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Personas: 46\n",
            "  Tiempo: 13752.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Personas: 19\n",
            "  Tiempo: 13659.1 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Personas: 15\n",
            "  Tiempo: 14149.8 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Personas: 4\n",
            "  Tiempo: 13761.5 ms\n",
            "  Checkpoint actualizado\n",
            "\n",
            "Liberando recursos...\n",
            "\n",
            "================================================================================\n",
            "COMBINACION COMPLETADA: large_quality\n",
            "================================================================================\n",
            "\n",
            "################################################################################\n",
            "EVALUACION COMPLETA FINALIZADA\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "EVALUACION FINALIZADA\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}