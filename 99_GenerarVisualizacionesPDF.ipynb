{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdC0MJqs76uYufmWCOwPmj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/99_GenerarVisualizacionesPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sistema de Generación de PDFs\n",
        "===================================================================\n",
        "\n",
        "Script completo listo para ejecutar en Google Colab que incluye:\n",
        "- Montaje automático de Google Drive\n",
        "- Instalación de dependencias\n",
        "- Detección automática de PDFs existentes\n",
        "- Sistema de checkpoints\n",
        "- Trazabilidad completa con TQDM\n",
        "\n",
        "Autor: Jesús L.\n",
        "Universidad: Universidad Oberta de Catalunya (UOC)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACIÓN INICIAL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"SISTEMA DE GENERACIÓN DE PDFs - TFM\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nPaso 1/4: Montando Google Drive...\")\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "print(\"✓ Google Drive montado correctamente\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# INSTALACIÓN DE DEPENDENCIAS\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Paso 2/4: Instalando dependencias...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "resultado = subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"img2pdf\", \"Pillow\", \"tqdm\"],\n",
        "    capture_output=True\n",
        ")\n",
        "\n",
        "if resultado.returncode == 0:\n",
        "    print(\"✓ Dependencias instaladas: img2pdf, Pillow, tqdm\\n\")\n",
        "else:\n",
        "    print(\"⚠ Error instalando dependencias\")\n",
        "    print(resultado.stderr.decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wwmIXK4eVk2",
        "outputId": "11a7b785-07ee-4cc6-9f7d-e1b0fb63a906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SISTEMA DE GENERACIÓN DE PDFs - TFM\n",
            "======================================================================\n",
            "\n",
            "Paso 1/4: Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "✓ Google Drive montado correctamente\n",
            "\n",
            "Paso 2/4: Instalando dependencias...\n",
            "✓ Dependencias instaladas: img2pdf, Pillow, tqdm\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CÓDIGO PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "print(\"Paso 3/4: Cargando módulos...\\n\")\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import re\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Set, Tuple, Optional\n",
        "\n",
        "try:\n",
        "    import img2pdf\n",
        "    from tqdm.auto import tqdm\n",
        "except ImportError as e:\n",
        "    print(f\"ERROR: No se pudieron importar dependencias: {e}\")\n",
        "    print(\"Ejecute: !pip install img2pdf Pillow tqdm\")\n",
        "    raise\n",
        "\n",
        "# Configuración de logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YKkjKlneeTE",
        "outputId": "2446cf03-ec4f-4345-b93b-d07508d1c456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paso 3/4: Cargando módulos...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlphaWarningCounter(logging.Handler):\n",
        "    \"\"\"Handler para contar warnings de alpha channel de img2pdf.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.count = 0\n",
        "\n",
        "    def emit(self, record):\n",
        "        if 'alpha' in record.getMessage().lower():\n",
        "            self.count += 1\n",
        "\n",
        "\n",
        "class GeneradorPDFVisualizaciones:\n",
        "    \"\"\"\n",
        "    Generador de PDFs con detección automática de progreso y checkpoints.\n",
        "\n",
        "    Características:\n",
        "    - Detecta PDFs ya existentes (no los regenera)\n",
        "    - Guarda checkpoint cada 5 PDFs\n",
        "    - Continúa automáticamente si se interrumpe\n",
        "    - Trazabilidad completa con TQDM\n",
        "    \"\"\"\n",
        "\n",
        "    PATRON_UMBRAL_DECIMAL = re.compile(r'_t0[._]\\d+$')\n",
        "    PATRON_SENSIBILIDAD_ESPECIFICA = re.compile(\n",
        "        r'_(baja|media|alta|maxima)_sensibilidad_t0[._]\\d+$'\n",
        "    )\n",
        "    EXTENSIONES_VALIDAS = {'.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG'}\n",
        "    CHECKPOINT_INTERVALO = 5\n",
        "\n",
        "    def __init__(self, ruta_indice: str, directorio_salida: str) -> None:\n",
        "        \"\"\"Inicializa el generador con detección de PDFs existentes.\"\"\"\n",
        "        self.ruta_indice = Path(ruta_indice)\n",
        "        self.directorio_salida = Path(directorio_salida)\n",
        "        self.checkpoint_file = self.directorio_salida / '.checkpoint.pkl'\n",
        "\n",
        "        if not self.ruta_indice.exists():\n",
        "            raise FileNotFoundError(f\"Índice maestro no encontrado: {self.ruta_indice}\")\n",
        "\n",
        "        self.directorio_salida.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        self.indice_maestro: Optional[Dict] = None\n",
        "        self.agrupaciones: defaultdict = defaultdict(list)\n",
        "\n",
        "        self.estadisticas = {\n",
        "            'visualizaciones_omitidas': 0,\n",
        "            'archivos_no_encontrados': 0,\n",
        "            'extensiones_invalidas': 0,\n",
        "            'alpha_warnings': 0,\n",
        "            'pdfs_generados': 0,\n",
        "            'errores': 0,\n",
        "            'total_imagenes_procesadas': 0\n",
        "        }\n",
        "\n",
        "        # Configurar contador de alpha warnings\n",
        "        self.alpha_counter = AlphaWarningCounter()\n",
        "        self.alpha_counter.setLevel(logging.WARNING)\n",
        "        img2pdf_logger = logging.getLogger('img2pdf')\n",
        "        img2pdf_logger.addHandler(self.alpha_counter)\n",
        "\n",
        "        # Cargar checkpoint O detectar PDFs existentes\n",
        "        self.configs_completadas = self._cargar_o_detectar_progreso()\n",
        "\n",
        "        logger.info(\"Inicializado GeneradorPDFVisualizaciones v1.2.1\")\n",
        "        logger.info(f\"  Índice: {self.ruta_indice}\")\n",
        "        logger.info(f\"  Salida: {self.directorio_salida}\")\n",
        "        if self.configs_completadas:\n",
        "            logger.info(f\"  PDFs detectados: {len(self.configs_completadas)}\")\n",
        "\n",
        "    def _cargar_o_detectar_progreso(self) -> Set[str]:\n",
        "        \"\"\"\n",
        "        Carga checkpoint O detecta PDFs existentes en el directorio.\n",
        "\n",
        "        Permite continuar sin perder progreso de ejecuciones previas.\n",
        "        \"\"\"\n",
        "        # Intentar cargar checkpoint\n",
        "        if self.checkpoint_file.exists():\n",
        "            try:\n",
        "                with open(self.checkpoint_file, 'rb') as f:\n",
        "                    checkpoint_data = pickle.load(f)\n",
        "                    if isinstance(checkpoint_data, set):\n",
        "                        logger.info(\"✓ Checkpoint encontrado\")\n",
        "                        return checkpoint_data\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Checkpoint corrupto: {e}\")\n",
        "\n",
        "        # Si no hay checkpoint, detectar PDFs existentes\n",
        "        logger.info(\"Detectando PDFs existentes en directorio...\")\n",
        "        pdfs_existentes = set()\n",
        "\n",
        "        try:\n",
        "            for pdf_file in self.directorio_salida.glob('*.pdf'):\n",
        "                config_name = pdf_file.stem\n",
        "                pdfs_existentes.add(config_name)\n",
        "\n",
        "            if pdfs_existentes:\n",
        "                logger.info(f\"✓ Detectados {len(pdfs_existentes)} PDFs existentes\")\n",
        "                logger.info(\"  Estos NO serán regenerados\")\n",
        "                self._guardar_checkpoint_inicial(pdfs_existentes)\n",
        "            else:\n",
        "                logger.info(\"  No se encontraron PDFs previos\")\n",
        "\n",
        "            return pdfs_existentes\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error detectando PDFs: {e}\")\n",
        "            return set()\n",
        "\n",
        "    def _guardar_checkpoint_inicial(self, configs: Set[str]) -> None:\n",
        "        \"\"\"Guarda checkpoint inicial con PDFs detectados.\"\"\"\n",
        "        try:\n",
        "            with open(self.checkpoint_file, 'wb') as f:\n",
        "                pickle.dump(configs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "            logger.info(\"✓ Checkpoint inicial creado\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"No se pudo crear checkpoint: {e}\")\n",
        "\n",
        "    def _guardar_checkpoint(self) -> None:\n",
        "        \"\"\"Guarda checkpoint periódicamente.\"\"\"\n",
        "        try:\n",
        "            with open(self.checkpoint_file, 'wb') as f:\n",
        "                pickle.dump(self.configs_completadas, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error guardando checkpoint: {e}\")\n",
        "\n",
        "    def _eliminar_checkpoint(self) -> None:\n",
        "        \"\"\"Elimina checkpoint al finalizar.\"\"\"\n",
        "        if self.checkpoint_file.exists():\n",
        "            try:\n",
        "                self.checkpoint_file.unlink()\n",
        "                logger.info(\"✓ Checkpoint eliminado (proceso completado)\")\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error eliminando checkpoint: {e}\")\n",
        "\n",
        "    def cargar_indice(self) -> None:\n",
        "        \"\"\"Carga el índice maestro desde JSON.\"\"\"\n",
        "        logger.info(\"Cargando índice maestro...\")\n",
        "        with open(self.ruta_indice, 'r', encoding='utf-8') as archivo:\n",
        "            self.indice_maestro = json.load(archivo)\n",
        "        logger.info(f\"✓ Índice cargado: {len(self.indice_maestro)} fotografías\")\n",
        "\n",
        "    def normalizar_codigo_config(self, codigo_config: str) -> str:\n",
        "        \"\"\"Normaliza códigos de configuración eliminando umbrales.\"\"\"\n",
        "        match_sensibilidad = self.PATRON_SENSIBILIDAD_ESPECIFICA.search(codigo_config)\n",
        "        if match_sensibilidad:\n",
        "            return self.PATRON_UMBRAL_DECIMAL.sub('', codigo_config)\n",
        "        match_umbral = self.PATRON_UMBRAL_DECIMAL.search(codigo_config)\n",
        "        if match_umbral:\n",
        "            return self.PATRON_UMBRAL_DECIMAL.sub('', codigo_config)\n",
        "        return codigo_config\n",
        "\n",
        "    def extraer_configuraciones(self) -> Set[str]:\n",
        "        \"\"\"Extrae y valida configuraciones del índice con barra de progreso.\"\"\"\n",
        "        logger.info(\"Extrayendo configuraciones...\")\n",
        "        configuraciones_encontradas: Set[str] = set()\n",
        "        visualizaciones_procesadas = 0\n",
        "\n",
        "        pbar_fotos = tqdm(\n",
        "            self.indice_maestro.items(),\n",
        "            desc=\"Escaneando fotografías\",\n",
        "            unit=\"foto\",\n",
        "            total=len(self.indice_maestro),\n",
        "            ncols=100\n",
        "        )\n",
        "\n",
        "        for foto_id, datos_foto in pbar_fotos:\n",
        "            modelos_disponibles = datos_foto.get('modelos_disponibles', {})\n",
        "\n",
        "            for codigo_config, info_modelo in modelos_disponibles.items():\n",
        "                ruta_viz = info_modelo.get('ruta_visualizacion')\n",
        "\n",
        "                if not ruta_viz:\n",
        "                    self.estadisticas['visualizaciones_omitidas'] += 1\n",
        "                    continue\n",
        "\n",
        "                ruta_viz_path = Path(ruta_viz)\n",
        "                if not ruta_viz_path.exists():\n",
        "                    self.estadisticas['archivos_no_encontrados'] += 1\n",
        "                    continue\n",
        "\n",
        "                if ruta_viz_path.suffix not in self.EXTENSIONES_VALIDAS:\n",
        "                    self.estadisticas['extensiones_invalidas'] += 1\n",
        "                    continue\n",
        "\n",
        "                config_normalizado = self.normalizar_codigo_config(codigo_config)\n",
        "                self.agrupaciones[config_normalizado].append((foto_id, str(ruta_viz_path)))\n",
        "                configuraciones_encontradas.add(config_normalizado)\n",
        "                visualizaciones_procesadas += 1\n",
        "\n",
        "            pbar_fotos.set_postfix({\n",
        "                'configs': len(configuraciones_encontradas),\n",
        "                'viz': visualizaciones_procesadas\n",
        "            })\n",
        "\n",
        "        pbar_fotos.close()\n",
        "\n",
        "        logger.info(f\"✓ Configuraciones: {len(configuraciones_encontradas)}\")\n",
        "        logger.info(f\"✓ Visualizaciones válidas: {visualizaciones_procesadas}\")\n",
        "\n",
        "        if self.estadisticas['visualizaciones_omitidas'] > 0:\n",
        "            logger.warning(f\"⚠ Sin ruta: {self.estadisticas['visualizaciones_omitidas']}\")\n",
        "\n",
        "        return configuraciones_encontradas\n",
        "\n",
        "    def ordenar_visualizaciones(self, visualizaciones: List[Tuple[str, str]]) -> List[str]:\n",
        "        \"\"\"Ordena visualizaciones alfabéticamente por foto_id.\"\"\"\n",
        "        visualizaciones_ordenadas = sorted(visualizaciones, key=lambda tupla: tupla[0])\n",
        "        return [ruta for _, ruta in visualizaciones_ordenadas]\n",
        "\n",
        "    def generar_pdf(\n",
        "        self,\n",
        "        config_normalizado: str,\n",
        "        rutas_imagenes: List[str],\n",
        "        pbar: Optional[tqdm] = None\n",
        "    ) -> Path:\n",
        "        \"\"\"Genera un PDF consolidado a partir de imágenes.\"\"\"\n",
        "        nombre_pdf = f\"{config_normalizado}.pdf\"\n",
        "        ruta_pdf = self.directorio_salida / nombre_pdf\n",
        "\n",
        "        if pbar:\n",
        "            pbar.set_description(f\"PDF: {nombre_pdf[:45]}\")\n",
        "\n",
        "        try:\n",
        "            count_before = self.alpha_counter.count\n",
        "            pdf_bytes = img2pdf.convert(rutas_imagenes)\n",
        "            count_after = self.alpha_counter.count\n",
        "\n",
        "            alpha_warnings_este_pdf = count_after - count_before\n",
        "            if alpha_warnings_este_pdf > 0:\n",
        "                self.estadisticas['alpha_warnings'] += alpha_warnings_este_pdf\n",
        "\n",
        "            with open(ruta_pdf, 'wb') as archivo_pdf:\n",
        "                archivo_pdf.write(pdf_bytes)\n",
        "\n",
        "            tamanio_mb = ruta_pdf.stat().st_size / (1024 * 1024)\n",
        "            self.estadisticas['pdfs_generados'] += 1\n",
        "            self.estadisticas['total_imagenes_procesadas'] += len(rutas_imagenes)\n",
        "\n",
        "            if pbar:\n",
        "                pbar.set_postfix({\n",
        "                    'MB': f'{tamanio_mb:.1f}',\n",
        "                    'imgs': len(rutas_imagenes),\n",
        "                    'alpha': self.estadisticas['alpha_warnings']\n",
        "                })\n",
        "\n",
        "            return ruta_pdf\n",
        "\n",
        "        except Exception as error:\n",
        "            self.estadisticas['errores'] += 1\n",
        "            logger.error(f\"Error en {nombre_pdf}: {error}\")\n",
        "            raise\n",
        "\n",
        "    def generar_todos_los_pdfs(self, forzar_reinicio: bool = False) -> Dict[str, Path]:\n",
        "        \"\"\"\n",
        "        Genera todos los PDFs pendientes con checkpoints.\n",
        "\n",
        "        Args:\n",
        "            forzar_reinicio: Si True, ignora PDFs existentes y empieza desde cero\n",
        "        \"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"GENERACIÓN DE PDFs CON AUTO-DETECCIÓN Y CHECKPOINTS\")\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "        if forzar_reinicio:\n",
        "            if self.checkpoint_file.exists():\n",
        "                self._eliminar_checkpoint()\n",
        "            self.configs_completadas = set()\n",
        "            logger.info(\"⚠ Reinicio forzado: ignorando PDFs existentes\")\n",
        "\n",
        "        self.cargar_indice()\n",
        "        configuraciones = self.extraer_configuraciones()\n",
        "\n",
        "        if not configuraciones:\n",
        "            logger.error(\"✗ No se encontraron configuraciones\")\n",
        "            return {}\n",
        "\n",
        "        configs_pendientes = sorted(configuraciones - self.configs_completadas)\n",
        "\n",
        "        if not configs_pendientes:\n",
        "            print(\"\\n\" + \"=\" * 70)\n",
        "            print(\"¡TODAS LAS CONFIGURACIONES YA ESTÁN COMPLETAS!\")\n",
        "            print(\"=\" * 70)\n",
        "            print(f\"\\nTotal: {len(configuraciones)} PDFs\")\n",
        "            print(f\"Ubicación: {self.directorio_salida}\")\n",
        "            self._eliminar_checkpoint()\n",
        "            return {}\n",
        "\n",
        "        print(f\"CONFIGURACIÓN DEL PROCESO:\")\n",
        "        print(f\"  Total configuraciones:     {len(configuraciones):>4}\")\n",
        "        print(f\"  Ya completadas (previas):  {len(self.configs_completadas):>4}\")\n",
        "        print(f\"  Pendientes por generar:    {len(configs_pendientes):>4}\")\n",
        "        print(f\"  Checkpoint cada:           {self.CHECKPOINT_INTERVALO:>4} PDFs\")\n",
        "        print()\n",
        "\n",
        "        pdfs_generados: Dict[str, Path] = {}\n",
        "        errores: List[Tuple[str, str]] = []\n",
        "\n",
        "        pbar_pdfs = tqdm(\n",
        "            configs_pendientes,\n",
        "            desc=\"Generando PDFs\",\n",
        "            unit=\"PDF\",\n",
        "            ncols=100,\n",
        "            colour='green',\n",
        "            initial=len(self.configs_completadas),\n",
        "            total=len(configuraciones)\n",
        "        )\n",
        "\n",
        "        contador_desde_checkpoint = 0\n",
        "\n",
        "        for config in pbar_pdfs:\n",
        "            try:\n",
        "                visualizaciones = self.agrupaciones[config]\n",
        "                rutas_ordenadas = self.ordenar_visualizaciones(visualizaciones)\n",
        "\n",
        "                ruta_pdf = self.generar_pdf(config, rutas_ordenadas, pbar=pbar_pdfs)\n",
        "                pdfs_generados[config] = ruta_pdf\n",
        "                self.configs_completadas.add(config)\n",
        "\n",
        "                contador_desde_checkpoint += 1\n",
        "\n",
        "                if contador_desde_checkpoint >= self.CHECKPOINT_INTERVALO:\n",
        "                    self._guardar_checkpoint()\n",
        "                    contador_desde_checkpoint = 0\n",
        "\n",
        "            except Exception as error:\n",
        "                errores.append((config, str(error)))\n",
        "                continue\n",
        "\n",
        "        pbar_pdfs.close()\n",
        "\n",
        "        if contador_desde_checkpoint > 0:\n",
        "            self._guardar_checkpoint()\n",
        "\n",
        "        if len(self.configs_completadas) >= len(configuraciones):\n",
        "            self._eliminar_checkpoint()\n",
        "\n",
        "        self._mostrar_resumen(pdfs_generados, errores, len(configuraciones))\n",
        "\n",
        "        return pdfs_generados\n",
        "\n",
        "    def _mostrar_resumen(\n",
        "        self,\n",
        "        pdfs_generados: Dict[str, Path],\n",
        "        errores: List[Tuple[str, str]],\n",
        "        total_configs: int\n",
        "    ) -> None:\n",
        "        \"\"\"Muestra resumen detallado del proceso.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"RESUMEN DE GENERACIÓN\")\n",
        "        print(\"=\" * 70 + \"\\n\")\n",
        "\n",
        "        print(\"ESTADÍSTICAS:\")\n",
        "        print(\"-\" * 70)\n",
        "        print(f\"  Total configuraciones:           {total_configs:>6}\")\n",
        "        print(f\"  PDFs ya existentes (previos):    {len(self.configs_completadas) - len(pdfs_generados):>6}\")\n",
        "        print(f\"  PDFs generados esta sesión:      {len(pdfs_generados):>6}\")\n",
        "        print(f\"  PDFs totales completados:        {len(self.configs_completadas):>6}\")\n",
        "        print(f\"  Imágenes procesadas (sesión):    {self.estadisticas['total_imagenes_procesadas']:>6}\")\n",
        "        print(f\"  Errores durante generación:      {len(errores):>6}\")\n",
        "        print(f\"  Warnings de canal alpha:         {self.estadisticas['alpha_warnings']:>6}\")\n",
        "\n",
        "        if pdfs_generados:\n",
        "            tamanio_total_mb = sum(\n",
        "                pdf.stat().st_size for pdf in pdfs_generados.values()\n",
        "            ) / (1024 * 1024)\n",
        "            print(f\"  Tamaño generado (sesión):        {tamanio_total_mb:>6.2f} MB\")\n",
        "\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        if errores:\n",
        "            print(f\"\\nERRORES DETECTADOS ({len(errores)}):\")\n",
        "            for config, error in errores[:5]:\n",
        "                print(f\"  - {config}: {error[:60]}...\")\n",
        "            if len(errores) > 5:\n",
        "                print(f\"  ... y {len(errores) - 5} errores más\")\n",
        "\n",
        "        if self.estadisticas['alpha_warnings'] > 0:\n",
        "            print(f\"\\nNOTA: {self.estadisticas['alpha_warnings']} imágenes con canal alpha procesadas.\")\n",
        "            print(\"      (Normal en PNGs con transparencia)\")\n",
        "\n",
        "        pendientes = total_configs - len(self.configs_completadas)\n",
        "        if pendientes > 0:\n",
        "            print(f\"\\n⚠ QUEDAN {pendientes} CONFIGURACIONES PENDIENTES\")\n",
        "            print(\"  Ejecute nuevamente esta celda para continuar\")\n",
        "        else:\n",
        "            print(\"\\n✓ ¡PROCESO COMPLETADO EXITOSAMENTE!\")\n",
        "            print(f\"  Ubicación: {self.directorio_salida}\")\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 70 + \"\\n\")\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# CELDA 4: EJECUCIÓN PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def main(forzar_reinicio: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Función principal para ejecutar la generación.\n",
        "\n",
        "    Args:\n",
        "        forzar_reinicio: Si True, ignora checkpoint y PDFs existentes\n",
        "    \"\"\"\n",
        "    print(\"Paso 4/4: Iniciando generación de PDFs...\\n\")\n",
        "\n",
        "    # Configuración de rutas del TFM\n",
        "    RUTA_INDICE = \"/content/drive/MyDrive/TFM/3_Analisis/fase1_integracion/indice_maestro.json\"\n",
        "    RUTA_SALIDA = \"/content/drive/MyDrive/TFM/3_Analisis/00_Visualizaciones\"\n",
        "\n",
        "    try:\n",
        "        generador = GeneradorPDFVisualizaciones(\n",
        "            ruta_indice=RUTA_INDICE,\n",
        "            directorio_salida=RUTA_SALIDA\n",
        "        )\n",
        "\n",
        "        pdfs_generados = generador.generar_todos_los_pdfs(forzar_reinicio=forzar_reinicio)\n",
        "\n",
        "        if pdfs_generados:\n",
        "            print(f\"✓ Sesión completada: {len(pdfs_generados)} PDFs nuevos generados\\n\")\n",
        "\n",
        "    except FileNotFoundError as error:\n",
        "        print(f\"\\n✗ ERROR: Archivo no encontrado\")\n",
        "        print(f\"  {error}\")\n",
        "        print(f\"\\nVerifique que las rutas sean correctas:\")\n",
        "        print(f\"  Índice: {RUTA_INDICE}\")\n",
        "        print(f\"  Salida: {RUTA_SALIDA}\")\n",
        "        raise\n",
        "\n",
        "    except Exception as error:\n",
        "        print(f\"\\n✗ ERROR INESPERADO: {error}\")\n",
        "        logger.exception(\"Traceback completo:\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# EJECUCIÓN\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ejecutar generación\n",
        "    # Para reiniciar desde cero: main(forzar_reinicio=True)\n",
        "    main()"
      ],
      "metadata": {
        "id": "-9NC4SC9eQWs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}