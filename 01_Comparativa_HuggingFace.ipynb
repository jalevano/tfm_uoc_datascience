{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAPzZ5n6CuTtxULpH25MxV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/01_Comparativa_HuggingFace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n_9cjv7sAb2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "85d865e0-d2fd-4469-db1e-2f99d721b7be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEVALUACIÓN COMPARATIVA. Mask2former vs OneFormer para Segmentación de personas.\\n\\nSe proporcionar análisis detallado de las ventajas de la segmentación panóptica\\ncon OneFormer frente segmentación de instancias tradicional.\\n\\nConceptos clave:\\n- Segmentación panóptica: Segmentación semántica e instancias\\n- Comparación arquitectónica: Transformer-based models estado del arte\\n- Evaluación académica: Métricas comprehensivas.\\n\\nAutor: Jesús L.\\nTrabajo: Evaluación comparativa de técnicas de segmentación.\\nFecha: Agosto 2025.\\n\\nReferencias Técnicas:\\n- Cheng et al. \"Masked-attention Mask Transformer for Universal Image Segmentation\" (Mask2Former)\\n- Jain et al. \"OneFormer: One Transformer to Rule Universal Image Segmentation\" (OneFormer)\\n- Kirillov et al. \"Panoptic Segmentation\" (Conceptos fundamentales)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "EVALUACIÓN COMPARATIVA. Mask2former vs OneFormer para Segmentación de personas.\n",
        "\n",
        "Se proporcionar análisis detallado de las ventajas de la segmentación panóptica\n",
        "con OneFormer frente segmentación de instancias tradicional.\n",
        "\n",
        "Conceptos clave:\n",
        "- Segmentación panóptica: Segmentación semántica e instancias\n",
        "- Comparación arquitectónica: Transformer-based models estado del arte\n",
        "- Evaluación académica: Métricas comprehensivas.\n",
        "\n",
        "Autor: Jesús L.\n",
        "Trabajo: Evaluación comparativa de técnicas de segmentación.\n",
        "Fecha: Agosto 2025.\n",
        "\n",
        "Referencias Técnicas:\n",
        "- Cheng et al. \"Masked-attention Mask Transformer for Universal Image Segmentation\" (Mask2Former)\n",
        "- Jain et al. \"OneFormer: One Transformer to Rule Universal Image Segmentation\" (OneFormer)\n",
        "- Kirillov et al. \"Panoptic Segmentation\" (Conceptos fundamentales)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZpmxzbqbfaH",
        "outputId": "81fa10a6-d8a5-4549-eff8-a2633a1eb594"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.8.1-py3-none-any.whl (982 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Optional, Tuple, Union, Literal\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import json\n",
        "import cv2\n",
        "from datetime import datetime\n",
        "import traceback\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "7gf3kDfrarKW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importaciones específicas de Hugging Face para ambos modelos\n",
        "from transformers import (\n",
        "    # Mask2Former components\n",
        "    Mask2FormerImageProcessor,\n",
        "    Mask2FormerForUniversalSegmentation,\n",
        "    # OneFormer components\n",
        "    OneFormerImageProcessor,\n",
        "    OneFormerForUniversalSegmentation,\n",
        "    # Generic auto-loading\n",
        "    AutoImageProcessor,\n",
        "    AutoModelForUniversalSegmentation\n",
        ")"
      ],
      "metadata": {
        "id": "n7kcXJnNa2yF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas y utilidades para evaluación\n",
        "from sklearn.metrics import precision_recall_fscore_support, jaccard_score\n",
        "import torchmetrics\n",
        "from torchmetrics.segmentation import MeanIoU, DiceScore\n",
        "from torchmetrics.classification import BinaryJaccardIndex"
      ],
      "metadata": {
        "id": "GQCmYcrVbHVB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilidades para procesamiento y visualización\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)"
      ],
      "metadata": {
        "id": "mKVmEPAScHhE"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}