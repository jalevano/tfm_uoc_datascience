{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOA0itiBEzOcu7VsAjbtIH8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/04_bodypix_evaluador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "p-wfdH7po3K_",
        "outputId": "de03e26b-d905-4e23-d8d2-465349a0b864"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nEVALUADOR BODYPIX - NOTEBOOK 2\\n================================================================================\\nSistema de evaluacion para modelos BodyPix con estructura estandarizada\\npara comparacion de modelos de segmentacion de personas en fotografia de retrato.\\n\\nCARACTERISTICAS PRINCIPALES:\\n- Procesamiento incremental con sistema de checkpoint robusto\\n- Gestion optima de memoria para Google Colab gratuito\\n- Guardado automatico despues de cada imagen procesada\\n- 3 modelos MobileNetV1 con multiplicadores 0.50, 0.75, 1.00\\n- 4 configuraciones de umbral de segmentacion\\n- Almacenamiento NPZ por fotografia con mascaras de probabilidad completas\\n- Segmentacion de partes del cuerpo (caracteristica unica de BodyPix)\\n- JSON ligero con metricas de rendimiento por umbral\\n- Visualizaciones estandarizadas\\n\\nMODELOS DISPONIBLES:\\n1. MobileNetV1 0.50: Arquitectura ligera optimizada para velocidad\\n2. MobileNetV1 0.75: Balance entre velocidad y calidad de segmentacion\\n3. MobileNetV1 1.00: Maxima calidad de segmentacion disponible\\n\\nCONFIGURACIONES DE UMBRAL:\\nLas configuraciones evaluan multiples umbrales de segmentacion para analizar\\nla sensibilidad del modelo a diferentes niveles de confianza:\\n\\n1. ultra_sensible: [0.3, 0.4, 0.5] - Maxima deteccion de pixels\\n2. sensibilidad_alta: [0.4, 0.5, 0.6] - Alta sensibilidad\\n3. sensibilidad_media: [0.5, 0.65, 0.8] - Balance precision-recall\\n4. baja_sensibilidad: [0.7, 0.8, 0.9] - Alta confianza\\n\\nALMACENAMIENTO NPZ (por fotografia):\\nBodyPix genera mascaras de segmentacion continuas (valores 0-1) que representan\\nla probabilidad de que cada pixel pertenezca a una persona, y adicionalmente\\npuede segmentar partes del cuerpo. Se almacena:\\n\\nInformacion de segmentacion de persona:\\n- mascara_probabilidad: Array (H, W) con valores 0.0-1.0 continuos\\n- mascaras_binarias_por_umbral: Dict con mascaras binarias para cada umbral\\n- dimensiones: Shape de la imagen procesada\\n- modelo_info: Metadatos del modelo usado\\n\\nInformacion de partes del cuerpo (CARACTERISTICA UNICA de BodyPix):\\n- mascara_partes: Array (H, W) con IDs de partes 0-23, o -1 para fondo\\n- grupo_cara: Mascara binaria agrupada de cara\\n- grupo_torso: Mascara binaria agrupada de torso\\n- grupo_brazos: Mascara binaria agrupada de brazos\\n- grupo_manos: Mascara binaria agrupada de manos\\n- grupo_piernas: Mascara binaria agrupada de piernas\\n- grupo_pies: Mascara binaria agrupada de pies\\n\\nNOTA SOBRE PARTES DEL CUERPO:\\nLa segmentacion de partes del cuerpo es una caracteristica UNICA de BodyPix\\nque ningun otro modelo del TFM proporciona. Se almacena de forma LIGERA:\\n- La mascara de partes es int8 (mismo tamaño que la imagen)\\n- Se pre-calculan 6 grupos semanticos para fotografia de retrato\\n- Incremento de tamaño: ~7% adicional en NPZ comprimido\\n- Valor para el TFM: Permite analisis especificos de composicion de retratos\\n\\nDIFERENCIAS CON OTROS MODELOS:\\nA diferencia de modelos de deteccion de instancias (YOLO, Mask2Former) o\\ngeneracion automatica (SAM2), BodyPix es un modelo de segmentacion semantica\\nque genera una unica mascara de probabilidad por imagen. No detecta instancias\\nindividuales ni proporciona bounding boxes nativamente.\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/2_Modelos/bodypix/{modelo}/{config}/resultados/\\n├── json/                           # Metricas por fotografia y umbral\\n├── mascaras/                       # NPZ con mascaras de probabilidad y partes\\n├── visualizaciones/                # Visualizaciones por fotografia\\n└── checkpoint.json                 # Estado del procesamiento\\n\\nEntrada: Imagenes desde /TFM/0_Imagenes/\\nSalida: JSON, mascaras NPZ y visualizaciones en estructura organizada\\n\\nReferencias:\\n- Papandreou et al. (2018) \"PersonLab: Person Pose Estimation and Instance \\n  Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model\"\\n- TensorFlow.js BodyPix: https://github.com/tensorflow/tfjs-models/tree/master/body-pix\\n\\nAutor: Jesus L.\\nProyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\\nUniversidad: Universidad Oberta de Cataluna (UOC)\\nFecha: Octubre 2025\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "EVALUADOR BODYPIX - NOTEBOOK 2\n",
        "================================================================================\n",
        "Sistema de evaluacion para modelos BodyPix con estructura estandarizada\n",
        "para comparacion de modelos de segmentacion de personas en fotografia de retrato.\n",
        "\n",
        "CARACTERISTICAS PRINCIPALES:\n",
        "- Procesamiento incremental con sistema de checkpoint robusto\n",
        "- Gestion optima de memoria para Google Colab gratuito\n",
        "- Guardado automatico despues de cada imagen procesada\n",
        "- 3 modelos MobileNetV1 con multiplicadores 0.50, 0.75, 1.00\n",
        "- 4 configuraciones de umbral de segmentacion\n",
        "- Almacenamiento NPZ por fotografia con mascaras de probabilidad completas\n",
        "- Segmentacion de partes del cuerpo (caracteristica unica de BodyPix)\n",
        "- JSON ligero con metricas de rendimiento por umbral\n",
        "- Visualizaciones estandarizadas\n",
        "\n",
        "MODELOS DISPONIBLES:\n",
        "1. MobileNetV1 0.50: Arquitectura ligera optimizada para velocidad\n",
        "2. MobileNetV1 0.75: Balance entre velocidad y calidad de segmentacion\n",
        "3. MobileNetV1 1.00: Maxima calidad de segmentacion disponible\n",
        "\n",
        "CONFIGURACIONES DE UMBRAL:\n",
        "Las configuraciones evaluan multiples umbrales de segmentacion para analizar\n",
        "la sensibilidad del modelo a diferentes niveles de confianza:\n",
        "\n",
        "1. ultra_sensible: [0.3, 0.4, 0.5] - Maxima deteccion de pixels\n",
        "2. sensibilidad_alta: [0.4, 0.5, 0.6] - Alta sensibilidad\n",
        "3. sensibilidad_media: [0.5, 0.65, 0.8] - Balance precision-recall\n",
        "4. baja_sensibilidad: [0.7, 0.8, 0.9] - Alta confianza\n",
        "\n",
        "ALMACENAMIENTO NPZ (por fotografia):\n",
        "BodyPix genera mascaras de segmentacion continuas (valores 0-1) que representan\n",
        "la probabilidad de que cada pixel pertenezca a una persona, y adicionalmente\n",
        "puede segmentar partes del cuerpo. Se almacena:\n",
        "\n",
        "Informacion de segmentacion de persona:\n",
        "- mascara_probabilidad: Array (H, W) con valores 0.0-1.0 continuos\n",
        "- mascaras_binarias_por_umbral: Dict con mascaras binarias para cada umbral\n",
        "- dimensiones: Shape de la imagen procesada\n",
        "- modelo_info: Metadatos del modelo usado\n",
        "\n",
        "Informacion de partes del cuerpo (CARACTERISTICA UNICA de BodyPix):\n",
        "- mascara_partes: Array (H, W) con IDs de partes 0-23, o -1 para fondo\n",
        "- grupo_cara: Mascara binaria agrupada de cara\n",
        "- grupo_torso: Mascara binaria agrupada de torso\n",
        "- grupo_brazos: Mascara binaria agrupada de brazos\n",
        "- grupo_manos: Mascara binaria agrupada de manos\n",
        "- grupo_piernas: Mascara binaria agrupada de piernas\n",
        "- grupo_pies: Mascara binaria agrupada de pies\n",
        "\n",
        "NOTA SOBRE PARTES DEL CUERPO:\n",
        "La segmentacion de partes del cuerpo es una caracteristica UNICA de BodyPix\n",
        "que ningun otro modelo del TFM proporciona. Se almacena de forma LIGERA:\n",
        "- La mascara de partes es int8 (mismo tamaño que la imagen)\n",
        "- Se pre-calculan 6 grupos semanticos para fotografia de retrato\n",
        "- Incremento de tamaño: ~7% adicional en NPZ comprimido\n",
        "- Valor para el TFM: Permite analisis especificos de composicion de retratos\n",
        "\n",
        "DIFERENCIAS CON OTROS MODELOS:\n",
        "A diferencia de modelos de deteccion de instancias (YOLO, Mask2Former) o\n",
        "generacion automatica (SAM2), BodyPix es un modelo de segmentacion semantica\n",
        "que genera una unica mascara de probabilidad por imagen. No detecta instancias\n",
        "individuales ni proporciona bounding boxes nativamente.\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/2_Modelos/bodypix/{modelo}/{config}/resultados/\n",
        "├── json/                           # Metricas por fotografia y umbral\n",
        "├── mascaras/                       # NPZ con mascaras de probabilidad y partes\n",
        "├── visualizaciones/                # Visualizaciones por fotografia\n",
        "└── checkpoint.json                 # Estado del procesamiento\n",
        "\n",
        "Entrada: Imagenes desde /TFM/0_Imagenes/\n",
        "Salida: JSON, mascaras NPZ y visualizaciones en estructura organizada\n",
        "\n",
        "Referencias:\n",
        "- Papandreou et al. (2018) \"PersonLab: Person Pose Estimation and Instance\n",
        "  Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model\"\n",
        "- TensorFlow.js BodyPix: https://github.com/tensorflow/tfjs-models/tree/master/body-pix\n",
        "\n",
        "Autor: Jesus L.\n",
        "Proyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "Universidad: Universidad Oberta de Cataluna (UOC)\n",
        "Fecha: Octubre 2025\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# INSTALACION DE DEPENDENCIAS (EJECUTAR EN COLAB)\n",
        "# =============================================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INSTALANDO DEPENDENCIAS BODYPIX\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Orden correcto de instalacion para evitar conflictos\n",
        "print(\"\\n[1/5] Actualizando packaging...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"packaging>=24.2.0\"])\n",
        "\n",
        "print(\"[2/5] Instalando TensorFlow...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tensorflow\"])\n",
        "\n",
        "print(\"[3/5] Instalando tfjs-graph-converter...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tfjs-graph-converter\"])\n",
        "\n",
        "print(\"[4/5] Instalando tf-bodypix...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tf-bodypix\"])\n",
        "\n",
        "print(\"[5/5] Instalando librerias de procesamiento...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"opencv-python\", \"Pillow\", \"matplotlib\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEPENDENCIAS INSTALADAS CORRECTAMENTE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# MONTAR GOOGLE DRIVE\n",
        "# =============================================================================\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    IN_COLAB = True\n",
        "    print(\"Google Drive montado correctamente\\n\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Entorno fuera de Google Colab\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7HrM4Jq3ghP",
        "outputId": "32e72d6c-f8aa-4409-fa0d-47608d6675be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INSTALANDO DEPENDENCIAS BODYPIX\n",
            "================================================================================\n",
            "\n",
            "[1/5] Actualizando packaging...\n",
            "[2/5] Instalando TensorFlow...\n",
            "[3/5] Instalando tfjs-graph-converter...\n",
            "[4/5] Instalando tf-bodypix...\n",
            "[5/5] Instalando librerias de procesamiento...\n",
            "\n",
            "================================================================================\n",
            "DEPENDENCIAS INSTALADAS CORRECTAMENTE\n",
            "================================================================================\n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict, field\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "from tf_bodypix.api import download_model, load_model, BodyPixModelPaths\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar TensorFlow para crecimiento dinamico de memoria GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"GPU configurada: {len(gpus)} dispositivo(s) disponible(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error configurando GPU: {e}\")\n",
        "else:\n",
        "    print(\"Ejecutando en CPU\")\n",
        "\n",
        "print(\"Librerias importadas correctamente\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYsESKcs3jBK",
        "outputId": "418e279c-ba52-4ea1-d644-f51ac46970cf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando en CPU\n",
            "Librerias importadas correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloBodyPix:\n",
        "    \"\"\"Informacion de un modelo BodyPix\"\"\"\n",
        "    nombre: str\n",
        "    nombre_corto: str\n",
        "    path: Any  # BodyPixModelPaths enum\n",
        "    arquitectura: str\n",
        "    multiplicador: float\n",
        "    descripcion: str\n",
        "\n",
        "MODELOS_DISPONIBLES = {\n",
        "    'mobilenet_v1_050': ModeloBodyPix(\n",
        "        nombre='MobileNetV1 0.50',\n",
        "        nombre_corto='mobilenet_v1_050',\n",
        "        path=BodyPixModelPaths.MOBILENET_FLOAT_50_STRIDE_16,\n",
        "        arquitectura='MobileNetV1',\n",
        "        multiplicador=0.50,\n",
        "        descripcion='Modelo ultraligero optimizado para velocidad'\n",
        "    ),\n",
        "    'mobilenet_v1_075': ModeloBodyPix(\n",
        "        nombre='MobileNetV1 0.75',\n",
        "        nombre_corto='mobilenet_v1_075',\n",
        "        path=BodyPixModelPaths.MOBILENET_FLOAT_75_STRIDE_16,\n",
        "        arquitectura='MobileNetV1',\n",
        "        multiplicador=0.75,\n",
        "        descripcion='Balance entre velocidad y calidad de segmentacion'\n",
        "    ),\n",
        "    'mobilenet_v1_100': ModeloBodyPix(\n",
        "        nombre='MobileNetV1 1.00',\n",
        "        nombre_corto='mobilenet_v1_100',\n",
        "        path=BodyPixModelPaths.MOBILENET_FLOAT_100_STRIDE_16,\n",
        "        arquitectura='MobileNetV1',\n",
        "        multiplicador=1.00,\n",
        "        descripcion='Maxima calidad de segmentacion disponible'\n",
        "    )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionUmbrales:\n",
        "    \"\"\"\n",
        "    Configuracion de umbrales de segmentacion para BodyPix.\n",
        "\n",
        "    Los umbrales controlan que pixels se consideran como persona basandose\n",
        "    en la probabilidad de segmentacion (valores 0.0 a 1.0).\n",
        "    \"\"\"\n",
        "    nombre: str\n",
        "    valores: List[float]\n",
        "    descripcion: str\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validacion de parametros\"\"\"\n",
        "        if not all(0.0 <= v <= 1.0 for v in self.valores):\n",
        "            raise ValueError(\"Los valores de umbral deben estar entre 0.0 y 1.0\")\n",
        "\n",
        "CONFIGURACIONES_UMBRALES = {\n",
        "    'ultra_sensible': ConfiguracionUmbrales(\n",
        "        nombre='ultra_sensible',\n",
        "        valores=[0.3, 0.4, 0.5],\n",
        "        descripcion='Maxima sensibilidad - Detecta mas pixels como persona'\n",
        "    ),\n",
        "    'sensibilidad_alta': ConfiguracionUmbrales(\n",
        "        nombre='sensibilidad_alta',\n",
        "        valores=[0.4, 0.5, 0.6],\n",
        "        descripcion='Alta sensibilidad - Incluye pixels con confianza moderada'\n",
        "    ),\n",
        "    'sensibilidad_media': ConfiguracionUmbrales(\n",
        "        nombre='sensibilidad_media',\n",
        "        valores=[0.5, 0.65, 0.8],\n",
        "        descripcion='Balance precision-recall - Configuracion estandar'\n",
        "    ),\n",
        "    'baja_sensibilidad': ConfiguracionUmbrales(\n",
        "        nombre='baja_sensibilidad',\n",
        "        valores=[0.7, 0.8, 0.9],\n",
        "        descripcion='Solo pixels de muy alta confianza'\n",
        "    )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionEvaluacion:\n",
        "    \"\"\"Configuracion principal del sistema de evaluacion\"\"\"\n",
        "\n",
        "    # Modelos a evaluar\n",
        "    modelos_evaluar: List[str] = None  # None = todos los modelos\n",
        "\n",
        "    # Configuraciones de umbrales a evaluar\n",
        "    configs_umbrales: List[str] = None  # None = ['sensibilidad_media']\n",
        "\n",
        "    # Rutas del sistema\n",
        "    ruta_base: Path = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    ruta_imagenes: Path = None\n",
        "    ruta_resultados: Path = None\n",
        "\n",
        "    # Parametros de procesamiento\n",
        "    max_dimension: int = 1024  # Dimension maxima para procesamiento\n",
        "    pausa_entre_imagenes: float = 2.0  # Segundos entre imagenes\n",
        "    pausa_entre_modelos: float = 5.0   # Segundos entre modelos\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Inicializacion de rutas por defecto\"\"\"\n",
        "        if self.ruta_imagenes is None:\n",
        "            self.ruta_imagenes = self.ruta_base / \"0_Imagenes\"\n",
        "        if self.ruta_resultados is None:\n",
        "            self.ruta_resultados = self.ruta_base / \"2_Modelos\" / \"bodypix\"\n",
        "        if self.modelos_evaluar is None:\n",
        "            self.modelos_evaluar = list(MODELOS_DISPONIBLES.keys())\n",
        "        if self.configs_umbrales is None:\n",
        "            self.configs_umbrales = ['sensibilidad_media']"
      ],
      "metadata": {
        "id": "e4xkjM733oLZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utilidades:\n",
        "    \"\"\"Funciones auxiliares para procesamiento de imagenes y archivos\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagen(ruta: Path, max_dim: int = None) -> Tuple[Image.Image, Dict]:\n",
        "        \"\"\"\n",
        "        Carga una imagen con opcion de redimensionamiento.\n",
        "\n",
        "        Args:\n",
        "            ruta: Path a la imagen\n",
        "            max_dim: Dimension maxima (opcional)\n",
        "\n",
        "        Returns:\n",
        "            Tupla (imagen, info_dimensiones)\n",
        "        \"\"\"\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "        dim_orig = img.size\n",
        "\n",
        "        redim = False\n",
        "        if max_dim and max(img.size) > max_dim:\n",
        "            ratio = max_dim / max(img.size)\n",
        "            new_size = tuple(int(d * ratio) for d in img.size)\n",
        "            img = img.resize(new_size, Image.LANCZOS)\n",
        "            redim = True\n",
        "\n",
        "        info = {\n",
        "            'original': {'width': dim_orig[0], 'height': dim_orig[1]},\n",
        "            'procesada': {\n",
        "                'width': img.size[0],\n",
        "                'height': img.size[1],\n",
        "                'redimensionada': redim\n",
        "            }\n",
        "        }\n",
        "        return img, info\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Dict, ruta: Path):\n",
        "        \"\"\"Guarda datos en formato JSON\"\"\"\n",
        "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def liberar_memoria():\n",
        "        \"\"\"Libera memoria GPU y RAM\"\"\"\n",
        "        gc.collect()\n",
        "        if tf.config.list_physical_devices('GPU'):\n",
        "            tf.keras.backend.clear_session()\n",
        "\n",
        "    @staticmethod\n",
        "    def obtener_memoria_gpu() -> Dict:\n",
        "        \"\"\"Obtiene informacion de memoria GPU disponible\"\"\"\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if not gpus:\n",
        "            return {'disponible': False}\n",
        "\n",
        "        return {\n",
        "            'disponible': True,\n",
        "            'dispositivos': len(gpus)\n",
        "        }"
      ],
      "metadata": {
        "id": "eQfpoz7g3s7x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE CHECKPOINT\n",
        "# =============================================================================\n",
        "\n",
        "class GestorCheckpoint:\n",
        "    \"\"\"\n",
        "    Gestiona el estado del procesamiento para permitir reanudacion tras\n",
        "    interrupciones. Mantiene registro de imagenes completadas por combinacion\n",
        "    de modelo y configuracion de umbrales.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ruta_checkpoint: Path):\n",
        "        self.ruta_checkpoint = ruta_checkpoint\n",
        "        self.checkpoint = self._cargar()\n",
        "\n",
        "    def _cargar(self) -> Dict:\n",
        "        \"\"\"Carga checkpoint existente o crea uno nuevo\"\"\"\n",
        "        if self.ruta_checkpoint.exists():\n",
        "            with open(self.ruta_checkpoint, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {\n",
        "            'imagenes_completadas': [],\n",
        "            'fecha_inicio': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def obtener_pendientes(self, todas_imagenes: List[str]) -> set:\n",
        "        \"\"\"Retorna conjunto de imagenes pendientes de procesar\"\"\"\n",
        "        completadas = set(self.checkpoint.get('imagenes_completadas', []))\n",
        "        return set(todas_imagenes) - completadas\n",
        "\n",
        "    def marcar_completada(self, nombre_imagen: str):\n",
        "        \"\"\"Marca una imagen como completada y persiste el checkpoint\"\"\"\n",
        "        if nombre_imagen not in self.checkpoint['imagenes_completadas']:\n",
        "            self.checkpoint['imagenes_completadas'].append(nombre_imagen)\n",
        "            self.checkpoint['ultima_actualizacion'] = datetime.now().isoformat()\n",
        "            Utilidades.guardar_json(self.checkpoint, self.ruta_checkpoint)"
      ],
      "metadata": {
        "id": "NoiK36Fv3vlj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE MASCARAS NPZ\n",
        "# =============================================================================\n",
        "\n",
        "class GestorMascaras:\n",
        "    \"\"\"\n",
        "    Gestiona el almacenamiento de mascaras en formato NPZ comprimido.\n",
        "\n",
        "    BodyPix genera una mascara de probabilidad continua (valores 0.0-1.0) y\n",
        "    opcionalmente una mascara de partes del cuerpo. Se almacenan de forma\n",
        "    eficiente para analisis posterior sin re-ejecutar el modelo.\n",
        "\n",
        "    NOTA: La mascara de partes del cuerpo es OPCIONAL y ligera (~mismo tamaño\n",
        "    que la mascara de persona, ya que se almacena como uint8).\n",
        "    \"\"\"\n",
        "\n",
        "    # Agrupaciones de partes del cuerpo para fotografia de retrato\n",
        "    # Simplificamos las 24 partes originales en 6 grupos semanticos\n",
        "    GRUPOS_PARTES_CUERPO = {\n",
        "        'cara': [0, 1],  # left_face, right_face\n",
        "        'torso': [12, 13],  # torso_front, torso_back\n",
        "        'brazos': [2, 3, 4, 5, 6, 7, 8, 9],  # todos los segmentos de brazos\n",
        "        'manos': [10, 11],  # left_hand, right_hand\n",
        "        'piernas': [14, 15, 16, 17, 18, 19, 20, 21],  # todos los segmentos de piernas\n",
        "        'pies': [22, 23]  # left_foot, right_foot\n",
        "    }\n",
        "\n",
        "    def __init__(self, directorio_mascaras: Path):\n",
        "        self.directorio_mascaras = directorio_mascaras\n",
        "        self.directorio_mascaras.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def guardar_mascaras(\n",
        "        self,\n",
        "        mascara_probabilidad: np.ndarray,\n",
        "        umbrales: List[float],\n",
        "        nombre_imagen: str,\n",
        "        modelo_info: Dict,\n",
        "        mascara_partes: Optional[np.ndarray] = None\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Guarda mascara de probabilidad, binarizaciones por umbral y opcionalmente\n",
        "        mascara de partes del cuerpo.\n",
        "\n",
        "        Args:\n",
        "            mascara_probabilidad: Array (H, W) con valores 0.0-1.0\n",
        "            umbrales: Lista de umbrales para binarizacion\n",
        "            nombre_imagen: Nombre del archivo de imagen\n",
        "            modelo_info: Metadatos del modelo\n",
        "            mascara_partes: (Opcional) Array (H, W) con IDs de partes 0-23, o -1 para fondo\n",
        "\n",
        "        Returns:\n",
        "            Nombre del archivo NPZ generado\n",
        "        \"\"\"\n",
        "        nombre_base = Path(nombre_imagen).stem\n",
        "        archivo_npz = self.directorio_mascaras / f\"{nombre_base}.npz\"\n",
        "\n",
        "        # Preparar mascaras binarias para cada umbral\n",
        "        mascaras_binarias = {}\n",
        "        for umbral in umbrales:\n",
        "            key = f'umbral_{umbral}'\n",
        "            mascaras_binarias[key] = (mascara_probabilidad >= umbral).astype(np.uint8)\n",
        "\n",
        "        # Datos base para guardar\n",
        "        datos_npz = {\n",
        "            # Mascara de probabilidad original (informacion continua unica de BodyPix)\n",
        "            'mascara_probabilidad': mascara_probabilidad.astype(np.float32),\n",
        "            # Mascaras binarias por umbral (pre-calculadas para analisis rapido)\n",
        "            **mascaras_binarias,\n",
        "            # Metadatos\n",
        "            'dimensiones': np.array(mascara_probabilidad.shape, dtype=np.int32),\n",
        "            'umbrales': np.array(umbrales, dtype=np.float32),\n",
        "            'modelo_nombre': modelo_info['nombre_corto']\n",
        "        }\n",
        "\n",
        "        # Añadir mascara de partes del cuerpo si esta disponible\n",
        "        if mascara_partes is not None:\n",
        "            # Almacenar la mascara de partes completa (ligera: uint8)\n",
        "            # Valores: 0-23 para partes del cuerpo, -1 para fondo\n",
        "            datos_npz['mascara_partes'] = mascara_partes.astype(np.int8)\n",
        "\n",
        "            # Pre-calcular mascaras agrupadas para analisis rapido\n",
        "            # Esto evita tener que procesar las 24 partes en analisis posterior\n",
        "            for nombre_grupo, ids_partes in self.GRUPOS_PARTES_CUERPO.items():\n",
        "                mascara_grupo = np.isin(mascara_partes, ids_partes).astype(np.uint8)\n",
        "                datos_npz[f'grupo_{nombre_grupo}'] = mascara_grupo\n",
        "\n",
        "        # Guardar en formato NPZ comprimido\n",
        "        np.savez_compressed(archivo_npz, **datos_npz)\n",
        "\n",
        "        return archivo_npz.name"
      ],
      "metadata": {
        "id": "-bbuAbrG3y1D"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE VISUALIZACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizaciones:\n",
        "    \"\"\"Genera visualizaciones estandarizadas de resultados de segmentacion\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generar_visualizacion(\n",
        "        imagen: np.ndarray,\n",
        "        mascara_probabilidad: np.ndarray,\n",
        "        umbral_vis: float,\n",
        "        ruta_salida: Path,\n",
        "        titulo: str\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Genera visualizacion de 2 paneles: imagen original y segmentacion.\n",
        "\n",
        "        Args:\n",
        "            imagen: Array RGB de la imagen original\n",
        "            mascara_probabilidad: Mascara de probabilidad (0.0-1.0)\n",
        "            umbral_vis: Umbral usado para la visualizacion\n",
        "            ruta_salida: Path donde guardar la visualizacion\n",
        "            titulo: Titulo para la figura\n",
        "        \"\"\"\n",
        "        ruta_salida.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "        # Panel 1: Imagen original\n",
        "        axes[0].imshow(imagen)\n",
        "        axes[0].set_title('Imagen Original', fontsize=12, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Panel 2: Segmentacion con overlay\n",
        "        axes[1].imshow(imagen)\n",
        "\n",
        "        # Aplicar umbral para visualizacion\n",
        "        mascara_binaria = mascara_probabilidad >= umbral_vis\n",
        "\n",
        "        # Crear overlay verde semi-transparente para persona\n",
        "        overlay = np.zeros_like(imagen)\n",
        "        overlay[mascara_binaria] = [0, 255, 0]\n",
        "\n",
        "        axes[1].imshow(overlay, alpha=0.4)\n",
        "        axes[1].set_title(\n",
        "            f'Segmentacion (umbral={umbral_vis})',\n",
        "            fontsize=12,\n",
        "            fontweight='bold'\n",
        "        )\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        # Calcular y mostrar estadisticas\n",
        "        area_persona = mascara_binaria.sum()\n",
        "        area_total = mascara_binaria.size\n",
        "        porcentaje = (area_persona / area_total) * 100\n",
        "\n",
        "        info_text = f\"Area persona: {porcentaje:.1f}%\\n\"\n",
        "        info_text += f\"Pixels: {area_persona:,} / {area_total:,}\"\n",
        "\n",
        "        axes[1].text(\n",
        "            0.02, 0.98, info_text,\n",
        "            transform=axes[1].transAxes,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
        "            fontsize=10,\n",
        "            family='monospace'\n",
        "        )\n",
        "\n",
        "        plt.suptitle(titulo, fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(ruta_salida, dpi=100, bbox_inches='tight')\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "nBmTx9eD35Md"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROCESADOR BODYPIX\n",
        "# =============================================================================\n",
        "\n",
        "class ProcesadorBodyPix:\n",
        "    \"\"\"\n",
        "    Procesador principal para modelos BodyPix.\n",
        "\n",
        "    Gestiona la carga del modelo, inferencia y procesamiento de resultados\n",
        "    para generar mascaras de segmentacion con diferentes umbrales.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, modelo_info: ModeloBodyPix, config: ConfiguracionEvaluacion):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "\n",
        "    def cargar_modelo(self):\n",
        "        \"\"\"Descarga y carga el modelo BodyPix\"\"\"\n",
        "        print(f\"  Cargando modelo {self.modelo_info.nombre}...\")\n",
        "        model_path = download_model(self.modelo_info.path)\n",
        "        self.model = load_model(model_path)\n",
        "        print(f\"  Modelo cargado correctamente\")\n",
        "\n",
        "    def procesar_imagen(\n",
        "        self,\n",
        "        img_path: Path,\n",
        "        umbrales: List[float],\n",
        "        ruta_resultados: Path\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Procesa una imagen con el modelo BodyPix.\n",
        "\n",
        "        Args:\n",
        "            img_path: Path a la imagen\n",
        "            umbrales: Lista de umbrales para evaluacion\n",
        "            ruta_resultados: Directorio base para resultados\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados estructurados y metadatos\n",
        "        \"\"\"\n",
        "        # Cargar imagen\n",
        "        img, info_img = Utilidades.cargar_imagen(img_path, self.config.max_dimension)\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        # Inferencia con BodyPix\n",
        "        tiempo_inicio = time.time()\n",
        "        result = self.model.predict_single(img_array)\n",
        "        tiempo_inferencia_ms = (time.time() - tiempo_inicio) * 1000\n",
        "\n",
        "        # Obtener mascara de probabilidad base\n",
        "        # BodyPix genera valores 0-255, normalizar a 0.0-1.0\n",
        "        mascara_prob_255 = result.get_mask(threshold=0.5).numpy()\n",
        "\n",
        "        # Asegurar que sea 2D (H, W)\n",
        "        if mascara_prob_255.ndim == 3:\n",
        "            # Si tiene canal adicional, tomar solo el primer canal\n",
        "            mascara_prob_255 = mascara_prob_255[:, :, 0]\n",
        "\n",
        "        mascara_probabilidad = mascara_prob_255.astype(np.float32) / 255.0\n",
        "\n",
        "        # Obtener mascara de partes del cuerpo (caracteristica unica de BodyPix)\n",
        "        # Esto es ligero: solo añade un array int8 del mismo tamaño que la imagen\n",
        "        mascara_partes = None\n",
        "        try:\n",
        "            mascara_partes_raw = result.get_part_mask(img_array)\n",
        "            # Convertir a array numpy con valores -1 (fondo) o 0-23 (partes)\n",
        "            mascara_partes = mascara_partes_raw.astype(np.int8)\n",
        "        except Exception as e:\n",
        "            # Si falla (modelo sin soporte de partes), continuar sin ellas\n",
        "            print(f\"    Advertencia: No se pudieron obtener partes del cuerpo: {e}\")\n",
        "\n",
        "        # Guardar mascaras en NPZ\n",
        "        gestor_mascaras = GestorMascaras(ruta_resultados / \"mascaras\")\n",
        "        archivo_npz = gestor_mascaras.guardar_mascaras(\n",
        "            mascara_probabilidad,\n",
        "            umbrales,\n",
        "            img_path.name,\n",
        "            {'nombre_corto': self.modelo_info.nombre_corto},\n",
        "            mascara_partes=mascara_partes\n",
        "        )\n",
        "\n",
        "        # Procesar cada umbral\n",
        "        detecciones_por_umbral = {}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            # Aplicar umbral\n",
        "            mascara_binaria = (mascara_probabilidad >= umbral).astype(np.uint8)\n",
        "\n",
        "            # Calcular metricas\n",
        "            area_persona = int(mascara_binaria.sum())\n",
        "            area_total = mascara_binaria.size\n",
        "            porcentaje_imagen = (area_persona / area_total) * 100\n",
        "\n",
        "            # Heuristica simple: considerar persona detectada si >= 5% de imagen\n",
        "            persona_detectada = porcentaje_imagen >= 5.0\n",
        "\n",
        "            detecciones_por_umbral[f'umbral_{umbral}'] = {\n",
        "                'umbral_usado': umbral,\n",
        "                'persona_detectada': persona_detectada,\n",
        "                'area_pixels': area_persona,\n",
        "                'area_total_pixels': area_total,\n",
        "                'porcentaje_imagen': round(porcentaje_imagen, 2),\n",
        "                'probabilidad_media_region': float(\n",
        "                    mascara_probabilidad[mascara_binaria > 0].mean()\n",
        "                    if area_persona > 0 else 0.0\n",
        "                )\n",
        "            }\n",
        "\n",
        "        # Calcular estadisticas de partes del cuerpo si estan disponibles\n",
        "        info_partes_cuerpo = None\n",
        "        if mascara_partes is not None:\n",
        "            info_partes_cuerpo = self._calcular_estadisticas_partes(\n",
        "                mascara_partes,\n",
        "                mascara_probabilidad\n",
        "            )\n",
        "\n",
        "        # Construir resultado con estructura estandarizada\n",
        "        resultado = {\n",
        "            'metadata': {\n",
        "                'imagen': {\n",
        "                    'nombre': img_path.name,\n",
        "                    'ruta': str(img_path),\n",
        "                    **info_img\n",
        "                },\n",
        "                'modelo': {\n",
        "                    'nombre': self.modelo_info.nombre,\n",
        "                    'nombre_corto': self.modelo_info.nombre_corto,\n",
        "                    'arquitectura': self.modelo_info.arquitectura,\n",
        "                    'multiplicador': self.modelo_info.multiplicador\n",
        "                },\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'tiempo_inferencia_ms': round(tiempo_inferencia_ms, 2)\n",
        "            },\n",
        "            'archivos_generados': {\n",
        "                'mascara_npz': archivo_npz\n",
        "            },\n",
        "            'detecciones_por_umbral': detecciones_por_umbral,\n",
        "            'partes_cuerpo': info_partes_cuerpo  # None si no disponible\n",
        "        }\n",
        "\n",
        "        return resultado, img_array, mascara_probabilidad\n",
        "\n",
        "    def _calcular_estadisticas_partes(\n",
        "        self,\n",
        "        mascara_partes: np.ndarray,\n",
        "        mascara_probabilidad: np.ndarray\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula estadisticas ligeras sobre las partes del cuerpo detectadas.\n",
        "\n",
        "        Estas estadisticas son LIGERAS y se calculan rapidamente. El analisis\n",
        "        detallado de partes se realizara en el Notebook 3 si es necesario.\n",
        "\n",
        "        Args:\n",
        "            mascara_partes: Array (H, W) con IDs de partes -1 a 23\n",
        "            mascara_probabilidad: Array (H, W) con probabilidades 0.0-1.0\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas basicas por grupo de partes\n",
        "        \"\"\"\n",
        "        # Asegurar que mascara_probabilidad sea 2D\n",
        "        if mascara_probabilidad.ndim == 3:\n",
        "            mascara_probabilidad = mascara_probabilidad[:, :, 0]\n",
        "\n",
        "        # Asegurar que mascara_partes sea 2D\n",
        "        if mascara_partes.ndim == 3:\n",
        "            mascara_partes = mascara_partes[:, :, 0]\n",
        "\n",
        "        area_total = mascara_partes.size\n",
        "        grupos_detectados = {}\n",
        "\n",
        "        for nombre_grupo, ids_partes in GestorMascaras.GRUPOS_PARTES_CUERPO.items():\n",
        "            # Mascara binaria del grupo\n",
        "            mascara_grupo = np.isin(mascara_partes, ids_partes)\n",
        "            area_grupo = int(mascara_grupo.sum())\n",
        "\n",
        "            if area_grupo > 0:\n",
        "                # Probabilidad media en esta region\n",
        "                prob_media = float(mascara_probabilidad[mascara_grupo].mean())\n",
        "\n",
        "                grupos_detectados[nombre_grupo] = {\n",
        "                    'area_pixels': area_grupo,\n",
        "                    'porcentaje_imagen': round((area_grupo / area_total) * 100, 2),\n",
        "                    'probabilidad_media': round(prob_media, 3)\n",
        "                }\n",
        "\n",
        "        return {\n",
        "            'grupos_detectados': grupos_detectados,\n",
        "            'num_grupos_detectados': len(grupos_detectados),\n",
        "            'grupos_disponibles': list(GestorMascaras.GRUPOS_PARTES_CUERPO.keys())\n",
        "        }\n",
        "\n",
        "    def limpiar_memoria(self):\n",
        "        \"\"\"Libera recursos del modelo\"\"\"\n",
        "        del self.model\n",
        "        self.model = None\n",
        "        Utilidades.liberar_memoria()"
      ],
      "metadata": {
        "id": "yFVZH_yW3794"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorBodyPix:\n",
        "    \"\"\"\n",
        "    Evaluador principal que coordina el procesamiento de todos los modelos\n",
        "    y configuraciones de umbrales.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionEvaluacion):\n",
        "        self.config = config\n",
        "\n",
        "    def evaluar_modelo_con_config_umbrales(\n",
        "        self,\n",
        "        modelo_key: str,\n",
        "        config_umbral_nombre: str,\n",
        "        imagenes: List[Path]\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Evalua un modelo con una configuracion de umbrales especifica.\n",
        "\n",
        "        Args:\n",
        "            modelo_key: Identificador del modelo a evaluar\n",
        "            config_umbral_nombre: Nombre de la configuracion de umbrales\n",
        "            imagenes: Lista de paths a imagenes\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas del procesamiento\n",
        "        \"\"\"\n",
        "        modelo_info = MODELOS_DISPONIBLES[modelo_key]\n",
        "        umbrales_config = CONFIGURACIONES_UMBRALES[config_umbral_nombre]\n",
        "\n",
        "        # Ruta de resultados incluye modelo y configuracion\n",
        "        ruta_resultados = (\n",
        "            self.config.ruta_resultados /\n",
        "            modelo_info.nombre_corto /\n",
        "            config_umbral_nombre /\n",
        "            \"resultados\"\n",
        "        )\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"MODELO: {modelo_info.nombre}\")\n",
        "        print(f\"UMBRALES: {umbrales_config.nombre} - {umbrales_config.valores}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Sistema de checkpoint\n",
        "        checkpoint = GestorCheckpoint(ruta_resultados / \"checkpoint.json\")\n",
        "        nombres_imgs = [img.name for img in imagenes]\n",
        "        pendientes = checkpoint.obtener_pendientes(nombres_imgs)\n",
        "        imgs_procesar = [img for img in imagenes if img.name in pendientes]\n",
        "\n",
        "        print(f\"Progreso: {len(imagenes) - len(imgs_procesar)}/{len(imagenes)} completadas\")\n",
        "        print(f\"Pendientes: {len(imgs_procesar)}\")\n",
        "\n",
        "        if len(imgs_procesar) == 0:\n",
        "            print(\"Todas las imagenes ya procesadas\")\n",
        "            return {'procesadas': 0}\n",
        "\n",
        "        # Cargar modelo\n",
        "        procesador = ProcesadorBodyPix(modelo_info, self.config)\n",
        "        procesador.cargar_modelo()\n",
        "\n",
        "        # Procesar imagenes pendientes\n",
        "        tiempo_inicio = time.time()\n",
        "\n",
        "        for i, img_path in enumerate(imgs_procesar, 1):\n",
        "            print(f\"\\n[{i}/{len(imgs_procesar)}] {img_path.name}\")\n",
        "\n",
        "            try:\n",
        "                # Procesar imagen\n",
        "                resultado, img_array, mascara_prob = procesador.procesar_imagen(\n",
        "                    img_path,\n",
        "                    umbrales_config.valores,\n",
        "                    ruta_resultados\n",
        "                )\n",
        "\n",
        "                # Guardar JSON\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                nombre_json = f\"{img_path.stem}_{timestamp}.json\"\n",
        "                ruta_json = ruta_resultados / \"json\" / nombre_json\n",
        "                Utilidades.guardar_json(resultado, ruta_json)\n",
        "\n",
        "                # Generar visualizacion (umbral medio)\n",
        "                umbral_vis = umbrales_config.valores[len(umbrales_config.valores)//2]\n",
        "                nombre_vis = f\"{img_path.stem}_{timestamp}.png\"\n",
        "                ruta_vis = ruta_resultados / \"visualizaciones\" / nombre_vis\n",
        "\n",
        "                GeneradorVisualizaciones.generar_visualizacion(\n",
        "                    img_array,\n",
        "                    mascara_prob,\n",
        "                    umbral_vis,\n",
        "                    ruta_vis,\n",
        "                    f\"{modelo_info.nombre_corto} - {umbrales_config.nombre}\"\n",
        "                )\n",
        "\n",
        "                # Marcar como completada\n",
        "                checkpoint.marcar_completada(img_path.name)\n",
        "\n",
        "                # Resumen\n",
        "                umbral_medio_key = f'umbral_{umbral_vis}'\n",
        "                persona_det = resultado['detecciones_por_umbral'][umbral_medio_key]['persona_detectada']\n",
        "                print(f\"  Completada - Persona detectada: {'Si' if persona_det else 'No'}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ERROR: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "            finally:\n",
        "                Utilidades.liberar_memoria()\n",
        "                if i < len(imgs_procesar):\n",
        "                    time.sleep(self.config.pausa_entre_imagenes)\n",
        "\n",
        "        tiempo_total = time.time() - tiempo_inicio\n",
        "\n",
        "        # Limpiar modelo\n",
        "        procesador.limpiar_memoria()\n",
        "\n",
        "        print(f\"\\nConfiguracion completada en {tiempo_total:.1f}s\")\n",
        "\n",
        "        return {\n",
        "            'procesadas': len(imgs_procesar),\n",
        "            'tiempo_segundos': round(tiempo_total, 2)\n",
        "        }\n",
        "\n",
        "    def ejecutar(self):\n",
        "        \"\"\"Ejecuta la evaluacion completa de todos los modelos y configuraciones\"\"\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"EVALUADOR BODYPIX - NOTEBOOK 2\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Modelos: {len(self.config.modelos_evaluar)}\")\n",
        "        for modelo_key in self.config.modelos_evaluar:\n",
        "            modelo = MODELOS_DISPONIBLES[modelo_key]\n",
        "            print(f\"  - {modelo.nombre} (multiplicador {modelo.multiplicador})\")\n",
        "\n",
        "        print(f\"\\nConfiguraciones de umbrales: {len(self.config.configs_umbrales)}\")\n",
        "        for config_name in self.config.configs_umbrales:\n",
        "            umbrales = CONFIGURACIONES_UMBRALES[config_name]\n",
        "            print(f\"  - {config_name}: {umbrales.valores}\")\n",
        "\n",
        "        print(f\"\\nDirectorio de imagenes: {self.config.ruta_imagenes}\")\n",
        "        print(f\"Directorio de resultados: {self.config.ruta_resultados}\")\n",
        "\n",
        "        # Cargar imagenes\n",
        "        imagenes = []\n",
        "        for extension in ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']:\n",
        "            imagenes.extend(sorted(self.config.ruta_imagenes.glob(extension)))\n",
        "        imagenes = sorted(set(imagenes))\n",
        "\n",
        "        print(f\"\\nTotal imagenes encontradas: {len(imagenes)}\")\n",
        "\n",
        "        if not imagenes:\n",
        "            print(\"ERROR: No se encontraron imagenes en el directorio\")\n",
        "            return\n",
        "\n",
        "        # Evaluar cada combinacion de modelo + configuracion\n",
        "        total_combinaciones = (\n",
        "            len(self.config.modelos_evaluar) *\n",
        "            len(self.config.configs_umbrales)\n",
        "        )\n",
        "        combinacion_actual = 0\n",
        "\n",
        "        for modelo_key in self.config.modelos_evaluar:\n",
        "            for config_umbral in self.config.configs_umbrales:\n",
        "                combinacion_actual += 1\n",
        "\n",
        "                print(f\"\\n{'#'*80}\")\n",
        "                print(f\"COMBINACION {combinacion_actual}/{total_combinaciones}\")\n",
        "                print(f\"{'#'*80}\")\n",
        "\n",
        "                self.evaluar_modelo_con_config_umbrales(\n",
        "                    modelo_key,\n",
        "                    config_umbral,\n",
        "                    imagenes\n",
        "                )\n",
        "\n",
        "                if combinacion_actual < total_combinaciones:\n",
        "                    print(f\"\\nPausa entre configuraciones: {self.config.pausa_entre_modelos}s\")\n",
        "                    time.sleep(self.config.pausa_entre_modelos)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"EVALUACION COMPLETADA\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Resultados guardados en: {self.config.ruta_resultados}\")"
      ],
      "metadata": {
        "id": "ME3XNN_k4ALJ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EJECUCION PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # Configurar evaluacion\n",
        "    config = ConfiguracionEvaluacion(\n",
        "        # Seleccionar modelos (None = todos los 3)\n",
        "        modelos_evaluar=None,\n",
        "\n",
        "        # Seleccionar configuraciones de umbrales\n",
        "        configs_umbrales=[\n",
        "            'ultra_sensible',\n",
        "            'sensibilidad_alta',\n",
        "            'sensibilidad_media',\n",
        "            'baja_sensibilidad'\n",
        "        ],\n",
        "\n",
        "        # Parametros de procesamiento\n",
        "        max_dimension=1024,\n",
        "        pausa_entre_imagenes=2.0,\n",
        "        pausa_entre_modelos=5.0\n",
        "    )\n",
        "\n",
        "    # Ejecutar evaluacion\n",
        "    evaluador = EvaluadorBodyPix(config)\n",
        "    evaluador.ejecutar()"
      ],
      "metadata": {
        "id": "EtiOWDw54OC-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s41f4g5p4eDd",
        "outputId": "62cdeb90-efeb-4b9a-a291-3afb218ad90f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EVALUADOR BODYPIX - NOTEBOOK 2\n",
            "================================================================================\n",
            "Modelos: 3\n",
            "  - MobileNetV1 0.50 (multiplicador 0.5)\n",
            "  - MobileNetV1 0.75 (multiplicador 0.75)\n",
            "  - MobileNetV1 1.00 (multiplicador 1.0)\n",
            "\n",
            "Configuraciones de umbrales: 4\n",
            "  - ultra_sensible: [0.3, 0.4, 0.5]\n",
            "  - sensibilidad_alta: [0.4, 0.5, 0.6]\n",
            "  - sensibilidad_media: [0.5, 0.65, 0.8]\n",
            "  - baja_sensibilidad: [0.7, 0.8, 0.9]\n",
            "\n",
            "Directorio de imagenes: /content/drive/MyDrive/TFM/0_Imagenes\n",
            "Directorio de resultados: /content/drive/MyDrive/TFM/2_Modelos/bodypix\n",
            "\n",
            "Total imagenes encontradas: 20\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 1/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: ultra_sensible - [0.3, 0.4, 0.5]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.50...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 95.3s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 2/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: sensibilidad_alta - [0.4, 0.5, 0.6]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.50...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 78.2s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 3/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: sensibilidad_media - [0.5, 0.65, 0.8]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.50...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 79.9s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 4/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: baja_sensibilidad - [0.7, 0.8, 0.9]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.50...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 78.4s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 5/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: ultra_sensible - [0.3, 0.4, 0.5]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 79.0s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 6/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: sensibilidad_alta - [0.4, 0.5, 0.6]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "Configuracion completada en 79.3s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 7/12\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: sensibilidad_media - [0.5, 0.65, 0.8]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "  Completada - Persona detectada: No\n",
            "\n",
            "[12/20] _DSC0441.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7a59ebb5d080>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lib/__init__.py\", line 127, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Completada - Persona detectada: No\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3832242952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-620083997.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Ejecutar evaluacion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mevaluador\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluadorBodyPix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mevaluador\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mejecutar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3883219558.py\u001b[0m in \u001b[0;36mejecutar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{'#'*80}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 self.evaluar_modelo_con_config_umbrales(\n\u001b[0m\u001b[1;32m    174\u001b[0m                     \u001b[0mmodelo_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0mconfig_umbral\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3883219558.py\u001b[0m in \u001b[0;36mevaluar_modelo_con_config_umbrales\u001b[0;34m(self, modelo_key, config_umbral_nombre, imagenes)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mUtilidades\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliberar_memoria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_procesar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpausa_entre_imagenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mtiempo_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtiempo_inicio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}