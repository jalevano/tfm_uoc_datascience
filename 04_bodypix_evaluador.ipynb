{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM5DzE8R8bvi5+qiqvO7FyB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/04_bodypix_evaluador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "p-wfdH7po3K_",
        "outputId": "53248dfd-2210-46cb-ab97-beb270b38e1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nEVALUADOR BODYPIX - NOTEBOOK 2\\n================================================================================\\nSistema de evaluacion para modelos BodyPix con estructura estandarizada\\npara comparacion de modelos de segmentacion de personas en fotografia de retrato.\\n\\nCARACTERISTICAS PRINCIPALES:\\n- Procesamiento incremental con sistema de checkpoint robusto\\n- Gestion optima de memoria para Google Colab gratuito\\n- Guardado automatico despues de cada imagen procesada\\n- 3 modelos MobileNetV1 con multiplicadores 0.50, 0.75, 1.00\\n- 4 configuraciones de umbral de segmentacion\\n- Almacenamiento NPZ por fotografia con mascaras de probabilidad completas\\n- Segmentacion de partes del cuerpo (caracteristica unica de BodyPix)\\n- JSON ligero con metricas de rendimiento por umbral\\n- Visualizaciones estandarizadas\\n\\nMODELOS DISPONIBLES:\\n1. MobileNetV1 0.50: Arquitectura ligera optimizada para velocidad\\n2. MobileNetV1 0.75: Balance entre velocidad y calidad de segmentacion\\n3. MobileNetV1 1.00: Maxima calidad de segmentacion disponible\\n\\nCONFIGURACIONES DE UMBRAL:\\nLas configuraciones evaluan multiples umbrales de segmentacion para analizar\\nla sensibilidad del modelo a diferentes niveles de confianza:\\n\\n1. ultra_sensible: [0.3, 0.4, 0.5] - Maxima deteccion de pixels\\n2. sensibilidad_alta: [0.4, 0.5, 0.6] - Alta sensibilidad\\n3. sensibilidad_media: [0.5, 0.65, 0.8] - Balance precision-recall\\n4. baja_sensibilidad: [0.7, 0.8, 0.9] - Alta confianza\\n\\nALMACENAMIENTO NPZ (por fotografia):\\nBodyPix genera mascaras de segmentacion continuas (valores 0-1) que representan\\nla probabilidad de que cada pixel pertenezca a una persona, y adicionalmente\\npuede segmentar partes del cuerpo. Se almacena:\\n\\nInformacion de segmentacion de persona:\\n- mascara_probabilidad: Array (H, W) con valores 0.0-1.0 continuos\\n- mascaras_binarias_por_umbral: Dict con mascaras binarias para cada umbral\\n- dimensiones: Shape de la imagen procesada\\n- modelo_info: Metadatos del modelo usado\\n\\nInformacion de partes del cuerpo (CARACTERISTICA UNICA de BodyPix):\\n- mascara_partes: Array (H, W) con IDs de partes 0-23, o -1 para fondo\\n- grupo_cara: Mascara binaria agrupada de cara\\n- grupo_torso: Mascara binaria agrupada de torso\\n- grupo_brazos: Mascara binaria agrupada de brazos\\n- grupo_manos: Mascara binaria agrupada de manos\\n- grupo_piernas: Mascara binaria agrupada de piernas\\n- grupo_pies: Mascara binaria agrupada de pies\\n\\nNOTA SOBRE PARTES DEL CUERPO:\\nLa segmentacion de partes del cuerpo es una caracteristica UNICA de BodyPix\\nque ningun otro modelo del TFM proporciona. Se almacena de forma LIGERA:\\n- La mascara de partes es int8 (mismo tamaÃ±o que la imagen)\\n- Se pre-calculan 6 grupos semanticos para fotografia de retrato\\n- Incremento de tamaÃ±o: ~7% adicional en NPZ comprimido\\n- Valor para el TFM: Permite analisis especificos de composicion de retratos\\n\\nDIFERENCIAS CON OTROS MODELOS:\\nA diferencia de modelos de deteccion de instancias (YOLO, Mask2Former) o\\ngeneracion automatica (SAM2), BodyPix es un modelo de segmentacion semantica\\nque genera una unica mascara de probabilidad por imagen. No detecta instancias\\nindividuales ni proporciona bounding boxes nativamente.\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/2_Modelos/bodypix/{modelo}/{config}/resultados/\\nâ”œâ”€â”€ json/                           # Metricas por fotografia y umbral\\nâ”œâ”€â”€ mascaras/                       # NPZ con mascaras de probabilidad y partes\\nâ”œâ”€â”€ visualizaciones/                # Visualizaciones por fotografia\\nâ””â”€â”€ checkpoint.json                 # Estado del procesamiento\\n\\nEntrada: Imagenes desde /TFM/0_Imagenes/\\nSalida: JSON, mascaras NPZ y visualizaciones en estructura organizada\\n\\nReferencias:\\n- Papandreou et al. (2018) \"PersonLab: Person Pose Estimation and Instance\\n  Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model\"\\n- TensorFlow.js BodyPix: https://github.com/tensorflow/tfjs-models/tree/master/body-pix\\n\\nAutor: Jesus L.\\nProyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\\nUniversidad: Universidad Oberta de Cataluna (UOC)\\nFecha: Octubre 2025\\n================================================================================\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "EVALUADOR BODYPIX - NOTEBOOK 2\n",
        "================================================================================\n",
        "Sistema de evaluacion para modelos BodyPix con estructura estandarizada\n",
        "para comparacion de modelos de segmentacion de personas en fotografia de retrato.\n",
        "\n",
        "CARACTERISTICAS PRINCIPALES:\n",
        "- Procesamiento incremental con sistema de checkpoint robusto\n",
        "- Gestion optima de memoria para Google Colab gratuito\n",
        "- Guardado automatico despues de cada imagen procesada\n",
        "- 3 modelos MobileNetV1 con multiplicadores 0.50, 0.75, 1.00\n",
        "- 4 configuraciones de umbral de segmentacion\n",
        "- Almacenamiento NPZ por fotografia con mascaras de probabilidad completas\n",
        "- Segmentacion de partes del cuerpo (caracteristica unica de BodyPix)\n",
        "- JSON ligero con metricas de rendimiento por umbral\n",
        "- Visualizaciones estandarizadas\n",
        "\n",
        "MODELOS DISPONIBLES:\n",
        "1. MobileNetV1 0.50: Arquitectura ligera optimizada para velocidad\n",
        "2. MobileNetV1 0.75: Balance entre velocidad y calidad de segmentacion\n",
        "3. MobileNetV1 1.00: Maxima calidad de segmentacion disponible\n",
        "\n",
        "CONFIGURACIONES DE UMBRAL:\n",
        "Las configuraciones evaluan multiples umbrales de segmentacion para analizar\n",
        "la sensibilidad del modelo a diferentes niveles de confianza:\n",
        "\n",
        "1. ultra_sensible: [0.3, 0.4, 0.5] - Maxima deteccion de pixels\n",
        "2. sensibilidad_alta: [0.4, 0.5, 0.6] - Alta sensibilidad\n",
        "3. sensibilidad_media: [0.5, 0.65, 0.8] - Balance precision-recall\n",
        "4. baja_sensibilidad: [0.7, 0.8, 0.9] - Alta confianza\n",
        "\n",
        "ALMACENAMIENTO NPZ (por fotografia):\n",
        "BodyPix genera mascaras de segmentacion continuas (valores 0-1) que representan\n",
        "la probabilidad de que cada pixel pertenezca a una persona, y adicionalmente\n",
        "puede segmentar partes del cuerpo. Se almacena:\n",
        "\n",
        "Informacion de segmentacion de persona:\n",
        "- mascara_probabilidad: Array (H, W) con valores 0.0-1.0 continuos\n",
        "- mascaras_binarias_por_umbral: Dict con mascaras binarias para cada umbral\n",
        "- dimensiones: Shape de la imagen procesada\n",
        "- modelo_info: Metadatos del modelo usado\n",
        "\n",
        "Informacion de partes del cuerpo (CARACTERISTICA UNICA de BodyPix):\n",
        "- mascara_partes: Array (H, W) con IDs de partes 0-23, o -1 para fondo\n",
        "- grupo_cara: Mascara binaria agrupada de cara\n",
        "- grupo_torso: Mascara binaria agrupada de torso\n",
        "- grupo_brazos: Mascara binaria agrupada de brazos\n",
        "- grupo_manos: Mascara binaria agrupada de manos\n",
        "- grupo_piernas: Mascara binaria agrupada de piernas\n",
        "- grupo_pies: Mascara binaria agrupada de pies\n",
        "\n",
        "NOTA SOBRE PARTES DEL CUERPO:\n",
        "La segmentacion de partes del cuerpo es una caracteristica UNICA de BodyPix\n",
        "que ningun otro modelo del TFM proporciona. Se almacena de forma LIGERA:\n",
        "- La mascara de partes es int8 (mismo tamaÃ±o que la imagen)\n",
        "- Se pre-calculan 6 grupos semanticos para fotografia de retrato\n",
        "- Incremento de tamaÃ±o: ~7% adicional en NPZ comprimido\n",
        "- Valor para el TFM: Permite analisis especificos de composicion de retratos\n",
        "\n",
        "DIFERENCIAS CON OTROS MODELOS:\n",
        "A diferencia de modelos de deteccion de instancias (YOLO, Mask2Former) o\n",
        "generacion automatica (SAM2), BodyPix es un modelo de segmentacion semantica\n",
        "que genera una unica mascara de probabilidad por imagen. No detecta instancias\n",
        "individuales ni proporciona bounding boxes nativamente.\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/2_Modelos/bodypix/{modelo}/{config}/resultados/\n",
        "â”œâ”€â”€ json/                           # Metricas por fotografia y umbral\n",
        "â”œâ”€â”€ mascaras/                       # NPZ con mascaras de probabilidad y partes\n",
        "â”œâ”€â”€ visualizaciones/                # Visualizaciones por fotografia\n",
        "â””â”€â”€ checkpoint.json                 # Estado del procesamiento\n",
        "\n",
        "Entrada: Imagenes desde /TFM/0_Imagenes/\n",
        "Salida: JSON, mascaras NPZ y visualizaciones en estructura organizada\n",
        "\n",
        "Referencias:\n",
        "- Papandreou et al. (2018) \"PersonLab: Person Pose Estimation and Instance\n",
        "  Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model\"\n",
        "- TensorFlow.js BodyPix: https://github.com/tensorflow/tfjs-models/tree/master/body-pix\n",
        "\n",
        "Autor: Jesus L.\n",
        "Proyecto: TFM - Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "Universidad: Universidad Oberta de Cataluna (UOC)\n",
        "Fecha: Octubre 2025\n",
        "================================================================================\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# INSTALACION DE DEPENDENCIAS (EJECUTAR EN COLAB)\n",
        "# =============================================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INSTALANDO DEPENDENCIAS BODYPIX\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Orden correcto de instalacion para evitar conflictos\n",
        "print(\"\\n[1/5] Actualizando packaging...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"packaging>=24.2.0\"])\n",
        "\n",
        "print(\"[2/5] Instalando TensorFlow...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tensorflow\"])\n",
        "\n",
        "print(\"[3/5] Instalando tfjs-graph-converter...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tfjs-graph-converter\"])\n",
        "\n",
        "print(\"[4/5] Instalando tf-bodypix...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"tf-bodypix\"])\n",
        "\n",
        "print(\"[5/5] Instalando librerias de procesamiento...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"opencv-python\", \"Pillow\", \"matplotlib\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DEPENDENCIAS INSTALADAS CORRECTAMENTE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# MONTAR GOOGLE DRIVE\n",
        "# =============================================================================\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    IN_COLAB = True\n",
        "    print(\"Google Drive montado correctamente\\n\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Entorno fuera de Google Colab\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "170HvJALqbwp",
        "outputId": "0e2c698a-220e-490c-ab76-64be9d67bfb6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INSTALANDO DEPENDENCIAS BODYPIX\n",
            "================================================================================\n",
            "\n",
            "[1/5] Actualizando packaging...\n",
            "[2/5] Instalando TensorFlow...\n",
            "[3/5] Instalando tfjs-graph-converter...\n",
            "[4/5] Instalando tf-bodypix...\n",
            "[5/5] Instalando librerias de procesamiento...\n",
            "\n",
            "================================================================================\n",
            "DEPENDENCIAS INSTALADAS CORRECTAMENTE\n",
            "================================================================================\n",
            "\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive montado correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict, field\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "from tf_bodypix.api import download_model, load_model, BodyPixModelPaths\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configurar TensorFlow para crecimiento dinamico de memoria GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"GPU configurada: {len(gpus)} dispositivo(s) disponible(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error configurando GPU: {e}\")\n",
        "else:\n",
        "    print(\"Ejecutando en CPU\")\n",
        "\n",
        "print(\"Librerias importadas correctamente\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "k2xEZ4tzrUGi",
        "outputId": "cd1336d8-39ca-46a8-8267-2d5c823ec783"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<p style=\"margin:0px;\">ðŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
              "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
              "        Decision Forests</a> using the same algorithms but with more features and faster\n",
              "    training!\n",
              "</p>\n",
              "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            Old code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import tensorflow_decision_forests as tfdf\n",
              "\n",
              "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
              "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
              "model.fit(tf_ds)\n",
              "</pre>\n",
              "    </div>\n",
              "    <div style=\"width: 5px;\"></div>\n",
              "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
              "        <p\n",
              "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
              "            New code</p>\n",
              "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
              "import ydf\n",
              "\n",
              "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
              "</pre>\n",
              "    </div>\n",
              "</div>\n",
              "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
              "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
              "        guide</a>)</p>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando en CPU\n",
            "Librerias importadas correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloBodyPix:\n",
        "    \"\"\"Informacion de un modelo BodyPix\"\"\"\n",
        "    nombre: str\n",
        "    nombre_corto: str\n",
        "    path: Any  # BodyPixModelPaths enum\n",
        "    arquitectura: str\n",
        "    multiplicador: float\n",
        "    descripcion: str\n",
        "\n",
        "MODELOS_DISPONIBLES = {\n",
        "    'mobilenet_v1_050': ModeloBodyPix(\n",
        "        nombre='MobileNetV1 0.50',\n",
        "        nombre_corto='mobilenet_v1_050',\n",
        "        path=BodyPixModelPaths.MOBILENET_FLOAT_50_STRIDE_16,\n",
        "        arquitectura='MobileNetV1',\n",
        "        multiplicador=0.50,\n",
        "        descripcion='Modelo ultraligero optimizado para velocidad'\n",
        "    ),\n",
        "    'mobilenet_v1_075': ModeloBodyPix(\n",
        "        nombre='MobileNetV1 0.75',\n",
        "        nombre_corto='mobilenet_v1_075',\n",
        "        path=BodyPixModelPaths.MOBILENET_FLOAT_75_STRIDE_16,\n",
        "        arquitectura='MobileNetV1',\n",
        "        multiplicador=0.75,\n",
        "        descripcion='Balance entre velocidad y calidad de segmentacion'\n",
        "    ),\n",
        "\n",
        "    #    'resnet50': ModeloBodyPix(\n",
        "    #     nombre='ResNet50',\n",
        "    #     nombre_corto='resnet50',\n",
        "    #     arquitectura='ResNet50',\n",
        "    #     multiplicador=1.0,\n",
        "    #     path=BodyPixModelPaths.RESNET50_FLOAT_STRIDE_16,\n",
        "    #     descripcion='Maxima calidad de segmentacion disponible'\n",
        "    # )\n",
        "    # 'mobilenet_v1_100': ModeloBodyPix(\n",
        "    #     nombre='MobileNetV1 1.00',\n",
        "    #     nombre_corto='mobilenet_v1_100',\n",
        "    #     path=BodyPixModelPaths.MOBILENET_FLOAT_100_STRIDE_16,\n",
        "    #     arquitectura='MobileNetV1',\n",
        "    #     multiplicador=1.00,\n",
        "    #     descripcion='Maxima calidad de segmentacion disponible'\n",
        "    # )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionUmbrales:\n",
        "    \"\"\"\n",
        "    Configuracion de umbrales de segmentacion para BodyPix.\n",
        "\n",
        "    Los umbrales controlan que pixels se consideran como persona basandose\n",
        "    en la probabilidad de segmentacion (valores 0.0 a 1.0).\n",
        "    \"\"\"\n",
        "    nombre: str\n",
        "    valores: List[float]\n",
        "    descripcion: str\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validacion de parametros\"\"\"\n",
        "        if not all(0.0 <= v <= 1.0 for v in self.valores):\n",
        "            raise ValueError(\"Los valores de umbral deben estar entre 0.0 y 1.0\")\n",
        "\n",
        "CONFIGURACIONES_UMBRALES = {\n",
        "    'ultra_sensible': ConfiguracionUmbrales(\n",
        "        nombre='ultra_sensible',\n",
        "        valores=[0.10, 0.15, 0.20],\n",
        "        descripcion='Maxima captura de la persona - Incluye bordes suaves (~55-66% area)'\n",
        "    ),\n",
        "    'sensibilidad_alta': ConfiguracionUmbrales(\n",
        "        nombre='sensibilidad_alta',\n",
        "        valores=[0.15, 0.20, 0.25],\n",
        "        descripcion='Alta sensibilidad - Balance captura/precision (~50-60% area)'\n",
        "    ),\n",
        "    'sensibilidad_media': ConfiguracionUmbrales(\n",
        "        nombre='sensibilidad_media',\n",
        "        valores=[0.20, 0.30, 0.40],\n",
        "        descripcion='Configuracion estandar para retrato - Precision optima (~40-55% area)'\n",
        "    ),\n",
        "    'baja_sensibilidad': ConfiguracionUmbrales(\n",
        "        nombre='baja_sensibilidad',\n",
        "        valores=[0.30, 0.40, 0.50],\n",
        "        descripcion='Alta precision - Solo regiones de maxima confianza (~35-47% area)'\n",
        "    )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionEvaluacion:\n",
        "    \"\"\"Configuracion principal del sistema de evaluacion\"\"\"\n",
        "\n",
        "    # Modelos a evaluar\n",
        "    modelos_evaluar: List[str] = None  # None = todos los modelos\n",
        "\n",
        "    # Configuraciones de umbrales a evaluar\n",
        "    configs_umbrales: List[str] = None  # None = ['sensibilidad_media']\n",
        "\n",
        "    # Rutas del sistema\n",
        "    ruta_base: Path = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    ruta_imagenes: Path = None\n",
        "    ruta_salida: Path = None\n",
        "\n",
        "    # Parametros de procesamiento\n",
        "    max_dimension: int = 1024  # Dimension maxima para procesamiento\n",
        "    pausa_entre_imagenes: float = 2.0  # Segundos entre imagenes\n",
        "    pausa_entre_modelos: float = 5.0   # Segundos entre modelos\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Inicializacion de rutas por defecto\"\"\"\n",
        "        if self.ruta_imagenes is None:\n",
        "            self.ruta_imagenes = self.ruta_base / \"0_Imagenes\"\n",
        "        if self.ruta_salida is None:\n",
        "            self.ruta_salida = self.ruta_base / \"2_Modelos\" / \"bodypix\"\n",
        "        if self.modelos_evaluar is None:\n",
        "            self.modelos_evaluar = list(MODELOS_DISPONIBLES.keys())\n",
        "        if self.configs_umbrales is None:\n",
        "            self.configs_umbrales = ['sensibilidad_media']"
      ],
      "metadata": {
        "id": "GIZeVvH0rXUG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utilidades:\n",
        "    \"\"\"Utilidades para manejo de imagenes y archivos\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagen(ruta_imagen: Path, max_dimension: int = None) -> Tuple[np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Carga una imagen y la convierte a RGB.\n",
        "\n",
        "        CRÃTICO: BodyPix funciona MEJOR con imÃ¡genes grandes.\n",
        "        NO redimensionar agresivamente. Solo si es absolutamente necesario.\n",
        "\n",
        "        Args:\n",
        "            ruta_imagen: Path a la imagen\n",
        "            max_dimension: DimensiÃ³n mÃ¡xima (usar None o valor alto tipo 4096)\n",
        "\n",
        "        Returns:\n",
        "            Tuple de (img_array_RGB, metadata)\n",
        "        \"\"\"\n",
        "        # Cargar con OpenCV (BGR por defecto)\n",
        "        img_bgr = cv2.imread(str(ruta_imagen))\n",
        "\n",
        "        if img_bgr is None:\n",
        "            raise ValueError(f\"No se pudo cargar la imagen: {ruta_imagen}\")\n",
        "\n",
        "        # CRÃTICO: Convertir BGR -> RGB\n",
        "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Obtener dimensiones originales\n",
        "        alto_orig, ancho_orig = img_rgb.shape[:2]\n",
        "\n",
        "        # Redimensionar SOLO si es excesivamente grande Y max_dimension estÃ¡ definido\n",
        "        if max_dimension and max(ancho_orig, alto_orig) > max_dimension:\n",
        "            ratio = max_dimension / max(ancho_orig, alto_orig)\n",
        "            nuevo_ancho = int(ancho_orig * ratio)\n",
        "            nuevo_alto = int(alto_orig * ratio)\n",
        "            img_rgb = cv2.resize(\n",
        "                img_rgb,\n",
        "                (nuevo_ancho, nuevo_alto),\n",
        "                interpolation=cv2.INTER_AREA\n",
        "            )\n",
        "            redimensionado = True\n",
        "        else:\n",
        "            redimensionado = False\n",
        "\n",
        "        # Metadata\n",
        "        alto_proc, ancho_proc = img_rgb.shape[:2]\n",
        "        info = {\n",
        "            'ancho_original': ancho_orig,\n",
        "            'alto_original': alto_orig,\n",
        "            'ancho_procesado': ancho_proc,\n",
        "            'alto_procesado': alto_proc,\n",
        "            'redimensionado': redimensionado,\n",
        "            'factor_escala': ancho_proc / ancho_orig if redimensionado else 1.0\n",
        "        }\n",
        "\n",
        "        return img_rgb, info\n",
        "\n",
        "    @staticmethod\n",
        "    def liberar_memoria():\n",
        "        \"\"\"\n",
        "        Libera memoria y limpia sesiÃ³n de TensorFlow/Keras.\n",
        "        \"\"\"\n",
        "        import gc\n",
        "        gc.collect()\n",
        "\n",
        "        try:\n",
        "            import tensorflow as tf\n",
        "            if tf.config.list_physical_devices('GPU'):\n",
        "                tf.keras.backend.clear_session()\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Dict, ruta: Path):\n",
        "        \"\"\"\n",
        "        Guarda un diccionario como archivo JSON.\n",
        "        \"\"\"\n",
        "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash_imagen(ruta: Path) -> str:\n",
        "        \"\"\"\n",
        "        Calcula hash MD5 de una imagen.\n",
        "        \"\"\"\n",
        "        import hashlib\n",
        "        with open(ruta, 'rb') as f:\n",
        "            return hashlib.md5(f.read()).hexdigest()[:16]"
      ],
      "metadata": {
        "id": "lio8d4pDriHM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE CHECKPOINT\n",
        "# =============================================================================\n",
        "\n",
        "class GestorCheckpoint:\n",
        "    \"\"\"\n",
        "    Gestiona el estado del procesamiento para permitir reanudacion tras\n",
        "    interrupciones. Mantiene registro de imagenes completadas por combinacion\n",
        "    de modelo y configuracion de umbrales.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ruta_checkpoint: Path):\n",
        "        self.ruta_checkpoint = ruta_checkpoint\n",
        "        self.checkpoint = self._cargar()\n",
        "\n",
        "    def _cargar(self) -> Dict:\n",
        "        \"\"\"Carga checkpoint existente o crea uno nuevo\"\"\"\n",
        "        if self.ruta_checkpoint.exists():\n",
        "            with open(self.ruta_checkpoint, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {\n",
        "            'imagenes_completadas': [],\n",
        "            'fecha_inicio': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def obtener_pendientes(self, todas_imagenes: List[str]) -> set:\n",
        "        \"\"\"Retorna conjunto de imagenes pendientes de procesar\"\"\"\n",
        "        completadas = set(self.checkpoint.get('imagenes_completadas', []))\n",
        "        return set(todas_imagenes) - completadas\n",
        "\n",
        "    def marcar_completada(self, nombre_imagen: str):\n",
        "        \"\"\"Marca una imagen como completada y persiste el checkpoint\"\"\"\n",
        "        if nombre_imagen not in self.checkpoint['imagenes_completadas']:\n",
        "            self.checkpoint['imagenes_completadas'].append(nombre_imagen)\n",
        "            self.checkpoint['ultima_actualizacion'] = datetime.now().isoformat()\n",
        "            Utilidades.guardar_json(self.checkpoint, self.ruta_checkpoint)"
      ],
      "metadata": {
        "id": "qdwVZm4SrjGE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# REEMPLAZO COMPLETO DE LA CLASE GestorMascaras\n",
        "# =============================================================================\n",
        "# INSTRUCCIONES:\n",
        "# 1. Busca en tu cÃ³digo: class GestorMascaras:\n",
        "# 2. Elimina toda la clase GestorMascaras (desde class hasta el final de la clase)\n",
        "# 3. ReemplÃ¡zala por esta versiÃ³n completa\n",
        "# =============================================================================\n",
        "\n",
        "class GestorMascaras:\n",
        "    \"\"\"\n",
        "    Gestor de almacenamiento de mascaras siguiendo patron YOLO.\n",
        "\n",
        "    CAMBIO PRINCIPAL: Un archivo NPZ por umbral (como YOLO).\n",
        "\n",
        "    ESTRUCTURA DE SALIDA:\n",
        "    {foto_id}_umbral{valor}.npz con keys:\n",
        "    - person_mask: Mascara binaria principal (H, W) uint8\n",
        "    - probability_mask: Mascara de probabilidad continua (H, W) float32\n",
        "    - body_parts_mask: IDs de partes del cuerpo (H, W) int8\n",
        "    - grupo_{nombre}: Mascaras agrupadas uint8\n",
        "    \"\"\"\n",
        "\n",
        "    # Mapeo de partes del cuerpo\n",
        "    GRUPOS_PARTES_CUERPO = {\n",
        "        'cara': [0, 1],\n",
        "        'torso': [2, 3, 4, 5, 12, 13],\n",
        "        'brazos': [6, 7, 8, 9],\n",
        "        'manos': [10, 11],\n",
        "        'piernas': [14, 15, 16, 17, 18, 19, 20, 21],\n",
        "        'pies': [22, 23]\n",
        "    }\n",
        "\n",
        "    def __init__(self, directorio_mascaras: Path):\n",
        "        \"\"\"\n",
        "        Inicializa el gestor.\n",
        "\n",
        "        Args:\n",
        "            directorio_mascaras: Directorio donde guardar las mascaras\n",
        "        \"\"\"\n",
        "        self.directorio_mascaras = Path(directorio_mascaras)\n",
        "        self.directorio_mascaras.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def guardar_mascaras(\n",
        "        self,\n",
        "        mascara_probabilidad: np.ndarray,\n",
        "        umbrales: List[float],\n",
        "        nombre_imagen: str,\n",
        "        metadatos: Dict,\n",
        "        mascara_partes: Optional[np.ndarray] = None,\n",
        "        masks_por_umbral: Optional[Dict[float, np.ndarray]] = None\n",
        "    ) -> Dict[float, str]:\n",
        "        \"\"\"\n",
        "        Guarda mascaras siguiendo patron YOLO (un NPZ por umbral).\n",
        "\n",
        "        Args:\n",
        "            mascara_probabilidad: Mascara de probabilidad (H, W) float32\n",
        "            umbrales: Lista de umbrales a procesar\n",
        "            nombre_imagen: Nombre de la imagen (ej: \"_DSC0036.jpg\")\n",
        "            metadatos: Metadatos del modelo\n",
        "            mascara_partes: Mascara de partes del cuerpo (H, W) int8\n",
        "            masks_por_umbral: Dict con mascaras ya calculadas por umbral\n",
        "\n",
        "        Returns:\n",
        "            Dict con {umbral: ruta_archivo}\n",
        "        \"\"\"\n",
        "        # Extraer foto_id (sin extension)\n",
        "        foto_id = Path(nombre_imagen).stem\n",
        "\n",
        "        rutas_generadas = {}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            # Obtener mascara binaria para este umbral\n",
        "            if masks_por_umbral is not None and umbral in masks_por_umbral:\n",
        "                # BodyPix: ya calculada\n",
        "                mascara_continua = masks_por_umbral[umbral]\n",
        "                mascara_binaria = (mascara_continua > 0.5).astype(np.uint8)\n",
        "            else:\n",
        "                # Generar desde probabilidades\n",
        "                mascara_binaria = (mascara_probabilidad >= umbral).astype(np.uint8)\n",
        "\n",
        "            # Nombre de archivo siguiendo patron YOLO\n",
        "            umbral_str = str(umbral).replace('.', '_')\n",
        "            nombre_npz = f\"{foto_id}_umbral{umbral_str}.npz\"\n",
        "            ruta_completa = self.directorio_mascaras / nombre_npz\n",
        "\n",
        "            # Construir diccionario NPZ\n",
        "            datos_npz = {\n",
        "                # KEY PRINCIPAL (compatible con indice maestro Fase 1)\n",
        "                'person_mask': mascara_binaria,\n",
        "\n",
        "                # Mascara de probabilidad continua (unica para BodyPix)\n",
        "                'probability_mask': mascara_probabilidad.astype(np.float32)\n",
        "            }\n",
        "\n",
        "            # Agregar partes del cuerpo si estan disponibles\n",
        "            if mascara_partes is not None:\n",
        "                # Mascara raw con IDs de partes\n",
        "                datos_npz['body_parts_mask'] = mascara_partes.astype(np.int8)\n",
        "\n",
        "                # Mascaras agrupadas por grupos semanticos\n",
        "                for nombre_grupo, ids_partes in self.GRUPOS_PARTES_CUERPO.items():\n",
        "                    mascara_grupo = np.isin(mascara_partes, ids_partes).astype(np.uint8)\n",
        "                    datos_npz[f'grupo_{nombre_grupo}'] = mascara_grupo\n",
        "\n",
        "            # Guardar archivo NPZ comprimido\n",
        "            np.savez_compressed(ruta_completa, **datos_npz)\n",
        "\n",
        "            rutas_generadas[umbral] = str(ruta_completa)\n",
        "\n",
        "        # Retornar la ruta del primer umbral (para compatibilidad con codigo existente)\n",
        "        # Pero ahora genera multiples archivos\n",
        "        return rutas_generadas[umbrales[0]] if umbrales else None\n",
        "\n",
        "    def cargar_mascaras(self, ruta_archivo: Path) -> Dict:\n",
        "        \"\"\"\n",
        "        Carga mascaras desde un archivo NPZ.\n",
        "\n",
        "        Args:\n",
        "            ruta_archivo: Path al archivo NPZ\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con mascaras y metadatos\n",
        "        \"\"\"\n",
        "        if not Path(ruta_archivo).exists():\n",
        "            raise FileNotFoundError(f\"Archivo no encontrado: {ruta_archivo}\")\n",
        "\n",
        "        data = np.load(ruta_archivo)\n",
        "\n",
        "        # Extraer datos base\n",
        "        resultado = {\n",
        "            'person_mask': data['person_mask'],\n",
        "            'probability_mask': data['probability_mask'] if 'probability_mask' in data else None\n",
        "        }\n",
        "\n",
        "        # Extraer partes del cuerpo si existen\n",
        "        if 'body_parts_mask' in data:\n",
        "            resultado['body_parts_mask'] = data['body_parts_mask']\n",
        "\n",
        "            # Extraer grupos\n",
        "            grupos = {}\n",
        "            for nombre_grupo in self.GRUPOS_PARTES_CUERPO.keys():\n",
        "                key = f'grupo_{nombre_grupo}'\n",
        "                if key in data:\n",
        "                    grupos[nombre_grupo] = data[key]\n",
        "\n",
        "            if grupos:\n",
        "                resultado['grupos_partes'] = grupos\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def obtener_informacion_archivo(self, ruta_archivo: Path) -> Dict:\n",
        "        \"\"\"\n",
        "        Obtiene informacion basica de un archivo NPZ.\n",
        "\n",
        "        Args:\n",
        "            ruta_archivo: Path al archivo NPZ\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con metadatos del archivo\n",
        "        \"\"\"\n",
        "        if not Path(ruta_archivo).exists():\n",
        "            raise FileNotFoundError(f\"Archivo no encontrado: {ruta_archivo}\")\n",
        "\n",
        "        data = np.load(ruta_archivo)\n",
        "\n",
        "        # Extraer umbral del nombre de archivo\n",
        "        umbral = self.extraer_umbral_de_nombre(ruta_archivo.name)\n",
        "\n",
        "        info = {\n",
        "            'nombre_archivo': Path(ruta_archivo).name,\n",
        "            'umbral': umbral,\n",
        "            'dimensiones': data['person_mask'].shape if 'person_mask' in data else None,\n",
        "            'tiene_partes': 'body_parts_mask' in data,\n",
        "            'arrays_disponibles': sorted(data.files),\n",
        "            'tamaÃ±o_bytes': Path(ruta_archivo).stat().st_size\n",
        "        }\n",
        "\n",
        "        return info\n",
        "\n",
        "    def listar_archivos(self) -> List[Path]:\n",
        "        \"\"\"\n",
        "        Lista todos los archivos NPZ en el directorio.\n",
        "\n",
        "        Returns:\n",
        "            Lista de paths a archivos NPZ\n",
        "        \"\"\"\n",
        "        return sorted(self.directorio_mascaras.glob(\"*.npz\"))\n",
        "\n",
        "    def listar_archivos_por_foto(self, foto_id: str) -> Dict[float, Path]:\n",
        "        \"\"\"\n",
        "        Lista todos los archivos NPZ de una fotografia organizados por umbral.\n",
        "\n",
        "        Args:\n",
        "            foto_id: Identificador de la fotografia (sin extension)\n",
        "\n",
        "        Returns:\n",
        "            Dict con {umbral: ruta_archivo}\n",
        "        \"\"\"\n",
        "        archivos = {}\n",
        "\n",
        "        patron = f\"{foto_id}_umbral*.npz\"\n",
        "        for archivo in self.directorio_mascaras.glob(patron):\n",
        "            umbral = self.extraer_umbral_de_nombre(archivo.name)\n",
        "            if umbral is not None:\n",
        "                archivos[umbral] = archivo\n",
        "\n",
        "        return archivos\n",
        "\n",
        "    @staticmethod\n",
        "    def extraer_umbral_de_nombre(nombre_archivo: str) -> Optional[float]:\n",
        "        \"\"\"\n",
        "        Extrae el valor de umbral desde el nombre de archivo.\n",
        "\n",
        "        Args:\n",
        "            nombre_archivo: Nombre del archivo NPZ\n",
        "\n",
        "        Returns:\n",
        "            Valor del umbral o None si no se puede extraer\n",
        "\n",
        "        Ejemplo:\n",
        "            \"_DSC0036_umbral0_5.npz\" -> 0.5\n",
        "            \"_DSC0592_umbral0_75.npz\" -> 0.75\n",
        "        \"\"\"\n",
        "        if '_umbral' not in nombre_archivo:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Extraer parte del umbral\n",
        "            umbral_parte = nombre_archivo.split('_umbral')[1]\n",
        "            umbral_str = umbral_parte.replace('.npz', '')\n",
        "\n",
        "            # Reemplazar guion bajo por punto decimal\n",
        "            umbral_str = umbral_str.replace('_', '.')\n",
        "\n",
        "            return float(umbral_str)\n",
        "\n",
        "        except (IndexError, ValueError):\n",
        "            return None\n",
        "\n",
        "    def obtener_estadisticas_directorio(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Obtiene estadisticas del directorio de mascaras.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas\n",
        "        \"\"\"\n",
        "        archivos = self.listar_archivos()\n",
        "\n",
        "        if not archivos:\n",
        "            return {\n",
        "                'total_archivos': 0,\n",
        "                'tamaÃ±o_total_mb': 0.0,\n",
        "                'fotos_unicas': 0,\n",
        "                'umbrales_unicos': []\n",
        "            }\n",
        "\n",
        "        tamaÃ±o_total = sum(f.stat().st_size for f in archivos)\n",
        "\n",
        "        # Extraer fotos y umbrales unicos\n",
        "        fotos = set()\n",
        "        umbrales = set()\n",
        "\n",
        "        for archivo in archivos:\n",
        "            # Extraer foto_id (parte antes de _umbral)\n",
        "            if '_umbral' in archivo.name:\n",
        "                foto_id = archivo.name.split('_umbral')[0]\n",
        "                fotos.add(foto_id)\n",
        "\n",
        "            # Extraer umbral\n",
        "            umbral = self.extraer_umbral_de_nombre(archivo.name)\n",
        "            if umbral is not None:\n",
        "                umbrales.add(umbral)\n",
        "\n",
        "        return {\n",
        "            'total_archivos': len(archivos),\n",
        "            'tamaÃ±o_total_mb': round(tamaÃ±o_total / (1024 * 1024), 2),\n",
        "            'fotos_unicas': len(fotos),\n",
        "            'umbrales_unicos': sorted(list(umbrales)),\n",
        "            'directorio': str(self.directorio_mascaras)\n",
        "        }\n"
      ],
      "metadata": {
        "id": "tTHJrjRTrmOG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE VISUALIZACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizaciones:\n",
        "    \"\"\"Genera visualizaciones estandarizadas de resultados de segmentacion\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generar_visualizacion(\n",
        "        imagen: np.ndarray,\n",
        "        mascara_probabilidad: np.ndarray,\n",
        "        umbral_vis: float,\n",
        "        ruta_salida: Path,\n",
        "        titulo: str\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Genera visualizacion de 2 paneles: imagen original y segmentacion.\n",
        "\n",
        "        Args:\n",
        "            imagen: Array RGB de la imagen original\n",
        "            mascara_probabilidad: Mascara de probabilidad (0.0-1.0)\n",
        "            umbral_vis: Umbral usado para la visualizacion\n",
        "            ruta_salida: Path donde guardar la visualizacion\n",
        "            titulo: Titulo para la figura\n",
        "        \"\"\"\n",
        "        ruta_salida.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "        # Panel 1: Imagen original\n",
        "        axes[0].imshow(imagen)\n",
        "        axes[0].set_title('Imagen Original', fontsize=12, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        # Panel 2: Segmentacion con overlay\n",
        "        axes[1].imshow(imagen)\n",
        "\n",
        "        # Aplicar umbral para visualizacion\n",
        "        mascara_binaria = mascara_probabilidad >= umbral_vis\n",
        "\n",
        "        # Crear overlay verde semi-transparente para persona\n",
        "        overlay = np.zeros_like(imagen)\n",
        "        overlay[mascara_binaria] = [0, 255, 0]\n",
        "\n",
        "        axes[1].imshow(overlay, alpha=0.4)\n",
        "        axes[1].set_title(\n",
        "            f'Segmentacion (umbral={umbral_vis})',\n",
        "            fontsize=12,\n",
        "            fontweight='bold'\n",
        "        )\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        # Calcular y mostrar estadisticas\n",
        "        area_persona = mascara_binaria.sum()\n",
        "        area_total = mascara_binaria.size\n",
        "        porcentaje = (area_persona / area_total) * 100\n",
        "\n",
        "        info_text = f\"Area persona: {porcentaje:.1f}%\\n\"\n",
        "        info_text += f\"Pixels: {area_persona:,} / {area_total:,}\"\n",
        "\n",
        "        axes[1].text(\n",
        "            0.02, 0.98, info_text,\n",
        "            transform=axes[1].transAxes,\n",
        "            verticalalignment='top',\n",
        "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),\n",
        "            fontsize=10,\n",
        "            family='monospace'\n",
        "        )\n",
        "\n",
        "        plt.suptitle(titulo, fontsize=14, fontweight='bold')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(ruta_salida, dpi=100, bbox_inches='tight')\n",
        "        plt.close()\n"
      ],
      "metadata": {
        "id": "zBVGg32Kr9XI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProcesadorBodyPix:\n",
        "    \"\"\"\n",
        "    Procesador para BodyPix - VERSIÃ“N DEFINITIVA CON DEBUG DE PARTES\n",
        "\n",
        "    MODIFICADO: Ahora sigue patrÃ³n YOLO para almacenamiento NPZ.\n",
        "    - Un archivo NPZ por fotografÃ­a Y por umbral\n",
        "    - Nomenclatura: {foto_id}_umbral{valor}.npz\n",
        "    - Key principal: 'person_mask' (compatible con Ã­ndice maestro)\n",
        "\n",
        "    Procesa imÃ¡genes SIN redimensionar (BodyPix funciona mejor con imÃ¡genes grandes).\n",
        "    Los valores de get_mask() son 0-1 (int32), NO 0-255.\n",
        "    Incluye debug detallado de partes del cuerpo detectadas.\n",
        "    \"\"\"\n",
        "\n",
        "    # Mapeo de IDs de partes del cuerpo de BodyPix\n",
        "    BODYPIX_PART_IDS = {\n",
        "        -1: 'fondo',\n",
        "        0: 'left_face',\n",
        "        1: 'right_face',\n",
        "        2: 'left_upper_arm_front',\n",
        "        3: 'left_upper_arm_back',\n",
        "        4: 'right_upper_arm_front',\n",
        "        5: 'right_upper_arm_back',\n",
        "        6: 'left_lower_arm_front',\n",
        "        7: 'left_lower_arm_back',\n",
        "        8: 'right_lower_arm_front',\n",
        "        9: 'right_lower_arm_back',\n",
        "        10: 'left_hand',\n",
        "        11: 'right_hand',\n",
        "        12: 'torso_front',\n",
        "        13: 'torso_back',\n",
        "        14: 'left_upper_leg_front',\n",
        "        15: 'left_upper_leg_back',\n",
        "        16: 'right_upper_leg_front',\n",
        "        17: 'right_upper_leg_back',\n",
        "        18: 'left_lower_leg_front',\n",
        "        19: 'left_lower_leg_back',\n",
        "        20: 'right_lower_leg_front',\n",
        "        21: 'right_lower_leg_back',\n",
        "        22: 'left_foot',\n",
        "        23: 'right_foot'\n",
        "    }\n",
        "\n",
        "    def __init__(self, modelo_info: ModeloBodyPix, config: ConfiguracionEvaluacion):\n",
        "        \"\"\"\n",
        "        Inicializa el procesador.\n",
        "\n",
        "        Args:\n",
        "            modelo_info: InformaciÃ³n del modelo BodyPix\n",
        "            config: ConfiguraciÃ³n de evaluaciÃ³n\n",
        "        \"\"\"\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config = config\n",
        "        self.model = None\n",
        "\n",
        "    def cargar_modelo(self):\n",
        "        \"\"\"\n",
        "        Descarga y carga el modelo BodyPix.\n",
        "        \"\"\"\n",
        "        print(f\"  Cargando modelo {self.modelo_info.nombre}...\")\n",
        "        model_path = download_model(self.modelo_info.path)\n",
        "        self.model = load_model(model_path)\n",
        "        print(f\"  Modelo cargado correctamente\")\n",
        "\n",
        "    def procesar_imagen(\n",
        "        self,\n",
        "        img_path: Path,\n",
        "        umbrales: List[float],\n",
        "        ruta_salida: Path\n",
        "    ) -> Tuple[Dict, np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Procesa una imagen con BodyPix.\n",
        "\n",
        "        MODIFICADO: Ahora genera un NPZ por umbral siguiendo patrÃ³n YOLO.\n",
        "\n",
        "        Args:\n",
        "            img_path: Path a la imagen a procesar\n",
        "            umbrales: Lista de umbrales de segmentaciÃ³n\n",
        "            ruta_salida: Directorio base para resultados\n",
        "\n",
        "        Returns:\n",
        "            Tupla (resultado_dict, imagen_array, mascara_probabilidad)\n",
        "\n",
        "        CRÃTICO: NO redimensionar agresivamente. BodyPix funciona mejor con imÃ¡genes grandes.\n",
        "        Los valores de get_mask() son 0-1 (int32), NO 0-255.\n",
        "        \"\"\"\n",
        "        # Cargar imagen SIN redimensionar (o con lÃ­mite muy alto)\n",
        "        img_array, info_img = Utilidades.cargar_imagen(img_path, max_dimension=4096)\n",
        "\n",
        "        print(f\"    Input - Shape: {img_array.shape}, \"\n",
        "              f\"Dtype: {img_array.dtype}, \"\n",
        "              f\"Range: [{img_array.min()}, {img_array.max()}]\")\n",
        "\n",
        "        # Tiempo total de inferencia\n",
        "        tiempo_total_inicio = time.time()\n",
        "\n",
        "        # Una inferencia por cada umbral (limitaciÃ³n de tf-bodypix)\n",
        "        print(f\"    Procesando {len(umbrales)} umbrales (inferencia por umbral)\")\n",
        "        masks_por_umbral = {}\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            # Inferencia para cada umbral\n",
        "            result = self.model.predict_single(img_array)\n",
        "\n",
        "            # Obtener mÃ¡scara\n",
        "            mask_raw = result.get_mask(threshold=umbral)\n",
        "\n",
        "            # Convertir a numpy\n",
        "            if hasattr(mask_raw, 'numpy'):\n",
        "                mask_np = mask_raw.numpy()\n",
        "            else:\n",
        "                mask_np = np.array(mask_raw)\n",
        "\n",
        "            # Shape (H, W, 1) -> (H, W)\n",
        "            if mask_np.ndim == 3:\n",
        "                mask_np = mask_np[:, :, 0]\n",
        "\n",
        "            # Los valores YA son 0-1 (int32), NO dividir por 255\n",
        "            mask_norm = mask_np.astype(np.float32)\n",
        "            masks_por_umbral[umbral] = mask_norm\n",
        "\n",
        "            # Limpiar\n",
        "            del result\n",
        "\n",
        "        tiempo_inferencia_ms = (time.time() - tiempo_total_inicio) * 1000\n",
        "        print(f\"    Inferencia completada en {tiempo_inferencia_ms:.1f}ms\")\n",
        "\n",
        "        # Usar umbral medio como referencia\n",
        "        umbral_medio = umbrales[len(umbrales) // 2]\n",
        "        mascara_probabilidad = masks_por_umbral[umbral_medio]\n",
        "\n",
        "        # EstadÃ­sticas\n",
        "        area_persona = (mascara_probabilidad > 0.5).sum()\n",
        "        area_total = mascara_probabilidad.size\n",
        "        porcentaje = (area_persona / area_total) * 100\n",
        "\n",
        "        print(f\"    MÃ¡scara (umbral={umbral_medio}) - \"\n",
        "              f\"Ãrea: {porcentaje:.1f}% \"\n",
        "              f\"({area_persona:,} / {area_total:,} pixels)\")\n",
        "\n",
        "        # Partes del cuerpo\n",
        "        mascara_partes = None\n",
        "        try:\n",
        "            # Inferencia para partes\n",
        "            result_parts = self.model.predict_single(img_array)\n",
        "            mask_for_parts = result_parts.get_mask(threshold=umbral_medio)\n",
        "\n",
        "            if hasattr(mask_for_parts, 'numpy'):\n",
        "                mask_for_parts = mask_for_parts.numpy()\n",
        "            else:\n",
        "                mask_for_parts = np.array(mask_for_parts)\n",
        "\n",
        "            if mask_for_parts.ndim == 3:\n",
        "                mask_for_parts = mask_for_parts[:, :, 0]\n",
        "\n",
        "            # Valores son 0-1, convertir a 0-255 para get_part_mask\n",
        "            mask_for_parts_255 = (mask_for_parts * 255).astype(np.uint8)\n",
        "\n",
        "            parts_raw = result_parts.get_part_mask(mask_for_parts_255)\n",
        "\n",
        "            if hasattr(parts_raw, 'numpy'):\n",
        "                parts_raw = parts_raw.numpy()\n",
        "            else:\n",
        "                parts_raw = np.array(parts_raw)\n",
        "\n",
        "            if parts_raw.ndim == 3:\n",
        "                parts_raw = parts_raw[:, :, 0]\n",
        "\n",
        "            mascara_partes = parts_raw.astype(np.int8)\n",
        "\n",
        "            # DEBUG DETALLADO de partes\n",
        "            self._debug_partes_detectadas(mascara_partes)\n",
        "\n",
        "            del result_parts\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    Sin partes del cuerpo: {str(e)}\")\n",
        "\n",
        "        # =====================================================================\n",
        "        # MODIFICADO: Guardar mÃ¡scaras siguiendo patrÃ³n YOLO\n",
        "        # =====================================================================\n",
        "        gestor_mascaras = GestorMascaras(ruta_salida / \"mascaras\")\n",
        "        archivo_npz = gestor_mascaras.guardar_mascaras(\n",
        "            mascara_probabilidad,\n",
        "            umbrales,\n",
        "            img_path.name,\n",
        "            {'nombre_corto': self.modelo_info.nombre_corto},\n",
        "            mascara_partes=mascara_partes,\n",
        "            masks_por_umbral=masks_por_umbral\n",
        "        )\n",
        "        # Ahora guardar_mascaras() retorna la primera ruta para compatibilidad\n",
        "        # pero internamente genera mÃºltiples archivos NPZ (uno por umbral)\n",
        "\n",
        "        # =====================================================================\n",
        "        # MODIFICADO: Procesar resultados por umbral con rutas individuales\n",
        "        # =====================================================================\n",
        "        detecciones_por_umbral = {}\n",
        "        foto_id = Path(img_path.name).stem\n",
        "\n",
        "        for umbral in umbrales:\n",
        "            mask = masks_por_umbral[umbral]\n",
        "            mascara_binaria = (mask > 0.5).astype(np.uint8)\n",
        "            area_persona = int(mascara_binaria.sum())\n",
        "            area_total = mascara_binaria.size\n",
        "            porcentaje_imagen = (area_persona / area_total) * 100\n",
        "            persona_detectada = porcentaje_imagen >= 5.0\n",
        "\n",
        "            # Construir ruta individual del NPZ para este umbral\n",
        "            umbral_str = str(umbral).replace('.', '_')\n",
        "            nombre_npz = f\"{foto_id}_umbral{umbral_str}.npz\"\n",
        "            ruta_npz_umbral = str(ruta_salida / \"mascaras\" / nombre_npz)\n",
        "\n",
        "            detecciones_por_umbral[f'umbral_{umbral}'] = {\n",
        "                'umbral_usado': umbral,\n",
        "                'persona_detectada': persona_detectada,\n",
        "                'area_pixels': area_persona,\n",
        "                'area_total_pixels': area_total,\n",
        "                'porcentaje_imagen': round(porcentaje_imagen, 2),\n",
        "                'probabilidad_media_region': float(\n",
        "                    mask[mascara_binaria > 0].mean()\n",
        "                    if area_persona > 0 else 0.0\n",
        "                ),\n",
        "                # NUEVO: Incluir ruta del NPZ especÃ­fico de este umbral\n",
        "                'ruta_mascara_npz': ruta_npz_umbral\n",
        "            }\n",
        "\n",
        "        # EstadÃ­sticas de partes\n",
        "        info_partes_cuerpo = None\n",
        "        if mascara_partes is not None:\n",
        "            info_partes_cuerpo = self._calcular_estadisticas_partes(\n",
        "                mascara_partes,\n",
        "                mascara_probabilidad\n",
        "            )\n",
        "\n",
        "        # =====================================================================\n",
        "        # MODIFICADO: Resultado con nueva estructura de archivos generados\n",
        "        # =====================================================================\n",
        "        resultado = {\n",
        "            'metadata': {\n",
        "                'imagen': {\n",
        "                    'nombre': img_path.name,\n",
        "                    'ruta': str(img_path),\n",
        "                    **info_img\n",
        "                },\n",
        "                'modelo': {\n",
        "                    'nombre': self.modelo_info.nombre,\n",
        "                    'nombre_corto': self.modelo_info.nombre_corto,\n",
        "                    'arquitectura': self.modelo_info.arquitectura,\n",
        "                    'multiplicador': self.modelo_info.multiplicador\n",
        "                },\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'tiempo_inferencia_ms': round(tiempo_inferencia_ms, 2),\n",
        "                'nota': 'BodyPix procesado con imÃ¡genes a resoluciÃ³n completa'\n",
        "            },\n",
        "            'archivos_generados': {\n",
        "                # MODIFICADO: Ahora las rutas estÃ¡n en detecciones_por_umbral\n",
        "                'patron_archivos': f'{foto_id}_umbral*.npz',\n",
        "                'num_archivos_npz': len(umbrales),\n",
        "                'nota': 'Rutas NPZ individuales en detecciones_por_umbral[umbral_X][\"ruta_mascara_npz\"]'\n",
        "            },\n",
        "            'detecciones_por_umbral': detecciones_por_umbral,\n",
        "            'partes_cuerpo': info_partes_cuerpo\n",
        "        }\n",
        "\n",
        "        return resultado, img_array, mascara_probabilidad\n",
        "\n",
        "    def _debug_partes_detectadas(self, mascara_partes: np.ndarray):\n",
        "        \"\"\"\n",
        "        Imprime debug detallado de las partes del cuerpo detectadas.\n",
        "\n",
        "        Args:\n",
        "            mascara_partes: Array (H, W) con IDs de partes del cuerpo\n",
        "        \"\"\"\n",
        "        partes_unicas = np.unique(mascara_partes)\n",
        "        area_total = mascara_partes.size\n",
        "\n",
        "        print(f\"    Partes detectadas ({len(partes_unicas)} tipos):\")\n",
        "\n",
        "        for part_id in partes_unicas:\n",
        "            nombre = self.BODYPIX_PART_IDS.get(int(part_id), f'desconocida_{part_id}')\n",
        "            area = (mascara_partes == part_id).sum()\n",
        "            pct = (area / area_total) * 100\n",
        "\n",
        "            # Solo mostrar partes significativas (>0.1% del Ã¡rea)\n",
        "            if pct > 0.1:\n",
        "                print(f\"      ID {part_id:2d}: {nombre:25s} - {pct:5.2f}% ({area:,} px)\")\n",
        "\n",
        "    def _calcular_estadisticas_partes(\n",
        "        self,\n",
        "        mascara_partes: np.ndarray,\n",
        "        mascara_probabilidad: np.ndarray\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula estadÃ­sticas de partes del cuerpo detectadas.\n",
        "\n",
        "        Retorna tanto estadÃ­sticas individuales como por grupos semÃ¡nticos.\n",
        "\n",
        "        Args:\n",
        "            mascara_partes: Array (H, W) con IDs de partes\n",
        "            mascara_probabilidad: Array (H, W) con probabilidades\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadÃ­sticas detalladas de partes\n",
        "        \"\"\"\n",
        "        # Normalizar dimensiones\n",
        "        if mascara_probabilidad.ndim == 3:\n",
        "            mascara_probabilidad = mascara_probabilidad[:, :, 0]\n",
        "\n",
        "        if mascara_partes.ndim == 3:\n",
        "            mascara_partes = mascara_partes[:, :, 0]\n",
        "\n",
        "        area_total = mascara_partes.size\n",
        "\n",
        "        # EstadÃ­sticas por parte individual\n",
        "        partes_individuales = {}\n",
        "        for part_id in np.unique(mascara_partes):\n",
        "            if part_id == -1:  # Skip fondo\n",
        "                continue\n",
        "\n",
        "            mascara_parte = (mascara_partes == part_id)\n",
        "            area_parte = int(mascara_parte.sum())\n",
        "\n",
        "            if area_parte > 0:\n",
        "                nombre = self.BODYPIX_PART_IDS.get(int(part_id), f'parte_{part_id}')\n",
        "                prob_media = float(mascara_probabilidad[mascara_parte].mean())\n",
        "\n",
        "                partes_individuales[nombre] = {\n",
        "                    'id': int(part_id),\n",
        "                    'area_pixels': area_parte,\n",
        "                    'porcentaje_imagen': round((area_parte / area_total) * 100, 2),\n",
        "                    'probabilidad_media': round(prob_media, 3)\n",
        "                }\n",
        "\n",
        "        # EstadÃ­sticas por grupos semÃ¡nticos\n",
        "        grupos_detectados = {}\n",
        "        for nombre_grupo, ids_partes in GestorMascaras.GRUPOS_PARTES_CUERPO.items():\n",
        "            mascara_grupo = np.isin(mascara_partes, ids_partes)\n",
        "            area_grupo = int(mascara_grupo.sum())\n",
        "\n",
        "            if area_grupo > 0:\n",
        "                prob_media = float(mascara_probabilidad[mascara_grupo].mean())\n",
        "\n",
        "                grupos_detectados[nombre_grupo] = {\n",
        "                    'area_pixels': area_grupo,\n",
        "                    'porcentaje_imagen': round((area_grupo / area_total) * 100, 2),\n",
        "                    'probabilidad_media': round(prob_media, 3)\n",
        "                }\n",
        "\n",
        "        return {\n",
        "            'partes_individuales': partes_individuales,\n",
        "            'grupos_semanticos': grupos_detectados,\n",
        "            'num_partes_detectadas': len(partes_individuales),\n",
        "            'num_grupos_detectados': len(grupos_detectados),\n",
        "            'grupos_disponibles': list(GestorMascaras.GRUPOS_PARTES_CUERPO.keys())\n",
        "        }\n",
        "\n",
        "    def limpiar_memoria(self):\n",
        "        \"\"\"\n",
        "        Libera recursos del modelo y memoria.\n",
        "        \"\"\"\n",
        "        if self.model is not None:\n",
        "            del self.model\n",
        "            self.model = None\n",
        "        Utilidades.liberar_memoria()"
      ],
      "metadata": {
        "id": "9dzgPFYAr_p-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorBodyPix:\n",
        "    \"\"\"\n",
        "    Evaluador principal que coordina el procesamiento de todos los modelos\n",
        "    y configuraciones de umbrales.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionEvaluacion):\n",
        "        self.config = config\n",
        "\n",
        "    def evaluar_modelo_con_config_umbrales(\n",
        "        self,\n",
        "        modelo_key: str,\n",
        "        config_umbral_nombre: str,\n",
        "        imagenes: List[Path]\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Evalua un modelo con una configuracion de umbrales especifica.\n",
        "\n",
        "        Args:\n",
        "            modelo_key: Identificador del modelo a evaluar\n",
        "            config_umbral_nombre: Nombre de la configuracion de umbrales\n",
        "            imagenes: Lista de paths a imagenes\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas del procesamiento\n",
        "        \"\"\"\n",
        "        modelo_info = MODELOS_DISPONIBLES[modelo_key]\n",
        "        umbrales_config = CONFIGURACIONES_UMBRALES[config_umbral_nombre]\n",
        "\n",
        "        # Estructura IGUAL que SAM2: /modelo/config/ (sin \"resultados\")\n",
        "        ruta_salida = (\n",
        "            self.config.ruta_salida /\n",
        "            modelo_info.nombre_corto /\n",
        "            config_umbral_nombre\n",
        "        )\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"MODELO: {modelo_info.nombre}\")\n",
        "        print(f\"UMBRALES: {umbrales_config.nombre} - {umbrales_config.valores}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Sistema de checkpoint\n",
        "        checkpoint = GestorCheckpoint(ruta_salida / \"checkpoint.json\")\n",
        "        nombres_imgs = [img.name for img in imagenes]\n",
        "        pendientes = checkpoint.obtener_pendientes(nombres_imgs)\n",
        "        imgs_procesar = [img for img in imagenes if img.name in pendientes]\n",
        "\n",
        "        print(f\"Progreso: {len(imagenes) - len(imgs_procesar)}/{len(imagenes)} completadas\")\n",
        "        print(f\"Pendientes: {len(imgs_procesar)}\")\n",
        "\n",
        "        if len(imgs_procesar) == 0:\n",
        "            print(\"Todas las imagenes ya procesadas\")\n",
        "            return {'procesadas': 0}\n",
        "\n",
        "        # Cargar modelo\n",
        "        procesador = ProcesadorBodyPix(modelo_info, self.config)\n",
        "        procesador.cargar_modelo()\n",
        "\n",
        "        # Procesar imagenes pendientes\n",
        "        tiempo_inicio = time.time()\n",
        "\n",
        "        for i, img_path in enumerate(imgs_procesar, 1):\n",
        "            print(f\"\\n[{i}/{len(imgs_procesar)}] {img_path.name}\")\n",
        "\n",
        "            try:\n",
        "                # Procesar imagen\n",
        "                resultado, img_array, mascara_prob = procesador.procesar_imagen(\n",
        "                    img_path,\n",
        "                    umbrales_config.valores,\n",
        "                    ruta_salida\n",
        "                )\n",
        "\n",
        "                # Guardar JSON\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                nombre_json = f\"{img_path.stem}_{timestamp}.json\"\n",
        "                ruta_json = ruta_salida / \"json\" / nombre_json\n",
        "                Utilidades.guardar_json(resultado, ruta_json)\n",
        "\n",
        "                # Generar visualizacion (umbral medio)\n",
        "                umbral_vis = umbrales_config.valores[len(umbrales_config.valores)//2]\n",
        "                nombre_vis = f\"{img_path.stem}_{timestamp}.png\"\n",
        "                ruta_vis = ruta_salida / \"visualizaciones\" / nombre_vis\n",
        "\n",
        "                GeneradorVisualizaciones.generar_visualizacion(\n",
        "                    img_array,\n",
        "                    mascara_prob,\n",
        "                    umbral_vis,\n",
        "                    ruta_vis,\n",
        "                    f\"{modelo_info.nombre_corto} - {umbrales_config.nombre}\"\n",
        "                )\n",
        "\n",
        "                # Marcar como completada\n",
        "                checkpoint.marcar_completada(img_path.name)\n",
        "\n",
        "                # Resumen\n",
        "                umbral_medio_key = f'umbral_{umbral_vis}'\n",
        "                persona_det = resultado['detecciones_por_umbral'][umbral_medio_key]['persona_detectada']\n",
        "                print(f\"  Completada - Persona detectada: {'Si' if persona_det else 'No'}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"  ERROR: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "            finally:\n",
        "                Utilidades.liberar_memoria()\n",
        "                if i < len(imgs_procesar):\n",
        "                    time.sleep(self.config.pausa_entre_imagenes)\n",
        "\n",
        "        tiempo_total = time.time() - tiempo_inicio\n",
        "\n",
        "        # Limpiar modelo\n",
        "        procesador.limpiar_memoria()\n",
        "\n",
        "        print(f\"\\nConfiguracion completada en {tiempo_total:.1f}s\")\n",
        "\n",
        "        return {\n",
        "            'procesadas': len(imgs_procesar),\n",
        "            'tiempo_segundos': round(tiempo_total, 2)\n",
        "        }\n",
        "\n",
        "    def ejecutar(self):\n",
        "        \"\"\"Ejecuta la evaluacion completa de todos los modelos y configuraciones\"\"\"\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"EVALUADOR BODYPIX\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Modelos: {len(self.config.modelos_evaluar)}\")\n",
        "        for modelo_key in self.config.modelos_evaluar:\n",
        "            modelo = MODELOS_DISPONIBLES[modelo_key]\n",
        "            print(f\"  - {modelo.nombre} (multiplicador {modelo.multiplicador})\")\n",
        "\n",
        "        print(f\"\\nConfiguraciones de umbrales: {len(self.config.configs_umbrales)}\")\n",
        "        for config_name in self.config.configs_umbrales:\n",
        "            umbrales = CONFIGURACIONES_UMBRALES[config_name]\n",
        "            print(f\"  - {config_name}: {umbrales.valores}\")\n",
        "\n",
        "        print(f\"\\nDirectorio de imagenes: {self.config.ruta_imagenes}\")\n",
        "        print(f\"Directorio de resultados: {self.config.ruta_salida}\")\n",
        "\n",
        "        # Cargar imagenes\n",
        "        imagenes = []\n",
        "        for extension in ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']:\n",
        "            imagenes.extend(sorted(self.config.ruta_imagenes.glob(extension)))\n",
        "        imagenes = sorted(set(imagenes))\n",
        "\n",
        "        print(f\"\\nTotal imagenes encontradas: {len(imagenes)}\")\n",
        "\n",
        "        if not imagenes:\n",
        "            print(\"ERROR: No se encontraron imagenes en el directorio\")\n",
        "            return\n",
        "\n",
        "        # Evaluar cada combinacion de modelo + configuracion\n",
        "        total_combinaciones = (\n",
        "            len(self.config.modelos_evaluar) *\n",
        "            len(self.config.configs_umbrales)\n",
        "        )\n",
        "        combinacion_actual = 0\n",
        "\n",
        "        for modelo_key in self.config.modelos_evaluar:\n",
        "            for config_umbral in self.config.configs_umbrales:\n",
        "                combinacion_actual += 1\n",
        "\n",
        "                print(f\"\\n{'#'*80}\")\n",
        "                print(f\"COMBINACION {combinacion_actual}/{total_combinaciones}\")\n",
        "                print(f\"{'#'*80}\")\n",
        "\n",
        "                self.evaluar_modelo_con_config_umbrales(\n",
        "                    modelo_key,\n",
        "                    config_umbral,\n",
        "                    imagenes\n",
        "                )\n",
        "\n",
        "                if combinacion_actual < total_combinaciones:\n",
        "                    print(f\"\\nPausa entre configuraciones: {self.config.pausa_entre_modelos}s\")\n",
        "                    time.sleep(self.config.pausa_entre_modelos)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"EVALUACION COMPLETADA\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Resultados guardados en: {self.config.ruta_salida}\")"
      ],
      "metadata": {
        "id": "YIuvm63xsI8W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EJECUCION PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    # Configurar evaluacion\n",
        "    config = ConfiguracionEvaluacion(\n",
        "        # Seleccionar [modelos] (None = todos los 3)\n",
        "        modelos_evaluar= None,\n",
        "\n",
        "        # Seleccionar configuraciones de umbrales\n",
        "        configs_umbrales=[\n",
        "            'ultra_sensible',\n",
        "            'sensibilidad_alta',\n",
        "            'sensibilidad_media',\n",
        "            'baja_sensibilidad'\n",
        "        ],\n",
        "\n",
        "        # Parametros de procesamiento\n",
        "        max_dimension=1024,\n",
        "        pausa_entre_imagenes=2.0,\n",
        "        pausa_entre_modelos=5.0\n",
        "    )\n",
        "\n",
        "    # Ejecutar evaluacion\n",
        "    evaluador = EvaluadorBodyPix(config)\n",
        "    evaluador.ejecutar()"
      ],
      "metadata": {
        "id": "Tsx-O2iJsQHQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyy0Yo1ZsTVE",
        "outputId": "af9b9497-90bb-407b-fb14-3effb86fad60"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EVALUADOR BODYPIX\n",
            "================================================================================\n",
            "Modelos: 2\n",
            "  - MobileNetV1 0.50 (multiplicador 0.5)\n",
            "  - MobileNetV1 0.75 (multiplicador 0.75)\n",
            "\n",
            "Configuraciones de umbrales: 4\n",
            "  - ultra_sensible: [0.1, 0.15, 0.2]\n",
            "  - sensibilidad_alta: [0.15, 0.2, 0.25]\n",
            "  - sensibilidad_media: [0.2, 0.3, 0.4]\n",
            "  - baja_sensibilidad: [0.3, 0.4, 0.5]\n",
            "\n",
            "Directorio de imagenes: /content/drive/MyDrive/TFM/0_Imagenes\n",
            "Directorio de resultados: /content/drive/MyDrive/TFM/2_Modelos/bodypix\n",
            "\n",
            "Total imagenes encontradas: 20\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 1/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: ultra_sensible - [0.1, 0.15, 0.2]\n",
            "================================================================================\n",
            "Progreso: 20/20 completadas\n",
            "Pendientes: 0\n",
            "Todas las imagenes ya procesadas\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 2/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: sensibilidad_alta - [0.15, 0.2, 0.25]\n",
            "================================================================================\n",
            "Progreso: 20/20 completadas\n",
            "Pendientes: 0\n",
            "Todas las imagenes ya procesadas\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 3/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: sensibilidad_media - [0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "Progreso: 20/20 completadas\n",
            "Pendientes: 0\n",
            "Todas las imagenes ya procesadas\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 4/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.50\n",
            "UMBRALES: baja_sensibilidad - [0.3, 0.4, 0.5]\n",
            "================================================================================\n",
            "Progreso: 20/20 completadas\n",
            "Pendientes: 0\n",
            "Todas las imagenes ya procesadas\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 5/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: ultra_sensible - [0.1, 0.15, 0.2]\n",
            "================================================================================\n",
            "Progreso: 18/20 completadas\n",
            "Pendientes: 2\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/2] _DSC0962.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4186.0ms\n",
            "    MÃ¡scara (umbral=0.15) - Ãrea: 37.0% (4,139,114 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 36.96% (4,139,114 px)\n",
            "      ID  0: left_face                 - 63.04% (7,059,350 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[2/2] _DSC0987.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3453.4ms\n",
            "    MÃ¡scara (umbral=0.15) - Ãrea: 63.0% (7,049,663 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 62.95% (7,049,663 px)\n",
            "      ID  0: left_face                 - 37.05% (4,148,801 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "Configuracion completada en 28.8s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 6/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: sensibilidad_alta - [0.15, 0.2, 0.25]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4256.9ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 68.3% (7,643,506 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 68.25% (7,643,506 px)\n",
            "      ID  0: left_face                 - 31.75% (3,554,958 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3483.0ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 48.9% (5,481,465 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 48.95% (5,481,465 px)\n",
            "      ID  0: left_face                 - 51.05% (5,716,999 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3506.5ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 41.8% (4,686,182 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 41.85% (4,686,182 px)\n",
            "      ID  0: left_face                 - 58.15% (6,512,282 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3458.1ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 81.8% (9,164,667 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 81.84% (9,164,667 px)\n",
            "      ID  0: left_face                 - 18.16% (2,033,797 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3843.0ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 25.9% (2,901,137 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 25.91% (2,901,137 px)\n",
            "      ID  0: left_face                 - 74.09% (8,297,327 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4947.6ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 23.2% (2,603,268 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 23.25% (2,603,268 px)\n",
            "      ID  0: left_face                 - 76.75% (8,595,196 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4751.7ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 34.2% (3,828,682 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 34.19% (3,828,682 px)\n",
            "      ID  0: left_face                 - 65.81% (7,369,782 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [11, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3574.4ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 36.5% (4,092,276 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 36.54% (4,092,276 px)\n",
            "      ID  0: left_face                 - 63.46% (7,106,188 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3532.6ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 47.6% (5,334,811 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.64% (5,334,811 px)\n",
            "      ID  0: left_face                 - 52.36% (5,863,653 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [20, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3479.6ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 20.7% (2,323,065 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 20.74% (2,323,065 px)\n",
            "      ID  0: left_face                 - 79.26% (8,875,399 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3588.5ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 47.4% (5,305,766 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.38% (5,305,766 px)\n",
            "      ID  0: left_face                 - 52.62% (5,892,698 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4145.1ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 51.4% (5,754,223 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 51.38% (5,754,223 px)\n",
            "      ID  0: left_face                 - 48.62% (5,444,241 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4881.4ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 34.3% (3,843,633 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 34.32% (3,843,633 px)\n",
            "      ID  0: left_face                 - 65.68% (7,354,831 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4378.1ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 57.3% (6,414,018 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 57.28% (6,414,018 px)\n",
            "      ID  0: left_face                 - 42.72% (4,784,446 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [3, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3568.6ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 37.1% (4,149,838 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 37.06% (4,149,838 px)\n",
            "      ID  0: left_face                 - 62.94% (7,048,626 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3445.8ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 40.1% (4,487,804 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 40.08% (4,487,804 px)\n",
            "      ID  0: left_face                 - 59.92% (6,710,660 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3440.8ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 30.4% (3,400,618 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 30.37% (3,400,618 px)\n",
            "      ID  0: left_face                 - 69.63% (7,797,846 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    Input - Shape: (4096, 2730, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3684.1ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 55.9% (6,247,485 / 11,182,080 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 55.87% (6,247,485 px)\n",
            "      ID  0: left_face                 - 44.13% (4,934,595 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4908.2ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 32.4% (3,627,551 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 32.39% (3,627,551 px)\n",
            "      ID  0: left_face                 - 67.61% (7,570,913 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4761.5ms\n",
            "    MÃ¡scara (umbral=0.2) - Ãrea: 56.0% (6,268,985 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 55.98% (6,268,985 px)\n",
            "      ID  0: left_face                 - 44.02% (4,929,479 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "Configuracion completada en 304.0s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 7/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: sensibilidad_media - [0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3580.7ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 62.8% (7,036,457 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 62.83% (7,036,457 px)\n",
            "      ID  0: left_face                 - 37.17% (4,162,007 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3583.7ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 47.0% (5,263,992 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.01% (5,263,992 px)\n",
            "      ID  0: left_face                 - 52.99% (5,934,472 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4464.2ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 35.4% (3,967,323 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 35.43% (3,967,323 px)\n",
            "      ID  0: left_face                 - 64.57% (7,231,141 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4961.4ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 78.0% (8,738,637 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 78.03% (8,738,637 px)\n",
            "      ID  0: left_face                 - 21.97% (2,459,827 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3975.4ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 20.9% (2,335,989 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 20.86% (2,335,989 px)\n",
            "      ID  0: left_face                 - 79.14% (8,862,475 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3588.6ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 22.4% (2,512,572 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 22.44% (2,512,572 px)\n",
            "      ID  0: left_face                 - 77.56% (8,685,892 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3603.9ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 28.0% (3,140,680 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 28.05% (3,140,680 px)\n",
            "      ID  0: left_face                 - 71.95% (8,057,784 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [11, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3662.4ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 31.3% (3,499,617 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 31.25% (3,499,617 px)\n",
            "      ID  0: left_face                 - 68.75% (7,698,847 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4562.3ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 40.0% (4,481,538 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 40.02% (4,481,538 px)\n",
            "      ID  0: left_face                 - 59.98% (6,716,926 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [20, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 5035.1ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 16.1% (1,798,481 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 16.06% (1,798,481 px)\n",
            "      ID  0: left_face                 - 83.94% (9,399,983 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3892.3ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 32.0% (3,586,478 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 32.03% (3,586,478 px)\n",
            "      ID  0: left_face                 - 67.97% (7,611,986 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3520.7ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 47.3% (5,299,681 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.33% (5,299,681 px)\n",
            "      ID  0: left_face                 - 52.67% (5,898,783 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3696.8ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 31.2% (3,498,296 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 31.24% (3,498,296 px)\n",
            "      ID  0: left_face                 - 68.76% (7,700,168 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3634.5ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 51.8% (5,797,949 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 51.77% (5,797,949 px)\n",
            "      ID  0: left_face                 - 48.23% (5,400,515 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [3, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4393.8ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 33.1% (3,710,322 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 33.13% (3,710,322 px)\n",
            "      ID  0: left_face                 - 66.87% (7,488,142 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4962.7ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 31.3% (3,506,668 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 31.31% (3,506,668 px)\n",
            "      ID  0: left_face                 - 68.69% (7,691,796 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4166.6ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 23.0% (2,575,266 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 23.00% (2,575,266 px)\n",
            "      ID  0: left_face                 - 77.00% (8,623,198 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    Input - Shape: (4096, 2730, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3493.0ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 47.5% (5,314,894 / 11,182,080 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.53% (5,314,894 px)\n",
            "      ID  0: left_face                 - 52.47% (5,867,186 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3533.2ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 25.6% (2,863,005 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 25.57% (2,863,005 px)\n",
            "      ID  0: left_face                 - 74.43% (8,335,459 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3603.8ms\n",
            "    MÃ¡scara (umbral=0.3) - Ãrea: 48.4% (5,423,274 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 48.43% (5,423,274 px)\n",
            "      ID  0: left_face                 - 51.57% (5,775,190 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "Configuracion completada en 307.9s\n",
            "\n",
            "Pausa entre configuraciones: 5.0s\n",
            "\n",
            "################################################################################\n",
            "COMBINACION 8/8\n",
            "################################################################################\n",
            "\n",
            "================================================================================\n",
            "MODELO: MobileNetV1 0.75\n",
            "UMBRALES: baja_sensibilidad - [0.3, 0.4, 0.5]\n",
            "================================================================================\n",
            "Progreso: 0/20 completadas\n",
            "Pendientes: 20\n",
            "  Cargando modelo MobileNetV1 0.75...\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4578.6ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 57.7% (6,460,358 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 57.69% (6,460,358 px)\n",
            "      ID  0: left_face                 - 42.31% (4,738,106 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3594.9ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 45.4% (5,081,936 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 45.38% (5,081,936 px)\n",
            "      ID  0: left_face                 - 54.62% (6,116,528 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3546.3ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 30.6% (3,428,391 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 30.61% (3,428,391 px)\n",
            "      ID  0: left_face                 - 69.39% (7,770,073 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3628.2ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 74.1% (8,299,663 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 74.11% (8,299,663 px)\n",
            "      ID  0: left_face                 - 25.89% (2,898,801 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4248.2ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 17.3% (1,933,219 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 17.26% (1,933,219 px)\n",
            "      ID  0: left_face                 - 82.74% (9,265,245 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 5038.6ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 21.6% (2,419,509 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 21.61% (2,419,509 px)\n",
            "      ID  0: left_face                 - 78.39% (8,778,955 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4402.1ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 23.9% (2,680,813 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 23.94% (2,680,813 px)\n",
            "      ID  0: left_face                 - 76.06% (8,517,651 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [11, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3602.3ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 26.7% (2,986,150 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 26.67% (2,986,150 px)\n",
            "      ID  0: left_face                 - 73.33% (8,212,314 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3513.6ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 34.4% (3,857,462 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 34.45% (3,857,462 px)\n",
            "      ID  0: left_face                 - 65.55% (7,341,002 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [20, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3500.3ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 13.5% (1,508,048 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 13.47% (1,508,048 px)\n",
            "      ID  0: left_face                 - 86.53% (9,690,416 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3688.7ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 22.9% (2,563,340 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 22.89% (2,563,340 px)\n",
            "      ID  0: left_face                 - 77.11% (8,635,124 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4896.6ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 44.1% (4,934,470 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 44.06% (4,934,470 px)\n",
            "      ID  0: left_face                 - 55.94% (6,263,994 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4790.3ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 29.0% (3,248,181 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 29.01% (3,248,181 px)\n",
            "      ID  0: left_face                 - 70.99% (7,950,283 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3527.2ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 47.3% (5,295,500 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 47.29% (5,295,500 px)\n",
            "      ID  0: left_face                 - 52.71% (5,902,964 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [3, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3568.7ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 31.0% (3,471,623 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 31.00% (3,471,623 px)\n",
            "      ID  0: left_face                 - 69.00% (7,726,841 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3688.2ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 26.6% (2,980,746 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 26.62% (2,980,746 px)\n",
            "      ID  0: left_face                 - 73.38% (8,217,718 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3719.6ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 19.4% (2,171,394 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 19.39% (2,171,394 px)\n",
            "      ID  0: left_face                 - 80.61% (9,027,070 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    Input - Shape: (4096, 2730, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4987.4ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 40.4% (4,518,125 / 11,182,080 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 40.41% (4,518,125 px)\n",
            "      ID  0: left_face                 - 59.59% (6,663,955 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 4772.8ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 20.1% (2,252,592 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 20.12% (2,252,592 px)\n",
            "      ID  0: left_face                 - 79.88% (8,945,872 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    Input - Shape: (4096, 2734, 3), Dtype: uint8, Range: [0, 255]\n",
            "    Procesando 3 umbrales (inferencia por umbral)\n",
            "    Inferencia completada en 3592.3ms\n",
            "    MÃ¡scara (umbral=0.4) - Ãrea: 43.7% (4,893,996 / 11,198,464 pixels)\n",
            "    Partes detectadas (2 tipos):\n",
            "      ID -1: fondo                     - 43.70% (4,893,996 px)\n",
            "      ID  0: left_face                 - 56.30% (6,304,468 px)\n",
            "  Completada - Persona detectada: Si\n",
            "\n",
            "Configuracion completada en 308.4s\n",
            "\n",
            "================================================================================\n",
            "EVALUACION COMPLETADA\n",
            "================================================================================\n",
            "Resultados guardados en: /content/drive/MyDrive/TFM/2_Modelos/bodypix\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# TEST DIAGNÃ“STICO AISLADO - EJECUTA ESTO EN UNA CELDA SEPARADA\n",
        "# ==============================================================================\n",
        "\n",
        "from tf_bodypix.api import download_model, load_model, BodyPixModelPaths\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Cargar modelo\n",
        "print(\"Cargando modelo...\")\n",
        "model_path = download_model(BodyPixModelPaths.MOBILENET_FLOAT_50_STRIDE_16)\n",
        "model = load_model(model_path)\n",
        "print(\"Modelo cargado\\n\")\n",
        "\n",
        "img_path = \"/content/drive/MyDrive/TFM/0_Imagenes/_DSC0023.jpg\"\n",
        "print(f\"Cargando imagen: {img_path}\")\n",
        "\n",
        "img_bgr = cv2.imread(img_path)\n",
        "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "print(f\"Imagen: {img_rgb.shape}, {img_rgb.dtype}, [{img_rgb.min()}, {img_rgb.max()}]\\n\")\n",
        "\n",
        "# Inferencia\n",
        "print(\"Haciendo inferencia...\")\n",
        "result = model.predict_single(img_rgb)\n",
        "print(\"Inferencia completada\\n\")\n",
        "\n",
        "print(\"Resultados por threshold:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for t in [0.05, 0.1, 0.15, 0.2, 0.3, 0.5]:\n",
        "    mask = result.get_mask(threshold=t)\n",
        "\n",
        "    # Verificar tipo\n",
        "    print(f\"\\nThreshold {t}:\")\n",
        "    print(f\"  Tipo de mask: {type(mask)}\")\n",
        "\n",
        "    # Convertir a numpy\n",
        "    if hasattr(mask, 'numpy'):\n",
        "        mask_np = mask.numpy()\n",
        "    else:\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "    print(f\"  Shape: {mask_np.shape}\")\n",
        "    print(f\"  Dtype: {mask_np.dtype}\")\n",
        "    print(f\"  Range: [{mask_np.min()}, {mask_np.max()}]\")\n",
        "\n",
        "    # Asegurar 2D\n",
        "    if mask_np.ndim == 3:\n",
        "        mask_np = mask_np[:, :, 0]\n",
        "\n",
        "    # Contar pixels\n",
        "    area = (mask_np > 0).sum()\n",
        "    total = mask_np.size\n",
        "    pct = (area / total) * 100\n",
        "\n",
        "    print(f\"  Pixels detectados: {area:,} ({pct:.1f}%)\")\n",
        "    print(f\"  Valores Ãºnicos: {np.unique(mask_np)}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0drLxyI4IL1z",
        "outputId": "887b29d3-ce03-40d6-f477-7b6671a44c70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando modelo...\n",
            "Modelo cargado\n",
            "\n",
            "Cargando imagen: /content/drive/MyDrive/TFM/0_Imagenes/_DSC0023.jpg\n",
            "Imagen: (6016, 4016, 3), uint8, [0, 255]\n",
            "\n",
            "Haciendo inferencia...\n",
            "Inferencia completada\n",
            "\n",
            "Resultados por threshold:\n",
            "------------------------------------------------------------\n",
            "\n",
            "Threshold 0.05:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 18,185,600 (75.3%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "Threshold 0.1:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 16,695,188 (69.1%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "Threshold 0.15:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 15,622,676 (64.7%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "Threshold 0.2:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 14,625,354 (60.5%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "Threshold 0.3:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 12,881,769 (53.3%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "Threshold 0.5:\n",
            "  Tipo de mask: <class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "  Shape: (6016, 4016, 1)\n",
            "  Dtype: int32\n",
            "  Range: [0, 1]\n",
            "  Pixels detectados: 9,872,097 (40.9%)\n",
            "  Valores Ãºnicos: [0 1]\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}