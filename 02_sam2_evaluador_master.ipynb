{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNyKtfg9ezOuiA9Q0hUr++r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/02_sam2_evaluador_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "abcgj0-7MpvM"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SAM 2.0 EVALUADOR\n",
        "# =============================================================================\n",
        "# Proyecto: Evaluaci√≥n Comparativa de Modelos de Segmentaci√≥n de Personas\n",
        "# Modelos: SAM 2.0 (Tiny, Small) - Extensible a Base Plus y Large\n",
        "# ============================================================================="
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Crear directorio de checkpoints\n",
        "CHECKPOINTS_DIR = Path(\"/content/drive/MyDrive/TFM/sam2/checkpoints\")\n",
        "CHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# URLs oficiales de Meta (Facebook Research)\n",
        "CHECKPOINTS = {\n",
        "    'sam2_hiera_tiny.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_tiny.pt',\n",
        "    'sam2_hiera_small.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_small.pt',\n",
        "    'sam2_hiera_base_plus.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt',\n",
        "    'sam2_hiera_large.pt': 'https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt',\n",
        "}\n",
        "\n",
        "print(\"üîΩ DESCARGANDO CHECKPOINTS SAM 2.0...\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for filename, url in CHECKPOINTS.items():\n",
        "    checkpoint_path = CHECKPOINTS_DIR / filename\n",
        "\n",
        "    if checkpoint_path.exists():\n",
        "        print(f\"‚úÖ {filename} ya existe (saltando descarga)\")\n",
        "    else:\n",
        "        print(f\"üì• Descargando {filename}...\")\n",
        "        print(f\"   URL: {url}\")\n",
        "\n",
        "        # Descargar usando wget\n",
        "        !wget -q --show-progress {url} -O {checkpoint_path}\n",
        "\n",
        "        if checkpoint_path.exists():\n",
        "            size_mb = checkpoint_path.stat().st_size / (1024 * 1024)\n",
        "            print(f\"   ‚úÖ Descargado correctamente ({size_mb:.1f} MB)\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå ERROR descargando {filename}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ DESCARGA DE CHECKPOINTS COMPLETADA\")\n",
        "print(f\"üìÅ Ubicaci√≥n: {CHECKPOINTS_DIR}\")\n",
        "\n",
        "# Verificar archivos descargados\n",
        "archivos = list(CHECKPOINTS_DIR.glob(\"*.pt\"))\n",
        "print(f\"\\nüìä Checkpoints disponibles: {len(archivos)}\")\n",
        "for archivo in archivos:\n",
        "    size_mb = archivo.stat().st_size / (1024 * 1024)\n",
        "    print(f\"   ‚Ä¢ {archivo.name}: {size_mb:.1f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAZgj2vts_E9",
        "outputId": "34fbc2d4-5b96-46ca-d03f-e76c6a5673e1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîΩ DESCARGANDO CHECKPOINTS SAM 2.0...\n",
            "================================================================================\n",
            "‚úÖ sam2_hiera_tiny.pt ya existe (saltando descarga)\n",
            "‚úÖ sam2_hiera_small.pt ya existe (saltando descarga)\n",
            "üì• Descargando sam2_hiera_base_plus.pt...\n",
            "   URL: https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_base_plus.pt\n",
            "/content/drive/MyDr 100%[===================>] 308.51M  35.2MB/s    in 7.8s    \n",
            "   ‚úÖ Descargado correctamente (308.5 MB)\n",
            "üì• Descargando sam2_hiera_large.pt...\n",
            "   URL: https://dl.fbaipublicfiles.com/segment_anything_2/072824/sam2_hiera_large.pt\n",
            "/content/drive/MyDr 100%[===================>] 856.35M  60.0MB/s    in 24s     \n",
            "   ‚úÖ Descargado correctamente (856.4 MB)\n",
            "\n",
            "================================================================================\n",
            "‚úÖ DESCARGA DE CHECKPOINTS COMPLETADA\n",
            "üìÅ Ubicaci√≥n: /content/drive/MyDrive/TFM/sam2/checkpoints\n",
            "\n",
            "üìä Checkpoints disponibles: 4\n",
            "   ‚Ä¢ sam2_hiera_tiny.pt: 148.7 MB\n",
            "   ‚Ä¢ sam2_hiera_small.pt: 175.8 MB\n",
            "   ‚Ä¢ sam2_hiera_base_plus.pt: 308.5 MB\n",
            "   ‚Ä¢ sam2_hiera_large.pt: 856.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALACI√ìN DE DEPENDENCIAS\n",
        "# =============================================================================\n",
        "\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q opencv-python matplotlib Pillow\n",
        "!pip install -q numpy scipy scikit-image\n",
        "!pip install -q git+https://github.com/facebookresearch/segment-anything-2.git\n",
        "\n",
        "# Librer√≠as especializadas para an√°lisis fotogr√°fico (IGUAL QUE MASK2FORMER)\n",
        "!pip install -q mahotas   # An√°lisis de texturas (Haralick features)\n",
        "!pip install -q piexif    # Metadatos EXIF\n",
        "!pip install -q shapely   # An√°lisis geom√©trico avanzado de pol√≠gonos\n",
        "\n",
        "print(\"‚úÖ Dependencias instaladas correctamente (incluyendo an√°lisis fotogr√°fico completo)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmJCA1SRet1F",
        "outputId": "48dd8e38-7b25-47ca-e633-b729e6bb6947"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for SAM-2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ Dependencias instaladas correctamente (incluyendo an√°lisis fotogr√°fico completo)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES Y CONFIGURACI√ìN INICIAL\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import hashlib\n",
        "import warnings\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import time\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Librer√≠as especializadas para an√°lisis fotogr√°fico\n",
        "import mahotas\n",
        "import piexif\n",
        "from shapely.geometry import Polygon, Point\n",
        "from shapely.validation import explain_validity\n",
        "from skimage import feature, filters, measure, morphology, segmentation, transform\n",
        "from skimage.color import rgb2gray, rgb2hsv, rgb2lab\n",
        "import skimage\n",
        "\n",
        "# SAM 2.0 imports\n",
        "from sam2.build_sam import build_sam2\n",
        "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
        "\n",
        "# Configuraci√≥n para entorno Colab\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úÖ Google Drive montado correctamente\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚ö†Ô∏è No estamos en Colab, continuando sin montar Drive...\")\n",
        "\n",
        "# Suprimir warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Verificar GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úÖ GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   VRAM total: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GPU no disponible - SAM 2.0 requiere GPU para funcionar eficientemente\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jn7p2doqhBpv",
        "outputId": "392bd650-9163-4edb-e0b6-c1dfdaaeb17a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive montado correctamente\n",
            "‚úÖ GPU disponible: Tesla T4\n",
            "   VRAM total: 14.74 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 3: CONFIGURACI√ìN Y ESTRUCTURAS DE DATOS\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloSAMInfo:\n",
        "    \"\"\"Informaci√≥n completa de un modelo SAM 2.0\"\"\"\n",
        "    nombre: str\n",
        "    checkpoint: str\n",
        "    config: str\n",
        "    parametros_millones: int\n",
        "    descripcion: str\n",
        "\n",
        "    def obtener_nombre_sanitizado(self) -> str:\n",
        "        \"\"\"Obtiene nombre corto para archivos\"\"\"\n",
        "        return self.nombre.replace('sam2_hiera_', '')\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionSAM:\n",
        "    \"\"\"Configuraci√≥n de generaci√≥n autom√°tica de m√°scaras\"\"\"\n",
        "    nombre: str\n",
        "    points_per_side: int\n",
        "    pred_iou_thresh: float\n",
        "    stability_score_thresh: float\n",
        "    crop_n_layers: int\n",
        "    crop_n_points_downscale_factor: int\n",
        "    min_mask_region_area: int\n",
        "    descripcion: str\n",
        "\n",
        "@dataclass\n",
        "class ConfigEvaluacionSAM:\n",
        "    \"\"\"Configuraci√≥n centralizada del sistema de evaluaci√≥n SAM 2.0\"\"\"\n",
        "\n",
        "    # Rutas base\n",
        "    BASE_PATH: Path = Path(\"/content/drive/MyDrive/TFM/sam2\")\n",
        "    DATASET_PATH: Path = BASE_PATH / \"imagenes\"\n",
        "    CHECKPOINTS_PATH: Path = BASE_PATH / \"checkpoints\"\n",
        "\n",
        "    # Par√°metros de procesamiento\n",
        "    MAX_SIZE_IMAGEN: int = 1024\n",
        "    GUARDAR_VISUALIZACIONES: bool = True\n",
        "    FORMATO_COCO_HABILITADO: bool = True\n",
        "\n",
        "    # Modelos SAM 2.0 a evaluar (OPTIMIZADO PARA RECURSOS LIMITADOS)\n",
        "    MODELOS: List[ModeloSAMInfo] = None\n",
        "\n",
        "    # Configuraciones de generaci√≥n de m√°scaras\n",
        "    CONFIGURACIONES: Dict[str, ConfiguracionSAM] = None\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Inicializa modelos y configuraciones\"\"\"\n",
        "\n",
        "        # MODELOS SAM 2.0 - Configuraci√≥n LOW-COST\n",
        "        self.MODELOS = [\n",
        "            ModeloSAMInfo(\n",
        "                nombre='sam2_hiera_tiny',\n",
        "                checkpoint='sam2_hiera_tiny.pt',\n",
        "                config='sam2_hiera_t.yaml',\n",
        "                parametros_millones=39,\n",
        "                descripcion='Modelo ultraligero para aplicaciones m√≥viles y edge computing'\n",
        "            ),\n",
        "            ModeloSAMInfo(\n",
        "                nombre='sam2_hiera_small',\n",
        "                checkpoint='sam2_hiera_small.pt',\n",
        "                config='sam2_hiera_s.yaml',\n",
        "                parametros_millones=46,\n",
        "                descripcion='Balance √≥ptimo calidad/velocidad para producci√≥n'\n",
        "            ),\n",
        "             ModeloSAMInfo(\n",
        "                 nombre='sam2_hiera_base_plus',\n",
        "                 checkpoint='sam2_hiera_base_plus.pt',\n",
        "                 config='sam2_hiera_b+.yaml',\n",
        "                 parametros_millones=80,\n",
        "                 descripcion='Modelo avanzado para producci√≥n de alta calidad'\n",
        "             ),\n",
        "             ModeloSAMInfo(\n",
        "                 nombre='sam2_hiera_large',\n",
        "                 checkpoint='sam2_hiera_large.pt',\n",
        "                 config='sam2_hiera_l.yaml',\n",
        "                 parametros_millones=224,\n",
        "                 descripcion='Modelo de investigaci√≥n - m√°xima calidad'\n",
        "             ),\n",
        "        ]\n",
        "\n",
        "        self.CONFIGURACIONES = {\n",
        "            'low_cost_tiny': ConfiguracionSAM(\n",
        "                nombre='low_cost_tiny',\n",
        "                points_per_side=16,  # 16x16 = 256 prompts (r√°pido)\n",
        "                pred_iou_thresh=0.88,\n",
        "                stability_score_thresh=0.92,\n",
        "                crop_n_layers=0,  # Sin crops para ahorrar memoria\n",
        "                crop_n_points_downscale_factor=2,\n",
        "                min_mask_region_area=200,  # Filtrar m√°scaras peque√±as\n",
        "                descripcion='Configuraci√≥n ultra-r√°pida optimizada para Tiny'\n",
        "            ),\n",
        "            'balanced_small': ConfiguracionSAM(\n",
        "                nombre='balanced_small',\n",
        "                points_per_side=24,  # 24x24 = 576 prompts (balance)\n",
        "                pred_iou_thresh=0.86,\n",
        "                stability_score_thresh=0.92,\n",
        "                crop_n_layers=1,\n",
        "                crop_n_points_downscale_factor=2,\n",
        "                min_mask_region_area=150,\n",
        "                descripcion='Configuraci√≥n balanceada para Small'\n",
        "            ),\n",
        "             'full_quality': ConfiguracionSAM(\n",
        "                 nombre='full_quality',\n",
        "                 points_per_side=32,  # 32x32 = 1024 prompts (completo)\n",
        "                 pred_iou_thresh=0.86,\n",
        "                 stability_score_thresh=0.92,\n",
        "                 crop_n_layers=1,\n",
        "                 crop_n_points_downscale_factor=2,\n",
        "                 min_mask_region_area=100,\n",
        "                 descripcion='Configuraci√≥n completa para m√°xima calidad'\n",
        "             ),\n",
        "        }\n",
        "\n",
        "    def validar_configuracion(self) -> bool:\n",
        "        \"\"\"Valida que la configuraci√≥n sea correcta\"\"\"\n",
        "        try:\n",
        "            # Validar rutas\n",
        "            if not self.DATASET_PATH.exists():\n",
        "                print(f\"‚ùå ERROR: Dataset no encontrado en {self.DATASET_PATH}\")\n",
        "                return False\n",
        "\n",
        "            # Contar im√°genes\n",
        "            imagenes = list(self.DATASET_PATH.glob('*.jpg')) + \\\n",
        "                      list(self.DATASET_PATH.glob('*.jpeg')) + \\\n",
        "                      list(self.DATASET_PATH.glob('*.png'))\n",
        "\n",
        "            if len(imagenes) == 0:\n",
        "                print(f\"‚ùå ERROR: No se encontraron im√°genes en {self.DATASET_PATH}\")\n",
        "                return False\n",
        "\n",
        "            print(f\"‚úÖ Dataset: {len(imagenes)} im√°genes encontradas\")\n",
        "\n",
        "            # Crear directorio de checkpoints si no existe\n",
        "            self.CHECKPOINTS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ERROR en validaci√≥n: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def obtener_resumen_configuracion(self) -> Dict[str, Any]:\n",
        "        \"\"\"Obtiene resumen de la configuraci√≥n\"\"\"\n",
        "        imagenes = list(self.DATASET_PATH.glob('*.jpg')) + \\\n",
        "                  list(self.DATASET_PATH.glob('*.jpeg')) + \\\n",
        "                  list(self.DATASET_PATH.glob('*.png'))\n",
        "\n",
        "        return {\n",
        "            'total_modelos': len(self.MODELOS),\n",
        "            'total_configuraciones': len(self.CONFIGURACIONES),\n",
        "            'total_combinaciones': len(self.MODELOS) * len(self.CONFIGURACIONES),\n",
        "            'total_imagenes': len(imagenes),\n",
        "            'dataset_path': str(self.DATASET_PATH),\n",
        "            'visualizaciones_habilitadas': self.GUARDAR_VISUALIZACIONES,\n",
        "            'formato_coco_habilitado': self.FORMATO_COCO_HABILITADO,\n",
        "        }"
      ],
      "metadata": {
        "id": "3464brb3inJX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SISTEMA DE LOGGING\n",
        "# =============================================================================\n",
        "class LoggerManager:\n",
        "    \"\"\"Gesti√≥n centralizada de logs del sistema\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_logs: Path):\n",
        "        self.directorio_logs = directorio_logs\n",
        "        self.directorio_logs.mkdir(parents=True, exist_ok=True)\n",
        "        self.loggers: Dict[str, logging.Logger] = {}\n",
        "        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    def crear_logger(self, nombre: str) -> logging.Logger:\n",
        "        \"\"\"Crea un logger espec√≠fico para un componente\"\"\"\n",
        "        if nombre in self.loggers:\n",
        "            return self.loggers[nombre]\n",
        "\n",
        "        logger = logging.getLogger(f\"SAM2_{nombre}_{self.timestamp}\")\n",
        "        logger.setLevel(logging.INFO)\n",
        "        logger.handlers = []\n",
        "\n",
        "        # Handler para archivo\n",
        "        archivo_log = self.directorio_logs / f\"{nombre}_{self.timestamp}.log\"\n",
        "        file_handler = logging.FileHandler(archivo_log, encoding='utf-8')\n",
        "        file_handler.setLevel(logging.INFO)\n",
        "\n",
        "        # Formato\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "            datefmt='%Y-%m-%d %H:%M:%S'\n",
        "        )\n",
        "        file_handler.setFormatter(formatter)\n",
        "        logger.addHandler(file_handler)\n",
        "\n",
        "        # Handler para consola (solo errores)\n",
        "        console_handler = logging.StreamHandler()\n",
        "        console_handler.setLevel(logging.ERROR)\n",
        "        console_handler.setFormatter(formatter)\n",
        "        logger.addHandler(console_handler)\n",
        "\n",
        "        self.loggers[nombre] = logger\n",
        "        return logger"
      ],
      "metadata": {
        "id": "n3xT59d7i1dx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utils:\n",
        "    \"\"\"Utilidades generales del sistema\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def limpiar_memoria():\n",
        "        \"\"\"Limpia memoria GPU y RAM\"\"\"\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    @staticmethod\n",
        "    def preparar_imagen(ruta: str, max_size: int = 1024) -> np.ndarray:\n",
        "        \"\"\"Prepara imagen para procesamiento con SAM\"\"\"\n",
        "        try:\n",
        "            imagen = cv2.imread(ruta)\n",
        "            if imagen is None:\n",
        "                raise ValueError(f\"No se pudo cargar la imagen: {ruta}\")\n",
        "\n",
        "            imagen = cv2.cvtColor(imagen, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Redimensionar si es necesario\n",
        "            h, w = imagen.shape[:2]\n",
        "            if max(h, w) > max_size:\n",
        "                scale = max_size / max(h, w)\n",
        "                new_w, new_h = int(w * scale), int(h * scale)\n",
        "                imagen = cv2.resize(imagen, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "            return imagen\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error cargando imagen {ruta}: {str(e)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def calcular_hash_imagen(ruta: str) -> str:\n",
        "        \"\"\"Calcula hash MD5 para identificaci√≥n √∫nica de imagen\"\"\"\n",
        "        try:\n",
        "            with open(ruta, 'rb') as f:\n",
        "                return hashlib.md5(f.read()).hexdigest()[:12]\n",
        "        except Exception:\n",
        "            return \"hash_error\"\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Any, archivo: Path, indent: int = 2) -> None:\n",
        "        \"\"\"Guarda datos en formato JSON con manejo de errores\"\"\"\n",
        "        try:\n",
        "            # Convertir numpy types a tipos nativos de Python\n",
        "            def convert_types(obj):\n",
        "                if isinstance(obj, np.integer):\n",
        "                    return int(obj)\n",
        "                elif isinstance(obj, np.floating):\n",
        "                    return float(obj)\n",
        "                elif isinstance(obj, np.ndarray):\n",
        "                    return obj.tolist()\n",
        "                elif isinstance(obj, dict):\n",
        "                    return {k: convert_types(v) for k, v in obj.items()}\n",
        "                elif isinstance(obj, list):\n",
        "                    return [convert_types(item) for item in obj]\n",
        "                return obj\n",
        "\n",
        "            datos_convertidos = convert_types(datos)\n",
        "\n",
        "            with open(archivo, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=indent, ensure_ascii=False, default=str)\n",
        "        except Exception as e:\n",
        "            raise IOError(f\"Error guardando JSON en {archivo}: {str(e)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def crear_nombre_archivo(modelo_info: ModeloSAMInfo, config_nombre: str,\n",
        "                           timestamp: str) -> str:\n",
        "        \"\"\"Crea nombres de archivo descriptivos y √∫nicos\"\"\"\n",
        "        modelo_nombre = modelo_info.obtener_nombre_sanitizado()\n",
        "        return f\"sam2_{modelo_nombre}_{config_nombre}_{timestamp}.json\""
      ],
      "metadata": {
        "id": "exykjf5sjO23"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXTRACTOR DE CARACTER√çSTICAS AVANZADAS\n",
        "# =============================================================================\n",
        "\n",
        "class ExtractorCaracteristicasAvanzado:\n",
        "    \"\"\"\n",
        "    Extractor de caracter√≠sticas fotogr√°ficas.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.logger = None\n",
        "\n",
        "    def set_logger(self, logger: logging.Logger):\n",
        "        \"\"\"Asigna logger para el extractor\"\"\"\n",
        "        self.logger = logger\n",
        "\n",
        "    def analizar_imagen_completa(self, imagen: Image.Image, ruta: str) -> Dict[str, Any]:\n",
        "        \"\"\"An√°lisis completo usando librer√≠as especializadas\"\"\"\n",
        "        img_array = np.array(imagen)\n",
        "        img_gray = rgb2gray(img_array)\n",
        "        img_hsv = rgb2hsv(img_array)\n",
        "        img_lab = rgb2lab(img_array)\n",
        "\n",
        "        img_gray_uint8 = (img_gray * 255).astype(np.uint8)\n",
        "\n",
        "        caracteristicas = {\n",
        "            'metadatos_basicos': self._extraer_metadatos_basicos(imagen, ruta),\n",
        "            'color_y_paleta': self._analizar_color_avanzado(img_array, img_hsv, img_lab),\n",
        "            'texturas_mahotas': self._extraer_texturas_mahotas(img_gray_uint8),\n",
        "            'texturas_skimage': self._extraer_texturas_skimage(img_gray),\n",
        "            'caracteristicas_geometricas': self._analizar_geometria_avanzada(img_gray_uint8),\n",
        "            'multiscale_features': self._extraer_multiscale_features(img_gray),\n",
        "            'propiedades_regionales': self._analizar_propiedades_regionales(img_gray),\n",
        "            'descriptores_locales': self._extraer_descriptores_locales(img_gray_uint8)\n",
        "        }\n",
        "\n",
        "        return caracteristicas\n",
        "\n",
        "    def _extraer_metadatos_basicos(self, imagen: Image.Image, ruta: str) -> Dict:\n",
        "        \"\"\"Metadatos b√°sicos de la imagen\"\"\"\n",
        "        w, h = imagen.size\n",
        "        return {\n",
        "            'dimensiones': {'ancho': w, 'alto': h},\n",
        "            'aspecto_ratio': round(w / h, 3),\n",
        "            'megapixeles': round((w * h) / 1000000, 2),\n",
        "            'orientacion': 'horizontal' if w > h else 'vertical' if h > w else 'cuadrada',\n",
        "            'formato': ruta.split('.')[-1].lower() if '.' in ruta else 'desconocido'\n",
        "        }\n",
        "\n",
        "    def _analizar_color_avanzado(self, img_rgb: np.ndarray, img_hsv: np.ndarray,\n",
        "                                img_lab: np.ndarray) -> Dict:\n",
        "        \"\"\"An√°lisis avanzado de color en m√∫ltiples espacios\"\"\"\n",
        "        return {\n",
        "            'estadisticas_rgb': {\n",
        "                'mean': img_rgb.mean(axis=(0, 1)).tolist(),\n",
        "                'std': img_rgb.std(axis=(0, 1)).tolist(),\n",
        "                'min': img_rgb.min(axis=(0, 1)).tolist(),\n",
        "                'max': img_rgb.max(axis=(0, 1)).tolist()\n",
        "            },\n",
        "            'hsv_distribucion': {\n",
        "                'hue_medio': float(img_hsv[:, :, 0].mean()),\n",
        "                'saturacion_media': float(img_hsv[:, :, 1].mean()),\n",
        "                'valor_medio': float(img_hsv[:, :, 2].mean())\n",
        "            },\n",
        "            'lab_luminancia': {\n",
        "                'L_medio': float(img_lab[:, :, 0].mean()),\n",
        "                'a_medio': float(img_lab[:, :, 1].mean()),\n",
        "                'b_medio': float(img_lab[:, :, 2].mean())\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _extraer_texturas_mahotas(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Caracter√≠sticas de textura usando Mahotas\"\"\"\n",
        "        try:\n",
        "            haralick = mahotas.features.haralick(img_gray, return_mean=True)\n",
        "            return {\n",
        "                'haralick_mean': haralick.tolist() if haralick is not None else []\n",
        "            }\n",
        "        except:\n",
        "            return {'haralick_mean': []}\n",
        "\n",
        "    def _extraer_texturas_skimage(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Caracter√≠sticas de textura usando scikit-image\"\"\"\n",
        "        try:\n",
        "            # GLCM\n",
        "            glcm = feature.graycomatrix(\n",
        "                (img_gray * 255).astype(np.uint8),\n",
        "                distances=[1],\n",
        "                angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
        "                levels=256,\n",
        "                symmetric=True,\n",
        "                normed=True\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'contrast': float(feature.graycoprops(glcm, 'contrast').mean()),\n",
        "                'dissimilarity': float(feature.graycoprops(glcm, 'dissimilarity').mean()),\n",
        "                'homogeneity': float(feature.graycoprops(glcm, 'homogeneity').mean()),\n",
        "                'energy': float(feature.graycoprops(glcm, 'energy').mean()),\n",
        "                'correlation': float(feature.graycoprops(glcm, 'correlation').mean())\n",
        "            }\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _analizar_geometria_avanzada(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"An√°lisis geom√©trico avanzado\"\"\"\n",
        "        try:\n",
        "            edges = feature.canny(img_gray)\n",
        "            return {\n",
        "                'edge_density': float(edges.sum() / edges.size),\n",
        "                'shape_index': float(img_gray.std() / img_gray.mean()) if img_gray.mean() > 0 else 0\n",
        "            }\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _extraer_multiscale_features(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Caracter√≠sticas multi-escala\"\"\"\n",
        "        try:\n",
        "            pyramid = list(skimage.transform.pyramid_gaussian(img_gray, max_layer=3))\n",
        "            return {\n",
        "                'num_scales': len(pyramid),\n",
        "                'scale_variance': [float(level.std()) for level in pyramid]\n",
        "            }\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _analizar_propiedades_regionales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Propiedades de regiones\"\"\"\n",
        "        try:\n",
        "            threshold = filters.threshold_otsu(img_gray)\n",
        "            binary = img_gray > threshold\n",
        "            labeled = measure.label(binary)\n",
        "            regions = measure.regionprops(labeled)\n",
        "\n",
        "            if regions:\n",
        "                areas = [r.area for r in regions]\n",
        "                return {\n",
        "                    'num_regions': len(regions),\n",
        "                    'mean_region_area': float(np.mean(areas)),\n",
        "                    'std_region_area': float(np.std(areas))\n",
        "                }\n",
        "            return {'num_regions': 0}\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _extraer_descriptores_locales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Descriptores locales (keypoints)\"\"\"\n",
        "        try:\n",
        "            # Detectar corners\n",
        "            corners = feature.corner_peaks(\n",
        "                feature.corner_harris(img_gray),\n",
        "                min_distance=5\n",
        "            )\n",
        "\n",
        "            return {\n",
        "                'num_corners': len(corners),\n",
        "                'corner_density': float(len(corners) / img_gray.size)\n",
        "            }\n",
        "        except:\n",
        "            return {}"
      ],
      "metadata": {
        "id": "Nn1kc1g4jWCD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ANALIZADOR DE M√ÅSCARAS CON SHAPELY\n",
        "# =============================================================================\n",
        "\n",
        "class MaskAnalyzer:\n",
        "    \"\"\"\n",
        "    Analizador avanzado de m√°scaras usando Shapely.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epsilon_factor: float = 0.005):\n",
        "        self.epsilon_factor = epsilon_factor\n",
        "\n",
        "    def analizar_mascara_completa(self, mask: np.ndarray,\n",
        "                                  imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        An√°lisis completo de una m√°scara individual\n",
        "\n",
        "        Args:\n",
        "            mask: M√°scara binaria (numpy array 2D)\n",
        "            imagen_shape: (altura, anchura) de la imagen original\n",
        "\n",
        "        Returns:\n",
        "            Dict con an√°lisis geom√©trico completo\n",
        "        \"\"\"\n",
        "        resultado = {\n",
        "            'caracteristicas_geometricas': {},\n",
        "            'shapely_geometry': {},\n",
        "            'caracteristicas_forma': {},\n",
        "            'caracteristicas_contextuales': {}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            mask_binary = mask.astype(np.uint8)\n",
        "\n",
        "            # An√°lisis geom√©trico b√°sico (scikit-image)\n",
        "            resultado['caracteristicas_geometricas'] = self._extraer_geometricas_basicas(\n",
        "                mask_binary, imagen_shape\n",
        "            )\n",
        "\n",
        "            # An√°lisis avanzado con Shapely\n",
        "            resultado['shapely_geometry'] = self._analizar_con_shapely(mask_binary)\n",
        "\n",
        "            # Caracter√≠sticas de forma avanzadas\n",
        "            resultado['caracteristicas_forma'] = self._extraer_caracteristicas_forma(\n",
        "                mask_binary\n",
        "            )\n",
        "\n",
        "            # Caracter√≠sticas contextuales (posici√≥n en imagen)\n",
        "            resultado['caracteristicas_contextuales'] = self._extraer_contextuales(\n",
        "                mask_binary, imagen_shape\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            resultado['error'] = str(e)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def _extraer_geometricas_basicas(self, mask: np.ndarray,\n",
        "                                    imagen_shape: Tuple[int, int]) -> Dict[str, float]:\n",
        "        \"\"\"Extrae caracter√≠sticas geom√©tricas b√°sicas usando scikit-image\"\"\"\n",
        "        try:\n",
        "            props = measure.regionprops(mask.astype(int))[0] if np.any(mask) else None\n",
        "\n",
        "            if props is None:\n",
        "                return self._geometricas_vacias()\n",
        "\n",
        "            total_pixels = imagen_shape[0] * imagen_shape[1]\n",
        "\n",
        "            return {\n",
        "                'area_pixels': float(props.area),\n",
        "                'area_percentage': float(props.area / total_pixels * 100),\n",
        "                'perimeter': float(props.perimeter),\n",
        "                'compactness': float(4 * np.pi * props.area / (props.perimeter ** 2)) if props.perimeter > 0 else 0.0,\n",
        "                'aspect_ratio': float(props.major_axis_length / props.minor_axis_length) if props.minor_axis_length > 0 else 0.0,\n",
        "                'orientation_angle': float(np.degrees(props.orientation)),\n",
        "                'centroid_y': float(props.centroid[0]),\n",
        "                'centroid_x': float(props.centroid[1]),\n",
        "                'solidity': float(props.solidity),\n",
        "                'extent': float(props.extent),\n",
        "                'eccentricity': float(props.eccentricity),\n",
        "                'major_axis_length': float(props.major_axis_length),\n",
        "                'minor_axis_length': float(props.minor_axis_length)\n",
        "            }\n",
        "        except:\n",
        "            return self._geometricas_vacias()\n",
        "\n",
        "    def _analizar_con_shapely(self, mask: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"An√°lisis geom√©trico avanzado usando Shapely\"\"\"\n",
        "        try:\n",
        "            # Encontrar contornos\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "            if not contours:\n",
        "                return self._shapely_vacio()\n",
        "\n",
        "            # Contorno principal\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            epsilon = self.epsilon_factor * cv2.arcLength(contour, True)\n",
        "            contour_simplified = cv2.approxPolyDP(contour, epsilon, True)\n",
        "\n",
        "            if len(contour_simplified) < 3:\n",
        "                return self._shapely_vacio()\n",
        "\n",
        "            # Crear pol√≠gono Shapely\n",
        "            coords = [(point[0][0], point[0][1]) for point in contour_simplified]\n",
        "            polygon = Polygon(coords)\n",
        "\n",
        "            # Validar pol√≠gono\n",
        "            is_valid = polygon.is_valid\n",
        "            validity_msg = explain_validity(polygon) if not is_valid else \"Valid\"\n",
        "\n",
        "            if not is_valid:\n",
        "                # Intentar reparar\n",
        "                polygon = polygon.buffer(0)\n",
        "                is_valid = polygon.is_valid\n",
        "\n",
        "            # Calcular m√©tricas geom√©tricas\n",
        "            convex_hull = polygon.convex_hull\n",
        "\n",
        "            return {\n",
        "                'polygon_valido': bool(is_valid),\n",
        "                'validity_message': validity_msg,\n",
        "                'area_shapely': float(polygon.area),\n",
        "                'perimeter_shapely': float(polygon.length),\n",
        "                'num_vertices': len(coords),\n",
        "                'convex_hull_area': float(convex_hull.area),\n",
        "                'convexity_ratio': float(polygon.area / convex_hull.area) if convex_hull.area > 0 else 0.0,\n",
        "                'is_simple': bool(polygon.is_simple),\n",
        "                'bounds': list(polygon.bounds)  # (minx, miny, maxx, maxy)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {**self._shapely_vacio(), 'error': str(e)}\n",
        "\n",
        "    def _extraer_caracteristicas_forma(self, mask: np.ndarray) -> Dict[str, float]:\n",
        "        \"\"\"Caracter√≠sticas de forma avanzadas\"\"\"\n",
        "        try:\n",
        "            # Momentos de Hu (invariantes a escala, rotaci√≥n, traslaci√≥n)\n",
        "            moments = cv2.moments(mask)\n",
        "            hu_moments = cv2.HuMoments(moments).flatten()\n",
        "\n",
        "            # Fourier descriptors (aproximaci√≥n simple)\n",
        "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            if contours:\n",
        "                contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "                # Curvatura aproximada\n",
        "                perimeter = cv2.arcLength(contour, True)\n",
        "                area = cv2.contourArea(contour)\n",
        "\n",
        "                return {\n",
        "                    'hu_moment_1': float(hu_moments[0]),\n",
        "                    'hu_moment_2': float(hu_moments[1]),\n",
        "                    'hu_moment_3': float(hu_moments[2]),\n",
        "                    'circularity': float(4 * np.pi * area / (perimeter ** 2)) if perimeter > 0 else 0.0,\n",
        "                    'roughness_factor': float(perimeter / (2 * np.sqrt(np.pi * area))) if area > 0 else 0.0\n",
        "                }\n",
        "\n",
        "            return {}\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _extraer_contextuales(self, mask: np.ndarray,\n",
        "                             imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"Caracter√≠sticas contextuales (posici√≥n relativa en imagen)\"\"\"\n",
        "        try:\n",
        "            h, w = imagen_shape\n",
        "            props = measure.regionprops(mask.astype(int))[0] if np.any(mask) else None\n",
        "\n",
        "            if props is None:\n",
        "                return {}\n",
        "\n",
        "            cy, cx = props.centroid\n",
        "\n",
        "            # Posici√≥n relativa normalizada\n",
        "            rel_x = cx / w\n",
        "            rel_y = cy / h\n",
        "\n",
        "            # Cuadrante (1-9, tipo numpad)\n",
        "            if rel_y < 0.33:\n",
        "                quadrant_y = 'superior'\n",
        "            elif rel_y < 0.66:\n",
        "                quadrant_y = 'centro'\n",
        "            else:\n",
        "                quadrant_y = 'inferior'\n",
        "\n",
        "            if rel_x < 0.33:\n",
        "                quadrant_x = 'izquierda'\n",
        "            elif rel_x < 0.66:\n",
        "                quadrant_x = 'centro'\n",
        "            else:\n",
        "                quadrant_x = 'derecha'\n",
        "\n",
        "            quadrant = f\"{quadrant_y}_{quadrant_x}\"\n",
        "\n",
        "            # Distancia al centro\n",
        "            center_dist = np.sqrt((rel_x - 0.5)**2 + (rel_y - 0.5)**2)\n",
        "\n",
        "            return {\n",
        "                'centroid_normalized_x': float(rel_x),\n",
        "                'centroid_normalized_y': float(rel_y),\n",
        "                'quadrant': quadrant,\n",
        "                'distance_to_center': float(center_dist),\n",
        "                'is_centered': bool(center_dist < 0.2)  # Dentro del 20% central\n",
        "            }\n",
        "        except:\n",
        "            return {}\n",
        "\n",
        "    def _geometricas_vacias(self) -> Dict[str, float]:\n",
        "        \"\"\"Retorna estructura vac√≠a para caracter√≠sticas geom√©tricas\"\"\"\n",
        "        return {\n",
        "            'area_pixels': 0.0,\n",
        "            'area_percentage': 0.0,\n",
        "            'perimeter': 0.0,\n",
        "            'compactness': 0.0,\n",
        "            'aspect_ratio': 0.0,\n",
        "            'orientation_angle': 0.0,\n",
        "            'centroid_y': 0.0,\n",
        "            'centroid_x': 0.0,\n",
        "            'solidity': 0.0,\n",
        "            'extent': 0.0,\n",
        "            'eccentricity': 0.0,\n",
        "            'major_axis_length': 0.0,\n",
        "            'minor_axis_length': 0.0\n",
        "        }\n",
        "\n",
        "    def _shapely_vacio(self) -> Dict[str, Any]:\n",
        "        \"\"\"Retorna estructura vac√≠a para an√°lisis Shapely\"\"\"\n",
        "        return {\n",
        "            'polygon_valido': False,\n",
        "            'validity_message': 'No polygon created',\n",
        "            'area_shapely': 0.0,\n",
        "            'perimeter_shapely': 0.0,\n",
        "            'num_vertices': 0,\n",
        "            'convex_hull_area': 0.0,\n",
        "            'convexity_ratio': 0.0,\n",
        "            'is_simple': False,\n",
        "            'bounds': [0.0, 0.0, 0.0, 0.0]\n",
        "        }"
      ],
      "metadata": {
        "id": "TtmiewiTjBE1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FiltradorPersonas:\n",
        "    \"\"\"Filtra m√°scaras que probablemente corresponden a personas\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger = None):\n",
        "        self.logger = logger or logging.getLogger(__name__)\n",
        "\n",
        "        # Par√°metros heur√≠sticos para detecci√≥n de personas en fotograf√≠a\n",
        "        self.MIN_AREA_RATIO = 0.05  # M√≠nimo 5% de la imagen\n",
        "        self.MAX_AREA_RATIO = 0.90  # M√°ximo 90% de la imagen\n",
        "        self.MIN_ASPECT_RATIO = 0.3  # Ancho/Alto m√≠nimo\n",
        "        self.MAX_ASPECT_RATIO = 1.5  # Ancho/Alto m√°ximo (personas son m√°s altas)\n",
        "        self.MIN_PREDICTED_IOU = 0.85  # Confianza m√≠nima de SAM\n",
        "        self.PREFERRED_CENTER_DISTANCE = 0.3  # Distancia al centro preferida\n",
        "\n",
        "    def filtrar_mascaras_personas(self, mascaras: List[Dict],\n",
        "                                  imagen_shape: Tuple[int, int]) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Filtra m√°scaras que probablemente son personas en fotograf√≠a de retrato\n",
        "\n",
        "        Args:\n",
        "            mascaras: Lista de m√°scaras generadas por SAM\n",
        "            imagen_shape: (altura, anchura) de la imagen\n",
        "\n",
        "        Returns:\n",
        "            Lista de m√°scaras filtradas y ordenadas por probabilidad de ser persona\n",
        "        \"\"\"\n",
        "        if not mascaras:\n",
        "            return []\n",
        "\n",
        "        h, w = imagen_shape\n",
        "        area_total = h * w\n",
        "        centro_x, centro_y = w / 2, h / 2\n",
        "\n",
        "        mascaras_filtradas = []\n",
        "\n",
        "        for mask_data in mascaras:\n",
        "            segmentacion = mask_data['segmentation']\n",
        "            bbox = mask_data['bbox']  # [x, y, width, height]\n",
        "            predicted_iou = mask_data.get('predicted_iou', 0)\n",
        "\n",
        "            # Calcular caracter√≠sticas\n",
        "            area = np.sum(segmentacion)\n",
        "            area_ratio = area / area_total\n",
        "\n",
        "            x, y, mask_w, mask_h = bbox\n",
        "            aspect_ratio = mask_w / mask_h if mask_h > 0 else 0\n",
        "\n",
        "            # Centro de la m√°scara\n",
        "            mask_centro_x = x + mask_w / 2\n",
        "            mask_centro_y = y + mask_h / 2\n",
        "\n",
        "            # Distancia al centro (normalizada)\n",
        "            dist_centro = np.sqrt(\n",
        "                ((mask_centro_x - centro_x) / w) ** 2 +\n",
        "                ((mask_centro_y - centro_y) / h) ** 2\n",
        "            )\n",
        "\n",
        "            # CRITERIOS DE FILTRADO\n",
        "            criterios_cumplidos = 0\n",
        "            max_criterios = 5\n",
        "\n",
        "            # 1. Tama√±o apropiado\n",
        "            if self.MIN_AREA_RATIO <= area_ratio <= self.MAX_AREA_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # 2. Aspect ratio de persona (m√°s alto que ancho)\n",
        "            if self.MIN_ASPECT_RATIO <= aspect_ratio <= self.MAX_ASPECT_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # 3. Confianza alta de SAM\n",
        "            if predicted_iou >= self.MIN_PREDICTED_IOU:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # 4. Posici√≥n central (t√≠pico en retratos)\n",
        "            if dist_centro <= self.PREFERRED_CENTER_DISTANCE:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # 5. Compacidad (personas son objetos compactos)\n",
        "            perimetro_aprox = 2 * (mask_w + mask_h)\n",
        "            compacidad = (4 * np.pi * area) / (perimetro_aprox ** 2) if perimetro_aprox > 0 else 0\n",
        "            if compacidad > 0.2:  # Umbral de compacidad\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # Calcular score de confianza\n",
        "            confidence_score = criterios_cumplidos / max_criterios\n",
        "\n",
        "            # FILTRO: Al menos 3 de 5 criterios\n",
        "            if criterios_cumplidos >= 3:\n",
        "                mask_data['person_confidence'] = confidence_score\n",
        "                mask_data['criteria_met'] = criterios_cumplidos\n",
        "                mask_data['area_ratio'] = float(area_ratio)\n",
        "                mask_data['aspect_ratio'] = float(aspect_ratio)\n",
        "                mask_data['center_distance'] = float(dist_centro)\n",
        "                mascaras_filtradas.append(mask_data)\n",
        "\n",
        "        # Ordenar por confianza (mayor primero)\n",
        "        mascaras_filtradas.sort(key=lambda x: x['person_confidence'], reverse=True)\n",
        "\n",
        "        self.logger.info(\n",
        "            f\"Filtrado: {len(mascaras)} m√°scaras ‚Üí {len(mascaras_filtradas)} personas candidatas\"\n",
        "        )\n",
        "\n",
        "        return mascaras_filtradas"
      ],
      "metadata": {
        "id": "39xDp_9kj3KJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE M√ÅSCARAS SAM 2.0\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorMascarasSAM:\n",
        "    \"\"\"Genera m√°scaras autom√°ticas usando SAM 2.0\"\"\"\n",
        "\n",
        "    def __init__(self, modelo_info: ModeloSAMInfo, config_sam: ConfiguracionSAM,\n",
        "                 checkpoints_path: Path, logger: logging.Logger):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config_sam = config_sam\n",
        "        self.checkpoints_path = checkpoints_path\n",
        "        self.logger = logger\n",
        "\n",
        "        self.modelo = None\n",
        "        self.mask_generator = None\n",
        "        self.filtrador = FiltradorPersonas(logger)\n",
        "\n",
        "    def cargar_modelo(self):\n",
        "        \"\"\"Carga el modelo SAM 2.0\"\"\"\n",
        "        try:\n",
        "            self.logger.info(f\"Cargando modelo {self.modelo_info.nombre}...\")\n",
        "\n",
        "            # Ruta al checkpoint\n",
        "            checkpoint_path = self.checkpoints_path / self.modelo_info.checkpoint\n",
        "\n",
        "            if not checkpoint_path.exists():\n",
        "                raise FileNotFoundError(\n",
        "                    f\"Checkpoint no encontrado: {checkpoint_path}\\n\"\n",
        "                    f\"Descarga los checkpoints desde: https://github.com/facebookresearch/segment-anything-2#model-checkpoints\"\n",
        "                )\n",
        "\n",
        "            # Construir modelo\n",
        "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "            self.modelo = build_sam2(\n",
        "                config_file=self.modelo_info.config,\n",
        "                ckpt_path=str(checkpoint_path),\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            # Crear generador autom√°tico\n",
        "            self.mask_generator = SAM2AutomaticMaskGenerator(\n",
        "                model=self.modelo,\n",
        "                points_per_side=self.config_sam.points_per_side,\n",
        "                pred_iou_thresh=self.config_sam.pred_iou_thresh,\n",
        "                stability_score_thresh=self.config_sam.stability_score_thresh,\n",
        "                crop_n_layers=self.config_sam.crop_n_layers,\n",
        "                crop_n_points_downscale_factor=self.config_sam.crop_n_points_downscale_factor,\n",
        "                min_mask_region_area=self.config_sam.min_mask_region_area,\n",
        "            )\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Modelo {self.modelo_info.nombre} cargado correctamente\")\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error cargando modelo: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def generar_mascaras(self, imagen: np.ndarray) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Genera m√°scaras autom√°ticas y filtra personas\n",
        "\n",
        "        Returns:\n",
        "            Dict con m√°scaras totales, personas detectadas y metadatos\n",
        "        \"\"\"\n",
        "        try:\n",
        "            inicio = time.time()\n",
        "\n",
        "            # Generar todas las m√°scaras\n",
        "            self.logger.info(\"Generando m√°scaras autom√°ticas...\")\n",
        "            mascaras_todas = self.mask_generator.generate(imagen)\n",
        "\n",
        "            tiempo_generacion = (time.time() - inicio) * 1000\n",
        "\n",
        "            # Filtrar m√°scaras de personas\n",
        "            mascaras_personas = self.filtrador.filtrar_mascaras_personas(\n",
        "                mascaras_todas,\n",
        "                imagen.shape[:2]\n",
        "            )\n",
        "\n",
        "            resultado = {\n",
        "                'total_mascaras_generadas': len(mascaras_todas),\n",
        "                'personas_detectadas': len(mascaras_personas),\n",
        "                'mascaras_personas': mascaras_personas,\n",
        "                'mascaras_todas': mascaras_todas,  # Guardar todas por si acaso\n",
        "                'tiempo_generacion_ms': tiempo_generacion,\n",
        "                'imagen_shape': imagen.shape[:2],\n",
        "            }\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"‚úÖ Generaci√≥n completa: {len(mascaras_todas)} m√°scaras ‚Üí \"\n",
        "                f\"{len(mascaras_personas)} personas en {tiempo_generacion:.1f}ms\"\n",
        "            )\n",
        "\n",
        "            return resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando m√°scaras: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def liberar_memoria(self):\n",
        "        \"\"\"Libera memoria del modelo\"\"\"\n",
        "        del self.modelo\n",
        "        del self.mask_generator\n",
        "        self.modelo = None\n",
        "        self.mask_generator = None\n",
        "        Utils.limpiar_memoria()\n",
        "        self.logger.info(\"Memoria liberada\")"
      ],
      "metadata": {
        "id": "Cr3fz98mkCyB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE M√ÅSCARAS (CON AN√ÅLISIS SHAPELY)\n",
        "# =============================================================================\n",
        "\n",
        "class GestorMascaras:\n",
        "    \"\"\"Gestiona el almacenamiento de m√°scaras individuales CON an√°lisis geom√©trico\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_salida: Path, logger: logging.Logger):\n",
        "        self.directorio_salida = directorio_salida\n",
        "        self.logger = logger\n",
        "        self.directorio_mascaras = directorio_salida / \"masks\"\n",
        "        self.directorio_mascaras.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Analizador de m√°scaras con Shapely\n",
        "        self.mask_analyzer = MaskAnalyzer()\n",
        "\n",
        "    def guardar_mascaras(self, mascaras_personas: List[Dict],\n",
        "                        nombre_archivo: str, hash_imagen: str,\n",
        "                        imagen_shape: Tuple[int, int]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Guarda m√°scaras individuales CON an√°lisis geom√©trico completo\n",
        "\n",
        "        Returns:\n",
        "            Metadatos de las m√°scaras guardadas (incluyendo an√°lisis Shapely)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            if not mascaras_personas:\n",
        "                return {'total_guardadas': 0, 'archivos': []}\n",
        "\n",
        "            archivos_guardados = []\n",
        "\n",
        "            for idx, mask_data in enumerate(mascaras_personas):\n",
        "                # An√°lisis geom√©trico completo de la m√°scara\n",
        "                analisis_geometrico = self.mask_analyzer.analizar_mascara_completa(\n",
        "                    mask_data['segmentation'],\n",
        "                    imagen_shape\n",
        "                )\n",
        "\n",
        "                # Nombre del archivo\n",
        "                nombre_base = Path(nombre_archivo).stem\n",
        "                archivo_mask = self.directorio_mascaras / f\"{nombre_base}_mask_{idx:03d}.npz\"\n",
        "\n",
        "                # Guardar m√°scara y metadatos completos\n",
        "                np.savez_compressed(\n",
        "                    archivo_mask,\n",
        "                    segmentation=mask_data['segmentation'].astype(np.uint8),\n",
        "                    bbox=np.array(mask_data['bbox']),\n",
        "                    area=mask_data['area'],\n",
        "                    predicted_iou=mask_data.get('predicted_iou', 0),\n",
        "                    stability_score=mask_data.get('stability_score', 0),\n",
        "                    person_confidence=mask_data.get('person_confidence', 0),\n",
        "                    criteria_met=mask_data.get('criteria_met', 0),\n",
        "                )\n",
        "\n",
        "                # Metadatos para JSON (incluye an√°lisis Shapely)\n",
        "                archivos_guardados.append({\n",
        "                    'archivo': archivo_mask.name,\n",
        "                    'indice': idx,\n",
        "                    'area': int(mask_data['area']),\n",
        "                    'confianza_persona': float(mask_data.get('person_confidence', 0)),\n",
        "                    'bbox': mask_data['bbox'],\n",
        "                    'analisis_geometrico': analisis_geometrico\n",
        "                })\n",
        "\n",
        "            metadatos = {\n",
        "                'total_guardadas': len(archivos_guardados),\n",
        "                'archivos': archivos_guardados,\n",
        "                'directorio': str(self.directorio_mascaras)\n",
        "            }\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Guardadas {len(archivos_guardados)} m√°scaras con an√°lisis geom√©trico\")\n",
        "\n",
        "            return metadatos\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error guardando m√°scaras: {str(e)}\")\n",
        "            return {'total_guardadas': 0, 'archivos': [], 'error': str(e)}"
      ],
      "metadata": {
        "id": "v2jRY4uKkK-z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE VISUALIZACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizacionesSAM:\n",
        "    \"\"\"Genera visualizaciones comparativas de resultados SAM\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_salida: Path, logger: logging.Logger = None):\n",
        "        self.directorio_salida = directorio_salida\n",
        "        self.directorio_salida.mkdir(parents=True, exist_ok=True)\n",
        "        self.logger = logger or logging.getLogger(__name__)\n",
        "\n",
        "    def generar_visualizacion_completa(self, imagen_original: np.ndarray,\n",
        "                                      nombre_archivo: str,\n",
        "                                      resultado_generacion: Dict,\n",
        "                                      modelo_nombre: str = \"SAM2\") -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Genera visualizaci√≥n completa: original + todas las m√°scaras + solo personas\n",
        "        \"\"\"\n",
        "        try:\n",
        "            mascaras_todas = resultado_generacion.get('mascaras_todas', [])\n",
        "            mascaras_personas = resultado_generacion.get('mascaras_personas', [])\n",
        "\n",
        "            if not mascaras_todas:\n",
        "                self.logger.warning(\"No hay m√°scaras para visualizar\")\n",
        "                return None\n",
        "\n",
        "            # Crear figura con 3 subplots\n",
        "            fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
        "            fig.suptitle(\n",
        "                f'{modelo_nombre} - {nombre_archivo}\\n'\n",
        "                f'Total: {len(mascaras_todas)} m√°scaras | Personas: {len(mascaras_personas)}',\n",
        "                fontsize=16, fontweight='bold'\n",
        "            )\n",
        "\n",
        "            # 1. Imagen original\n",
        "            axes[0].imshow(imagen_original)\n",
        "            axes[0].set_title('Imagen Original', fontsize=14)\n",
        "            axes[0].axis('off')\n",
        "\n",
        "            # 2. Todas las m√°scaras\n",
        "            self._visualizar_mascaras(axes[1], imagen_original, mascaras_todas,\n",
        "                                     f'Todas las M√°scaras ({len(mascaras_todas)})')\n",
        "\n",
        "            # 3. Solo personas\n",
        "            self._visualizar_mascaras(axes[2], imagen_original, mascaras_personas,\n",
        "                                     f'Personas Detectadas ({len(mascaras_personas)})',\n",
        "                                     mostrar_confianza=True)\n",
        "\n",
        "            # Guardar\n",
        "            nombre_vis = Path(nombre_archivo).stem + f'_{modelo_nombre}_completo.png'\n",
        "            ruta_salida = self.directorio_salida / nombre_vis\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(ruta_salida, dpi=150, bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "            self.logger.info(f\"‚úÖ Visualizaci√≥n guardada: {ruta_salida.name}\")\n",
        "\n",
        "            return str(ruta_salida)\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generando visualizaci√≥n: {str(e)}\")\n",
        "            plt.close('all')\n",
        "            return None\n",
        "\n",
        "    def _visualizar_mascaras(self, ax, imagen: np.ndarray, mascaras: List[Dict],\n",
        "                            titulo: str, mostrar_confianza: bool = False):\n",
        "        \"\"\"Visualiza m√°scaras en un eje\"\"\"\n",
        "        ax.imshow(imagen)\n",
        "\n",
        "        if not mascaras:\n",
        "            ax.set_title(f'{titulo} - Vac√≠o', fontsize=12)\n",
        "            ax.axis('off')\n",
        "            return\n",
        "\n",
        "        # Crear overlay con colores aleatorios\n",
        "        overlay = np.zeros_like(imagen, dtype=np.float32)\n",
        "\n",
        "        for mask_data in mascaras:\n",
        "            seg = mask_data['segmentation']\n",
        "            color = np.random.random(3)\n",
        "\n",
        "            # Aplicar m√°scara con transparencia\n",
        "            for c in range(3):\n",
        "                overlay[:, :, c] += seg * color[c] * 0.6\n",
        "\n",
        "        # Normalizar y mostrar\n",
        "        overlay = np.clip(overlay, 0, 1)\n",
        "        ax.imshow(overlay, alpha=0.5)\n",
        "\n",
        "        # A√±adir bounding boxes si es visualizaci√≥n de personas\n",
        "        if mostrar_confianza:\n",
        "            for mask_data in mascaras:\n",
        "                bbox = mask_data['bbox']\n",
        "                confianza = mask_data.get('person_confidence', 0)\n",
        "\n",
        "                rect = mpatches.Rectangle(\n",
        "                    (bbox[0], bbox[1]), bbox[2], bbox[3],\n",
        "                    fill=False, edgecolor='lime', linewidth=2\n",
        "                )\n",
        "                ax.add_patch(rect)\n",
        "\n",
        "                # Etiqueta con confianza\n",
        "                ax.text(\n",
        "                    bbox[0], bbox[1] - 5,\n",
        "                    f'{confianza:.2f}',\n",
        "                    color='lime', fontsize=10, fontweight='bold',\n",
        "                    bbox=dict(facecolor='black', alpha=0.7, pad=2)\n",
        "                )\n",
        "\n",
        "        ax.set_title(titulo, fontsize=12)\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "PLZXdYInkTZ7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROCESADOR DE RESULTADOS (CON AN√ÅLISIS FOTOGR√ÅFICO)\n",
        "# =============================================================================\n",
        "\n",
        "class ProcesadorResultados:\n",
        "    \"\"\"Procesa y almacena resultados de evaluaci√≥n CON an√°lisis fotogr√°fico completo\"\"\"\n",
        "\n",
        "    def __init__(self, directorio_salida: Path, logger_manager: LoggerManager):\n",
        "        self.directorio_salida = directorio_salida\n",
        "        self.logger_manager = logger_manager\n",
        "        self.logger = logger_manager.crear_logger(\"procesador\")\n",
        "\n",
        "        # Extractor de caracter√≠sticas fotogr√°ficas (IGUAL QUE MASK2FORMER)\n",
        "        self.extractor = ExtractorCaracteristicasAvanzado()\n",
        "        self.extractor.set_logger(self.logger)\n",
        "\n",
        "        # Componentes\n",
        "        self.gestor_mascaras = GestorMascaras(directorio_salida, self.logger)\n",
        "        self.generador_vis = GeneradorVisualizacionesSAM(\n",
        "            directorio_salida / \"visualizaciones\",\n",
        "            self.logger\n",
        "        )\n",
        "\n",
        "        # Contadores\n",
        "        self.imagenes_procesadas = 0\n",
        "        self.imagenes_exitosas = 0\n",
        "        self.tiempo_total_procesamiento = 0\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: str,\n",
        "                       generador: GeneradorMascarasSAM,\n",
        "                       modelo_nombre: str, config_nombre: str,\n",
        "                       guardar_visualizacion: bool = True) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"Procesa una imagen y guarda resultados CON an√°lisis fotogr√°fico completo\"\"\"\n",
        "\n",
        "        inicio_procesamiento = time.time()\n",
        "        nombre_archivo = os.path.basename(ruta_imagen)\n",
        "\n",
        "        try:\n",
        "            # Preparar imagen\n",
        "            imagen_np = Utils.preparar_imagen(ruta_imagen)\n",
        "            imagen_pil = Image.fromarray(imagen_np)\n",
        "            hash_imagen = Utils.calcular_hash_imagen(ruta_imagen)\n",
        "\n",
        "            self.logger.info(f\"Extrayendo caracter√≠sticas fotogr√°ficas de {nombre_archivo}...\")\n",
        "            caracteristicas_avanzadas = self.extractor.analizar_imagen_completa(\n",
        "                imagen_pil,\n",
        "                ruta_imagen\n",
        "            )\n",
        "\n",
        "            # Informaci√≥n completa de la imagen\n",
        "            info_imagen = {\n",
        "                'archivo': nombre_archivo,\n",
        "                'ruta_completa': ruta_imagen,\n",
        "                'hash_md5': hash_imagen,\n",
        "                'resolucion': {\n",
        "                    'altura': imagen_np.shape[0],\n",
        "                    'anchura': imagen_np.shape[1],\n",
        "                    'canales': imagen_np.shape[2] if len(imagen_np.shape) > 2 else 1\n",
        "                },\n",
        "                'caracteristicas_avanzadas': caracteristicas_avanzadas\n",
        "            }\n",
        "\n",
        "            # Generar m√°scaras\n",
        "            resultado_mascaras = generador.generar_mascaras(imagen_np)\n",
        "\n",
        "            # Guardar m√°scaras individuales con an√°lisis geom√©trico\n",
        "            metadatos_mascaras = self.gestor_mascaras.guardar_mascaras(\n",
        "                resultado_mascaras['mascaras_personas'],\n",
        "                nombre_archivo,\n",
        "                hash_imagen,\n",
        "                imagen_np.shape[:2]\n",
        "            )\n",
        "\n",
        "            # Generar visualizaci√≥n\n",
        "            ruta_visualizacion = None\n",
        "            if guardar_visualizacion:\n",
        "                ruta_visualizacion = self.generador_vis.generar_visualizacion_completa(\n",
        "                    imagen_np, nombre_archivo, resultado_mascaras,\n",
        "                    modelo_nombre=f\"{modelo_nombre}_{config_nombre}\"\n",
        "                )\n",
        "\n",
        "            # Construir resultado completo\n",
        "            tiempo_procesamiento = (time.time() - inicio_procesamiento) * 1000\n",
        "\n",
        "            resultado = {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo': modelo_nombre,\n",
        "                'configuracion': config_nombre,\n",
        "                'imagen': info_imagen,\n",
        "                'deteccion': {\n",
        "                    'total_mascaras_generadas': resultado_mascaras['total_mascaras_generadas'],\n",
        "                    'personas_detectadas': resultado_mascaras['personas_detectadas'],\n",
        "                    'tiempo_generacion_ms': resultado_mascaras['tiempo_generacion_ms'],\n",
        "                    'mascaras_guardadas': metadatos_mascaras,\n",
        "                },\n",
        "                'visualizacion': {\n",
        "                    'archivo': Path(ruta_visualizacion).name if ruta_visualizacion else None,\n",
        "                    'ruta': str(ruta_visualizacion) if ruta_visualizacion else None\n",
        "                },\n",
        "                'rendimiento': {\n",
        "                    'tiempo_total_procesamiento_ms': tiempo_procesamiento,\n",
        "                },\n",
        "                'exito': True\n",
        "            }\n",
        "\n",
        "            # Actualizar contadores\n",
        "            self.imagenes_procesadas += 1\n",
        "            self.imagenes_exitosas += 1\n",
        "            self.tiempo_total_procesamiento += tiempo_procesamiento\n",
        "\n",
        "            self.logger.info(\n",
        "                f\"‚úÖ {nombre_archivo} - {resultado_mascaras['personas_detectadas']} personas \"\n",
        "                f\"({tiempo_procesamiento:.1f}ms)\"\n",
        "            )\n",
        "\n",
        "            return resultado\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"‚ùå Error procesando {nombre_archivo}: {str(e)}\")\n",
        "\n",
        "            self.imagenes_procesadas += 1\n",
        "\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'modelo': modelo_nombre,\n",
        "                'imagen': {'archivo': nombre_archivo},\n",
        "                'error': str(e),\n",
        "                'exito': False\n",
        "            }"
      ],
      "metadata": {
        "id": "kvZpVCdkki-R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL SAM 2.0\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorSAM2:\n",
        "    \"\"\"Evaluador principal de modelos SAM 2.0\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfigEvaluacionSAM):\n",
        "        self.config = config\n",
        "\n",
        "        # Crear directorio de ejecuci√≥n con timestamp\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        self.directorio_ejecucion = config.BASE_PATH / \"resultados\" / f\"{timestamp}_evaluacion_sam2\"\n",
        "        self.directorio_ejecucion.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Sistema de logging\n",
        "        self.logger_manager = LoggerManager(self.directorio_ejecucion / \"logs\")\n",
        "        self.logger = self.logger_manager.crear_logger(\"evaluador_principal\")\n",
        "\n",
        "        self.logger.info(\"=\"*80)\n",
        "        self.logger.info(\"EVALUADOR SAM 2.0 INICIALIZADO\")\n",
        "        self.logger.info(f\"Directorio de ejecuci√≥n: {self.directorio_ejecucion}\")\n",
        "        self.logger.info(\"=\"*80)\n",
        "\n",
        "        # Estad√≠sticas\n",
        "        self.estadisticas_globales = {\n",
        "            'timestamp_inicio': timestamp,\n",
        "            'modelos_evaluados': [],\n",
        "            'imagenes_procesadas': 0,\n",
        "            'imagenes_exitosas': 0,\n",
        "        }\n",
        "\n",
        "    def ejecutar_evaluacion_completa(self) -> Dict[str, List[str]]:\n",
        "        \"\"\"Ejecuta evaluaci√≥n completa de todos los modelos y configuraciones\"\"\"\n",
        "\n",
        "        archivos_resultado = {}\n",
        "\n",
        "        # Obtener lista de im√°genes\n",
        "        imagenes = self._obtener_imagenes_dataset()\n",
        "        total_imagenes = len(imagenes)\n",
        "\n",
        "        self.logger.info(f\"Iniciando evaluaci√≥n con {total_imagenes} im√°genes\")\n",
        "\n",
        "        # Iterar sobre modelos\n",
        "        for modelo_info in self.config.MODELOS:\n",
        "            modelo_nombre = modelo_info.obtener_nombre_sanitizado()\n",
        "\n",
        "            print(f\"\\n{'='*100}\")\n",
        "            print(f\"ü§ñ EVALUANDO MODELO: {modelo_info.nombre}\")\n",
        "            print(f\"   Par√°metros: {modelo_info.parametros_millones}M\")\n",
        "            print(f\"   Descripci√≥n: {modelo_info.descripcion}\")\n",
        "            print(f\"{'='*100}\\n\")\n",
        "\n",
        "            # Seleccionar configuraci√≥n apropiada para el modelo\n",
        "            if 'tiny' in modelo_info.nombre:\n",
        "                config_usar = self.config.CONFIGURACIONES['low_cost_tiny']\n",
        "            else:\n",
        "                config_usar = self.config.CONFIGURACIONES['balanced_small']\n",
        "\n",
        "            archivos_modelo = self._evaluar_modelo(\n",
        "                modelo_info,\n",
        "                config_usar,\n",
        "                imagenes\n",
        "            )\n",
        "\n",
        "            archivos_resultado[modelo_nombre] = archivos_modelo\n",
        "\n",
        "            # Liberar memoria entre modelos\n",
        "            Utils.limpiar_memoria()\n",
        "\n",
        "            print(f\"\\n‚úÖ Modelo {modelo_nombre} completado\\n\")\n",
        "\n",
        "        # Guardar estad√≠sticas globales\n",
        "        self._guardar_estadisticas_globales()\n",
        "\n",
        "        return archivos_resultado\n",
        "\n",
        "    def _evaluar_modelo(self, modelo_info: ModeloSAMInfo,\n",
        "                       config_sam: ConfiguracionSAM,\n",
        "                       imagenes: List[Path]) -> List[str]:\n",
        "        \"\"\"Eval√∫a un modelo espec√≠fico con una configuraci√≥n\"\"\"\n",
        "\n",
        "        modelo_nombre = modelo_info.obtener_nombre_sanitizado()\n",
        "        config_nombre = config_sam.nombre\n",
        "\n",
        "        # Crear directorio para este modelo\n",
        "        dir_modelo = self.directorio_ejecucion / modelo_nombre\n",
        "        dir_json = dir_modelo / \"json\"\n",
        "        dir_json.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Inicializar componentes\n",
        "        generador = GeneradorMascarasSAM(\n",
        "            modelo_info, config_sam,\n",
        "            self.config.CHECKPOINTS_PATH,\n",
        "            self.logger_manager.crear_logger(f\"generador_{modelo_nombre}\")\n",
        "        )\n",
        "\n",
        "        procesador = ProcesadorResultados(\n",
        "            dir_modelo,\n",
        "            self.logger_manager\n",
        "        )\n",
        "\n",
        "        # Cargar modelo\n",
        "        try:\n",
        "            generador.cargar_modelo()\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error cargando modelo {modelo_nombre}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "        # Procesar im√°genes\n",
        "        resultados = []\n",
        "        archivos_guardados = []\n",
        "\n",
        "        for idx, ruta_imagen in enumerate(imagenes, 1):\n",
        "            print(f\"   [{idx}/{len(imagenes)}] Procesando: {ruta_imagen.name}...\", end=' ')\n",
        "\n",
        "            resultado = procesador.procesar_imagen(\n",
        "                str(ruta_imagen),\n",
        "                generador,\n",
        "                modelo_nombre,\n",
        "                config_nombre,\n",
        "                guardar_visualizacion=self.config.GUARDAR_VISUALIZACIONES\n",
        "            )\n",
        "\n",
        "            if resultado:\n",
        "                resultados.append(resultado)\n",
        "\n",
        "                if resultado.get('exito'):\n",
        "                    print(f\"‚úÖ {resultado['deteccion']['personas_detectadas']} personas\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Error\")\n",
        "\n",
        "            # Limpiar memoria cada imagen (importante para Colab)\n",
        "            Utils.limpiar_memoria()\n",
        "\n",
        "        # Guardar resultados en JSON\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        nombre_json = Utils.crear_nombre_archivo(modelo_info, config_nombre, timestamp)\n",
        "        archivo_json = dir_json / nombre_json\n",
        "\n",
        "        resumen = {\n",
        "            'metadata': {\n",
        "                'modelo': asdict(modelo_info),\n",
        "                'configuracion': asdict(config_sam),\n",
        "                'timestamp': timestamp,\n",
        "                'total_imagenes': len(imagenes),\n",
        "                'imagenes_exitosas': procesador.imagenes_exitosas,\n",
        "            },\n",
        "            'resultados': resultados,\n",
        "            'estadisticas': {\n",
        "                'imagenes_procesadas': procesador.imagenes_procesadas,\n",
        "                'imagenes_exitosas': procesador.imagenes_exitosas,\n",
        "                'tiempo_total_ms': procesador.tiempo_total_procesamiento,\n",
        "            }\n",
        "        }\n",
        "\n",
        "        Utils.guardar_json(resumen, archivo_json)\n",
        "        archivos_guardados.append(str(archivo_json))\n",
        "\n",
        "        # Actualizar estad√≠sticas globales\n",
        "        self.estadisticas_globales['modelos_evaluados'].append(modelo_nombre)\n",
        "        self.estadisticas_globales['imagenes_procesadas'] += procesador.imagenes_procesadas\n",
        "        self.estadisticas_globales['imagenes_exitosas'] += procesador.imagenes_exitosas\n",
        "\n",
        "        # Liberar modelo\n",
        "        generador.liberar_memoria()\n",
        "\n",
        "        return archivos_guardados\n",
        "\n",
        "    def _obtener_imagenes_dataset(self) -> List[Path]:\n",
        "        \"\"\"Obtiene lista de im√°genes del dataset\"\"\"\n",
        "        extensiones = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
        "        imagenes = []\n",
        "        for ext in extensiones:\n",
        "            imagenes.extend(self.config.DATASET_PATH.glob(ext))\n",
        "\n",
        "        imagenes.sort()\n",
        "        return imagenes\n",
        "\n",
        "    def _guardar_estadisticas_globales(self):\n",
        "        \"\"\"Guarda estad√≠sticas globales de la ejecuci√≥n\"\"\"\n",
        "        archivo_stats = self.directorio_ejecucion / \"estadisticas_globales.json\"\n",
        "        Utils.guardar_json(self.estadisticas_globales, archivo_stats)\n",
        "        self.logger.info(f\"Estad√≠sticas globales guardadas en {archivo_stats}\")\n",
        "\n",
        "    def obtener_estadisticas_ejecucion(self) -> Dict[str, Any]:\n",
        "        \"\"\"Obtiene estad√≠sticas de la ejecuci√≥n\"\"\"\n",
        "        return {\n",
        "            'directorio_ejecucion': str(self.directorio_ejecucion),\n",
        "            'modelos_evaluados': len(self.estadisticas_globales['modelos_evaluados']),\n",
        "            'imagenes_procesadas': self.estadisticas_globales['imagenes_procesadas'],\n",
        "            'imagenes_exitosas': self.estadisticas_globales['imagenes_exitosas'],\n",
        "        }"
      ],
      "metadata": {
        "id": "zldvhXTmk7rJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# FUNCI√ìN PRINCIPAL\n",
        "# ============================================================================\n",
        "def main():\n",
        "    \"\"\"\n",
        "      Funci√≥n principal √∫nica del sistema de evaluaci√≥n SAM 2.0\n",
        "      Ejecuta autom√°ticamente todos los modelos configurados\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Configuraci√≥n inicial\n",
        "        config = ConfigEvaluacionSAM()\n",
        "\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(f\"SISTEMA DE EVALUACI√ìN SAM 2.0 - OPTIMIZADO PARA RECURSOS LIMITADOS\")\n",
        "        print(f\"{'='*100}\")\n",
        "\n",
        "        print(f\"\\nConfiguraci√≥n de evaluaci√≥n:\")\n",
        "        print(f\"   Modelos SAM 2.0: {len(config.MODELOS)}\")\n",
        "        for i, modelo in enumerate(config.MODELOS):\n",
        "            print(f\"      [{i}] {modelo.nombre} ({modelo.parametros_millones}M params)\")\n",
        "\n",
        "        print(f\"   Configuraciones: {len(config.CONFIGURACIONES)}\")\n",
        "        for nombre, cfg in config.CONFIGURACIONES.items():\n",
        "            print(f\"      {nombre}: {cfg.descripcion}\")\n",
        "\n",
        "        # Validar configuraci√≥n\n",
        "        if not config.validar_configuracion():\n",
        "            print(\"‚ùå ERROR: Configuraci√≥n inv√°lida. Verificar paths y par√°metros.\")\n",
        "            return\n",
        "\n",
        "        print(\"‚úÖ Configuraci√≥n validada correctamente\")\n",
        "\n",
        "        # Crear evaluador\n",
        "        evaluador = EvaluadorSAM2(config)\n",
        "\n",
        "        # Mostrar resumen\n",
        "        resumen_config = config.obtener_resumen_configuracion()\n",
        "        print(f\"\\nRESUMEN DE CONFIGURACI√ìN:\")\n",
        "        print(f\"   Total combinaciones: {resumen_config['total_combinaciones']}\")\n",
        "        print(f\"   Total im√°genes: {resumen_config['total_imagenes']}\")\n",
        "        print(f\"   Dataset: {resumen_config['dataset_path']}\")\n",
        "        print(f\"   Visualizaciones: {'‚úì Habilitadas' if resumen_config['visualizaciones_habilitadas'] else '‚úó Deshabilitadas'}\")\n",
        "\n",
        "        # Ejecutar evaluaci√≥n completa\n",
        "        print(f\"\\nüöÄ INICIANDO EVALUACI√ìN AUTOM√ÅTICA COMPLETA...\")\n",
        "        archivos_resultado = evaluador.ejecutar_evaluacion_completa()\n",
        "\n",
        "        # Obtener estad√≠sticas finales\n",
        "        estadisticas = evaluador.obtener_estadisticas_ejecucion()\n",
        "\n",
        "        # Resumen final\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(f\"‚úÖ EVALUACI√ìN COMPLETA FINALIZADA EXITOSAMENTE\")\n",
        "        print(f\"{'='*100}\")\n",
        "\n",
        "        print(f\"üìÅ Directorio de resultados: {estadisticas['directorio_ejecucion']}\")\n",
        "        print(f\"üìä Im√°genes procesadas: {estadisticas['imagenes_procesadas']}\")\n",
        "        print(f\"‚úÖ Im√°genes exitosas: {estadisticas['imagenes_exitosas']}\")\n",
        "        print(f\"ü§ñ Modelos evaluados: {estadisticas['modelos_evaluados']}\")\n",
        "\n",
        "        print(f\"\\nüìÇ RESUMEN POR MODELO:\")\n",
        "        for modelo, archivos in archivos_resultado.items():\n",
        "            print(f\"   {modelo}: {len(archivos)} evaluaciones completadas\")\n",
        "\n",
        "        print(f\"\\n{'='*100}\")\n",
        "        print(\"üéâ ¬°EVALUACI√ìN SAM 2.0 COMPLETADA!\")\n",
        "        print(f\"{'='*100}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR CR√çTICO: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ],
      "metadata": {
        "id": "S0JMrRNnlTop"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EJECUTAR EVALUACI√ìN\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNcU8Gx2mGkl",
        "outputId": "952c49e1-c009-4ea8-9dd3-16ec92408992"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_evaluador_principal_20251005_192422:================================================================================\n",
            "INFO:SAM2_evaluador_principal_20251005_192422:EVALUADOR SAM 2.0 INICIALIZADO\n",
            "INFO:SAM2_evaluador_principal_20251005_192422:Directorio de ejecuci√≥n: /content/drive/MyDrive/TFM/sam2/resultados/20251005_192422_evaluacion_sam2\n",
            "INFO:SAM2_evaluador_principal_20251005_192422:================================================================================\n",
            "INFO:SAM2_evaluador_principal_20251005_192422:Iniciando evaluaci√≥n con 6 im√°genes\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Cargando modelo sam2_hiera_tiny...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            "SISTEMA DE EVALUACI√ìN SAM 2.0 - OPTIMIZADO PARA RECURSOS LIMITADOS\n",
            "====================================================================================================\n",
            "\n",
            "Configuraci√≥n de evaluaci√≥n:\n",
            "   Modelos SAM 2.0: 4\n",
            "      [0] sam2_hiera_tiny (39M params)\n",
            "      [1] sam2_hiera_small (46M params)\n",
            "      [2] sam2_hiera_base_plus (80M params)\n",
            "      [3] sam2_hiera_large (224M params)\n",
            "   Configuraciones: 3\n",
            "      low_cost_tiny: Configuraci√≥n ultra-r√°pida optimizada para Tiny\n",
            "      balanced_small: Configuraci√≥n balanceada para Small\n",
            "      full_quality: Configuraci√≥n completa para m√°xima calidad\n",
            "‚úÖ Dataset: 6 im√°genes encontradas\n",
            "‚úÖ Configuraci√≥n validada correctamente\n",
            "\n",
            "RESUMEN DE CONFIGURACI√ìN:\n",
            "   Total combinaciones: 12\n",
            "   Total im√°genes: 6\n",
            "   Dataset: /content/drive/MyDrive/TFM/sam2/imagenes\n",
            "   Visualizaciones: ‚úì Habilitadas\n",
            "\n",
            "üöÄ INICIANDO EVALUACI√ìN AUTOM√ÅTICA COMPLETA...\n",
            "\n",
            "====================================================================================================\n",
            "ü§ñ EVALUANDO MODELO: sam2_hiera_tiny\n",
            "   Par√°metros: 39M\n",
            "   Descripci√≥n: Modelo ultraligero para aplicaciones m√≥viles y edge computing\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Modelo sam2_hiera_tiny cargado correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [1/6] Procesando: 1.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 1.jpg...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 5 m√°scaras ‚Üí 3 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 5 m√°scaras ‚Üí 3 personas en 1527.7ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 3 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 1_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 1.jpg - 3 personas (5813.8ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 3 personas\n",
            "   [2/6] Procesando: 2.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 2.jpg...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 14 m√°scaras ‚Üí 11 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 14 m√°scaras ‚Üí 11 personas en 1416.6ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 11 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 2_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 2.jpg - 11 personas (5818.1ms)\n",
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 3.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 11 personas\n",
            "   [3/6] Procesando: 3.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 3 m√°scaras ‚Üí 3 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 3 m√°scaras ‚Üí 3 personas en 1380.7ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 3 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 3_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 3.jpg - 3 personas (5699.0ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 3 personas\n",
            "   [4/6] Procesando: 5.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 5.jpg...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 11 m√°scaras ‚Üí 8 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 11 m√°scaras ‚Üí 8 personas en 1676.6ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 8 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 5_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 5.jpg - 8 personas (6618.8ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 8 personas\n",
            "   [5/6] Procesando: 6.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 6.jpg...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 24 m√°scaras ‚Üí 15 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 24 m√°scaras ‚Üí 15 personas en 1510.9ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 15 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 6_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 6.jpg - 15 personas (6927.8ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 15 personas\n",
            "   [6/6] Procesando: 7.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 7.jpg...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_tiny_20251005_192422:Filtrado: 10 m√°scaras ‚Üí 6 personas candidatas\n",
            "INFO:SAM2_generador_tiny_20251005_192422:‚úÖ Generaci√≥n completa: 10 m√°scaras ‚Üí 6 personas en 1423.8ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 6 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 7_tiny_low_cost_tiny_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 7.jpg - 6 personas (5223.0ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 6 personas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_tiny_20251005_192422:Memoria liberada\n",
            "INFO:SAM2_generador_small_20251005_192422:Cargando modelo sam2_hiera_small...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Modelo tiny completado\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ü§ñ EVALUANDO MODELO: sam2_hiera_small\n",
            "   Par√°metros: 46M\n",
            "   Descripci√≥n: Balance √≥ptimo calidad/velocidad para producci√≥n\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Modelo sam2_hiera_small cargado correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [1/6] Procesando: 1.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 1.jpg...\n",
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 7 m√°scaras ‚Üí 5 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 7 m√°scaras ‚Üí 5 personas en 6619.7ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 5 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 1_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 1.jpg - 5 personas (10569.8ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 5 personas\n",
            "   [2/6] Procesando: 2.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 2.jpg...\n",
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 26 m√°scaras ‚Üí 20 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 26 m√°scaras ‚Üí 20 personas en 6594.4ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 20 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 2_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 2.jpg - 20 personas (12313.4ms)\n",
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 3.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 20 personas\n",
            "   [3/6] Procesando: 3.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 8 m√°scaras ‚Üí 7 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 8 m√°scaras ‚Üí 7 personas en 6446.2ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 7 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 3_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 3.jpg - 7 personas (11755.1ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 7 personas\n",
            "   [4/6] Procesando: 5.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 5.jpg...\n",
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 13 m√°scaras ‚Üí 10 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 13 m√°scaras ‚Üí 10 personas en 7029.1ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 10 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 5_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 5.jpg - 10 personas (11580.5ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 10 personas\n",
            "   [5/6] Procesando: 6.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 6.jpg...\n",
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 34 m√°scaras ‚Üí 25 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 34 m√°scaras ‚Üí 25 personas en 6611.7ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 25 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 6_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 6.jpg - 25 personas (13197.9ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 25 personas\n",
            "   [6/6] Procesando: 7.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 7.jpg...\n",
            "INFO:SAM2_generador_small_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_small_20251005_192422:Filtrado: 14 m√°scaras ‚Üí 11 personas candidatas\n",
            "INFO:SAM2_generador_small_20251005_192422:‚úÖ Generaci√≥n completa: 14 m√°scaras ‚Üí 11 personas en 6457.1ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 11 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 7_small_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 7.jpg - 11 personas (10645.7ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 11 personas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_small_20251005_192422:Memoria liberada\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Cargando modelo sam2_hiera_base_plus...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Modelo small completado\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ü§ñ EVALUANDO MODELO: sam2_hiera_base_plus\n",
            "   Par√°metros: 80M\n",
            "   Descripci√≥n: Modelo avanzado para producci√≥n de alta calidad\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Modelo sam2_hiera_base_plus cargado correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [1/6] Procesando: 1.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 1.jpg...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 7 m√°scaras ‚Üí 5 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 7 m√°scaras ‚Üí 5 personas en 7156.8ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 5 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 1_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 1.jpg - 5 personas (11365.9ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 5 personas\n",
            "   [2/6] Procesando: 2.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 2.jpg...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 29 m√°scaras ‚Üí 21 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 29 m√°scaras ‚Üí 21 personas en 7406.0ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 21 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 2_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 2.jpg - 21 personas (12494.7ms)\n",
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 3.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 21 personas\n",
            "   [3/6] Procesando: 3.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 13 m√°scaras ‚Üí 11 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 13 m√°scaras ‚Üí 11 personas en 7049.5ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 11 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 3_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 3.jpg - 11 personas (12510.3ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 11 personas\n",
            "   [4/6] Procesando: 5.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 5.jpg...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 16 m√°scaras ‚Üí 12 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 16 m√°scaras ‚Üí 12 personas en 7995.7ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 12 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 5_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 5.jpg - 12 personas (12282.7ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 12 personas\n",
            "   [5/6] Procesando: 6.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 6.jpg...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 42 m√°scaras ‚Üí 28 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 42 m√°scaras ‚Üí 28 personas en 7299.4ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 28 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 6_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 6.jpg - 28 personas (13231.8ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 28 personas\n",
            "   [6/6] Procesando: 7.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 7.jpg...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:Filtrado: 23 m√°scaras ‚Üí 16 personas candidatas\n",
            "INFO:SAM2_generador_base_plus_20251005_192422:‚úÖ Generaci√≥n completa: 23 m√°scaras ‚Üí 16 personas en 7135.1ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 16 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 7_base_plus_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 7.jpg - 16 personas (11319.9ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 16 personas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_base_plus_20251005_192422:Memoria liberada\n",
            "INFO:SAM2_generador_large_20251005_192422:Cargando modelo sam2_hiera_large...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Modelo base_plus completado\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "ü§ñ EVALUANDO MODELO: sam2_hiera_large\n",
            "   Par√°metros: 224M\n",
            "   Descripci√≥n: Modelo de investigaci√≥n - m√°xima calidad\n",
            "====================================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Modelo sam2_hiera_large cargado correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   [1/6] Procesando: 1.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 1.jpg...\n",
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 12 m√°scaras ‚Üí 10 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 12 m√°scaras ‚Üí 10 personas en 9384.0ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 10 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 1_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 1.jpg - 10 personas (14144.7ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 10 personas\n",
            "   [2/6] Procesando: 2.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 2.jpg...\n",
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 35 m√°scaras ‚Üí 25 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 35 m√°scaras ‚Üí 25 personas en 9396.9ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 25 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 2_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 2.jpg - 25 personas (16233.1ms)\n",
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 3.jpg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 25 personas\n",
            "   [3/6] Procesando: 3.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 17 m√°scaras ‚Üí 15 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 17 m√°scaras ‚Üí 15 personas en 9114.6ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 15 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 3_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 3.jpg - 15 personas (14792.2ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 15 personas\n",
            "   [4/6] Procesando: 5.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 5.jpg...\n",
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 16 m√°scaras ‚Üí 13 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 16 m√°scaras ‚Üí 13 personas en 9487.4ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 13 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 5_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 5.jpg - 13 personas (14183.6ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 13 personas\n",
            "   [5/6] Procesando: 6.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 6.jpg...\n",
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 43 m√°scaras ‚Üí 28 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 43 m√°scaras ‚Üí 28 personas en 9257.9ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 28 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 6_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 6.jpg - 28 personas (15234.7ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 28 personas\n",
            "   [6/6] Procesando: 7.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_procesador_20251005_192422:Extrayendo caracter√≠sticas fotogr√°ficas de 7.jpg...\n",
            "INFO:SAM2_generador_large_20251005_192422:Generando m√°scaras autom√°ticas...\n",
            "INFO:SAM2_generador_large_20251005_192422:Filtrado: 25 m√°scaras ‚Üí 16 personas candidatas\n",
            "INFO:SAM2_generador_large_20251005_192422:‚úÖ Generaci√≥n completa: 25 m√°scaras ‚Üí 16 personas en 9081.4ms\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Guardadas 16 m√°scaras con an√°lisis geom√©trico\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ Visualizaci√≥n guardada: 7_large_balanced_small_completo.png\n",
            "INFO:SAM2_procesador_20251005_192422:‚úÖ 7.jpg - 16 personas (13110.6ms)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ 16 personas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:SAM2_generador_large_20251005_192422:Memoria liberada\n",
            "INFO:SAM2_evaluador_principal_20251005_192422:Estad√≠sticas globales guardadas en /content/drive/MyDrive/TFM/sam2/resultados/20251005_192422_evaluacion_sam2/estadisticas_globales.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Modelo large completado\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "‚úÖ EVALUACI√ìN COMPLETA FINALIZADA EXITOSAMENTE\n",
            "====================================================================================================\n",
            "üìÅ Directorio de resultados: /content/drive/MyDrive/TFM/sam2/resultados/20251005_192422_evaluacion_sam2\n",
            "üìä Im√°genes procesadas: 24\n",
            "‚úÖ Im√°genes exitosas: 24\n",
            "ü§ñ Modelos evaluados: 4\n",
            "\n",
            "üìÇ RESUMEN POR MODELO:\n",
            "   tiny: 1 evaluaciones completadas\n",
            "   small: 1 evaluaciones completadas\n",
            "   base_plus: 1 evaluaciones completadas\n",
            "   large: 1 evaluaciones completadas\n",
            "\n",
            "====================================================================================================\n",
            "üéâ ¬°EVALUACI√ìN SAM 2.0 COMPLETADA!\n",
            "====================================================================================================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}