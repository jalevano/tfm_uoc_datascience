{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwSD0llcSp54OC6653x+ld",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2C - PCA, CLUSTERING Y ANALISIS DE REDUNDANCIA\n",
        "================================================================================\n",
        "Trabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "en Fotografia de Retrato\n",
        "\n",
        "Autor: Jesus L.\n",
        "Universidad: Universitat Oberta de Catalunya (UOC)\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "DESCRIPCION:\n",
        "Fase 2C del analisis comparativo. Realiza analisis exploratorio multivariante\n",
        "sobre TODAS las metricas de segmentacion disponibles.\n",
        "\n",
        "VERSION 3.0 - CAMBIOS:\n",
        "- Excluye boundary_iou (valores incorrectos por implementacion Canny)\n",
        "- Usa chamfer_distance y hausdorff_distance como metricas de calidad de borde\n",
        "- PCA global y por categoria de metricas\n",
        "- Clustering de fotografias por dificultad\n",
        "- Analisis de redundancia entre metricas\n",
        "\n",
        "METRICAS UTILIZADAS (64 metricas):\n",
        "- Clasicas: IoU, Dice, Precision, Recall, F1 (5)\n",
        "- Distancias de borde: Chamfer, Hausdorff (2) - REEMPLAZAN boundary_iou\n",
        "- Geometricas Shapely: 28 metricas\n",
        "- Haralick interior: 13 metricas texturales\n",
        "- Haralick borde: 13 metricas texturales\n",
        "- Intensidad: 4 metricas\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/3_Analisis/fase2c_pca_clustering/\n",
        "├── pca_global/\n",
        "│   ├── pca_scores.csv\n",
        "│   ├── pca_loadings.csv\n",
        "│   └── pca_varianza.csv\n",
        "├── pca_por_categoria/\n",
        "│   └── (CSV por categoria)\n",
        "├── clustering/\n",
        "│   ├── clusters_fotografias.csv\n",
        "│   └── caracterizacion_clusters.json\n",
        "├── correlaciones/\n",
        "│   ├── matriz_correlaciones.csv\n",
        "│   ├── correlaciones_con_iou.csv\n",
        "│   └── metricas_redundantes.csv\n",
        "├── visualizaciones/\n",
        "│   └── (PNG generados)\n",
        "├── resumen_fase2c.json\n",
        "\n",
        "================================================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qT2PJcG2R1tC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8d8051a9-da44-4e90-d791-ec8b1a1c425b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nFASE 2C - PCA, CLUSTERING Y ANALISIS DE REDUNDANCIA (VERSION 3.0)\\n================================================================================\\nTrabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\\nen Fotografia de Retrato\\n\\nAutor: Jesus L.\\nUniversidad: Universitat Oberta de Catalunya (UOC)\\nFecha: Diciembre 2025\\n\\nDESCRIPCION:\\nFase 2C del analisis comparativo. Realiza analisis exploratorio multivariante\\nsobre TODAS las metricas de segmentacion disponibles.\\n\\nVERSION 3.0 - CAMBIOS:\\n- Excluye boundary_iou (valores incorrectos por implementacion Canny)\\n- Usa chamfer_distance y hausdorff_distance como metricas de calidad de borde\\n- PCA global y por categoria de metricas\\n- Clustering de fotografias por dificultad\\n- Analisis de redundancia entre metricas\\n\\nMETRICAS UTILIZADAS (64 metricas):\\n- Clasicas: IoU, Dice, Precision, Recall, F1 (5)\\n- Distancias de borde: Chamfer, Hausdorff (2) - REEMPLAZAN boundary_iou\\n- Geometricas Shapely: 28 metricas\\n- Haralick interior: 13 metricas texturales\\n- Haralick borde: 13 metricas texturales\\n- Intensidad: 4 metricas\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/3_Analisis/fase2c_pca_clustering/\\n├── pca_global/\\n│   ├── pca_scores.csv\\n│   ├── pca_loadings.csv\\n│   └── pca_varianza.csv\\n├── pca_por_categoria/\\n│   └── (CSV por categoria)\\n├── clustering/\\n│   ├── clusters_fotografias.csv\\n│   └── caracterizacion_clusters.json\\n├── correlaciones/\\n│   ├── matriz_correlaciones.csv\\n│   ├── correlaciones_con_iou.csv\\n│   └── metricas_redundantes.csv\\n├── visualizaciones/\\n│   └── (PNG generados)\\n├── resumen_fase2c.json\\n\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import warnings\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hlAdqvW3HHMt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION DE VISUALIZACION\n",
        "# =============================================================================\n",
        "\n",
        "plt.rcParams.update({\n",
        "    'figure.figsize': (12, 8),\n",
        "    'figure.dpi': 150,\n",
        "    'savefig.dpi': 300,\n",
        "    'font.size': 10,\n",
        "    'axes.titlesize': 12,\n",
        "    'axes.labelsize': 10,\n",
        "    'xtick.labelsize': 9,\n",
        "    'ytick.labelsize': 9,\n",
        "    'legend.fontsize': 9,\n",
        "    'axes.grid': True,\n",
        "    'grid.alpha': 0.3,\n",
        "    'axes.spines.top': False,\n",
        "    'axes.spines.right': False\n",
        "})\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Paleta de colores para modelos\n",
        "COLORES_MODELOS = {\n",
        "    'yolov8': '#2ecc71',\n",
        "    'oneformer': '#3498db',\n",
        "    'sam2': '#e74c3c',\n",
        "    'sam2_prompts': '#9b59b6',\n",
        "    'mask2former': '#f39c12',\n",
        "    'bodypix': '#1abc9c'\n",
        "}\n",
        "\n",
        "# Colores para clusters de dificultad\n",
        "COLORES_CLUSTERS = {0: '#27ae60', 1: '#f1c40f', 2: '#e74c3c'}\n",
        "NOMBRES_CLUSTERS = {0: 'Facil', 1: 'Medio', 2: 'Dificil'}\n",
        "\n",
        "# Colores para categorias de metricas\n",
        "COLORES_CATEGORIAS = {\n",
        "    'clasicas': '#3498db',\n",
        "    'distancias_borde': '#e67e22',\n",
        "    'geometricas': '#2ecc71',\n",
        "    'haralick_interior': '#e74c3c',\n",
        "    'haralick_borde': '#9b59b6',\n",
        "    'intensidad': '#f39c12'\n",
        "}"
      ],
      "metadata": {
        "id": "z8f7r2_vHJRh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionFase2C:\n",
        "    \"\"\"Configuracion centralizada para Fase 2C.\"\"\"\n",
        "    ruta_base_tfm: Path\n",
        "    ruta_datos_fase2b: Path = None\n",
        "    ruta_salida: Path = None\n",
        "    n_componentes_pca: int = 5\n",
        "    n_clusters: int = 3\n",
        "    umbral_redundancia: float = 0.90\n",
        "    umbral_correlacion_significativa: float = 0.30\n",
        "    random_state: int = 42\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.ruta_datos_fase2b is None:\n",
        "            self.ruta_datos_fase2b = (\n",
        "                self.ruta_base_tfm / \"3_Analisis\" / \"fase2b_correlaciones\" /\n",
        "                \"metricas_fusionadas.csv\"\n",
        "            )\n",
        "        if self.ruta_salida is None:\n",
        "            self.ruta_salida = self.ruta_base_tfm / \"3_Analisis\" / \"fase2c_pca_clustering\""
      ],
      "metadata": {
        "id": "k65h11CPHO5Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DEFINICION DE CATEGORIAS DE METRICAS\n",
        "# =============================================================================\n",
        "\n",
        "# NOTA: boundary_iou EXCLUIDO por valores incorrectos (implementacion Canny sin tolerancia)\n",
        "# Se usan chamfer_distance y hausdorff_distance como metricas de calidad de borde\n",
        "\n",
        "METRICAS_POR_CATEGORIA = {\n",
        "    'identificadores': [\n",
        "        'codigo_foto', 'config_codigo', 'modelo'\n",
        "    ],\n",
        "\n",
        "    # Metricas clasicas de segmentacion (SIN boundary_iou)\n",
        "    'clasicas': [\n",
        "        'iou', 'dice', 'precision', 'recall', 'f1_score'\n",
        "    ],\n",
        "\n",
        "    # Metricas de calidad de borde (REEMPLAZAN boundary_iou)\n",
        "    'distancias_borde': [\n",
        "        'chamfer_distance',      # Error promedio del borde (menor = mejor)\n",
        "        'hausdorff_distance'     # Error maximo del borde (menor = mejor)\n",
        "    ],\n",
        "\n",
        "    # Metricas geometricas Shapely\n",
        "    'geometricas': [\n",
        "        'area_px', 'perimetro_px', 'centroide_x', 'centroide_y',\n",
        "        'bbox_xmin', 'bbox_ymin', 'bbox_xmax', 'bbox_ymax',\n",
        "        'aspect_ratio', 'orientacion_grados', 'solidity', 'compacidad',\n",
        "        'circularity', 'elongation', 'rectangularity',\n",
        "        'num_componentes', 'ratio_componente_principal',\n",
        "        'distancia_centro_px', 'zona_tercios', 'recorte_bordes_porcentaje',\n",
        "        'espacio_negativo',\n",
        "        'desplazamiento_centroide_px', 'diferencia_orientacion_grados',\n",
        "        'ratio_solidity', 'diferencia_compacidad', 'symmetric_difference_area_px'\n",
        "    ],\n",
        "\n",
        "    # Haralick interior de la mascara (13 features)\n",
        "    'haralick_interior': [\n",
        "        'haralick_interior_angular_second_moment',\n",
        "        'haralick_interior_contrast',\n",
        "        'haralick_interior_correlation',\n",
        "        'haralick_interior_sum_of_squares_variance',\n",
        "        'haralick_interior_inverse_difference_moment',\n",
        "        'haralick_interior_sum_average',\n",
        "        'haralick_interior_sum_variance',\n",
        "        'haralick_interior_sum_entropy',\n",
        "        'haralick_interior_entropy',\n",
        "        'haralick_interior_difference_variance',\n",
        "        'haralick_interior_difference_entropy',\n",
        "        'haralick_interior_information_measure_correlation_1',\n",
        "        'haralick_interior_information_measure_correlation_2'\n",
        "    ],\n",
        "\n",
        "    # Haralick borde de la mascara (13 features)\n",
        "    'haralick_borde': [\n",
        "        'haralick_borde_angular_second_moment',\n",
        "        'haralick_borde_contrast',\n",
        "        'haralick_borde_correlation',\n",
        "        'haralick_borde_sum_of_squares_variance',\n",
        "        'haralick_borde_inverse_difference_moment',\n",
        "        'haralick_borde_sum_average',\n",
        "        'haralick_borde_sum_variance',\n",
        "        'haralick_borde_sum_entropy',\n",
        "        'haralick_borde_entropy',\n",
        "        'haralick_borde_difference_variance',\n",
        "        'haralick_borde_difference_entropy',\n",
        "        'haralick_borde_information_measure_correlation_1',\n",
        "        'haralick_borde_information_measure_correlation_2'\n",
        "    ],\n",
        "\n",
        "    # Estadisticas de intensidad\n",
        "    'intensidad': [\n",
        "        'intensidad_media', 'intensidad_std', 'intensidad_min', 'intensidad_max'\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Metricas seleccionadas para PCA global (subconjunto representativo)\n",
        "METRICAS_PCA_GLOBAL = [\n",
        "    # Clasicas\n",
        "    'iou', 'dice', 'precision', 'recall', 'f1_score',\n",
        "    # Distancias de borde (reemplazan boundary_iou)\n",
        "    'chamfer_distance', 'hausdorff_distance',\n",
        "    # Geometricas clave\n",
        "    'solidity', 'compacidad', 'circularity', 'elongation', 'aspect_ratio',\n",
        "    'espacio_negativo', 'desplazamiento_centroide_px',\n",
        "    # Haralick interior (top 5)\n",
        "    'haralick_interior_contrast', 'haralick_interior_correlation',\n",
        "    'haralick_interior_entropy', 'haralick_interior_homogeneity',\n",
        "    'haralick_interior_energy',\n",
        "    # Haralick borde (top 5)\n",
        "    'haralick_borde_contrast', 'haralick_borde_correlation',\n",
        "    'haralick_borde_entropy', 'haralick_borde_homogeneity',\n",
        "    'haralick_borde_energy'\n",
        "]"
      ],
      "metadata": {
        "id": "oDRHHy_VHYD_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIONES DE UTILIDAD\n",
        "# =============================================================================\n",
        "\n",
        "def convertir_a_serializable(obj: Any) -> Any:\n",
        "    \"\"\"Convierte tipos numpy/pandas a tipos Python nativos para JSON.\"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convertir_a_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convertir_a_serializable(v) for v in obj]\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        if np.isnan(obj) or np.isinf(obj):\n",
        "            return None\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, (np.bool_, bool)):\n",
        "        return bool(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif pd.isna(obj):\n",
        "        return None\n",
        "    return obj"
      ],
      "metadata": {
        "id": "gcU5pe8zHapR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: CARGADOR DE DATOS\n",
        "# =============================================================================\n",
        "\n",
        "class CargadorDatos:\n",
        "    \"\"\"Carga y prepara datos para Fase 2C.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def cargar_datos(self) -> pd.DataFrame:\n",
        "        \"\"\"Carga el dataset fusionado de Fase 2B.\"\"\"\n",
        "        self.logger.info(f\"Cargando datos de: {self.config.ruta_datos_fase2b}\")\n",
        "\n",
        "        if not self.config.ruta_datos_fase2b.exists():\n",
        "            raise FileNotFoundError(f\"No existe: {self.config.ruta_datos_fase2b}\")\n",
        "\n",
        "        df = pd.read_csv(self.config.ruta_datos_fase2b)\n",
        "\n",
        "        self.logger.info(f\"  Filas: {len(df)}\")\n",
        "        self.logger.info(f\"  Columnas: {len(df.columns)}\")\n",
        "        self.logger.info(f\"  Modelos: {df['modelo'].nunique()}\")\n",
        "        self.logger.info(f\"  Fotografias: {df['codigo_foto'].nunique()}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def identificar_metricas_disponibles(self, df: pd.DataFrame) -> Dict[str, List[str]]:\n",
        "        \"\"\"Identifica metricas disponibles por categoria en el dataset.\"\"\"\n",
        "        self.logger.info(\"Identificando metricas disponibles por categoria...\")\n",
        "\n",
        "        metricas_disponibles = {}\n",
        "        total_disponibles = 0\n",
        "\n",
        "        for categoria, metricas in METRICAS_POR_CATEGORIA.items():\n",
        "            if categoria == 'identificadores':\n",
        "                continue\n",
        "\n",
        "            disponibles = [m for m in metricas if m in df.columns and df[m].notna().sum() > 0]\n",
        "            metricas_disponibles[categoria] = disponibles\n",
        "            total_disponibles += len(disponibles)\n",
        "\n",
        "            self.logger.info(f\"  {categoria}: {len(disponibles)}/{len(metricas)} metricas\")\n",
        "\n",
        "        self.logger.info(f\"  TOTAL metricas disponibles: {total_disponibles}\")\n",
        "\n",
        "        return metricas_disponibles\n",
        "\n",
        "    def preparar_matriz_pca(self, df: pd.DataFrame,\n",
        "                            metricas: List[str]) -> Tuple[np.ndarray, pd.DataFrame, List[str]]:\n",
        "        \"\"\"\n",
        "        Prepara matriz estandarizada para PCA.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame con datos\n",
        "            metricas: Lista de metricas a incluir\n",
        "\n",
        "        Returns:\n",
        "            Tupla (matriz_estandarizada, metadata, nombres_features)\n",
        "        \"\"\"\n",
        "        # Filtrar metricas disponibles\n",
        "        metricas_validas = [m for m in metricas if m in df.columns]\n",
        "\n",
        "        if len(metricas_validas) < 3:\n",
        "            raise ValueError(f\"Insuficientes metricas validas: {len(metricas_validas)}\")\n",
        "\n",
        "        # Extraer metricas\n",
        "        df_metricas = df[metricas_validas].copy()\n",
        "\n",
        "        # Metadata\n",
        "        cols_meta = ['modelo', 'config_codigo', 'codigo_foto']\n",
        "        cols_meta = [c for c in cols_meta if c in df.columns]\n",
        "        df_meta = df[cols_meta].copy()\n",
        "\n",
        "        # Eliminar filas con demasiados NaN (>50%)\n",
        "        umbral_nan = len(metricas_validas) * 0.5\n",
        "        mask_valido = df_metricas.notna().sum(axis=1) >= umbral_nan\n",
        "\n",
        "        df_metricas = df_metricas[mask_valido].reset_index(drop=True)\n",
        "        df_meta = df_meta[mask_valido].reset_index(drop=True)\n",
        "\n",
        "        self.logger.info(f\"  Filas validas: {len(df_metricas)}/{len(df)}\")\n",
        "\n",
        "        # Imputar NaN restantes con mediana\n",
        "        for col in df_metricas.columns:\n",
        "            if df_metricas[col].isna().any():\n",
        "                mediana = df_metricas[col].median()\n",
        "                df_metricas[col].fillna(mediana, inplace=True)\n",
        "\n",
        "        # Estandarizar\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(df_metricas)\n",
        "\n",
        "        return X_scaled, df_meta, metricas_validas"
      ],
      "metadata": {
        "id": "eTFUl7g8HeGW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR PCA\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorPCA:\n",
        "    \"\"\"Ejecuta analisis PCA sobre metricas de segmentacion.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def ejecutar_pca(self, X: np.ndarray, nombres_features: List[str],\n",
        "                     n_componentes: int = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Ejecuta PCA.\n",
        "\n",
        "        Args:\n",
        "            X: Matriz estandarizada (n_samples, n_features)\n",
        "            nombres_features: Nombres de las features\n",
        "            n_componentes: Numero de componentes (default: config)\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados PCA\n",
        "        \"\"\"\n",
        "        if n_componentes is None:\n",
        "            n_componentes = min(\n",
        "                self.config.n_componentes_pca,\n",
        "                X.shape[1],\n",
        "                X.shape[0] - 1\n",
        "            )\n",
        "\n",
        "        self.logger.info(f\"  Ejecutando PCA con {n_componentes} componentes...\")\n",
        "\n",
        "        pca = PCA(n_components=n_componentes, random_state=self.config.random_state)\n",
        "        scores = pca.fit_transform(X)\n",
        "\n",
        "        var_explicada = pca.explained_variance_ratio_\n",
        "        var_acumulada = np.cumsum(var_explicada)\n",
        "\n",
        "        self.logger.info(f\"  Varianza explicada por PC1: {var_explicada[0]*100:.1f}%\")\n",
        "        self.logger.info(f\"  Varianza total ({n_componentes} PCs): {var_acumulada[-1]*100:.1f}%\")\n",
        "\n",
        "        return {\n",
        "            'pca_model': pca,\n",
        "            'scores': scores,\n",
        "            'loadings': pca.components_,\n",
        "            'varianza_explicada': var_explicada,\n",
        "            'varianza_acumulada': var_acumulada,\n",
        "            'n_componentes': n_componentes,\n",
        "            'feature_names': nombres_features\n",
        "        }\n",
        "\n",
        "    def ejecutar_pca_por_categoria(self, df: pd.DataFrame,\n",
        "                                    metricas_por_cat: Dict[str, List[str]]) -> Dict[str, Dict]:\n",
        "        \"\"\"\n",
        "        Ejecuta PCA separado por cada categoria de metricas.\n",
        "\n",
        "        Returns:\n",
        "            Diccionario {categoria: resultados_pca}\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Ejecutando PCA por categoria...\")\n",
        "\n",
        "        resultados = {}\n",
        "\n",
        "        for categoria, metricas in metricas_por_cat.items():\n",
        "            if len(metricas) < 3:\n",
        "                self.logger.warning(f\"  {categoria}: Insuficientes metricas ({len(metricas)}), omitiendo\")\n",
        "                continue\n",
        "\n",
        "            # Preparar datos de esta categoria\n",
        "            df_cat = df[metricas].dropna(thresh=len(metricas)//2)\n",
        "\n",
        "            if len(df_cat) < 20:\n",
        "                self.logger.warning(f\"  {categoria}: Insuficientes observaciones ({len(df_cat)}), omitiendo\")\n",
        "                continue\n",
        "\n",
        "            # Imputar NaN\n",
        "            for col in df_cat.columns:\n",
        "                if df_cat[col].isna().any():\n",
        "                    df_cat[col].fillna(df_cat[col].median(), inplace=True)\n",
        "\n",
        "            # Estandarizar\n",
        "            scaler = StandardScaler()\n",
        "            X = scaler.fit_transform(df_cat)\n",
        "\n",
        "            # PCA\n",
        "            n_comp = min(5, len(metricas), len(df_cat) - 1)\n",
        "            resultado = self.ejecutar_pca(X, metricas, n_comp)\n",
        "\n",
        "            resultados[categoria] = resultado\n",
        "\n",
        "            self.logger.info(f\"  {categoria}: {n_comp} PCs, {resultado['varianza_acumulada'][-1]*100:.1f}% varianza\")\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def obtener_top_loadings(self, resultado_pca: Dict, n_top: int = 5) -> Dict[str, List]:\n",
        "        \"\"\"Obtiene las variables con mayores loadings absolutos por componente.\"\"\"\n",
        "        top_por_pc = {}\n",
        "\n",
        "        loadings = resultado_pca['loadings']\n",
        "        nombres = resultado_pca['feature_names']\n",
        "\n",
        "        for i in range(resultado_pca['n_componentes']):\n",
        "            # Ordenar por valor absoluto\n",
        "            indices = np.argsort(np.abs(loadings[i]))[::-1][:n_top]\n",
        "            top_por_pc[f'PC{i+1}'] = [\n",
        "                {'feature': nombres[idx], 'loading': float(loadings[i, idx])}\n",
        "                for idx in indices\n",
        "            ]\n",
        "\n",
        "        return top_por_pc"
      ],
      "metadata": {
        "id": "X_RUkjs6HhRO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR CLUSTERING\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorClustering:\n",
        "    \"\"\"Clustering de fotografias por nivel de dificultad.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.labels = None\n",
        "        self.df_features = None\n",
        "\n",
        "    def preparar_features_fotografias(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Prepara features agregadas por fotografia para clustering.\n",
        "\n",
        "        Cada fotografia se caracteriza por:\n",
        "        - IoU medio, std, min, max\n",
        "        - Dice medio\n",
        "        - Chamfer distance medio (calidad de borde)\n",
        "        - Numero de modelos con IoU > 0.8\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Preparando features de fotografias para clustering...\")\n",
        "\n",
        "        # Agregar por foto\n",
        "        agg_dict = {'iou': ['mean', 'std', 'min', 'max']}\n",
        "\n",
        "        if 'dice' in df.columns:\n",
        "            agg_dict['dice'] = 'mean'\n",
        "\n",
        "        if 'chamfer_distance' in df.columns:\n",
        "            agg_dict['chamfer_distance'] = 'mean'\n",
        "\n",
        "        if 'hausdorff_distance' in df.columns:\n",
        "            agg_dict['hausdorff_distance'] = 'mean'\n",
        "\n",
        "        features = df.groupby('codigo_foto').agg(agg_dict)\n",
        "        features.columns = ['_'.join(col).strip('_') for col in features.columns]\n",
        "        features = features.reset_index()\n",
        "\n",
        "        # Renombrar para claridad\n",
        "        rename_map = {\n",
        "            'iou_mean': 'iou_mean',\n",
        "            'iou_std': 'iou_std',\n",
        "            'iou_min': 'iou_min',\n",
        "            'iou_max': 'iou_max'\n",
        "        }\n",
        "        features = features.rename(columns=rename_map)\n",
        "\n",
        "        # Rango IoU (variabilidad entre modelos)\n",
        "        features['iou_rango'] = features['iou_max'] - features['iou_min']\n",
        "\n",
        "        # Contar modelos con IoU > 0.8 (modelos que funcionan bien)\n",
        "        modelos_buenos = df[df['iou'] > 0.8].groupby('codigo_foto')['modelo'].nunique()\n",
        "        modelos_buenos = modelos_buenos.reset_index()\n",
        "        modelos_buenos.columns = ['codigo_foto', 'n_modelos_buenos']\n",
        "\n",
        "        features = features.merge(modelos_buenos, on='codigo_foto', how='left')\n",
        "        features['n_modelos_buenos'].fillna(0, inplace=True)\n",
        "\n",
        "        self.logger.info(f\"  Fotografias: {len(features)}\")\n",
        "        self.logger.info(f\"  Features: {list(features.columns)}\")\n",
        "\n",
        "        self.df_features = features\n",
        "        return features\n",
        "\n",
        "    def ejecutar_kmeans(self, df_features: pd.DataFrame = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Ejecuta K-means clustering.\n",
        "\n",
        "        Clusters interpretados como:\n",
        "        - Cluster 0: Facil (alto IoU medio, baja varianza)\n",
        "        - Cluster 1: Medio\n",
        "        - Cluster 2: Dificil (bajo IoU medio, alta varianza)\n",
        "        \"\"\"\n",
        "        if df_features is None:\n",
        "            df_features = self.df_features\n",
        "\n",
        "        self.logger.info(f\"Ejecutando K-means (k={self.config.n_clusters})...\")\n",
        "\n",
        "        # Features para clustering\n",
        "        cols_clustering = ['iou_mean', 'iou_std', 'iou_rango', 'n_modelos_buenos']\n",
        "        cols_disponibles = [c for c in cols_clustering if c in df_features.columns]\n",
        "\n",
        "        X = df_features[cols_disponibles].fillna(0).values\n",
        "\n",
        "        # Estandarizar\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # K-means\n",
        "        kmeans = KMeans(\n",
        "            n_clusters=self.config.n_clusters,\n",
        "            random_state=self.config.random_state,\n",
        "            n_init=10\n",
        "        )\n",
        "        labels_orig = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "        # Metricas de calidad\n",
        "        silhouette = silhouette_score(X_scaled, labels_orig)\n",
        "        calinski = calinski_harabasz_score(X_scaled, labels_orig)\n",
        "\n",
        "        self.logger.info(f\"  Silhouette Score: {silhouette:.3f}\")\n",
        "        self.logger.info(f\"  Calinski-Harabasz: {calinski:.1f}\")\n",
        "\n",
        "        # Reordenar clusters: 0=facil (mayor IoU), 2=dificil (menor IoU)\n",
        "        df_temp = df_features.copy()\n",
        "        df_temp['cluster_orig'] = labels_orig\n",
        "        medias_iou = df_temp.groupby('cluster_orig')['iou_mean'].mean()\n",
        "        orden = medias_iou.sort_values(ascending=False).index.tolist()\n",
        "        mapeo = {old: new for new, old in enumerate(orden)}\n",
        "        self.labels = np.array([mapeo[l] for l in labels_orig])\n",
        "\n",
        "        # Caracterizacion de clusters\n",
        "        df_temp['cluster'] = self.labels\n",
        "        caracterizacion = {}\n",
        "\n",
        "        for c in range(self.config.n_clusters):\n",
        "            df_c = df_temp[df_temp['cluster'] == c]\n",
        "            caracterizacion[c] = {\n",
        "                'nombre': NOMBRES_CLUSTERS[c],\n",
        "                'n_fotos': int(len(df_c)),\n",
        "                'iou_mean': float(df_c['iou_mean'].mean()),\n",
        "                'iou_std_mean': float(df_c['iou_std'].mean()),\n",
        "                'iou_rango_mean': float(df_c['iou_rango'].mean()),\n",
        "                'fotos': df_c['codigo_foto'].tolist()\n",
        "            }\n",
        "            self.logger.info(\n",
        "                f\"  Cluster {c} ({NOMBRES_CLUSTERS[c]}): \"\n",
        "                f\"{len(df_c)} fotos, IoU medio={df_c['iou_mean'].mean():.3f}\"\n",
        "            )\n",
        "\n",
        "        return {\n",
        "            'silhouette': float(silhouette),\n",
        "            'calinski_harabasz': float(calinski),\n",
        "            'n_clusters': self.config.n_clusters,\n",
        "            'caracterizacion': caracterizacion\n",
        "        }\n",
        "\n",
        "    def ejecutar_jerarquico(self, df_features: pd.DataFrame = None) -> np.ndarray:\n",
        "        \"\"\"Ejecuta clustering jerarquico (para dendrograma).\"\"\"\n",
        "        if df_features is None:\n",
        "            df_features = self.df_features\n",
        "\n",
        "        cols = ['iou_mean', 'iou_std', 'iou_rango']\n",
        "        cols_disponibles = [c for c in cols if c in df_features.columns]\n",
        "\n",
        "        X = df_features[cols_disponibles].fillna(0).values\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        return linkage(X_scaled, method='ward')"
      ],
      "metadata": {
        "id": "36lIE7oAHlH-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR CORRELACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorCorrelaciones:\n",
        "    \"\"\"Analiza correlaciones entre metricas de segmentacion.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def calcular_matriz_correlaciones(self, df: pd.DataFrame,\n",
        "                                       metricas: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Calcula matriz de correlacion Pearson entre metricas.\"\"\"\n",
        "        self.logger.info(f\"Calculando matriz de correlaciones ({len(metricas)} metricas)...\")\n",
        "\n",
        "        metricas_validas = [m for m in metricas if m in df.columns]\n",
        "        df_metricas = df[metricas_validas].dropna(thresh=len(metricas_validas)//2)\n",
        "\n",
        "        matriz = df_metricas.corr(method='pearson')\n",
        "\n",
        "        self.logger.info(f\"  Matriz: {matriz.shape[0]}x{matriz.shape[1]}\")\n",
        "\n",
        "        return matriz\n",
        "\n",
        "    def identificar_metricas_redundantes(self, matriz: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Identifica pares de metricas altamente correlacionadas (redundantes).\"\"\"\n",
        "        self.logger.info(f\"Identificando metricas redundantes (|r| > {self.config.umbral_redundancia})...\")\n",
        "\n",
        "        redundantes = []\n",
        "        n = len(matriz)\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(i + 1, n):\n",
        "                r = matriz.iloc[i, j]\n",
        "                if abs(r) > self.config.umbral_redundancia:\n",
        "                    redundantes.append({\n",
        "                        'metrica_1': matriz.index[i],\n",
        "                        'metrica_2': matriz.columns[j],\n",
        "                        'correlacion': float(r),\n",
        "                        'tipo': 'positiva' if r > 0 else 'negativa'\n",
        "                    })\n",
        "\n",
        "        df_red = pd.DataFrame(redundantes)\n",
        "\n",
        "        if len(df_red) > 0:\n",
        "            df_red = df_red.sort_values('correlacion', key=abs, ascending=False)\n",
        "\n",
        "        self.logger.info(f\"  Pares redundantes encontrados: {len(df_red)}\")\n",
        "\n",
        "        return df_red\n",
        "\n",
        "    def calcular_correlaciones_con_iou(self, df: pd.DataFrame,\n",
        "                                        metricas: List[str]) -> pd.DataFrame:\n",
        "        \"\"\"Calcula correlaciones de todas las metricas con IoU.\"\"\"\n",
        "        self.logger.info(\"Calculando correlaciones de metricas con IoU...\")\n",
        "\n",
        "        correlaciones = []\n",
        "\n",
        "        for metrica in metricas:\n",
        "            if metrica == 'iou' or metrica not in df.columns:\n",
        "                continue\n",
        "\n",
        "            mask = df[metrica].notna() & df['iou'].notna()\n",
        "            n = mask.sum()\n",
        "\n",
        "            if n < 20:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                r, p = stats.pearsonr(df.loc[mask, metrica], df.loc[mask, 'iou'])\n",
        "\n",
        "                correlaciones.append({\n",
        "                    'metrica': metrica,\n",
        "                    'correlacion_iou': float(r),\n",
        "                    'p_valor': float(p),\n",
        "                    'n_observaciones': int(n),\n",
        "                    'significativo': p < 0.05,\n",
        "                    'magnitud': 'alta' if abs(r) > 0.5 else 'media' if abs(r) > 0.3 else 'baja'\n",
        "                })\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "        df_corr = pd.DataFrame(correlaciones)\n",
        "\n",
        "        if len(df_corr) > 0:\n",
        "            df_corr = df_corr.sort_values('correlacion_iou', key=abs, ascending=False)\n",
        "\n",
        "        n_sig = df_corr['significativo'].sum() if len(df_corr) > 0 else 0\n",
        "        self.logger.info(f\"  Correlaciones calculadas: {len(df_corr)}\")\n",
        "        self.logger.info(f\"  Significativas (p<0.05): {n_sig}\")\n",
        "\n",
        "        return df_corr"
      ],
      "metadata": {
        "id": "VpGAjEPSHn6g"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: GENERADOR VISUALIZACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizaciones:\n",
        "    \"\"\"Genera visualizaciones para Fase 2C.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "        self.ruta_viz = config.ruta_salida / \"visualizaciones\"\n",
        "\n",
        "    def _crear_directorio(self):\n",
        "        \"\"\"Crea directorio de visualizaciones si no existe.\"\"\"\n",
        "        self.ruta_viz.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def generar_scree_plot(self, resultado_pca: Dict, titulo: str = \"PCA\") -> Path:\n",
        "        \"\"\"Genera scree plot de varianza explicada.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        n = resultado_pca['n_componentes']\n",
        "        x = range(1, n + 1)\n",
        "        var = resultado_pca['varianza_explicada'] * 100\n",
        "        acum = resultado_pca['varianza_acumulada'] * 100\n",
        "\n",
        "        # Barras de varianza individual\n",
        "        bars = ax.bar(x, var, color='steelblue', alpha=0.7, label='Individual')\n",
        "\n",
        "        # Linea de varianza acumulada\n",
        "        ax.plot(x, acum, 'ro-', linewidth=2, markersize=8, label='Acumulada')\n",
        "\n",
        "        # Linea de referencia 80%\n",
        "        ax.axhline(y=80, color='gray', linestyle='--', alpha=0.5, label='80%')\n",
        "\n",
        "        # Etiquetas en barras\n",
        "        for i, v in enumerate(var):\n",
        "            ax.text(i + 1, v + 1.5, f'{v:.1f}%', ha='center', fontsize=9)\n",
        "\n",
        "        ax.set_xlabel('Componente Principal')\n",
        "        ax.set_ylabel('Varianza Explicada (%)')\n",
        "        ax.set_title(f'{titulo}: Varianza Explicada por Componente', fontweight='bold')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels([f'PC{i}' for i in x])\n",
        "        ax.legend(loc='right')\n",
        "        ax.set_ylim(0, 105)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        nombre_archivo = titulo.lower().replace(' ', '_').replace(':', '').replace('/', '_')\n",
        "        ruta = self.ruta_viz / f'scree_{nombre_archivo}.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta\n",
        "\n",
        "    def generar_biplot(self, resultado_pca: Dict, df_meta: pd.DataFrame,\n",
        "                       titulo: str = \"PCA\") -> Path:\n",
        "        \"\"\"Genera biplot con scores y loadings.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        scores = resultado_pca['scores'][:, :2]\n",
        "        loadings = resultado_pca['loadings'][:2, :].T\n",
        "        nombres = resultado_pca['feature_names']\n",
        "\n",
        "        # Scatter de scores por modelo\n",
        "        if 'modelo' in df_meta.columns:\n",
        "            modelos = df_meta['modelo'].values[:len(scores)]\n",
        "            for modelo in np.unique(modelos):\n",
        "                mask = modelos == modelo\n",
        "                color = COLORES_MODELOS.get(modelo, '#666666')\n",
        "                ax.scatter(scores[mask, 0], scores[mask, 1],\n",
        "                          c=color, label=modelo, alpha=0.5, s=30, edgecolors='white')\n",
        "        else:\n",
        "            ax.scatter(scores[:, 0], scores[:, 1], alpha=0.5, s=30)\n",
        "\n",
        "        # Flechas de loadings\n",
        "        scale = np.abs(scores).max() / np.abs(loadings).max() * 0.8\n",
        "\n",
        "        for i, (name, loading) in enumerate(zip(nombres, loadings)):\n",
        "            ax.arrow(0, 0, loading[0] * scale, loading[1] * scale,\n",
        "                    head_width=0.08, head_length=0.06, fc='darkred', ec='darkred', alpha=0.7)\n",
        "\n",
        "            # Nombre abreviado\n",
        "            nombre_corto = name[:20] + '...' if len(name) > 20 else name\n",
        "            offset = 1.12 if loading[1] >= 0 else 1.08\n",
        "            ax.text(loading[0] * scale * offset, loading[1] * scale * offset,\n",
        "                   nombre_corto, fontsize=7, ha='center', color='darkred')\n",
        "\n",
        "        ax.axhline(y=0, color='gray', linewidth=0.5)\n",
        "        ax.axvline(x=0, color='gray', linewidth=0.5)\n",
        "\n",
        "        var = resultado_pca['varianza_explicada'] * 100\n",
        "        ax.set_xlabel(f'PC1 ({var[0]:.1f}%)')\n",
        "        ax.set_ylabel(f'PC2 ({var[1]:.1f}%)')\n",
        "        ax.set_title(f'{titulo}: Biplot', fontweight='bold')\n",
        "\n",
        "        if 'modelo' in df_meta.columns:\n",
        "            ax.legend(loc='upper right', title='Modelo', fontsize=8)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        nombre_archivo = titulo.lower().replace(' ', '_').replace(':', '').replace('/', '_')\n",
        "        ruta = self.ruta_viz / f'biplot_{nombre_archivo}.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta\n",
        "\n",
        "    def generar_heatmap_correlaciones(self, matriz: pd.DataFrame,\n",
        "                                       titulo: str = \"Correlaciones\") -> Path:\n",
        "        \"\"\"Genera heatmap de matriz de correlaciones.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        n = len(matriz)\n",
        "        size = max(10, min(20, n * 0.5))\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(size, size * 0.9))\n",
        "\n",
        "        # Mascara triangular superior\n",
        "        mask = np.triu(np.ones_like(matriz, dtype=bool), k=1)\n",
        "\n",
        "        sns.heatmap(\n",
        "            matriz,\n",
        "            mask=mask,\n",
        "            annot=n <= 15,\n",
        "            fmt='.2f' if n <= 15 else '',\n",
        "            cmap='RdBu_r',\n",
        "            center=0,\n",
        "            vmin=-1, vmax=1,\n",
        "            square=True,\n",
        "            linewidths=0.5 if n <= 20 else 0,\n",
        "            cbar_kws={'shrink': 0.8, 'label': 'Correlacion'},\n",
        "            ax=ax,\n",
        "            annot_kws={'size': 7}\n",
        "        )\n",
        "\n",
        "        ax.set_title(f'{titulo}', fontweight='bold', pad=20)\n",
        "\n",
        "        # Rotar etiquetas\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        nombre_archivo = titulo.lower().replace(' ', '_').replace(':', '').replace('/', '_')\n",
        "        ruta = self.ruta_viz / f'heatmap_{nombre_archivo}.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta\n",
        "\n",
        "    def generar_dendrograma(self, linkage_matrix: np.ndarray,\n",
        "                            etiquetas: List[str]) -> Path:\n",
        "        \"\"\"Genera dendrograma de clustering jerarquico.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "        # Abreviar etiquetas\n",
        "        etiquetas_cortas = [e.replace('_DSC', '').replace('_', '') for e in etiquetas]\n",
        "\n",
        "        dendrogram(\n",
        "            linkage_matrix,\n",
        "            labels=etiquetas_cortas,\n",
        "            leaf_rotation=90,\n",
        "            leaf_font_size=9,\n",
        "            ax=ax,\n",
        "            color_threshold=0.7 * max(linkage_matrix[:, 2])\n",
        "        )\n",
        "\n",
        "        ax.set_xlabel('Fotografia')\n",
        "        ax.set_ylabel('Distancia (Ward)')\n",
        "        ax.set_title('Clustering Jerarquico de Fotografias por Dificultad', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        ruta = self.ruta_viz / 'dendrograma_fotografias.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta\n",
        "\n",
        "    def generar_scatter_clusters(self, df_features: pd.DataFrame,\n",
        "                                  labels: np.ndarray) -> Path:\n",
        "        \"\"\"Genera scatter plot de clusters.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "        df_plot = df_features.copy()\n",
        "        df_plot['cluster'] = labels\n",
        "\n",
        "        # Panel 1: IoU mean vs std\n",
        "        ax = axes[0]\n",
        "        for c in range(3):\n",
        "            mask = df_plot['cluster'] == c\n",
        "            ax.scatter(\n",
        "                df_plot.loc[mask, 'iou_mean'],\n",
        "                df_plot.loc[mask, 'iou_std'],\n",
        "                c=COLORES_CLUSTERS[c],\n",
        "                label=NOMBRES_CLUSTERS[c],\n",
        "                s=100, alpha=0.7, edgecolors='white', linewidth=1\n",
        "            )\n",
        "\n",
        "            # Etiquetas de fotos\n",
        "            for _, row in df_plot[mask].iterrows():\n",
        "                ax.annotate(row['codigo_foto'].replace('_DSC', ''),\n",
        "                           (row['iou_mean'], row['iou_std']),\n",
        "                           fontsize=6, alpha=0.7)\n",
        "\n",
        "        ax.set_xlabel('IoU Medio (todos los modelos)')\n",
        "        ax.set_ylabel('IoU Desviacion Estandar')\n",
        "        ax.set_title('Clusters: Rendimiento vs Variabilidad')\n",
        "        ax.legend(title='Dificultad')\n",
        "\n",
        "        # Panel 2: IoU mean vs rango\n",
        "        ax = axes[1]\n",
        "        for c in range(3):\n",
        "            mask = df_plot['cluster'] == c\n",
        "            ax.scatter(\n",
        "                df_plot.loc[mask, 'iou_mean'],\n",
        "                df_plot.loc[mask, 'iou_rango'],\n",
        "                c=COLORES_CLUSTERS[c],\n",
        "                label=NOMBRES_CLUSTERS[c],\n",
        "                s=100, alpha=0.7, edgecolors='white', linewidth=1\n",
        "            )\n",
        "\n",
        "        ax.set_xlabel('IoU Medio')\n",
        "        ax.set_ylabel('Rango IoU (max - min)')\n",
        "        ax.set_title('Clusters: Rendimiento vs Rango entre Modelos')\n",
        "        ax.legend(title='Dificultad')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        ruta = self.ruta_viz / 'clusters_fotografias.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta\n",
        "\n",
        "    def generar_barplot_correlaciones_iou(self, df_corr: pd.DataFrame,\n",
        "                                           n_top: int = 25) -> Path:\n",
        "        \"\"\"Genera barplot horizontal de correlaciones con IoU.\"\"\"\n",
        "        self._crear_directorio()\n",
        "\n",
        "        df_top = df_corr.head(n_top).copy()\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "        # Colores segun signo\n",
        "        colores = ['#e74c3c' if r < 0 else '#27ae60'\n",
        "                   for r in df_top['correlacion_iou']]\n",
        "\n",
        "        y_pos = range(len(df_top))\n",
        "        bars = ax.barh(y_pos, df_top['correlacion_iou'], color=colores, alpha=0.7)\n",
        "\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(df_top['metrica'], fontsize=8)\n",
        "        ax.set_xlabel('Correlacion con IoU')\n",
        "        ax.set_title(f'Top {n_top} Metricas mas Correlacionadas con IoU', fontweight='bold')\n",
        "        ax.axvline(x=0, color='black', linewidth=0.5)\n",
        "        ax.set_xlim(-1, 1)\n",
        "        ax.invert_yaxis()\n",
        "\n",
        "        # Leyenda\n",
        "        legend_elements = [\n",
        "            mpatches.Patch(color='#27ae60', label='Correlacion positiva'),\n",
        "            mpatches.Patch(color='#e74c3c', label='Correlacion negativa')\n",
        "        ]\n",
        "        ax.legend(handles=legend_elements, loc='lower right')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        ruta = self.ruta_viz / 'correlaciones_con_iou.png'\n",
        "        fig.savefig(ruta, dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "        self.logger.info(f\"  Guardado: {ruta.name}\")\n",
        "        return ruta"
      ],
      "metadata": {
        "id": "SVLQv4YmHsJE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ORQUESTADOR FASE 2C\n",
        "# =============================================================================\n",
        "\n",
        "class OrquestadorFase2C:\n",
        "    \"\"\"Orquesta la ejecucion completa de Fase 2C.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2C):\n",
        "        self.config = config\n",
        "        self.logger = self._configurar_logger()\n",
        "\n",
        "        # Componentes\n",
        "        self.cargador = CargadorDatos(config, self.logger)\n",
        "        self.analizador_pca = AnalizadorPCA(config, self.logger)\n",
        "        self.analizador_clustering = AnalizadorClustering(config, self.logger)\n",
        "        self.analizador_corr = AnalizadorCorrelaciones(config, self.logger)\n",
        "        self.generador_viz = GeneradorVisualizaciones(config, self.logger)\n",
        "\n",
        "        # Resultados\n",
        "        self.resultados = {}\n",
        "        self.df = None\n",
        "\n",
        "    def _configurar_logger(self) -> logging.Logger:\n",
        "        \"\"\"Configura logger para Fase 2C.\"\"\"\n",
        "        logger = logging.getLogger('Fase2C')\n",
        "        logger.setLevel(logging.INFO)\n",
        "        logger.handlers = []\n",
        "\n",
        "        handler = logging.StreamHandler(sys.stdout)\n",
        "        handler.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter(\n",
        "            '[%(asctime)s] %(levelname)-8s | %(message)s',\n",
        "            datefmt='%H:%M:%S'\n",
        "        )\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "\n",
        "        return logger\n",
        "\n",
        "    def ejecutar(self) -> Dict:\n",
        "        \"\"\"Ejecuta el pipeline completo de Fase 2C.\"\"\"\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(\"FASE 2C - PCA, CLUSTERING Y ANALISIS DE REDUNDANCIA\")\n",
        "        self.logger.info(\"Version 3.0 - Usando Chamfer/Hausdorff en lugar de Boundary IoU\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "\n",
        "        inicio = datetime.now()\n",
        "\n",
        "        # Paso 1: Cargar datos\n",
        "        self.logger.info(\"\\n[PASO 1/8] Cargando datos de Fase 2B...\")\n",
        "        self.df = self.cargador.cargar_datos()\n",
        "\n",
        "        # Paso 2: Identificar metricas\n",
        "        self.logger.info(\"\\n[PASO 2/8] Identificando metricas disponibles...\")\n",
        "        metricas_por_cat = self.cargador.identificar_metricas_disponibles(self.df)\n",
        "        self.resultados['metricas_por_categoria'] = {k: len(v) for k, v in metricas_por_cat.items()}\n",
        "\n",
        "        # Paso 3: PCA global\n",
        "        self.logger.info(\"\\n[PASO 3/8] Ejecutando PCA global...\")\n",
        "        metricas_pca = [m for m in METRICAS_PCA_GLOBAL if m in self.df.columns]\n",
        "        self.logger.info(f\"  Metricas para PCA global: {len(metricas_pca)}\")\n",
        "\n",
        "        X_pca, df_meta, nombres_features = self.cargador.preparar_matriz_pca(self.df, metricas_pca)\n",
        "        self.resultados['pca_global'] = self.analizador_pca.ejecutar_pca(X_pca, nombres_features)\n",
        "        self.resultados['top_loadings'] = self.analizador_pca.obtener_top_loadings(\n",
        "            self.resultados['pca_global']\n",
        "        )\n",
        "\n",
        "        # Paso 4: PCA por categoria\n",
        "        self.logger.info(\"\\n[PASO 4/8] Ejecutando PCA por categoria...\")\n",
        "        self.resultados['pca_categorias'] = self.analizador_pca.ejecutar_pca_por_categoria(\n",
        "            self.df, metricas_por_cat\n",
        "        )\n",
        "\n",
        "        # Paso 5: Clustering\n",
        "        self.logger.info(\"\\n[PASO 5/8] Ejecutando clustering de fotografias...\")\n",
        "        df_features = self.analizador_clustering.preparar_features_fotografias(self.df)\n",
        "        self.resultados['clustering'] = self.analizador_clustering.ejecutar_kmeans(df_features)\n",
        "        linkage_mat = self.analizador_clustering.ejecutar_jerarquico(df_features)\n",
        "\n",
        "        # Paso 6: Correlaciones\n",
        "        self.logger.info(\"\\n[PASO 6/8] Analizando correlaciones entre metricas...\")\n",
        "        todas_metricas = []\n",
        "        for cat, mets in metricas_por_cat.items():\n",
        "            todas_metricas.extend(mets)\n",
        "\n",
        "        matriz_corr = self.analizador_corr.calcular_matriz_correlaciones(self.df, todas_metricas)\n",
        "        self.resultados['redundantes'] = self.analizador_corr.identificar_metricas_redundantes(matriz_corr)\n",
        "        self.resultados['corr_iou'] = self.analizador_corr.calcular_correlaciones_con_iou(\n",
        "            self.df, todas_metricas\n",
        "        )\n",
        "\n",
        "        # Paso 7: Visualizaciones\n",
        "        self.logger.info(\"\\n[PASO 7/8] Generando visualizaciones...\")\n",
        "\n",
        "        self.generador_viz.generar_scree_plot(self.resultados['pca_global'], \"PCA Global\")\n",
        "        self.generador_viz.generar_biplot(self.resultados['pca_global'], df_meta, \"PCA Global\")\n",
        "\n",
        "        # Heatmap (solo si matriz no es muy grande)\n",
        "        if len(matriz_corr) <= 40:\n",
        "            self.generador_viz.generar_heatmap_correlaciones(matriz_corr, \"Metricas Segmentacion\")\n",
        "\n",
        "        self.generador_viz.generar_dendrograma(linkage_mat, df_features['codigo_foto'].tolist())\n",
        "        self.generador_viz.generar_scatter_clusters(df_features, self.analizador_clustering.labels)\n",
        "        self.generador_viz.generar_barplot_correlaciones_iou(self.resultados['corr_iou'])\n",
        "\n",
        "        # Paso 8: Guardar resultados\n",
        "        self.logger.info(\"\\n[PASO 8/8] Guardando resultados...\")\n",
        "        self._guardar_resultados(df_features, matriz_corr, df_meta)\n",
        "\n",
        "        # Resumen final\n",
        "        duracion = (datetime.now() - inicio).total_seconds()\n",
        "\n",
        "        self.logger.info(\"\\n\" + \"=\" * 70)\n",
        "        self.logger.info(\"FASE 2C COMPLETADA\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(f\"Duracion: {duracion:.1f} segundos\")\n",
        "        self.logger.info(f\"Resultados guardados en: {self.config.ruta_salida}\")\n",
        "\n",
        "        return self.resultados\n",
        "\n",
        "    def _guardar_resultados(self, df_features: pd.DataFrame,\n",
        "                            matriz_corr: pd.DataFrame,\n",
        "                            df_meta: pd.DataFrame) -> None:\n",
        "        \"\"\"Guarda todos los resultados en archivos.\"\"\"\n",
        "        self.config.ruta_salida.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # --- PCA Global ---\n",
        "        pca_dir = self.config.ruta_salida / \"pca_global\"\n",
        "        pca_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        pca = self.resultados['pca_global']\n",
        "        n_comp = pca['n_componentes']\n",
        "        cols_pc = [f'PC{i+1}' for i in range(n_comp)]\n",
        "\n",
        "        # Scores\n",
        "        df_scores = pd.DataFrame(pca['scores'], columns=cols_pc)\n",
        "        for col in ['modelo', 'config_codigo', 'codigo_foto']:\n",
        "            if col in df_meta.columns:\n",
        "                df_scores[col] = df_meta[col].values[:len(df_scores)]\n",
        "        df_scores.to_csv(pca_dir / 'pca_scores.csv', index=False)\n",
        "\n",
        "        # Loadings\n",
        "        df_loadings = pd.DataFrame(\n",
        "            pca['loadings'].T,\n",
        "            index=pca['feature_names'],\n",
        "            columns=cols_pc\n",
        "        )\n",
        "        df_loadings.to_csv(pca_dir / 'pca_loadings.csv')\n",
        "\n",
        "        # Varianza\n",
        "        df_var = pd.DataFrame({\n",
        "            'componente': cols_pc,\n",
        "            'varianza_explicada': pca['varianza_explicada'],\n",
        "            'varianza_acumulada': pca['varianza_acumulada']\n",
        "        })\n",
        "        df_var.to_csv(pca_dir / 'pca_varianza.csv', index=False)\n",
        "\n",
        "        self.logger.info(f\"  PCA global guardado en: {pca_dir}\")\n",
        "\n",
        "        # --- Clustering ---\n",
        "        cl_dir = self.config.ruta_salida / \"clustering\"\n",
        "        cl_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        df_clusters = df_features[['codigo_foto']].copy()\n",
        "        df_clusters['cluster'] = self.analizador_clustering.labels\n",
        "        df_clusters['nombre_cluster'] = df_clusters['cluster'].map(NOMBRES_CLUSTERS)\n",
        "        df_clusters['iou_mean'] = df_features['iou_mean']\n",
        "        df_clusters['iou_std'] = df_features['iou_std']\n",
        "        df_clusters.to_csv(cl_dir / 'clusters_fotografias.csv', index=False)\n",
        "\n",
        "        # Caracterizacion JSON\n",
        "        with open(cl_dir / 'caracterizacion_clusters.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(\n",
        "                convertir_a_serializable(self.resultados['clustering']['caracterizacion']),\n",
        "                f, indent=2, ensure_ascii=False\n",
        "            )\n",
        "\n",
        "        self.logger.info(f\"  Clustering guardado en: {cl_dir}\")\n",
        "\n",
        "        # --- Correlaciones ---\n",
        "        corr_dir = self.config.ruta_salida / \"correlaciones\"\n",
        "        corr_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        matriz_corr.to_csv(corr_dir / 'matriz_correlaciones.csv')\n",
        "        self.resultados['redundantes'].to_csv(corr_dir / 'metricas_redundantes.csv', index=False)\n",
        "        self.resultados['corr_iou'].to_csv(corr_dir / 'correlaciones_con_iou.csv', index=False)\n",
        "\n",
        "        self.logger.info(f\"  Correlaciones guardadas en: {corr_dir}\")\n",
        "\n",
        "        # --- Resumen JSON ---\n",
        "        resumen = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'version': '3.0',\n",
        "            'nota': 'boundary_iou excluido, usando chamfer/hausdorff',\n",
        "            'datos': {\n",
        "                'filas': len(self.df),\n",
        "                'columnas': len(self.df.columns),\n",
        "                'modelos': int(self.df['modelo'].nunique()),\n",
        "                'fotografias': int(self.df['codigo_foto'].nunique())\n",
        "            },\n",
        "            'pca_global': {\n",
        "                'n_componentes': pca['n_componentes'],\n",
        "                'varianza_total': float(pca['varianza_acumulada'][-1]),\n",
        "                'varianza_pc1': float(pca['varianza_explicada'][0])\n",
        "            },\n",
        "            'clustering': {\n",
        "                'algoritmo': 'kmeans',\n",
        "                'n_clusters': self.resultados['clustering']['n_clusters'],\n",
        "                'silhouette': self.resultados['clustering']['silhouette'],\n",
        "                'calinski_harabasz': self.resultados['clustering']['calinski_harabasz']\n",
        "            },\n",
        "            'correlaciones': {\n",
        "                'total_metricas': len(matriz_corr),\n",
        "                'pares_redundantes': len(self.resultados['redundantes']),\n",
        "                'correlaciones_significativas_iou': int(self.resultados['corr_iou']['significativo'].sum())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open(self.config.ruta_salida / 'resumen_fase2c.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(resumen, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        self.logger.info(f\"  Resumen guardado: resumen_fase2c.json\")"
      ],
      "metadata": {
        "id": "jLQk6rPnH8h8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCION PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def ejecutar_fase2c(ruta_base_tfm: str,\n",
        "                    ruta_datos: str = None) -> OrquestadorFase2C:\n",
        "    \"\"\"\n",
        "    Ejecuta Fase 2C completa.\n",
        "\n",
        "    Args:\n",
        "        ruta_base_tfm: Ruta base del proyecto TFM\n",
        "        ruta_datos: Ruta opcional al CSV fusionado de Fase 2B\n",
        "\n",
        "    Returns:\n",
        "        OrquestadorFase2C con resultados\n",
        "    \"\"\"\n",
        "    config = ConfiguracionFase2C(ruta_base_tfm=Path(ruta_base_tfm))\n",
        "\n",
        "    if ruta_datos:\n",
        "        config.ruta_datos_fase2b = Path(ruta_datos)\n",
        "\n",
        "    orquestador = OrquestadorFase2C(config)\n",
        "    orquestador.ejecutar()\n",
        "\n",
        "    return orquestador"
      ],
      "metadata": {
        "id": "tz5y-qekH_Rt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Montar Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Rutas\n",
        "    RUTA_BASE = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    RUTA_DATOS = RUTA_BASE / \"3_Analisis\" / \"fase2b_correlaciones\" / \"metricas_fusionadas.csv\"\n",
        "\n",
        "    # Verificar existencia\n",
        "    if not RUTA_DATOS.exists():\n",
        "        print(f\"ERROR: No existe el archivo de Fase 2B\")\n",
        "        print(f\"Ruta esperada: {RUTA_DATOS}\")\n",
        "        print(\"\\nEjecute Fase 2B primero.\")\n",
        "    else:\n",
        "        print(f\"Archivo encontrado: {RUTA_DATOS}\")\n",
        "        print(f\"Iniciando Fase 2C...\\n\")\n",
        "\n",
        "        # Ejecutar\n",
        "        orquestador = ejecutar_fase2c(str(RUTA_BASE), str(RUTA_DATOS))\n",
        "\n",
        "        # Mostrar resumen\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"RESUMEN DE RESULTADOS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        if 'clustering' in orquestador.resultados:\n",
        "            print(\"\\nCLUSTERS DE FOTOGRAFIAS:\")\n",
        "            for c, info in orquestador.resultados['clustering']['caracterizacion'].items():\n",
        "                print(f\"  {info['nombre']}: {info['n_fotos']} fotos, IoU medio = {info['iou_mean']:.4f}\")\n",
        "\n",
        "        if 'corr_iou' in orquestador.resultados:\n",
        "            df_corr = orquestador.resultados['corr_iou']\n",
        "            print(f\"\\nTOP 5 CORRELACIONES CON IoU:\")\n",
        "            for _, row in df_corr.head(5).iterrows():\n",
        "                print(f\"  {row['metrica']}: r = {row['correlacion_iou']:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNS-aUACHC4W",
        "outputId": "111cf569-f0b7-423f-c5ce-741aa88cb422"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Archivo encontrado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n",
            "Iniciando Fase 2C...\n",
            "\n",
            "[21:17:49] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | FASE 2C - PCA, CLUSTERING Y ANALISIS DE REDUNDANCIA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:FASE 2C - PCA, CLUSTERING Y ANALISIS DE REDUNDANCIA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | Version 3.0 - Usando Chamfer/Hausdorff en lugar de Boundary IoU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Version 3.0 - Usando Chamfer/Hausdorff en lugar de Boundary IoU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | \n",
            "[PASO 1/8] Cargando datos de Fase 2B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 1/8] Cargando datos de Fase 2B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | Cargando datos de: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Cargando datos de: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Filas: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Filas: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Columnas: 220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Columnas: 220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Modelos: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Modelos: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | \n",
            "[PASO 2/8] Identificando metricas disponibles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 2/8] Identificando metricas disponibles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | Identificando metricas disponibles por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Identificando metricas disponibles por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   clasicas: 5/5 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  clasicas: 5/5 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   distancias_borde: 2/2 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  distancias_borde: 2/2 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   geometricas: 26/26 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  geometricas: 26/26 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   haralick_interior: 13/13 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  haralick_interior: 13/13 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   haralick_borde: 13/13 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  haralick_borde: 13/13 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   intensidad: 4/4 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  intensidad: 4/4 metricas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   TOTAL metricas disponibles: 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  TOTAL metricas disponibles: 63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | \n",
            "[PASO 3/8] Ejecutando PCA global...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 3/8] Ejecutando PCA global...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Metricas para PCA global: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Metricas para PCA global: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Filas validas: 2360/2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Filas validas: 2360/2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza explicada por PC1: 40.4%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 40.4%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza total (5 PCs): 77.8%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (5 PCs): 77.8%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | \n",
            "[PASO 4/8] Ejecutando PCA por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 4/8] Ejecutando PCA por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     | Ejecutando PCA por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Ejecutando PCA por categoria...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza explicada por PC1: 93.4%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 93.4%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza total (5 PCs): 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (5 PCs): 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   clasicas: 5 PCs, 100.0% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  clasicas: 5 PCs, 100.0% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] WARNING  |   distancias_borde: Insuficientes metricas (2), omitiendo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:Fase2C:  distancias_borde: Insuficientes metricas (2), omitiendo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza explicada por PC1: 40.1%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 40.1%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza total (5 PCs): 83.3%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (5 PCs): 83.3%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   geometricas: 5 PCs, 83.3% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  geometricas: 5 PCs, 83.3% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza explicada por PC1: 54.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 54.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza total (5 PCs): 92.7%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (5 PCs): 92.7%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   haralick_interior: 5 PCs, 92.7% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  haralick_interior: 5 PCs, 92.7% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 5 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:49] INFO     |   Varianza explicada por PC1: 48.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 48.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Varianza total (5 PCs): 94.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (5 PCs): 94.2%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   haralick_borde: 5 PCs, 94.2% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  haralick_borde: 5 PCs, 94.2% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Ejecutando PCA con 4 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Ejecutando PCA con 4 componentes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Varianza explicada por PC1: 46.5%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza explicada por PC1: 46.5%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Varianza total (4 PCs): 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Varianza total (4 PCs): 100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   intensidad: 4 PCs, 100.0% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  intensidad: 4 PCs, 100.0% varianza\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | \n",
            "[PASO 5/8] Ejecutando clustering de fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 5/8] Ejecutando clustering de fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | Preparando features de fotografias para clustering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Preparando features de fotografias para clustering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Features: ['codigo_foto', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'dice_mean', 'chamfer_distance_mean', 'hausdorff_distance_mean', 'iou_rango', 'n_modelos_buenos']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Features: ['codigo_foto', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'dice_mean', 'chamfer_distance_mean', 'hausdorff_distance_mean', 'iou_rango', 'n_modelos_buenos']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | Ejecutando K-means (k=3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Ejecutando K-means (k=3)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Silhouette Score: 0.381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Silhouette Score: 0.381\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Calinski-Harabasz: 13.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Calinski-Harabasz: 13.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Cluster 0 (Facil): 3 fotos, IoU medio=0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Cluster 0 (Facil): 3 fotos, IoU medio=0.830\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Cluster 1 (Medio): 9 fotos, IoU medio=0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Cluster 1 (Medio): 9 fotos, IoU medio=0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Cluster 2 (Dificil): 8 fotos, IoU medio=0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Cluster 2 (Dificil): 8 fotos, IoU medio=0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | \n",
            "[PASO 6/8] Analizando correlaciones entre metricas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 6/8] Analizando correlaciones entre metricas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | Calculando matriz de correlaciones (63 metricas)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Calculando matriz de correlaciones (63 metricas)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Matriz: 63x63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Matriz: 63x63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | Identificando metricas redundantes (|r| > 0.9)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Identificando metricas redundantes (|r| > 0.9)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Pares redundantes encontrados: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Pares redundantes encontrados: 39\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | Calculando correlaciones de metricas con IoU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Calculando correlaciones de metricas con IoU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Correlaciones calculadas: 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Correlaciones calculadas: 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     |   Significativas (p<0.05): 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Significativas (p<0.05): 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:50] INFO     | \n",
            "[PASO 7/8] Generando visualizaciones...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 7/8] Generando visualizaciones...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:51] INFO     |   Guardado: scree_pca_global.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Guardado: scree_pca_global.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:52] INFO     |   Guardado: biplot_pca_global.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Guardado: biplot_pca_global.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:53] INFO     |   Guardado: dendrograma_fotografias.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Guardado: dendrograma_fotografias.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:54] INFO     |   Guardado: clusters_fotografias.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Guardado: clusters_fotografias.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     |   Guardado: correlaciones_con_iou.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Guardado: correlaciones_con_iou.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | \n",
            "[PASO 8/8] Guardando resultados...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "[PASO 8/8] Guardando resultados...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     |   PCA global guardado en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/pca_global\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  PCA global guardado en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/pca_global\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     |   Clustering guardado en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Clustering guardado en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     |   Correlaciones guardadas en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/correlaciones\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Correlaciones guardadas en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering/correlaciones\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     |   Resumen guardado: resumen_fase2c.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:  Resumen guardado: resumen_fase2c.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | \n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | FASE 2C COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:FASE 2C COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | Duracion: 6.3 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Duracion: 6.3 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:17:55] INFO     | Resultados guardados en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2C:Resultados guardados en: /content/drive/MyDrive/TFM/3_Analisis/fase2c_pca_clustering\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RESUMEN DE RESULTADOS\n",
            "======================================================================\n",
            "\n",
            "CLUSTERS DE FOTOGRAFIAS:\n",
            "  Facil: 3 fotos, IoU medio = 0.8298\n",
            "  Medio: 9 fotos, IoU medio = 0.7177\n",
            "  Dificil: 8 fotos, IoU medio = 0.5733\n",
            "\n",
            "TOP 5 CORRELACIONES CON IoU:\n",
            "  f1_score: r = 0.984\n",
            "  dice: r = 0.984\n",
            "  precision: r = 0.904\n",
            "  recall: r = 0.876\n",
            "  chamfer_distance: r = -0.721\n"
          ]
        }
      ]
    }
  ]
}