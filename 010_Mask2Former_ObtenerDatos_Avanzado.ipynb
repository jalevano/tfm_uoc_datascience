{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNhVIfrI8wFPf790cIWAT+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/010_Mask2Former_ObtenerDatos_Avanzado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mahotas scikit-image opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baQ_rCzsB-uf",
        "outputId": "0ecca98f-b5b1-46d8-d392-c4b59d0f7c64"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (0.25.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from mahotas) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (1.16.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (2025.8.28)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image) (0.4)\n",
            "Downloading mahotas-1.4.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D1vfgs_B_qX8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import mahotas as mh\n",
        "from skimage import feature, filters, segmentation, measure\n",
        "from skimage.color import rgb2gray, rgb2hsv, rgb2lab\n",
        "from sklearn.cluster import KMeans\n",
        "from typing import Dict, Any\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExtractorCaracteristicasAvanzado:\n",
        "    \"\"\"\n",
        "    Extractor de caracter√≠sticas de im√°genes usando librer√≠as especiales\n",
        "    para an√°lisis completo.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        print(\"üîß Inicializando Extractor de Caracter√≠sticas Avanzado\")\n",
        "        print(\"   üìö Librer√≠as: Mahotas, Scikit-image, OpenCV\")\n",
        "\n",
        "    def analizar_imagen_completa(self, imagen: Image.Image, ruta: str) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        An√°lisis completo usando librer√≠as especializadas\n",
        "\n",
        "        Args:\n",
        "            imagen: Imagen PIL en formato RGB\n",
        "            ruta: Ruta del archivo original\n",
        "\n",
        "        Returns:\n",
        "            Diccionario completo con caracter√≠sticas extra√≠das\n",
        "        \"\"\"\n",
        "        # Conversiones b√°sicas\n",
        "        img_array = np.array(imagen)\n",
        "        img_gray = rgb2gray(img_array)\n",
        "        img_hsv = rgb2hsv(img_array)\n",
        "        img_lab = rgb2lab(img_array)\n",
        "\n",
        "        # Convertir a uint8 para mahotas\n",
        "        img_gray_uint8 = (img_gray * 255).astype(np.uint8)\n",
        "\n",
        "        caracteristicas = {\n",
        "            'metadatos_basicos': self._extraer_metadatos_basicos(imagen, ruta),\n",
        "            'color_y_paleta': self._analizar_color_avanzado(img_array, img_hsv, img_lab),\n",
        "            'texturas_mahotas': self._extraer_texturas_mahotas(img_gray_uint8),\n",
        "            'texturas_skimage': self._extraer_texturas_skimage(img_gray),\n",
        "            'caracteristicas_geometricas': self._analizar_geometria_avanzada(img_gray_uint8),\n",
        "            'multiscale_features': self._extraer_multiscale_features(img_gray),\n",
        "            'propiedades_regionales': self._analizar_propiedades_regionales(img_gray),\n",
        "            'descriptores_locales': self._extraer_descriptores_locales(img_gray_uint8)\n",
        "        }\n",
        "\n",
        "        return caracteristicas\n",
        "\n",
        "    def _extraer_metadatos_basicos(self, imagen: Image.Image, ruta: str) -> Dict:\n",
        "        \"\"\"Metadatos b√°sicos de la imagen\"\"\"\n",
        "        w, h = imagen.size\n",
        "        return {\n",
        "            'dimensiones': {'ancho': w, 'alto': h},\n",
        "            'aspecto_ratio': round(w / h, 3),\n",
        "            'megapixeles': round((w * h) / 1000000, 2),\n",
        "            'orientacion': 'horizontal' if w > h else 'vertical' if h > w else 'cuadrada',\n",
        "            'formato': ruta.split('.')[-1].lower() if '.' in ruta else 'desconocido'\n",
        "        }\n",
        "\n",
        "    def _analizar_color_avanzado(self, img_rgb: np.ndarray, img_hsv: np.ndarray, img_lab: np.ndarray) -> Dict:\n",
        "        \"\"\"An√°lisis de color usando sklearn para paleta dominante\"\"\"\n",
        "        # Paleta dominante con K-means\n",
        "        pixels = img_rgb.reshape(-1, 3)\n",
        "        kmeans = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
        "        kmeans.fit(pixels)\n",
        "\n",
        "        colores_dominantes = kmeans.cluster_centers_.astype(int).tolist()\n",
        "        proporciones = np.bincount(kmeans.labels_) / len(kmeans.labels_)\n",
        "\n",
        "        # Estad√≠sticas b√°sicas por canal\n",
        "        stats_color = {\n",
        "            'paleta_dominante': colores_dominantes,\n",
        "            'proporciones_colores': proporciones.tolist(),\n",
        "            'estadisticas_rgb': {\n",
        "                'media': np.mean(img_rgb, axis=(0,1)).tolist(),\n",
        "                'std': np.std(img_rgb, axis=(0,1)).tolist(),\n",
        "                'rango': {\n",
        "                    'min': np.min(img_rgb, axis=(0,1)).tolist(),\n",
        "                    'max': np.max(img_rgb, axis=(0,1)).tolist()\n",
        "                }\n",
        "            },\n",
        "            'hsv_global': {\n",
        "                'hue_medio': float(np.mean(img_hsv[:,:,0])),\n",
        "                'saturacion_media': float(np.mean(img_hsv[:,:,1])),\n",
        "                'valor_medio': float(np.mean(img_hsv[:,:,2]))\n",
        "            },\n",
        "            'lab_luminancia': {\n",
        "                'L_medio': float(np.mean(img_lab[:,:,0])),\n",
        "                'a_medio': float(np.mean(img_lab[:,:,1])),\n",
        "                'b_medio': float(np.mean(img_lab[:,:,2]))\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return stats_color\n",
        "\n",
        "    def _extraer_texturas_mahotas(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Extracci√≥n de caracter√≠sticas de textura usando Mahotas\"\"\"\n",
        "        try:\n",
        "            # Caracter√≠sticas Haralick (muy utilizadas en an√°lisis de texturas)\n",
        "            haralick_features = mh.features.haralick(img_gray, return_mean=True)\n",
        "\n",
        "            # Local Binary Pattern\n",
        "            lbp = mh.features.lbp(img_gray, radius=1, points=8, ignore_zeros=False)\n",
        "\n",
        "            # Caracter√≠sticas Zernike (descriptores de forma)\n",
        "            try:\n",
        "                zernike_features = mh.features.zernike_moments(img_gray, radius=21)\n",
        "            except:\n",
        "                zernike_features = np.zeros(25)  # Fallback si falla\n",
        "\n",
        "            # Threshold de Otsu\n",
        "            otsu_threshold = mh.otsu(img_gray)\n",
        "\n",
        "            # Caracter√≠sticas adicionales\n",
        "            pftas = mh.features.pftas(img_gray)  # Parameter-free threshold adjacency statistics\n",
        "\n",
        "            return {\n",
        "                'haralick_features': haralick_features.tolist(),\n",
        "                'lbp_histogram': np.histogram(lbp, bins=50)[0].tolist(),\n",
        "                'zernike_moments': zernike_features.tolist(),\n",
        "                'otsu_threshold': float(otsu_threshold),\n",
        "                'pftas': pftas.tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en Mahotas: {str(e)}\",\n",
        "                'haralick_features': [],\n",
        "                'lbp_histogram': [],\n",
        "                'zernike_moments': [],\n",
        "                'otsu_threshold': 0.0,\n",
        "                'pftas': []\n",
        "            }\n",
        "\n",
        "    def _extraer_texturas_skimage(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Extracci√≥n de caracter√≠sticas de textura usando Scikit-image\"\"\"\n",
        "        try:\n",
        "            # Local Binary Pattern con scikit-image\n",
        "            lbp_skimage = feature.local_binary_pattern(img_gray, P=8, R=1, method='uniform')\n",
        "\n",
        "            # GLCM (Gray Level Co-occurrence Matrix) features\n",
        "            img_scaled = (img_gray * 255).astype(np.uint8)\n",
        "            glcm = feature.graycomatrix(img_scaled, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
        "                                      levels=256, symmetric=True, normed=True)\n",
        "\n",
        "            # Propiedades GLCM\n",
        "            contrast = feature.graycoprops(glcm, 'contrast').mean()\n",
        "            dissimilarity = feature.graycoprops(glcm, 'dissimilarity').mean()\n",
        "            homogeneity = feature.graycoprops(glcm, 'homogeneity').mean()\n",
        "            energy = feature.graycoprops(glcm, 'energy').mean()\n",
        "            correlation = feature.graycoprops(glcm, 'correlation').mean()\n",
        "\n",
        "            return {\n",
        "                'lbp_uniform_histogram': np.histogram(lbp_skimage, bins=10)[0].tolist(),\n",
        "                'glcm_properties': {\n",
        "                    'contrast': float(contrast),\n",
        "                    'dissimilarity': float(dissimilarity),\n",
        "                    'homogeneity': float(homogeneity),\n",
        "                    'energy': float(energy),\n",
        "                    'correlation': float(correlation)\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en Scikit-image: {str(e)}\",\n",
        "                'lbp_uniform_histogram': [],\n",
        "                'glcm_properties': {}\n",
        "            }\n",
        "\n",
        "    def _analizar_geometria_avanzada(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"An√°lisis geom√©trico usando mahotas y scikit-image\"\"\"\n",
        "        try:\n",
        "            # Detecci√≥n de bordes con diferentes m√©todos\n",
        "            edges_canny = feature.canny(img_gray / 255.0)\n",
        "\n",
        "            # Usando mahotas para bordes\n",
        "            edges_sobel = mh.sobel(img_gray)\n",
        "\n",
        "            # Detecci√≥n de esquinas\n",
        "            corners = feature.corner_harris(img_gray / 255.0)\n",
        "            corner_peaks = feature.corner_peaks(corners, min_distance=5)\n",
        "\n",
        "            # An√°lisis de forma usando momentos\n",
        "            moments = measure.moments(img_gray)\n",
        "            centroid = measure.centroid(img_gray)\n",
        "\n",
        "            return {\n",
        "                'bordes_canny': float(np.sum(edges_canny)),\n",
        "                'bordes_sobel_intensidad': float(np.mean(edges_sobel)),\n",
        "                'num_corners': len(corner_peaks),\n",
        "                'centroide': [float(centroid[0]), float(centroid[1])],\n",
        "                'momentos_hu': measure.moments_hu(moments).tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en an√°lisis geom√©trico: {str(e)}\",\n",
        "                'bordes_canny': 0.0,\n",
        "                'bordes_sobel_intensidad': 0.0,\n",
        "                'num_corners': 0,\n",
        "                'centroide': [0.0, 0.0],\n",
        "                'momentos_hu': []\n",
        "            }\n",
        "\n",
        "    def _extraer_multiscale_features(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Caracter√≠sticas multi-escala usando scikit-image\"\"\"\n",
        "        try:\n",
        "            # Caracter√≠sticas b√°sicas multi-escala\n",
        "            features_multiscale = feature.multiscale_basic_features(\n",
        "                img_gray,\n",
        "                intensity=True,\n",
        "                edges=True,\n",
        "                texture=True,\n",
        "                sigma_min=0.5,\n",
        "                sigma_max=8\n",
        "            )\n",
        "\n",
        "            # Estad√≠sticas de las caracter√≠sticas multi-escala\n",
        "            return {\n",
        "                'num_features': features_multiscale.shape[-1],\n",
        "                'feature_means': np.mean(features_multiscale, axis=(0,1)).tolist(),\n",
        "                'feature_stds': np.std(features_multiscale, axis=(0,1)).tolist()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en features multiscale: {str(e)}\",\n",
        "                'num_features': 0,\n",
        "                'feature_means': [],\n",
        "                'feature_stds': []\n",
        "            }\n",
        "\n",
        "    def _analizar_propiedades_regionales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"An√°lisis de propiedades regionales usando segmentaci√≥n\"\"\"\n",
        "        try:\n",
        "            # Segmentaci√≥n usando SLIC\n",
        "            segments = segmentation.slic(img_gray, n_segments=100, compactness=10)\n",
        "\n",
        "            # Propiedades de regiones\n",
        "            regions = measure.regionprops(segments, intensity_image=img_gray)\n",
        "\n",
        "            if regions:\n",
        "                areas = [r.area for r in regions]\n",
        "                eccentricities = [r.eccentricity for r in regions]\n",
        "                intensities = [r.mean_intensity for r in regions]\n",
        "\n",
        "                return {\n",
        "                    'num_regiones': len(regions),\n",
        "                    'area_promedio': float(np.mean(areas)),\n",
        "                    'excentricidad_promedio': float(np.mean(eccentricities)),\n",
        "                    'intensidad_promedio_regiones': float(np.mean(intensities)),\n",
        "                    'variabilidad_areas': float(np.std(areas)),\n",
        "                    'variabilidad_intensidades': float(np.std(intensities))\n",
        "                }\n",
        "            else:\n",
        "                return {'num_regiones': 0}\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en an√°lisis regional: {str(e)}\",\n",
        "                'num_regiones': 0\n",
        "            }\n",
        "\n",
        "    def _extraer_descriptores_locales(self, img_gray: np.ndarray) -> Dict:\n",
        "        \"\"\"Descriptores locales usando OpenCV integrado\"\"\"\n",
        "        try:\n",
        "            # Conversi√≥n para OpenCV\n",
        "            img_cv = img_gray.copy()\n",
        "\n",
        "            # Detecci√≥n de puntos clave con diferentes detectores\n",
        "            # ORB (orientaci√≥n y escala invariante)\n",
        "            orb = cv2.ORB_create(nfeatures=100)\n",
        "            keypoints_orb = orb.detect(img_cv, None)\n",
        "\n",
        "            # FAST corners\n",
        "            fast = cv2.FastFeatureDetector_create()\n",
        "            keypoints_fast = fast.detect(img_cv, None)\n",
        "\n",
        "            # BRIEF descriptors (si hay keypoints)\n",
        "            brief = cv2.xfeatures2d.BriefDescriptorExtractor_create() if hasattr(cv2, 'xfeatures2d') else None\n",
        "\n",
        "            return {\n",
        "                'orb_keypoints': len(keypoints_orb),\n",
        "                'fast_keypoints': len(keypoints_fast),\n",
        "                'keypoint_density': (len(keypoints_orb) + len(keypoints_fast)) / (img_gray.shape[0] * img_gray.shape[1])\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'error': f\"Error en descriptores locales: {str(e)}\",\n",
        "                'orb_keypoints': 0,\n",
        "                'fast_keypoints': 0,\n",
        "                'keypoint_density': 0.0\n",
        "            }\n",
        "\n",
        "# Clase integrada mejorada que usa el extractor avanzado\n",
        "class ProcesadorResultadosConLibrerias(ProcesadorResultados):\n",
        "    \"\"\"\n",
        "    Versi√≥n optimizada usando librer√≠as especializadas\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_path: str):\n",
        "        super().__init__(output_path)\n",
        "        self.extractor = ExtractorCaracteristicasAvanzado()\n",
        "        print(\"‚úÖ Procesador con librer√≠as especializadas inicializado\")\n",
        "\n",
        "    def procesar_imagen(self, ruta_imagen: str, detector: DetectorPersonas,\n",
        "                       umbrales: List[float]) -> Optional[Dict]:\n",
        "        \"\"\"\n",
        "        Procesamiento con caracter√≠sticas extra√≠das usando librer√≠as especializadas\n",
        "        \"\"\"\n",
        "        inicio = time.time()\n",
        "\n",
        "        try:\n",
        "            # Preparar imagen\n",
        "            imagen = Utils.preparar_imagen(ruta_imagen)\n",
        "            hash_img = Utils.calcular_hash(ruta_imagen)\n",
        "\n",
        "            # Extracci√≥n completa de caracter√≠sticas usando librer√≠as\n",
        "            print(f\"   üîç Extrayendo caracter√≠sticas avanzadas...\")\n",
        "            caracteristicas_avanzadas = self.extractor.analizar_imagen_completa(imagen, ruta_imagen)\n",
        "\n",
        "            # Detecci√≥n de personas (original)\n",
        "            resultados_deteccion = detector.detectar_en_imagen(imagen, umbrales)\n",
        "\n",
        "            tiempo_total = (time.time() - inicio) * 1000\n",
        "\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {\n",
        "                    'archivo': os.path.basename(ruta_imagen),\n",
        "                    'hash': hash_img,\n",
        "                    'ruta_completa': ruta_imagen,\n",
        "                    'caracteristicas_avanzadas': caracteristicas_avanzadas  # üîÑ NUEVO\n",
        "                },\n",
        "                'deteccion': resultados_deteccion,\n",
        "                'tiempo_total_ms': tiempo_total,\n",
        "                'modelo': detector.modelo_info,\n",
        "                'version_extractor': 'librerias_especializadas',  # üîÑ NUEVO\n",
        "                'exitoso': True\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'imagen': {\n",
        "                    'archivo': os.path.basename(ruta_imagen),\n",
        "                    'ruta_completa': ruta_imagen\n",
        "                },\n",
        "                'error': str(e),\n",
        "                'exitoso': False\n",
        "            }\n",
        "\n",
        "    def mostrar_resumen_avanzado(self, resultados: List[Dict], umbral_config: str) -> None:\n",
        "        \"\"\"\n",
        "        Resumen que incluye estad√≠sticas de las caracter√≠sticas extra√≠das\n",
        "        \"\"\"\n",
        "        # Resumen original\n",
        "        super().mostrar_resumen(resultados, umbral_config)\n",
        "\n",
        "        exitosos = [r for r in resultados if r.get('exitoso', False)]\n",
        "        if not exitosos:\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüß¨ AN√ÅLISIS DE CARACTER√çSTICAS AVANZADAS:\")\n",
        "\n",
        "        # Recopilar estad√≠sticas de caracter√≠sticas\n",
        "        haralick_means = []\n",
        "        glcm_contrasts = []\n",
        "        num_corners = []\n",
        "\n",
        "        for r in exitosos:\n",
        "            carac = r['imagen'].get('caracteristicas_avanzadas', {})\n",
        "\n",
        "            # Caracter√≠sticas Haralick\n",
        "            texturas_mh = carac.get('texturas_mahotas', {})\n",
        "            if 'haralick_features' in texturas_mh and texturas_mh['haralick_features']:\n",
        "                haralick_means.append(np.mean(texturas_mh['haralick_features']))\n",
        "\n",
        "            # GLCM contrast\n",
        "            texturas_sk = carac.get('texturas_skimage', {})\n",
        "            glcm_props = texturas_sk.get('glcm_properties', {})\n",
        "            if 'contrast' in glcm_props:\n",
        "                glcm_contrasts.append(glcm_props['contrast'])\n",
        "\n",
        "            # Corners\n",
        "            geom = carac.get('caracteristicas_geometricas', {})\n",
        "            if 'num_corners' in geom:\n",
        "                num_corners.append(geom['num_corners'])\n",
        "\n",
        "        if haralick_means:\n",
        "            print(f\"   üìä Haralick promedio: {np.mean(haralick_means):.3f} ¬± {np.std(haralick_means):.3f}\")\n",
        "        if glcm_contrasts:\n",
        "            print(f\"   ‚ö° GLCM Contrast: {np.mean(glcm_contrasts):.3f} ¬± {np.std(glcm_contrasts):.3f}\")\n",
        "        if num_corners:\n",
        "            print(f\"   üìê Esquinas promedio: {np.mean(num_corners):.1f} ¬± {np.std(num_corners):.1f}\")\n",
        "\n",
        "        print(f\"   üî¨ Usando: Mahotas + Scikit-image + OpenCV\")\n",
        "\n",
        "# Funci√≥n principal actualizada que mantiene compatibilidad con el c√≥digo original\n",
        "def ejecutar_con_librerias_especializadas(modelo_idx: int = 0, umbral_config: str = 'alta_sensibilidad'):\n",
        "    \"\"\"\n",
        "    Funci√≥n principal que usa librer√≠as especializadas para extracci√≥n de caracter√≠sticas\n",
        "    \"\"\"\n",
        "    # Validaciones (iguales que antes)\n",
        "    if modelo_idx >= len(config.MODELOS_INFO):\n",
        "        print(f\"‚ùå Modelo index inv√°lido. M√°ximo: {len(config.MODELOS_INFO)-1}\")\n",
        "        return\n",
        "\n",
        "    if umbral_config not in config.UMBRALES:\n",
        "        print(f\"‚ùå Configuraci√≥n inv√°lida. Disponibles: {list(config.UMBRALES.keys())}\")\n",
        "        return\n",
        "\n",
        "    modelo_info = config.MODELOS_INFO[modelo_idx]\n",
        "    umbral_info = config.UMBRALES[umbral_config]\n",
        "\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"üöÄ EVALUACI√ìN CON LIBRER√çAS ESPECIALIZADAS\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"üìã CONFIGURACI√ìN:\")\n",
        "    print(f\"   ü§ñ Modelo: {modelo_info['nombre_corto']}\")\n",
        "    print(f\"   üîß Tipo: {modelo_info['tipo'].upper()}\")\n",
        "    print(f\"   üìö Librer√≠as: Mahotas + Scikit-image + OpenCV\")\n",
        "    print(f\"   ‚öôÔ∏è  Umbrales: {umbral_info['descripcion']}\")\n",
        "\n",
        "    # Cargar im√°genes\n",
        "    imagenes = Utils.cargar_imagenes(config.DATASET_PATH)\n",
        "    if not imagenes:\n",
        "        print(\"‚ùå No se encontraron im√°genes para procesar\")\n",
        "        return\n",
        "\n",
        "    umbrales = umbral_info['valores']\n",
        "\n",
        "    # Usar procesador con librer√≠as especializadas\n",
        "    detector = DetectorPersonas(modelo_info)\n",
        "    procesador = ProcesadorResultadosConLibrerias(config.OUTPUT_PATH)  # üîÑ CAMBIO CLAVE\n",
        "\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"üîÑ PROCESANDO {len(imagenes)} IM√ÅGENES\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    resultados = []\n",
        "    tiempo_inicio_total = time.time()\n",
        "\n",
        "    for i, ruta in enumerate(tqdm(imagenes, desc=\"Procesando con librer√≠as especializadas\")):\n",
        "        nombre_archivo = os.path.basename(ruta)\n",
        "        print(f\"\\nüì∑ [{i+1:3d}/{len(imagenes):3d}] {nombre_archivo}\")\n",
        "\n",
        "        resultado = procesador.procesar_imagen(ruta, detector, umbrales)\n",
        "\n",
        "        if resultado and resultado.get('exitoso', False):\n",
        "            resultados.append(resultado)\n",
        "\n",
        "            # Mostrar info b√°sica\n",
        "            deteccion = resultado['deteccion']\n",
        "            mejor_umbral = min(umbrales)\n",
        "            datos = deteccion.get(f'umbral_{mejor_umbral}', {})\n",
        "            personas = datos.get('personas', 0)\n",
        "            tiempo_img = deteccion.get('tiempo_inferencia_ms', 0)\n",
        "\n",
        "            print(f\"   ‚úÖ {personas:2d} personas | {tiempo_img:.1f}ms | Caracter√≠sticas ‚úì\")\n",
        "\n",
        "    # Guardar resultados\n",
        "    tiempo_total = time.time() - tiempo_inicio_total\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    nombre_archivo = f\"especializado_{Utils.crear_nombre_archivo(modelo_info, umbral_config, timestamp)}\"\n",
        "    archivo_completo = config.OUTPUT_PATH / nombre_archivo\n",
        "\n",
        "    metadatos = {\n",
        "        'metadatos': {\n",
        "            'version': 'librerias_especializadas_mahotas_skimage',\n",
        "            'modelo': modelo_info,\n",
        "            'configuracion_umbrales': {\n",
        "                'nombre': umbral_config,\n",
        "                'descripcion': umbral_info['descripcion'],\n",
        "                'valores': umbral_info['valores']\n",
        "            },\n",
        "            'timestamp': timestamp,\n",
        "            'tiempo_total_segundos': tiempo_total,\n",
        "            'total_imagenes': len(imagenes),\n",
        "            'imagenes_exitosas': len(resultados),\n",
        "            'librerias_usadas': ['mahotas', 'scikit-image', 'opencv-python']\n",
        "        },\n",
        "        'resultados': resultados\n",
        "    }\n",
        "\n",
        "    Utils.guardar_json(metadatos, str(archivo_completo))\n",
        "\n",
        "    # Mostrar resumen avanzado\n",
        "    procesador.mostrar_resumen_avanzado(resultados, umbral_config)\n",
        "\n",
        "    print(f\"\\n‚è±Ô∏è  TIEMPO TOTAL: {tiempo_total:.1f} segundos\")\n",
        "    print(f\"üìÅ Archivo guardado como: {nombre_archivo}\")\n",
        "    print(f\"üéØ Caracter√≠sticas extra√≠das: Haralick, LBP, GLCM, Zernike, Multi-scale\")\n",
        "\n",
        "    detector.limpiar()\n",
        "    return str(archivo_completo)\n",
        "\n",
        "### FUNCI√ìN MAIN MEJORADA - IGUAL ESTRUCTURA QUE TU ORIGINAL ###\n",
        "def main_con_caracteristicas_avanzadas():\n",
        "    \"\"\"\n",
        "    Funci√≥n main que mantiene la misma estructura que tu c√≥digo original\n",
        "    pero usa las librer√≠as especializadas para extracci√≥n de caracter√≠sticas\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"üéØ EVALUACI√ìN COMPLETA MASK2FORMER + CARACTER√çSTICAS AVANZADAS\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"üìä Modelos disponibles: {len(config.MODELOS_INFO)}\")\n",
        "    print(f\"‚öôÔ∏è  Configuraciones de umbral: {len(config.UMBRALES)}\")\n",
        "    print(f\"üî¨ Caracter√≠sticas: Mahotas + Scikit-image + OpenCV\")\n",
        "\n",
        "    total_combinaciones = len(config.MODELOS_INFO) * len(config.UMBRALES)\n",
        "    print(f\"üîÑ Total de combinaciones: {total_combinaciones}\")\n",
        "\n",
        "    combinacion_actual = 0\n",
        "\n",
        "    try:\n",
        "        for i, modelo_info in enumerate(config.MODELOS_INFO):\n",
        "            for umbral_config in config.UMBRALES.keys():\n",
        "                combinacion_actual += 1\n",
        "\n",
        "                print(f\"\\n{'='*100}\")\n",
        "                print(f\"üîÑ COMBINACI√ìN {combinacion_actual}/{total_combinaciones}\")\n",
        "                print(f\"{'='*100}\")\n",
        "\n",
        "                # üîÑ CAMBIO PRINCIPAL: Usar la nueva funci√≥n con caracter√≠sticas\n",
        "                resultado = ejecutar_con_librerias_especializadas(i, umbral_config)\n",
        "\n",
        "                if resultado:\n",
        "                    print(f\"‚úÖ Combinaci√≥n {combinacion_actual} completada exitosamente\")\n",
        "                    print(f\"üìÅ Archivo: {os.path.basename(resultado)}\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Error en combinaci√≥n {combinacion_actual}\")\n",
        "\n",
        "                # Pausa entre combinaciones para liberar memoria (igual que antes)\n",
        "                if combinacion_actual < total_combinaciones:\n",
        "                    print(f\"‚è≥ Pausa de 3 segundos para liberar memoria...\")\n",
        "                    time.sleep(3)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\n\\n‚ö†Ô∏è  EVALUACI√ìN INTERRUMPIDA POR EL USUARIO\")\n",
        "        print(f\"üìä Progreso: {combinacion_actual}/{total_combinaciones} combinaciones completadas\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR DURANTE LA EVALUACI√ìN: {str(e)}\")\n",
        "        print(f\"üìä Progreso: {combinacion_actual}/{total_combinaciones} combinaciones completadas\")\n",
        "\n",
        "    print(f\"\\nüéâ EVALUACIONES FINALIZADAS\")\n",
        "    print(f\"üìÅ Todos los resultados guardados en: {config.OUTPUT_PATH}\")\n",
        "    print(f\"üî¨ Con caracter√≠sticas avanzadas extra√≠das usando librer√≠as especializadas\")\n",
        "\n",
        "### COMPATIBILIDAD: Mantener funci√≥n original disponible ###\n",
        "def main_original():\n",
        "    \"\"\"\n",
        "    Tu funci√≥n main original sin modificaciones (por si quieres comparar)\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"üéØ EVALUACI√ìN COMPLETA MASK2FORMER (VERSI√ìN ORIGINAL)\")\n",
        "    print(f\"{'='*100}\")\n",
        "    print(f\"üìä Modelos disponibles: {len(config.MODELOS_INFO)}\")\n",
        "    print(f\"‚öôÔ∏è  Configuraciones de umbral: {len(config.UMBRALES)}\")\n",
        "\n",
        "    total_combinaciones = len(config.MODELOS_INFO) * len(config.UMBRALES)\n",
        "    print(f\"üîÑ Total de combinaciones: {total_combinaciones}\")\n",
        "\n",
        "    combinacion_actual = 0\n",
        "\n",
        "    try:\n",
        "        for i, modelo_info in enumerate(config.MODELOS_INFO):\n",
        "            for umbral_config in config.UMBRALES.keys():\n",
        "                combinacion_actual += 1\n",
        "\n",
        "                print(f\"\\n{'='*100}\")\n",
        "                print(f\"üîÑ COMBINACI√ìN {combinacion_actual}/{total_combinaciones}\")\n",
        "                print(f\"{'='*100}\")\n",
        "\n",
        "                # Usar tu funci√≥n original\n",
        "                resultado = ejecutar_evaluacion_basica(i, umbral_config)\n",
        "\n",
        "                if resultado:\n",
        "                    print(f\"‚úÖ Combinaci√≥n {combinacion_actual} completada exitosamente\")\n",
        "                else:\n",
        "                    print(f\"‚ùå Error en combinaci√≥n {combinacion_actual}\")\n",
        "\n",
        "                # Pausa entre combinaciones para liberar memoria\n",
        "                if combinacion_actual < total_combinaciones:\n",
        "                    print(f\"‚è≥ Pausa de 3 segundos para liberar memoria...\")\n",
        "                    time.sleep(3)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(f\"\\n\\n‚ö†Ô∏è  EVALUACI√ìN INTERRUMPIDA POR EL USUARIO\")\n",
        "        print(f\"üìä Progreso: {combinacion_actual}/{total_combinaciones} combinaciones completadas\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå ERROR DURANTE LA EVALUACI√ìN: {str(e)}\")\n",
        "        print(f\"üìä Progreso: {combinacion_actual}/{total_combinaciones} combinaciones completadas\")\n",
        "\n",
        "    print(f\"\\nüéâ EVALUACIONES FINALIZADAS\")\n",
        "    print(f\"üìÅ Todos los resultados guardados en: {config.OUTPUT_PATH}\")\n",
        "\n",
        "### FUNCI√ìN MAIN PRINCIPAL - LA QUE DEBES USAR ###\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Funci√≥n main principal que permite elegir entre versiones\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\"üöÄ SISTEMA DE EVALUACI√ìN MASK2FORMER\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    print(\"Seleccione el modo de ejecuci√≥n:\")\n",
        "    print(\"1. ‚ú® CON caracter√≠sticas avanzadas (Recomendado)\")\n",
        "    print(\"2. üìä Versi√≥n original (solo detecci√≥n)\")\n",
        "    print(\"3. üî¨ Ejecutar ambas versiones\")\n",
        "\n",
        "    # Para uso en Colab/Jupyter, puedes cambiar esto por un valor fijo\n",
        "    # Ejemplo: opcion = \"1\"  # Para ejecutar siempre con caracter√≠sticas avanzadas\n",
        "\n",
        "    try:\n",
        "        opcion = input(\"\\nIngrese su opci√≥n (1, 2, o 3): \").strip()\n",
        "    except:\n",
        "        # Si no hay input (como en algunos entornos), usar opci√≥n por defecto\n",
        "        opcion = \"1\"\n",
        "        print(\"Usando opci√≥n por defecto: Caracter√≠sticas avanzadas\")\n",
        "\n",
        "    if opcion == \"1\":\n",
        "        print(f\"\\nüöÄ Ejecutando con CARACTER√çSTICAS AVANZADAS...\")\n",
        "        main_con_caracteristicas_avanzadas()\n",
        "\n",
        "    elif opcion == \"2\":\n",
        "        print(f\"\\nüìä Ejecutando VERSI√ìN ORIGINAL...\")\n",
        "        main_original()\n",
        "\n",
        "    elif opcion == \"3\":\n",
        "        print(f\"\\nüî¨ Ejecutando AMBAS VERSIONES...\")\n",
        "        print(f\"\\n{'='*50} FASE 1: CARACTER√çSTICAS AVANZADAS {'='*50}\")\n",
        "        main_con_caracteristicas_avanzadas()\n",
        "\n",
        "        print(f\"\\n{'='*50} FASE 2: VERSI√ìN ORIGINAL {'='*50}\")\n",
        "        main_original()\n",
        "\n",
        "    else:\n",
        "        print(\"‚ùå Opci√≥n inv√°lida. Ejecutando versi√≥n con caracter√≠sticas avanzadas por defecto...\")\n",
        "        main_con_caracteristicas_avanzadas()"
      ],
      "metadata": {
        "id": "yUy2kFnOBPRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}