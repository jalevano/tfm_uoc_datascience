{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+p7KSOkOvqFH8tk5awO0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DRdZE4g2ASZP",
        "outputId": "e77a26d8-e9bd-4cac-e226-18da9d9652b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n================================================================================\\nFASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\\n================================================================================\\nTrabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\\nen Fotografia de Retrato\\n\\nAutor: Jesus L.\\nUniversidad: Universidad Oberta de Cataluna (UOC)\\nFecha: Diciembre 2025\\n\\nDESCRIPCION:\\nFase 2B del analisis comparativo de modelos de segmentacion. Fusiona las metricas\\nde segmentacion calculadas en Fase 2A con las caracteristicas fotograficas\\nextraidas en Fase 1, permitiendo analizar como los parametros de captura\\n(apertura, ISO, exposicion) y las propiedades de imagen (contraste, nitidez,\\ncomplejidad textural) afectan al rendimiento de cada modelo.\\n\\nDEPENDENCIAS DE DATOS:\\n- Requiere Fase 2A completada (CSVs de metricas por modelo)\\n- Requiere JSONs de caracteristicas fotograficas (20 archivos)\\n- Genera dataset fusionado para fases posteriores\\n\\nANALISIS INCLUIDOS:\\n1. Consolidacion de CSVs de metricas de todos los modelos\\n2. Extraccion de caracteristicas fotograficas clave (20 variables)\\n3. Fusion de datasets por codigo de fotografia\\n4. Correlaciones globales: caracteristicas vs IoU\\n5. Correlaciones por modelo: sensibilidad diferencial\\n6. Test de hipotesis especificas (bokeh, contraste, exposicion, fondo)\\n7. Tamano de efecto entre modelos (Cohen's d, eta cuadrado)\\n8. Estadisticas descriptivas y resumen ejecutivo\\n\\nCARACTERISTICAS FOTOGRAFICAS EXTRAIDAS:\\n- EXIF: apertura, ISO, exposicion, focal\\n- Calidad: brillo, subexposicion, sobreexposicion, rango dinamico\\n- Contraste: RMS, nitidez Laplacian, SNR\\n- Textura: homogeneidad GLCM, entropia Haralick, contraste Haralick\\n- Frecuencia: ratio alta frecuencia\\n- Saliencia: centro, ratio centro/periferia, distancia centroide\\n- Color: entropia, saturacion\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/3_Analisis/fase2b_correlaciones/\\n├── metricas_fusionadas.csv           # Dataset completo fusionado\\n├── caracteristicas_fotograficas.csv  # Caracteristicas por foto\\n├── correlaciones_globales.csv        # Correlaciones caracteristicas vs IoU\\n├── correlaciones_por_modelo.csv      # Correlaciones segmentadas por modelo\\n├── test_hipotesis.json               # Resultados de tests estadisticos\\n├── tamano_efecto.json                # Cohen's d entre modelos\\n\\n================================================================================\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n",
        "================================================================================\n",
        "Trabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "en Fotografia de Retrato\n",
        "\n",
        "Autor: Jesus L.\n",
        "Universidad: Universidad Oberta de Cataluna (UOC)\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "DESCRIPCION:\n",
        "Fase 2B del analisis comparativo de modelos de segmentacion. Fusiona las metricas\n",
        "de segmentacion calculadas en Fase 2A con las caracteristicas fotograficas\n",
        "extraidas en Fase 1, permitiendo analizar como los parametros de captura\n",
        "(apertura, ISO, exposicion) y las propiedades de imagen (contraste, nitidez,\n",
        "complejidad textural) afectan al rendimiento de cada modelo.\n",
        "\n",
        "DEPENDENCIAS DE DATOS:\n",
        "- Requiere Fase 2A completada (CSVs de metricas por modelo)\n",
        "- Requiere JSONs de caracteristicas fotograficas (20 archivos)\n",
        "- Genera dataset fusionado para fases posteriores\n",
        "\n",
        "ANALISIS INCLUIDOS:\n",
        "1. Consolidacion de CSVs de metricas de todos los modelos\n",
        "2. Extraccion de caracteristicas fotograficas clave (20 variables)\n",
        "3. Fusion de datasets por codigo de fotografia\n",
        "4. Correlaciones globales: caracteristicas vs IoU\n",
        "5. Correlaciones por modelo: sensibilidad diferencial\n",
        "6. Test de hipotesis especificas (bokeh, contraste, exposicion, fondo)\n",
        "7. Tamano de efecto entre modelos (Cohen's d, eta cuadrado)\n",
        "8. Estadisticas descriptivas y resumen ejecutivo\n",
        "\n",
        "CARACTERISTICAS FOTOGRAFICAS EXTRAIDAS:\n",
        "- EXIF: apertura, ISO, exposicion, focal\n",
        "- Calidad: brillo, subexposicion, sobreexposicion, rango dinamico\n",
        "- Contraste: RMS, nitidez Laplacian, SNR\n",
        "- Textura: homogeneidad GLCM, entropia Haralick, contraste Haralick\n",
        "- Frecuencia: ratio alta frecuencia\n",
        "- Saliencia: centro, ratio centro/periferia, distancia centroide\n",
        "- Color: entropia, saturacion\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/3_Analisis/fase2b_correlaciones/\n",
        "├── metricas_fusionadas.csv           # Dataset completo fusionado\n",
        "├── caracteristicas_fotograficas.csv  # Caracteristicas por foto\n",
        "├── correlaciones_globales.csv        # Correlaciones caracteristicas vs IoU\n",
        "├── correlaciones_por_modelo.csv      # Correlaciones segmentadas por modelo\n",
        "├── test_hipotesis.json               # Resultados de tests estadisticos\n",
        "├── tamano_efecto.json                # Cohen's d entre modelos\n",
        "\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n"
      ],
      "metadata": {
        "id": "ioVauJqMBMJr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIONES DE UTILIDAD PARA SERIALIZACION\n",
        "# =============================================================================\n",
        "\n",
        "def convertir_a_serializable(obj: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Convierte tipos numpy y pandas a tipos Python nativos para JSON.\n",
        "\n",
        "    Args:\n",
        "        obj: Objeto a convertir\n",
        "\n",
        "    Returns:\n",
        "        Objeto con tipos serializables\n",
        "    \"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convertir_a_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convertir_a_serializable(v) for v in obj]\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, (np.bool_, bool)):\n",
        "        return bool(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif pd.isna(obj):\n",
        "        return None\n",
        "    return obj"
      ],
      "metadata": {
        "id": "BvsRrYLzBUvV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionFase2B:\n",
        "    \"\"\"\n",
        "    Configuracion central para el pipeline de Fase 2B.\n",
        "\n",
        "    Attributes:\n",
        "        ruta_base_tfm: Ruta raiz del proyecto TFM\n",
        "        ruta_csvs_fase2a: Directorio con CSVs de metricas de Fase 2A\n",
        "        ruta_jsons_caracteristicas: Directorio con JSONs de caracteristicas\n",
        "        ruta_salida: Directorio para resultados de Fase 2B\n",
        "        nivel_significancia: Alpha para tests estadisticos (default 0.05)\n",
        "        min_observaciones_correlacion: Minimo de observaciones para calcular correlacion\n",
        "    \"\"\"\n",
        "    ruta_base_tfm: Path\n",
        "    ruta_csvs_fase2a: Path = None\n",
        "    ruta_jsons_caracteristicas: Path = None\n",
        "    ruta_salida: Path = None\n",
        "    nivel_significancia: float = 0.05\n",
        "    min_observaciones_correlacion: int = 10\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Inicializa rutas derivadas si no se especifican.\"\"\"\n",
        "        if self.ruta_csvs_fase2a is None:\n",
        "            self.ruta_csvs_fase2a = self.ruta_base_tfm / \"3_Analisis\" / \"fase2_evaluacion\" / \"metricas_agregadas\"\n",
        "        if self.ruta_jsons_caracteristicas is None:\n",
        "            self.ruta_jsons_caracteristicas = self.ruta_base_tfm / \"0_Imagenes\" / \"caracteristicas\"\n",
        "        if self.ruta_salida is None:\n",
        "            self.ruta_salida = self.ruta_base_tfm / \"3_Analisis\" / \"fase2b_correlaciones\""
      ],
      "metadata": {
        "id": "mLAlgSBgBaj7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONSTANTES: CARACTERISTICAS FOTOGRAFICAS A EXTRAER\n",
        "# =============================================================================\n",
        "\n",
        "CARACTERISTICAS_CLAVE = {\n",
        "    # EXIF - Parametros de captura\n",
        "    'foto_apertura': ('metadatos_exif', 'apertura_fnumber'),\n",
        "    'foto_iso': ('metadatos_exif', 'iso'),\n",
        "    'foto_exposicion': ('metadatos_exif', 'tiempo_exposicion_segundos'),\n",
        "    'foto_focal': ('metadatos_exif', 'distancia_focal'),\n",
        "\n",
        "    # Calidad - Exposicion\n",
        "    'foto_brillo': ('calidad', 'exposicion', 'brillo_medio'),\n",
        "    'foto_subexp_pct': ('calidad', 'exposicion', 'sub_expuesto_pct'),\n",
        "    'foto_sobreexp_pct': ('calidad', 'exposicion', 'sobre_expuesto_pct'),\n",
        "    'foto_rango_dinamico': ('calidad', 'exposicion', 'rango_dinamico'),\n",
        "\n",
        "    # Calidad - Contraste y Nitidez\n",
        "    'foto_contraste_rms': ('calidad', 'contraste', 'rms'),\n",
        "    'foto_nitidez_laplacian': ('calidad', 'nitidez', 'laplacian'),\n",
        "    'foto_snr': ('calidad', 'ruido', 'snr'),\n",
        "\n",
        "    # Texturas\n",
        "    'foto_homogeneity': ('texturas', 'glcm', 'homogeneity_mean'),\n",
        "    'foto_haralick_entropy': ('texturas', 'haralick', 'entropy'),\n",
        "    'foto_haralick_contrast': ('texturas', 'haralick', 'contrast'),\n",
        "\n",
        "    # Frecuencia\n",
        "    'foto_freq_ratio_alta': ('analisis_frecuencia', 'ratio_alta'),\n",
        "\n",
        "    # Saliencia\n",
        "    'foto_saliencia_centro': ('saliencia_visual', 'distribucion_espacial', 'saliencia_centro'),\n",
        "    'foto_ratio_centro_periferia': ('saliencia_visual', 'distribucion_espacial', 'ratio_centro_periferia'),\n",
        "    'foto_centroide_distancia': ('saliencia_visual', 'centroide', 'distancia_desde_centro'),\n",
        "\n",
        "    # Color\n",
        "    'foto_entropia_color': ('estadisticas_color', 'global', 'entropia'),\n",
        "    'foto_saturacion': ('estadisticas_color', 'hsv', 'saturation_mean'),\n",
        "}"
      ],
      "metadata": {
        "id": "xUCtLQovBp99"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: CARGADOR DE DATOS\n",
        "# =============================================================================\n",
        "\n",
        "class CargadorDatosFase2B:\n",
        "    \"\"\"\n",
        "    Gestiona la carga y consolidacion de datos para Fase 2B.\n",
        "\n",
        "    Responsabilidades:\n",
        "    - Cargar y consolidar CSVs de metricas de todos los modelos\n",
        "    - Cargar y extraer caracteristicas de JSONs fotograficos\n",
        "    - Fusionar ambos datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el cargador de datos.\n",
        "\n",
        "        Args:\n",
        "            config: Configuracion de Fase 2B\n",
        "            logger: Logger para registro de eventos\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def cargar_csvs_metricas(self, rutas_csv: Dict[str, Path]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Consolida multiples CSVs de metricas en un unico DataFrame.\n",
        "\n",
        "        Args:\n",
        "            rutas_csv: Diccionario {nombre_modelo: ruta_csv}\n",
        "\n",
        "        Returns:\n",
        "            DataFrame consolidado con todas las metricas\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Cargando CSVs de metricas de Fase 2A...\")\n",
        "\n",
        "        dataframes = []\n",
        "\n",
        "        for modelo, ruta in rutas_csv.items():\n",
        "            try:\n",
        "                df = pd.read_csv(ruta)\n",
        "\n",
        "                # Corregir nombre de modelo si es necesario\n",
        "                if modelo == 'sam2_prompts' and 'modelo' in df.columns:\n",
        "                    df['modelo'] = 'sam2_prompts'\n",
        "\n",
        "                self.logger.info(f\"  {modelo}: {len(df)} filas, {len(df.columns)} columnas\")\n",
        "                dataframes.append(df)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"  Error cargando {modelo}: {e}\")\n",
        "\n",
        "        if not dataframes:\n",
        "            raise ValueError(\"No se pudieron cargar CSVs de metricas\")\n",
        "\n",
        "        # Concatenar todos los DataFrames\n",
        "        df_consolidado = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "        self.logger.info(f\"Total consolidado: {len(df_consolidado)} filas\")\n",
        "\n",
        "        return df_consolidado\n",
        "\n",
        "    def extraer_caracteristicas_json(self, ruta_json: Path) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extrae caracteristicas clave de un JSON de fotografia.\n",
        "\n",
        "        Args:\n",
        "            ruta_json: Ruta al archivo JSON\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con caracteristicas extraidas\n",
        "        \"\"\"\n",
        "        with open(ruta_json, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Obtener nombre de foto\n",
        "        nombre = data.get('metadatos_archivo', {}).get('nombre_archivo', '')\n",
        "        nombre = nombre.replace('.jpg', '').replace('.JPG', '')\n",
        "\n",
        "        caracteristicas = {'codigo_foto': nombre}\n",
        "\n",
        "        # Extraer cada caracteristica definida\n",
        "        for nombre_col, ruta_keys in CARACTERISTICAS_CLAVE.items():\n",
        "            valor = self._extraer_valor_anidado(data, ruta_keys)\n",
        "\n",
        "            # Convertir a numerico si es posible\n",
        "            if valor is not None and not isinstance(valor, (int, float)):\n",
        "                try:\n",
        "                    valor = float(valor)\n",
        "                except (ValueError, TypeError):\n",
        "                    valor = None\n",
        "\n",
        "            caracteristicas[nombre_col] = valor\n",
        "\n",
        "        return caracteristicas\n",
        "\n",
        "    def _extraer_valor_anidado(self, data: Dict, keys: Tuple) -> Any:\n",
        "        \"\"\"\n",
        "        Extrae un valor de un diccionario anidado siguiendo una ruta de claves.\n",
        "\n",
        "        Args:\n",
        "            data: Diccionario fuente\n",
        "            keys: Tupla de claves para navegar\n",
        "\n",
        "        Returns:\n",
        "            Valor extraido o None si no existe\n",
        "        \"\"\"\n",
        "        resultado = data\n",
        "        for key in keys:\n",
        "            if isinstance(resultado, dict) and key in resultado:\n",
        "                resultado = resultado[key]\n",
        "            else:\n",
        "                return None\n",
        "        return resultado\n",
        "\n",
        "    def cargar_caracteristicas_fotograficas(self, rutas_json: List[Path]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Carga caracteristicas de multiples JSONs fotograficos.\n",
        "\n",
        "        Args:\n",
        "            rutas_json: Lista de rutas a archivos JSON\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con caracteristicas por fotografia\n",
        "        \"\"\"\n",
        "        self.logger.info(f\"Cargando caracteristicas de {len(rutas_json)} fotografias...\")\n",
        "\n",
        "        caracteristicas_list = []\n",
        "\n",
        "        for ruta in rutas_json:\n",
        "            try:\n",
        "                caract = self.extraer_caracteristicas_json(ruta)\n",
        "                caracteristicas_list.append(caract)\n",
        "                self.logger.debug(f\"  {caract['codigo_foto']}: OK\")\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"  Error en {ruta.name}: {e}\")\n",
        "\n",
        "        df_caracteristicas = pd.DataFrame(caracteristicas_list)\n",
        "\n",
        "        self.logger.info(f\"Caracteristicas extraidas: {len(df_caracteristicas)} fotos x {len(df_caracteristicas.columns)} columnas\")\n",
        "\n",
        "        return df_caracteristicas\n",
        "\n",
        "    def fusionar_datos(self, df_metricas: pd.DataFrame,\n",
        "                       df_caracteristicas: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Fusiona metricas de segmentacion con caracteristicas fotograficas.\n",
        "\n",
        "        Args:\n",
        "            df_metricas: DataFrame con metricas de Fase 2A\n",
        "            df_caracteristicas: DataFrame con caracteristicas fotograficas\n",
        "\n",
        "        Returns:\n",
        "            DataFrame fusionado\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Fusionando metricas con caracteristicas fotograficas...\")\n",
        "\n",
        "        df_fusionado = df_metricas.merge(\n",
        "            df_caracteristicas,\n",
        "            on='codigo_foto',\n",
        "            how='left'\n",
        "        )\n",
        "\n",
        "        # Verificar fotos sin match\n",
        "        fotos_metricas = set(df_metricas['codigo_foto'].unique())\n",
        "        fotos_caract = set(df_caracteristicas['codigo_foto'].unique())\n",
        "        sin_match = fotos_metricas - fotos_caract\n",
        "\n",
        "        if sin_match:\n",
        "            self.logger.warning(f\"Fotos sin caracteristicas: {len(sin_match)}\")\n",
        "            for foto in sin_match:\n",
        "                self.logger.warning(f\"  - {foto}\")\n",
        "        else:\n",
        "            self.logger.info(\"Todas las fotos tienen caracteristicas asociadas\")\n",
        "\n",
        "        self.logger.info(f\"Dataset fusionado: {len(df_fusionado)} filas x {len(df_fusionado.columns)} columnas\")\n",
        "\n",
        "        return df_fusionado"
      ],
      "metadata": {
        "id": "wWU8qCg9BqU-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE CORRELACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorCorrelaciones:\n",
        "    \"\"\"\n",
        "    Ejecuta analisis de correlaciones entre caracteristicas fotograficas\n",
        "    y metricas de segmentacion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el analizador.\n",
        "\n",
        "        Args:\n",
        "            config: Configuracion de Fase 2B\n",
        "            logger: Logger para registro\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def calcular_correlaciones_globales(self, df: pd.DataFrame,\n",
        "                                        metrica_objetivo: str = 'iou') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula correlaciones entre todas las caracteristicas fotograficas\n",
        "        y una metrica objetivo.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metrica_objetivo: Columna objetivo (default: IoU)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con correlaciones ordenadas por magnitud\n",
        "        \"\"\"\n",
        "        self.logger.info(f\"Calculando correlaciones globales vs {metrica_objetivo}...\")\n",
        "\n",
        "        # Identificar columnas de caracteristicas fotograficas\n",
        "        cols_foto = [c for c in df.columns if c.startswith('foto_')]\n",
        "\n",
        "        correlaciones = []\n",
        "\n",
        "        for col in cols_foto:\n",
        "            # Filtrar valores no nulos\n",
        "            mask = df[col].notna() & df[metrica_objetivo].notna()\n",
        "            n_obs = mask.sum()\n",
        "\n",
        "            if n_obs >= self.config.min_observaciones_correlacion:\n",
        "                try:\n",
        "                    corr, pval = stats.pearsonr(\n",
        "                        df.loc[mask, col],\n",
        "                        df.loc[mask, metrica_objetivo]\n",
        "                    )\n",
        "\n",
        "                    correlaciones.append({\n",
        "                        'caracteristica': col.replace('foto_', ''),\n",
        "                        'correlacion': corr,\n",
        "                        'p_valor': pval,\n",
        "                        'n_observaciones': n_obs,\n",
        "                        'significativo': pval < self.config.nivel_significancia\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    self.logger.warning(f\"Error calculando correlacion para {col}: {e}\")\n",
        "\n",
        "        df_corr = pd.DataFrame(correlaciones)\n",
        "\n",
        "        if not df_corr.empty:\n",
        "            # Ordenar por magnitud de correlacion\n",
        "            df_corr = df_corr.sort_values('correlacion', key=abs, ascending=False)\n",
        "            df_corr = df_corr.reset_index(drop=True)\n",
        "\n",
        "        return df_corr\n",
        "\n",
        "    def calcular_correlaciones_por_modelo(self, df: pd.DataFrame,\n",
        "                                          metrica_objetivo: str = 'iou') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula correlaciones segmentadas por modelo.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metrica_objetivo: Columna objetivo\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con correlaciones por modelo\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Calculando correlaciones por modelo...\")\n",
        "\n",
        "        cols_foto = [c for c in df.columns if c.startswith('foto_')]\n",
        "        modelos = df['modelo'].unique()\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for modelo in modelos:\n",
        "            df_modelo = df[df['modelo'] == modelo]\n",
        "            n_total = len(df_modelo)\n",
        "\n",
        "            for col in cols_foto:\n",
        "                mask = df_modelo[col].notna() & df_modelo[metrica_objetivo].notna()\n",
        "                n_obs = mask.sum()\n",
        "\n",
        "                if n_obs >= self.config.min_observaciones_correlacion:\n",
        "                    try:\n",
        "                        corr, pval = stats.pearsonr(\n",
        "                            df_modelo.loc[mask, col],\n",
        "                            df_modelo.loc[mask, metrica_objetivo]\n",
        "                        )\n",
        "\n",
        "                        resultados.append({\n",
        "                            'modelo': modelo,\n",
        "                            'caracteristica': col.replace('foto_', ''),\n",
        "                            'correlacion': corr,\n",
        "                            'p_valor': pval,\n",
        "                            'n_observaciones': n_obs,\n",
        "                            'significativo': pval < self.config.nivel_significancia\n",
        "                        })\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "        df_corr_modelo = pd.DataFrame(resultados)\n",
        "\n",
        "        return df_corr_modelo\n",
        "\n",
        "    def identificar_top_predictores(self, df_corr_modelo: pd.DataFrame,\n",
        "                                    top_n: int = 5) -> Dict[str, List[Dict]]:\n",
        "        \"\"\"\n",
        "        Identifica los top-N predictores para cada modelo.\n",
        "\n",
        "        Args:\n",
        "            df_corr_modelo: DataFrame de correlaciones por modelo\n",
        "            top_n: Numero de predictores a retornar\n",
        "\n",
        "        Returns:\n",
        "            Diccionario {modelo: [top predictores]}\n",
        "        \"\"\"\n",
        "        resultado = {}\n",
        "\n",
        "        for modelo in df_corr_modelo['modelo'].unique():\n",
        "            df_m = df_corr_modelo[df_corr_modelo['modelo'] == modelo]\n",
        "            df_m = df_m.sort_values('correlacion', key=abs, ascending=False)\n",
        "\n",
        "            top = df_m.head(top_n).to_dict('records')\n",
        "            resultado[modelo] = top\n",
        "\n",
        "        return resultado"
      ],
      "metadata": {
        "id": "haudjHT5CKlo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE HIPOTESIS\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorHipotesis:\n",
        "    \"\"\"\n",
        "    Ejecuta tests estadisticos para hipotesis especificas sobre\n",
        "    la relacion entre caracteristicas fotograficas y segmentacion.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el analizador de hipotesis.\n",
        "\n",
        "        Args:\n",
        "            config: Configuracion de Fase 2B\n",
        "            logger: Logger para registro\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def test_hipotesis_apertura(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        H1: La apertura (bokeh) afecta la calidad de segmentacion.\n",
        "\n",
        "        Divide fotografias en apertura abierta (<2.5) vs cerrada (>=2.5)\n",
        "        y compara IoU medio.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados del test\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Testing H1: Efecto de apertura (bokeh)...\")\n",
        "\n",
        "        mask = df['foto_apertura'].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        umbral_apertura = 2.5\n",
        "        df_h['grupo_apertura'] = df_h['foto_apertura'].apply(\n",
        "            lambda x: 'abierta_bokeh' if x < umbral_apertura else 'cerrada_nitida'\n",
        "        )\n",
        "\n",
        "        grupo_abierta = df_h[df_h['grupo_apertura'] == 'abierta_bokeh']['iou']\n",
        "        grupo_cerrada = df_h[df_h['grupo_apertura'] == 'cerrada_nitida']['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H1: Apertura afecta segmentacion',\n",
        "            'variable': 'foto_apertura',\n",
        "            'umbral': umbral_apertura,\n",
        "            'grupo_1': {\n",
        "                'nombre': 'abierta_bokeh (f < 2.5)',\n",
        "                'n': len(grupo_abierta),\n",
        "                'iou_mean': float(grupo_abierta.mean()),\n",
        "                'iou_std': float(grupo_abierta.std())\n",
        "            },\n",
        "            'grupo_2': {\n",
        "                'nombre': 'cerrada_nitida (f >= 2.5)',\n",
        "                'n': len(grupo_cerrada),\n",
        "                'iou_mean': float(grupo_cerrada.mean()),\n",
        "                'iou_std': float(grupo_cerrada.std())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Test t de Student\n",
        "        if len(grupo_abierta) > 1 and len(grupo_cerrada) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_abierta, grupo_cerrada)\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "\n",
        "            # Cohen's d\n",
        "            cohens_d = self._calcular_cohens_d(grupo_abierta, grupo_cerrada)\n",
        "            resultado['cohens_d'] = float(cohens_d)\n",
        "            resultado['interpretacion_efecto'] = self._interpretar_cohens_d(cohens_d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_hipotesis_homogeneidad(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        H2: La homogeneidad del fondo afecta la segmentacion.\n",
        "\n",
        "        Divide por mediana de homogeneidad GLCM.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados del test\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Testing H2: Efecto de homogeneidad del fondo...\")\n",
        "\n",
        "        mask = df['foto_homogeneity'].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h['foto_homogeneity'].median()\n",
        "        df_h['grupo_fondo'] = df_h['foto_homogeneity'].apply(\n",
        "            lambda x: 'uniforme' if x > mediana else 'complejo'\n",
        "        )\n",
        "\n",
        "        grupo_uniforme = df_h[df_h['grupo_fondo'] == 'uniforme']['iou']\n",
        "        grupo_complejo = df_h[df_h['grupo_fondo'] == 'complejo']['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H2: Homogeneidad fondo afecta segmentacion',\n",
        "            'variable': 'foto_homogeneity',\n",
        "            'umbral': float(mediana),\n",
        "            'grupo_1': {\n",
        "                'nombre': 'fondo_uniforme (> mediana)',\n",
        "                'n': len(grupo_uniforme),\n",
        "                'iou_mean': float(grupo_uniforme.mean()),\n",
        "                'iou_std': float(grupo_uniforme.std())\n",
        "            },\n",
        "            'grupo_2': {\n",
        "                'nombre': 'fondo_complejo (<= mediana)',\n",
        "                'n': len(grupo_complejo),\n",
        "                'iou_mean': float(grupo_complejo.mean()),\n",
        "                'iou_std': float(grupo_complejo.std())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_uniforme) > 1 and len(grupo_complejo) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_uniforme, grupo_complejo)\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "\n",
        "            cohens_d = self._calcular_cohens_d(grupo_uniforme, grupo_complejo)\n",
        "            resultado['cohens_d'] = float(cohens_d)\n",
        "            resultado['interpretacion_efecto'] = self._interpretar_cohens_d(cohens_d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_hipotesis_subexposicion(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        H3: La subexposicion (contraluz) afecta la segmentacion.\n",
        "\n",
        "        Divide en contraluz severo (>10% subexpuesto) vs normal.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados del test\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Testing H3: Efecto de subexposicion (contraluz)...\")\n",
        "\n",
        "        mask = df['foto_subexp_pct'].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        umbral = 10.0\n",
        "        df_h['grupo_exposicion'] = df_h['foto_subexp_pct'].apply(\n",
        "            lambda x: 'contraluz_severo' if x > umbral else 'normal'\n",
        "        )\n",
        "\n",
        "        grupo_contraluz = df_h[df_h['grupo_exposicion'] == 'contraluz_severo']['iou']\n",
        "        grupo_normal = df_h[df_h['grupo_exposicion'] == 'normal']['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H3: Subexposicion afecta segmentacion',\n",
        "            'variable': 'foto_subexp_pct',\n",
        "            'umbral': umbral,\n",
        "            'grupo_1': {\n",
        "                'nombre': 'contraluz_severo (> 10%)',\n",
        "                'n': len(grupo_contraluz),\n",
        "                'iou_mean': float(grupo_contraluz.mean()),\n",
        "                'iou_std': float(grupo_contraluz.std())\n",
        "            },\n",
        "            'grupo_2': {\n",
        "                'nombre': 'exposicion_normal (<= 10%)',\n",
        "                'n': len(grupo_normal),\n",
        "                'iou_mean': float(grupo_normal.mean()),\n",
        "                'iou_std': float(grupo_normal.std())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_contraluz) > 1 and len(grupo_normal) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_contraluz, grupo_normal)\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "\n",
        "            cohens_d = self._calcular_cohens_d(grupo_contraluz, grupo_normal)\n",
        "            resultado['cohens_d'] = float(cohens_d)\n",
        "            resultado['interpretacion_efecto'] = self._interpretar_cohens_d(cohens_d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_hipotesis_contraste(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        H4: El contraste de la imagen afecta la segmentacion.\n",
        "\n",
        "        Divide por mediana de contraste RMS.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados del test\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Testing H4: Efecto del contraste...\")\n",
        "\n",
        "        mask = df['foto_contraste_rms'].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h['foto_contraste_rms'].median()\n",
        "        df_h['grupo_contraste'] = df_h['foto_contraste_rms'].apply(\n",
        "            lambda x: 'alto' if x > mediana else 'bajo'\n",
        "        )\n",
        "\n",
        "        grupo_alto = df_h[df_h['grupo_contraste'] == 'alto']['iou']\n",
        "        grupo_bajo = df_h[df_h['grupo_contraste'] == 'bajo']['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H4: Contraste afecta segmentacion',\n",
        "            'variable': 'foto_contraste_rms',\n",
        "            'umbral': float(mediana),\n",
        "            'grupo_1': {\n",
        "                'nombre': 'contraste_alto (> mediana)',\n",
        "                'n': len(grupo_alto),\n",
        "                'iou_mean': float(grupo_alto.mean()),\n",
        "                'iou_std': float(grupo_alto.std())\n",
        "            },\n",
        "            'grupo_2': {\n",
        "                'nombre': 'contraste_bajo (<= mediana)',\n",
        "                'n': len(grupo_bajo),\n",
        "                'iou_mean': float(grupo_bajo.mean()),\n",
        "                'iou_std': float(grupo_bajo.std())\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_alto) > 1 and len(grupo_bajo) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_alto, grupo_bajo)\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "\n",
        "            cohens_d = self._calcular_cohens_d(grupo_alto, grupo_bajo)\n",
        "            resultado['cohens_d'] = float(cohens_d)\n",
        "            resultado['interpretacion_efecto'] = self._interpretar_cohens_d(cohens_d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def ejecutar_todos_los_tests(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Ejecuta todas las hipotesis predefinidas.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con todos los resultados\n",
        "        \"\"\"\n",
        "        return {\n",
        "            'H1_apertura': self.test_hipotesis_apertura(df),\n",
        "            'H2_homogeneidad': self.test_hipotesis_homogeneidad(df),\n",
        "            'H3_subexposicion': self.test_hipotesis_subexposicion(df),\n",
        "            'H4_contraste': self.test_hipotesis_contraste(df)\n",
        "        }\n",
        "\n",
        "    def _calcular_cohens_d(self, grupo1: pd.Series, grupo2: pd.Series) -> float:\n",
        "        \"\"\"\n",
        "        Calcula el tamano de efecto Cohen's d.\n",
        "\n",
        "        Args:\n",
        "            grupo1: Primera muestra\n",
        "            grupo2: Segunda muestra\n",
        "\n",
        "        Returns:\n",
        "            Valor de Cohen's d\n",
        "        \"\"\"\n",
        "        n1, n2 = len(grupo1), len(grupo2)\n",
        "        var1, var2 = grupo1.var(), grupo2.var()\n",
        "\n",
        "        # Pooled standard deviation\n",
        "        pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
        "\n",
        "        if pooled_std == 0:\n",
        "            return 0.0\n",
        "\n",
        "        return (grupo1.mean() - grupo2.mean()) / pooled_std\n",
        "\n",
        "    def _interpretar_cohens_d(self, d: float) -> str:\n",
        "        \"\"\"\n",
        "        Interpreta el valor de Cohen's d segun convenciones.\n",
        "\n",
        "        Args:\n",
        "            d: Valor de Cohen's d\n",
        "\n",
        "        Returns:\n",
        "            Interpretacion textual\n",
        "        \"\"\"\n",
        "        d_abs = abs(d)\n",
        "\n",
        "        if d_abs < 0.2:\n",
        "            return \"insignificante\"\n",
        "        elif d_abs < 0.5:\n",
        "            return \"pequeno\"\n",
        "        elif d_abs < 0.8:\n",
        "            return \"mediano\"\n",
        "        else:\n",
        "            return \"grande\""
      ],
      "metadata": {
        "id": "0B20n5JbCYx4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE TAMANO DE EFECTO ENTRE MODELOS\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorEfectoModelos:\n",
        "    \"\"\"\n",
        "    Calcula tamanos de efecto entre pares de modelos.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el analizador.\n",
        "\n",
        "        Args:\n",
        "            config: Configuracion de Fase 2B\n",
        "            logger: Logger para registro\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def calcular_cohens_d_entre_modelos(self, df: pd.DataFrame,\n",
        "                                        metrica: str = 'iou') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula Cohen's d para todos los pares de modelos.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metrica: Metrica a comparar\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con comparaciones pareadas\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Calculando Cohen's d entre modelos...\")\n",
        "\n",
        "        modelos = sorted(df['modelo'].unique())\n",
        "        comparaciones = []\n",
        "\n",
        "        for i, modelo1 in enumerate(modelos):\n",
        "            for modelo2 in modelos[i+1:]:\n",
        "                grupo1 = df[df['modelo'] == modelo1][metrica].dropna()\n",
        "                grupo2 = df[df['modelo'] == modelo2][metrica].dropna()\n",
        "\n",
        "                if len(grupo1) > 1 and len(grupo2) > 1:\n",
        "                    d = self._cohens_d(grupo1, grupo2)\n",
        "                    t_stat, p_val = stats.ttest_ind(grupo1, grupo2)\n",
        "\n",
        "                    comparaciones.append({\n",
        "                        'modelo_1': modelo1,\n",
        "                        'modelo_2': modelo2,\n",
        "                        'n_1': len(grupo1),\n",
        "                        'n_2': len(grupo2),\n",
        "                        'mean_1': float(grupo1.mean()),\n",
        "                        'mean_2': float(grupo2.mean()),\n",
        "                        'cohens_d': float(d),\n",
        "                        'interpretacion': self._interpretar_d(d),\n",
        "                        't_statistic': float(t_stat),\n",
        "                        'p_valor': float(p_val),\n",
        "                        'significativo': p_val < self.config.nivel_significancia\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(comparaciones)\n",
        "\n",
        "    def calcular_eta_cuadrado(self, df: pd.DataFrame,\n",
        "                             metrica: str = 'iou') -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula eta cuadrado (ANOVA) para comparar todos los modelos.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metrica: Metrica a comparar\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados de ANOVA\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Calculando eta cuadrado (ANOVA)...\")\n",
        "\n",
        "        # Preparar grupos por modelo\n",
        "        grupos = [df[df['modelo'] == m][metrica].dropna().values\n",
        "                  for m in df['modelo'].unique()]\n",
        "\n",
        "        # ANOVA one-way\n",
        "        f_stat, p_val = stats.f_oneway(*grupos)\n",
        "\n",
        "        # Calcular eta cuadrado\n",
        "        # SS_between / SS_total\n",
        "        grand_mean = df[metrica].mean()\n",
        "        ss_total = ((df[metrica] - grand_mean) ** 2).sum()\n",
        "\n",
        "        ss_between = 0\n",
        "        for modelo in df['modelo'].unique():\n",
        "            grupo = df[df['modelo'] == modelo][metrica]\n",
        "            ss_between += len(grupo) * (grupo.mean() - grand_mean) ** 2\n",
        "\n",
        "        eta_squared = ss_between / ss_total if ss_total > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'metrica': metrica,\n",
        "            'n_modelos': len(df['modelo'].unique()),\n",
        "            'n_total': len(df),\n",
        "            'f_statistic': float(f_stat),\n",
        "            'p_valor': float(p_val),\n",
        "            'eta_squared': float(eta_squared),\n",
        "            'interpretacion': self._interpretar_eta(eta_squared),\n",
        "            'significativo': p_val < self.config.nivel_significancia\n",
        "        }\n",
        "\n",
        "    def _cohens_d(self, grupo1: pd.Series, grupo2: pd.Series) -> float:\n",
        "        \"\"\"Calcula Cohen's d entre dos grupos.\"\"\"\n",
        "        n1, n2 = len(grupo1), len(grupo2)\n",
        "        var1, var2 = grupo1.var(), grupo2.var()\n",
        "        pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
        "\n",
        "        if pooled_std == 0:\n",
        "            return 0.0\n",
        "        return (grupo1.mean() - grupo2.mean()) / pooled_std\n",
        "\n",
        "    def _interpretar_d(self, d: float) -> str:\n",
        "        \"\"\"Interpreta Cohen's d.\"\"\"\n",
        "        d_abs = abs(d)\n",
        "        if d_abs < 0.2:\n",
        "            return \"insignificante\"\n",
        "        elif d_abs < 0.5:\n",
        "            return \"pequeno\"\n",
        "        elif d_abs < 0.8:\n",
        "            return \"mediano\"\n",
        "        return \"grande\"\n",
        "\n",
        "    def _interpretar_eta(self, eta: float) -> str:\n",
        "        \"\"\"Interpreta eta cuadrado.\"\"\"\n",
        "        if eta < 0.01:\n",
        "            return \"insignificante\"\n",
        "        elif eta < 0.06:\n",
        "            return \"pequeno\"\n",
        "        elif eta < 0.14:\n",
        "            return \"mediano\"\n",
        "        return \"grande\""
      ],
      "metadata": {
        "id": "r9mbAOKnDRF8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# CLASE: GENERADOR DE ESTADISTICAS DESCRIPTIVAS\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorEstadisticas:\n",
        "    \"\"\"\n",
        "    Genera estadisticas descriptivas del dataset fusionado.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger):\n",
        "        \"\"\"\n",
        "        Inicializa el generador.\n",
        "\n",
        "        Args:\n",
        "            logger: Logger para registro\n",
        "        \"\"\"\n",
        "        self.logger = logger\n",
        "\n",
        "    def estadisticas_por_modelo(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula estadisticas descriptivas por modelo.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas por modelo\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Generando estadisticas por modelo...\")\n",
        "\n",
        "        stats_modelo = {}\n",
        "\n",
        "        for modelo in df['modelo'].unique():\n",
        "            df_m = df[df['modelo'] == modelo]\n",
        "\n",
        "            stats_modelo[modelo] = {\n",
        "                'n_evaluaciones': int(len(df_m)),\n",
        "                'n_configuraciones': int(df_m['config_codigo'].nunique()),\n",
        "                'n_fotos': int(df_m['codigo_foto'].nunique()),\n",
        "                'iou': {\n",
        "                    'mean': float(df_m['iou'].mean()),\n",
        "                    'std': float(df_m['iou'].std()),\n",
        "                    'min': float(df_m['iou'].min()),\n",
        "                    'max': float(df_m['iou'].max()),\n",
        "                    'median': float(df_m['iou'].median()),\n",
        "                    'q25': float(df_m['iou'].quantile(0.25)),\n",
        "                    'q75': float(df_m['iou'].quantile(0.75))\n",
        "                },\n",
        "                'dice': {\n",
        "                    'mean': float(df_m['dice'].mean()) if 'dice' in df_m.columns else None,\n",
        "                    'std': float(df_m['dice'].std()) if 'dice' in df_m.columns else None\n",
        "                }\n",
        "            }\n",
        "\n",
        "        return stats_modelo\n",
        "\n",
        "    def estadisticas_por_foto(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"\n",
        "        Calcula estadisticas descriptivas por fotografia.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con estadisticas por foto\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Generando estadisticas por fotografia...\")\n",
        "\n",
        "        stats_foto = {}\n",
        "\n",
        "        for foto in df['codigo_foto'].unique():\n",
        "            df_f = df[df['codigo_foto'] == foto]\n",
        "\n",
        "            stats_foto[foto] = {\n",
        "                'n_evaluaciones': int(len(df_f)),\n",
        "                'iou_mean': float(df_f['iou'].mean()),\n",
        "                'iou_std': float(df_f['iou'].std()),\n",
        "                'mejor_modelo': df_f.loc[df_f['iou'].idxmax(), 'modelo'],\n",
        "                'mejor_config': df_f.loc[df_f['iou'].idxmax(), 'config_codigo'],\n",
        "                'mejor_iou': float(df_f['iou'].max())\n",
        "            }\n",
        "\n",
        "        return stats_foto\n",
        "\n",
        "    def ranking_global(self, df: pd.DataFrame, top_n: int = 20) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Genera ranking global de configuraciones por IoU.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            top_n: Numero de configuraciones a incluir\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con ranking\n",
        "        \"\"\"\n",
        "        self.logger.info(f\"Generando ranking TOP-{top_n}...\")\n",
        "\n",
        "        ranking = df.groupby(['modelo', 'config_codigo']).agg({\n",
        "            'iou': ['mean', 'std', 'min', 'max', 'count']\n",
        "        }).round(4)\n",
        "\n",
        "        ranking.columns = ['iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n_fotos']\n",
        "        ranking = ranking.reset_index()\n",
        "        ranking = ranking.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        return ranking.head(top_n)"
      ],
      "metadata": {
        "id": "PeDxEA5KDWnq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =============================================================================\n",
        "# CLASE: ORQUESTADOR FASE 2B\n",
        "# =============================================================================\n",
        "\n",
        "class OrquestadorFase2B:\n",
        "    \"\"\"\n",
        "    Orquesta la ejecucion completa de Fase 2B.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B):\n",
        "        \"\"\"\n",
        "        Inicializa el orquestador.\n",
        "\n",
        "        Args:\n",
        "            config: Configuracion de Fase 2B\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.logger = self._configurar_logger()\n",
        "\n",
        "        # Componentes\n",
        "        self.cargador = CargadorDatosFase2B(config, self.logger)\n",
        "        self.analizador_corr = AnalizadorCorrelaciones(config, self.logger)\n",
        "        self.analizador_hip = AnalizadorHipotesis(config, self.logger)\n",
        "        self.analizador_efecto = AnalizadorEfectoModelos(config, self.logger)\n",
        "        self.generador_stats = GeneradorEstadisticas(self.logger)\n",
        "\n",
        "        # Resultados\n",
        "        self.df_fusionado = None\n",
        "        self.df_caracteristicas = None\n",
        "        self.correlaciones_globales = None\n",
        "        self.correlaciones_por_modelo = None\n",
        "        self.resultados_hipotesis = None\n",
        "        self.tamano_efecto_modelos = None\n",
        "        self.estadisticas = None\n",
        "\n",
        "    def _configurar_logger(self) -> logging.Logger:\n",
        "        \"\"\"Configura el logger para Fase 2B.\"\"\"\n",
        "        logger = logging.getLogger('Fase2B')\n",
        "        logger.setLevel(logging.INFO)\n",
        "\n",
        "        if not logger.handlers:\n",
        "            handler = logging.StreamHandler(sys.stdout)\n",
        "            handler.setLevel(logging.INFO)\n",
        "            formatter = logging.Formatter(\n",
        "                '[%(asctime)s] %(levelname)-8s | %(message)s',\n",
        "                datefmt='%H:%M:%S'\n",
        "            )\n",
        "            handler.setFormatter(formatter)\n",
        "            logger.addHandler(handler)\n",
        "\n",
        "        return logger\n",
        "\n",
        "    def ejecutar(self, rutas_csv: Dict[str, Path],\n",
        "                 rutas_json: List[Path]) -> None:\n",
        "        \"\"\"\n",
        "        Ejecuta el pipeline completo de Fase 2B.\n",
        "\n",
        "        Args:\n",
        "            rutas_csv: Diccionario {modelo: ruta_csv}\n",
        "            rutas_json: Lista de rutas a JSONs de caracteristicas\n",
        "        \"\"\"\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(\"FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "\n",
        "        inicio = datetime.now()\n",
        "\n",
        "        # Paso 1: Cargar y consolidar datos\n",
        "        self.logger.info(\"\\n[PASO 1/7] Cargando y consolidando datos...\")\n",
        "        df_metricas = self.cargador.cargar_csvs_metricas(rutas_csv)\n",
        "        self.df_caracteristicas = self.cargador.cargar_caracteristicas_fotograficas(rutas_json)\n",
        "        self.df_fusionado = self.cargador.fusionar_datos(df_metricas, self.df_caracteristicas)\n",
        "\n",
        "        # Paso 2: Correlaciones globales\n",
        "        self.logger.info(\"\\n[PASO 2/7] Calculando correlaciones globales...\")\n",
        "        self.correlaciones_globales = self.analizador_corr.calcular_correlaciones_globales(\n",
        "            self.df_fusionado\n",
        "        )\n",
        "\n",
        "        # Paso 3: Correlaciones por modelo\n",
        "        self.logger.info(\"\\n[PASO 3/7] Calculando correlaciones por modelo...\")\n",
        "        self.correlaciones_por_modelo = self.analizador_corr.calcular_correlaciones_por_modelo(\n",
        "            self.df_fusionado\n",
        "        )\n",
        "\n",
        "        # Paso 4: Tests de hipotesis\n",
        "        self.logger.info(\"\\n[PASO 4/7] Ejecutando tests de hipotesis...\")\n",
        "        self.resultados_hipotesis = self.analizador_hip.ejecutar_todos_los_tests(\n",
        "            self.df_fusionado\n",
        "        )\n",
        "\n",
        "        # Paso 5: Tamano de efecto entre modelos\n",
        "        self.logger.info(\"\\n[PASO 5/7] Calculando tamano de efecto entre modelos...\")\n",
        "        self.tamano_efecto_modelos = {\n",
        "            'cohens_d_pareado': self.analizador_efecto.calcular_cohens_d_entre_modelos(\n",
        "                self.df_fusionado\n",
        "            ).to_dict('records'),\n",
        "            'anova_eta_squared': self.analizador_efecto.calcular_eta_cuadrado(\n",
        "                self.df_fusionado\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Paso 6: Estadisticas descriptivas\n",
        "        self.logger.info(\"\\n[PASO 6/7] Generando estadisticas descriptivas...\")\n",
        "        self.estadisticas = {\n",
        "            'por_modelo': self.generador_stats.estadisticas_por_modelo(self.df_fusionado),\n",
        "            'por_foto': self.generador_stats.estadisticas_por_foto(self.df_fusionado),\n",
        "            'ranking_top20': self.generador_stats.ranking_global(self.df_fusionado, 20).to_dict('records')\n",
        "        }\n",
        "\n",
        "        # Paso 7: Guardar resultados\n",
        "        self.logger.info(\"\\n[PASO 7/7] Guardando resultados...\")\n",
        "        self._guardar_resultados()\n",
        "\n",
        "        duracion = (datetime.now() - inicio).total_seconds()\n",
        "\n",
        "        self.logger.info(\"\\n\" + \"=\" * 70)\n",
        "        self.logger.info(\"FASE 2B COMPLETADA\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(f\"Duracion: {duracion:.1f} segundos\")\n",
        "        self.logger.info(f\"Evaluaciones procesadas: {len(self.df_fusionado)}\")\n",
        "        self.logger.info(f\"Modelos: {self.df_fusionado['modelo'].nunique()}\")\n",
        "        self.logger.info(f\"Fotografias: {self.df_fusionado['codigo_foto'].nunique()}\")\n",
        "\n",
        "    def _guardar_resultados(self) -> None:\n",
        "        \"\"\"Guarda todos los resultados en archivos.\"\"\"\n",
        "        # Crear directorio de salida\n",
        "        self.config.ruta_salida.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # CSV fusionado\n",
        "        ruta_fusionado = self.config.ruta_salida / 'metricas_fusionadas.csv'\n",
        "        self.df_fusionado.to_csv(ruta_fusionado, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_fusionado}\")\n",
        "\n",
        "        # Caracteristicas fotograficas\n",
        "        ruta_caract = self.config.ruta_salida / 'caracteristicas_fotograficas.csv'\n",
        "        self.df_caracteristicas.to_csv(ruta_caract, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_caract}\")\n",
        "\n",
        "        # Correlaciones globales\n",
        "        ruta_corr_global = self.config.ruta_salida / 'correlaciones_globales.csv'\n",
        "        self.correlaciones_globales.to_csv(ruta_corr_global, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_corr_global}\")\n",
        "\n",
        "        # Correlaciones por modelo\n",
        "        ruta_corr_modelo = self.config.ruta_salida / 'correlaciones_por_modelo.csv'\n",
        "        self.correlaciones_por_modelo.to_csv(ruta_corr_modelo, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_corr_modelo}\")\n",
        "\n",
        "        # Test de hipotesis\n",
        "        ruta_hipotesis = self.config.ruta_salida / 'test_hipotesis.json'\n",
        "        with open(ruta_hipotesis, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.resultados_hipotesis), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_hipotesis}\")\n",
        "\n",
        "        # Tamano de efecto\n",
        "        ruta_efecto = self.config.ruta_salida / 'tamano_efecto.json'\n",
        "        with open(ruta_efecto, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.tamano_efecto_modelos), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_efecto}\")\n",
        "\n",
        "        # Estadisticas\n",
        "        ruta_stats = self.config.ruta_salida / 'estadisticas_descriptivas.json'\n",
        "        with open(ruta_stats, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.estadisticas), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta_stats}\")\n",
        "\n",
        "    def imprimir_resumen(self) -> None:\n",
        "        \"\"\"Imprime un resumen de los resultados principales.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"RESUMEN DE RESULTADOS FASE 2B\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Correlaciones globales significativas\n",
        "        print(\"\\nCORRELACIONES GLOBALES SIGNIFICATIVAS (p < 0.05):\")\n",
        "        print(\"-\" * 50)\n",
        "        corr_sig = self.correlaciones_globales[\n",
        "            self.correlaciones_globales['significativo']\n",
        "        ]\n",
        "        for _, row in corr_sig.head(10).iterrows():\n",
        "            direccion = \"+\" if row['correlacion'] > 0 else \"-\"\n",
        "            print(f\"  {row['caracteristica']:<25} r={row['correlacion']:>7.4f} ({direccion})\")\n",
        "\n",
        "        # IoU por modelo\n",
        "        print(\"\\nRENDIMIENTO POR MODELO (IoU):\")\n",
        "        print(\"-\" * 50)\n",
        "        for modelo, stats in sorted(\n",
        "            self.estadisticas['por_modelo'].items(),\n",
        "            key=lambda x: x[1]['iou']['mean'],\n",
        "            reverse=True\n",
        "        ):\n",
        "            iou = stats['iou']\n",
        "            print(f\"  {modelo:<15} mean={iou['mean']:.4f} std={iou['std']:.4f} \"\n",
        "                  f\"[{iou['min']:.4f}, {iou['max']:.4f}]\")\n",
        "\n",
        "        # Hipotesis\n",
        "        print(\"\\nRESULTADOS DE HIPOTESIS:\")\n",
        "        print(\"-\" * 50)\n",
        "        for key, result in self.resultados_hipotesis.items():\n",
        "            sig = \"SI\" if result.get('test_t', {}).get('significativo', False) else \"NO\"\n",
        "            efecto = result.get('interpretacion_efecto', 'N/A')\n",
        "            print(f\"  {key}: Significativo={sig}, Efecto={efecto}\")\n",
        "\n",
        "        # ANOVA\n",
        "        anova = self.tamano_efecto_modelos['anova_eta_squared']\n",
        "        print(f\"\\nANOVA GLOBAL:\")\n",
        "        print(f\"  F={anova['f_statistic']:.2f}, p={anova['p_valor']:.2e}\")\n",
        "        print(f\"  Eta^2={anova['eta_squared']:.4f} ({anova['interpretacion']})\")"
      ],
      "metadata": {
        "id": "FwqsCJI5DiAI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCION PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def ejecutar_fase2b(ruta_base_tfm: str,\n",
        "                    rutas_csv: Dict[str, str],\n",
        "                    rutas_json: List[str]) -> OrquestadorFase2B:\n",
        "    \"\"\"\n",
        "    Ejecuta el pipeline completo de Fase 2B.\n",
        "\n",
        "    Args:\n",
        "        ruta_base_tfm: Ruta base del proyecto TFM\n",
        "        rutas_csv: Diccionario {modelo: ruta_csv}\n",
        "        rutas_json: Lista de rutas a JSONs de caracteristicas\n",
        "\n",
        "    Returns:\n",
        "        OrquestadorFase2B con resultados\n",
        "    \"\"\"\n",
        "    config = ConfiguracionFase2B(\n",
        "        ruta_base_tfm=Path(ruta_base_tfm)\n",
        "    )\n",
        "\n",
        "    orquestador = OrquestadorFase2B(config)\n",
        "\n",
        "    # Convertir rutas a Path\n",
        "    rutas_csv_path = {k: Path(v) for k, v in rutas_csv.items()}\n",
        "    rutas_json_path = [Path(r) for r in rutas_json]\n",
        "\n",
        "    orquestador.ejecutar(rutas_csv_path, rutas_json_path)\n",
        "    orquestador.imprimir_resumen()\n",
        "\n",
        "    return orquestador"
      ],
      "metadata": {
        "id": "Jdtl8PJcBPAn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PUNTO DE ENTRADA PARA PRUEBAS LOCALES\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # ===========================================================================\n",
        "    # CONFIGURACIÓN DE RUTAS\n",
        "    # ===========================================================================\n",
        "\n",
        "    RUTA_BASE_TFM = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    RUTA_FASE2A = RUTA_BASE_TFM / \"3_Analisis\" / \"fase2_evaluacion\" / \"metricas_agregadas\"\n",
        "    RUTA_CARACTERISTICAS = RUTA_BASE_TFM / \"1_Caracteristicas\" / \"json\"\n",
        "\n",
        "    # CSVs de métricas por modelo\n",
        "    rutas_csv = {\n",
        "        'yolov8': RUTA_FASE2A / \"todas_metricas.csv\",\n",
        "        'bodypix': RUTA_FASE2A / \"bodypix_todas_metricas.csv\",\n",
        "        'mask2former': RUTA_FASE2A / \"m2f_todas_metricas.csv\",\n",
        "        'oneformer': RUTA_FASE2A / \"of_todas_metricas.csv\",\n",
        "        'sam2': RUTA_FASE2A / \"s2_todas_metricas.csv\",\n",
        "        'sam2_prompts': RUTA_FASE2A / \"s2p_todas_metricas.csv\"\n",
        "    }\n",
        "\n",
        "    # JSONs de características fotográficas\n",
        "    rutas_json = sorted(RUTA_CARACTERISTICAS.glob(\"_DSC*_caracteristicas.json\"))\n",
        "\n",
        "    # Verificar archivos\n",
        "    print(\"Verificando archivos...\")\n",
        "    for modelo, ruta in rutas_csv.items():\n",
        "        existe = \"OK\" if ruta.exists() else \"NO ENCONTRADO\"\n",
        "        print(f\"  {modelo}: {existe}\")\n",
        "    print(f\"  JSONs encontrados: {len(rutas_json)}\")\n",
        "\n",
        "    # Ejecutar Fase 2B\n",
        "    orquestador = ejecutar_fase2b(\n",
        "        ruta_base_tfm=str(RUTA_BASE_TFM),\n",
        "        rutas_csv={k: str(v) for k, v in rutas_csv.items()},\n",
        "        rutas_json=[str(r) for r in rutas_json]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEm3seK-Dk7A",
        "outputId": "faefd743-021c-46ff-87f6-1918f2546ba0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Verificando archivos...\n",
            "  yolov8: OK\n",
            "  bodypix: OK\n",
            "  mask2former: OK\n",
            "  oneformer: OK\n",
            "  sam2: OK\n",
            "  sam2_prompts: OK\n",
            "  JSONs encontrados: 20\n",
            "[21:44:14] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | \n",
            "[PASO 1/7] Cargando y consolidando datos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 1/7] Cargando y consolidando datos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | Cargando CSVs de metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Cargando CSVs de metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   yolov8: 400 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  yolov8: 400 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   bodypix: 480 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  bodypix: 480 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   mask2former: 135 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  mask2former: 135 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   oneformer: 517 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  oneformer: 517 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   sam2: 240 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  sam2: 240 filas, 67 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     |   sam2_prompts: 588 filas, 72 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  sam2_prompts: 588 filas, 72 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | Total consolidado: 2360 filas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Total consolidado: 2360 filas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:14] INFO     | Cargando caracteristicas de 20 fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Cargando caracteristicas de 20 fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Caracteristicas extraidas: 20 fotos x 21 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Caracteristicas extraidas: 20 fotos x 21 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Fusionando metricas con caracteristicas fotograficas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Fusionando metricas con caracteristicas fotograficas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Todas las fotos tienen caracteristicas asociadas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Todas las fotos tienen caracteristicas asociadas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Dataset fusionado: 2360 filas x 92 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Dataset fusionado: 2360 filas x 92 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | \n",
            "[PASO 2/7] Calculando correlaciones globales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 2/7] Calculando correlaciones globales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Calculando correlaciones globales vs iou...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando correlaciones globales vs iou...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | \n",
            "[PASO 3/7] Calculando correlaciones por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1746441710.py:49: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  corr, pval = stats.pearsonr(\n",
            "INFO:Fase2B:\n",
            "[PASO 3/7] Calculando correlaciones por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Calculando correlaciones por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando correlaciones por modelo...\n",
            "/tmp/ipython-input-1746441710.py:102: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  corr, pval = stats.pearsonr(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | \n",
            "[PASO 4/7] Ejecutando tests de hipotesis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 4/7] Ejecutando tests de hipotesis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Testing H1: Efecto de apertura (bokeh)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H1: Efecto de apertura (bokeh)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Testing H2: Efecto de homogeneidad del fondo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H2: Efecto de homogeneidad del fondo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:21] INFO     | Testing H3: Efecto de subexposicion (contraluz)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H3: Efecto de subexposicion (contraluz)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Testing H4: Efecto del contraste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H4: Efecto del contraste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | \n",
            "[PASO 5/7] Calculando tamano de efecto entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 5/7] Calculando tamano de efecto entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Calculando Cohen's d entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando Cohen's d entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Calculando eta cuadrado (ANOVA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando eta cuadrado (ANOVA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | \n",
            "[PASO 6/7] Generando estadisticas descriptivas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 6/7] Generando estadisticas descriptivas...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Generando estadisticas por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando estadisticas por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Generando estadisticas por fotografia...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando estadisticas por fotografia...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Generando ranking TOP-20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando ranking TOP-20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | \n",
            "[PASO 7/7] Guardando resultados...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 7/7] Guardando resultados...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/caracteristicas_fotograficas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/caracteristicas_fotograficas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_globales.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_globales.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_por_modelo.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_por_modelo.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/test_hipotesis.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/test_hipotesis.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/tamano_efecto.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/tamano_efecto.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/estadisticas_descriptivas.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/estadisticas_descriptivas.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | \n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | FASE 2B COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:FASE 2B COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Duracion: 8.1 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Duracion: 8.1 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Evaluaciones procesadas: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Evaluaciones procesadas: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Modelos: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Modelos: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21:44:22] INFO     | Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Fotografias: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RESUMEN DE RESULTADOS FASE 2B\n",
            "======================================================================\n",
            "\n",
            "CORRELACIONES GLOBALES SIGNIFICATIVAS (p < 0.05):\n",
            "--------------------------------------------------\n",
            "  homogeneity               r=-0.1407 (-)\n",
            "  haralick_contrast         r= 0.1352 (+)\n",
            "  haralick_entropy          r= 0.1302 (+)\n",
            "  nitidez_laplacian         r= 0.1235 (+)\n",
            "  snr                       r=-0.1129 (-)\n",
            "  exposicion                r=-0.0929 (-)\n",
            "  freq_ratio_alta           r= 0.0760 (+)\n",
            "  apertura                  r= 0.0747 (+)\n",
            "  entropia_color            r= 0.0682 (+)\n",
            "  saturacion                r= 0.0638 (+)\n",
            "\n",
            "RENDIMIENTO POR MODELO (IoU):\n",
            "--------------------------------------------------\n",
            "  yolov8          mean=0.9498 std=0.0527 [0.0010, 0.9803]\n",
            "  oneformer       mean=0.8790 std=0.2185 [0.1692, 0.9908]\n",
            "  mask2former     mean=0.6933 std=0.3572 [0.0000, 0.9878]\n",
            "  bodypix         mean=0.6559 std=0.1740 [0.2022, 0.9535]\n",
            "  sam2_prompts    mean=0.4614 std=0.3746 [0.0000, 0.9861]\n",
            "  sam2            mean=0.3077 std=0.3616 [0.0000, 0.9812]\n",
            "\n",
            "RESULTADOS DE HIPOTESIS:\n",
            "--------------------------------------------------\n",
            "  H1_apertura: Significativo=SI, Efecto=insignificante\n",
            "  H2_homogeneidad: Significativo=SI, Efecto=insignificante\n",
            "  H3_subexposicion: Significativo=NO, Efecto=insignificante\n",
            "  H4_contraste: Significativo=SI, Efecto=pequeno\n",
            "\n",
            "ANOVA GLOBAL:\n",
            "  F=306.01, p=8.04e-253\n",
            "  Eta^2=0.3939 (grande)\n"
          ]
        }
      ]
    }
  ]
}