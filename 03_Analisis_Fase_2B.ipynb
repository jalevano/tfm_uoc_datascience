{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoYw6ai5LpVglFG2JWxP8R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "DRdZE4g2ASZP",
        "outputId": "65ec893d-9d8e-4a40-b533-ede2688bee00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n================================================================================\\nFASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\\n================================================================================\\nTrabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\\nen Fotografia de Retrato\\n\\nAutor: Jesus L.\\nUniversidad: Universidad Oberta de Cataluna (UOC)\\nFecha: Diciembre 2025\\n\\nDESCRIPCION:\\nFase 2B del analisis comparativo de modelos de segmentacion. Fusiona las metricas\\nde segmentacion calculadas en Fase 2A con las caracteristicas fotograficas\\nextraidas en Fase 1, permitiendo analizar como los parametros de captura\\n(apertura, ISO, exposicion) y las propiedades de imagen (contraste, nitidez,\\ncomplejidad textural) afectan al rendimiento de cada modelo.\\n\\nDEPENDENCIAS DE DATOS:\\n- Requiere Fase 2A completada (CSVs de metricas por modelo)\\n- Requiere JSONs de caracteristicas fotograficas (20 archivos)\\n- Genera dataset fusionado para fases posteriores\\n\\nANALISIS INCLUIDOS:\\n1. Consolidacion de CSVs de metricas de todos los modelos\\n2. Extraccion de caracteristicas fotograficas clave (20 variables)\\n3. Fusion de datasets por codigo de fotografia\\n4. Correlaciones globales: caracteristicas vs IoU\\n5. Correlaciones por modelo: sensibilidad diferencial\\n6. Test de hipotesis especificas (bokeh, contraste, exposicion, fondo)\\n7. Tamano de efecto entre modelos (Cohen's d, eta cuadrado)\\n8. Estadisticas descriptivas y resumen ejecutivo\\n\\nCARACTERISTICAS FOTOGRAFICAS EXTRAIDAS:\\n- EXIF: apertura, ISO, exposicion, focal\\n- Calidad: brillo, subexposicion, sobreexposicion, rango dinamico\\n- Contraste: RMS, nitidez Laplacian, SNR\\n- Textura: homogeneidad GLCM, entropia Haralick, contraste Haralick\\n- Frecuencia: ratio alta frecuencia\\n- Saliencia: centro, ratio centro/periferia, distancia centroide\\n- Color: entropia, saturacion\\n\\nVERSION ACTUALIZADA:\\n- Extrae 152 caracteristicas fotograficas (vs 20 en version anterior)\\n- Incluye todas las texturas: Haralick, GLCM, LBP, Zernike\\n- Incluye analisis de frecuencia completo\\n- Incluye bordes y gradientes\\n- Correlaciones con multiples metricas objetivo (IoU, Dice, Boundary IoU)\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/3_Analisis/fase2b_correlaciones/\\n├── metricas_fusionadas.csv           # Dataset completo (67 + 152 columnas)\\n├── caracteristicas_fotograficas.csv  # 152 caracteristicas por foto\\n├── correlaciones_globales.csv        # Todas las correlaciones\\n├── correlaciones_por_modelo.csv      # Correlaciones segmentadas\\n├── correlaciones_multimetrica.csv    # Correlaciones vs IoU, Dice, Boundary\\n├── test_hipotesis.json               # Resultados de tests\\n├── tamano_efecto.json                # Cohen's d entre modelos\\n├── estadisticas_descriptivas.json    # Stats completas\\n\\n================================================================================\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n",
        "================================================================================\n",
        "Trabajo Fin de Master: Evaluacion Comparativa de Tecnicas de Segmentacion\n",
        "en Fotografia de Retrato\n",
        "\n",
        "Autor: Jesus L.\n",
        "Universidad: Universidad Oberta de Cataluna (UOC)\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "DESCRIPCION:\n",
        "Fase 2B del analisis comparativo de modelos de segmentacion. Fusiona las metricas\n",
        "de segmentacion calculadas en Fase 2A con las caracteristicas fotograficas\n",
        "extraidas en Fase 1, permitiendo analizar como los parametros de captura\n",
        "(apertura, ISO, exposicion) y las propiedades de imagen (contraste, nitidez,\n",
        "complejidad textural) afectan al rendimiento de cada modelo.\n",
        "\n",
        "DEPENDENCIAS DE DATOS:\n",
        "- Requiere Fase 2A completada (CSVs de metricas por modelo)\n",
        "- Requiere JSONs de caracteristicas fotograficas (20 archivos)\n",
        "- Genera dataset fusionado para fases posteriores\n",
        "\n",
        "ANALISIS INCLUIDOS:\n",
        "1. Consolidacion de CSVs de metricas de todos los modelos\n",
        "2. Extraccion de caracteristicas fotograficas clave (20 variables)\n",
        "3. Fusion de datasets por codigo de fotografia\n",
        "4. Correlaciones globales: caracteristicas vs IoU\n",
        "5. Correlaciones por modelo: sensibilidad diferencial\n",
        "6. Test de hipotesis especificas (bokeh, contraste, exposicion, fondo)\n",
        "7. Tamano de efecto entre modelos (Cohen's d, eta cuadrado)\n",
        "8. Estadisticas descriptivas y resumen ejecutivo\n",
        "\n",
        "CARACTERISTICAS FOTOGRAFICAS EXTRAIDAS:\n",
        "- EXIF: apertura, ISO, exposicion, focal\n",
        "- Calidad: brillo, subexposicion, sobreexposicion, rango dinamico\n",
        "- Contraste: RMS, nitidez Laplacian, SNR\n",
        "- Textura: homogeneidad GLCM, entropia Haralick, contraste Haralick\n",
        "- Frecuencia: ratio alta frecuencia\n",
        "- Saliencia: centro, ratio centro/periferia, distancia centroide\n",
        "- Color: entropia, saturacion\n",
        "\n",
        "VERSION ACTUALIZADA:\n",
        "- Extrae 152 caracteristicas fotograficas (vs 20 en version anterior)\n",
        "- Incluye todas las texturas: Haralick, GLCM, LBP, Zernike\n",
        "- Incluye analisis de frecuencia completo\n",
        "- Incluye bordes y gradientes\n",
        "- Correlaciones con multiples metricas objetivo (IoU, Dice, Boundary IoU)\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/3_Analisis/fase2b_correlaciones/\n",
        "├── metricas_fusionadas.csv           # Dataset completo (67 + 152 columnas)\n",
        "├── caracteristicas_fotograficas.csv  # 152 caracteristicas por foto\n",
        "├── correlaciones_globales.csv        # Todas las correlaciones\n",
        "├── correlaciones_por_modelo.csv      # Correlaciones segmentadas\n",
        "├── correlaciones_multimetrica.csv    # Correlaciones vs IoU, Dice, Boundary\n",
        "├── test_hipotesis.json               # Resultados de tests\n",
        "├── tamano_efecto.json                # Cohen's d entre modelos\n",
        "├── estadisticas_descriptivas.json    # Stats completas\n",
        "\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "ioVauJqMBMJr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIONES DE UTILIDAD PARA SERIALIZACION\n",
        "# =============================================================================\n",
        "\n",
        "def convertir_a_serializable(obj: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Convierte tipos numpy y pandas a tipos Python nativos para JSON.\n",
        "\n",
        "    Args:\n",
        "        obj: Objeto a convertir\n",
        "\n",
        "    Returns:\n",
        "        Objeto con tipos serializables\n",
        "    \"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: convertir_a_serializable(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, list):\n",
        "        return [convertir_a_serializable(v) for v in obj]\n",
        "    elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "        if np.isnan(obj) or np.isinf(obj):\n",
        "            return None\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, (np.bool_, bool)):\n",
        "        return bool(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif pd.isna(obj):\n",
        "        return None\n",
        "    return obj"
      ],
      "metadata": {
        "id": "BvsRrYLzBUvV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACION\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionFase2B:\n",
        "    \"\"\"\n",
        "    Configuracion central para el pipeline de Fase 2B.\n",
        "\n",
        "    Attributes:\n",
        "        ruta_base_tfm: Ruta raiz del proyecto TFM\n",
        "        ruta_csvs_fase2a: Directorio con CSVs de metricas de Fase 2A\n",
        "        ruta_jsons_caracteristicas: Directorio con JSONs de caracteristicas\n",
        "        ruta_salida: Directorio para resultados de Fase 2B\n",
        "        nivel_significancia: Alpha para tests estadisticos (default 0.05)\n",
        "        min_observaciones_correlacion: Minimo de observaciones para calcular correlacion\n",
        "    \"\"\"\n",
        "    ruta_base_tfm: Path\n",
        "    ruta_csvs_fase2a: Path = None\n",
        "    ruta_jsons_caracteristicas: Path = None\n",
        "    ruta_salida: Path = None\n",
        "    nivel_significancia: float = 0.05\n",
        "    min_observaciones_correlacion: int = 10\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.ruta_csvs_fase2a is None:\n",
        "            self.ruta_csvs_fase2a = self.ruta_base_tfm / \"3_Analisis\" / \"fase2_evaluacion\" / \"metricas_agregadas\"\n",
        "        if self.ruta_jsons_caracteristicas is None:\n",
        "            self.ruta_jsons_caracteristicas = self.ruta_base_tfm / \"1_Caracteristicas\" / \"json\"\n",
        "        if self.ruta_salida is None:\n",
        "            self.ruta_salida = self.ruta_base_tfm / \"3_Analisis\" / \"fase2b_correlaciones\""
      ],
      "metadata": {
        "id": "mLAlgSBgBaj7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONSTANTES: CARACTERISTICAS FOTOGRAFICAS A EXTRAER\n",
        "# =============================================================================\n",
        "\n",
        "CARACTERISTICAS_EXHAUSTIVAS = {\n",
        "    # =========================================================================\n",
        "    # METADATOS DE ARCHIVO (9 campos)\n",
        "    # =========================================================================\n",
        "    'meta_ancho': ('metadatos_archivo', 'ancho_original'),\n",
        "    'meta_alto': ('metadatos_archivo', 'alto_original'),\n",
        "    'meta_tamano_mb': ('metadatos_archivo', 'tamano_archivo_mb'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # EXIF - PARAMETROS DE CAPTURA (14 campos)\n",
        "    # =========================================================================\n",
        "    'exif_apertura': ('metadatos_exif', 'apertura_fnumber'),\n",
        "    'exif_iso': ('metadatos_exif', 'iso'),\n",
        "    'exif_exposicion_seg': ('metadatos_exif', 'tiempo_exposicion_segundos'),\n",
        "    'exif_focal': ('metadatos_exif', 'distancia_focal'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # ESTADISTICAS DE COLOR - RGB (12 campos)\n",
        "    # =========================================================================\n",
        "    'color_rgb_r_mean': ('estadisticas_color', 'rgb', 'mean', 0),\n",
        "    'color_rgb_g_mean': ('estadisticas_color', 'rgb', 'mean', 1),\n",
        "    'color_rgb_b_mean': ('estadisticas_color', 'rgb', 'mean', 2),\n",
        "    'color_rgb_r_std': ('estadisticas_color', 'rgb', 'stddev', 0),\n",
        "    'color_rgb_g_std': ('estadisticas_color', 'rgb', 'stddev', 1),\n",
        "    'color_rgb_b_std': ('estadisticas_color', 'rgb', 'stddev', 2),\n",
        "\n",
        "    # =========================================================================\n",
        "    # ESTADISTICAS DE COLOR - HSV (6 campos)\n",
        "    # =========================================================================\n",
        "    'color_hsv_hue_mean': ('estadisticas_color', 'hsv', 'hue_mean'),\n",
        "    'color_hsv_hue_std': ('estadisticas_color', 'hsv', 'hue_std'),\n",
        "    'color_hsv_sat_mean': ('estadisticas_color', 'hsv', 'saturation_mean'),\n",
        "    'color_hsv_sat_std': ('estadisticas_color', 'hsv', 'saturation_std'),\n",
        "    'color_hsv_val_mean': ('estadisticas_color', 'hsv', 'value_mean'),\n",
        "    'color_hsv_val_std': ('estadisticas_color', 'hsv', 'value_std'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # ESTADISTICAS DE COLOR - LAB (6 campos)\n",
        "    # =========================================================================\n",
        "    'color_lab_l_mean': ('estadisticas_color', 'lab', 'l_mean'),\n",
        "    'color_lab_l_std': ('estadisticas_color', 'lab', 'l_std'),\n",
        "    'color_lab_a_mean': ('estadisticas_color', 'lab', 'a_mean'),\n",
        "    'color_lab_a_std': ('estadisticas_color', 'lab', 'a_std'),\n",
        "    'color_lab_b_mean': ('estadisticas_color', 'lab', 'b_mean'),\n",
        "    'color_lab_b_std': ('estadisticas_color', 'lab', 'b_std'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # ESTADISTICAS DE COLOR - GLOBAL (3 campos)\n",
        "    # =========================================================================\n",
        "    'color_brillo': ('estadisticas_color', 'global', 'brillo_promedio'),\n",
        "    'color_contraste': ('estadisticas_color', 'global', 'contraste'),\n",
        "    'color_entropia': ('estadisticas_color', 'global', 'entropia'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # HISTOGRAMAS (12 campos - estadisticas por canal)\n",
        "    # =========================================================================\n",
        "    'hist_rojo_pico': ('histogramas', 'rojo', 'pico_principal'),\n",
        "    'hist_rojo_media': ('histogramas', 'rojo', 'media'),\n",
        "    'hist_rojo_std': ('histogramas', 'rojo', 'std'),\n",
        "    'hist_verde_pico': ('histogramas', 'verde', 'pico_principal'),\n",
        "    'hist_verde_media': ('histogramas', 'verde', 'media'),\n",
        "    'hist_verde_std': ('histogramas', 'verde', 'std'),\n",
        "    'hist_azul_pico': ('histogramas', 'azul', 'pico_principal'),\n",
        "    'hist_azul_media': ('histogramas', 'azul', 'media'),\n",
        "    'hist_azul_std': ('histogramas', 'azul', 'std'),\n",
        "    'hist_intensidad_entropia': ('histogramas', 'intensidad', 'entropia'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # TEXTURAS - HARALICK (13 campos)\n",
        "    # =========================================================================\n",
        "    'tex_haralick_asm': ('texturas', 'haralick', 'angular_second_moment'),\n",
        "    'tex_haralick_contrast': ('texturas', 'haralick', 'contrast'),\n",
        "    'tex_haralick_correlation': ('texturas', 'haralick', 'correlation'),\n",
        "    'tex_haralick_sum_squares': ('texturas', 'haralick', 'sum_of_squares'),\n",
        "    'tex_haralick_idm': ('texturas', 'haralick', 'inverse_diff_moment'),\n",
        "    'tex_haralick_sum_avg': ('texturas', 'haralick', 'sum_average'),\n",
        "    'tex_haralick_sum_var': ('texturas', 'haralick', 'sum_variance'),\n",
        "    'tex_haralick_sum_entropy': ('texturas', 'haralick', 'sum_entropy'),\n",
        "    'tex_haralick_entropy': ('texturas', 'haralick', 'entropy'),\n",
        "    'tex_haralick_diff_var': ('texturas', 'haralick', 'difference_variance'),\n",
        "    'tex_haralick_diff_entropy': ('texturas', 'haralick', 'difference_entropy'),\n",
        "    'tex_haralick_imc1': ('texturas', 'haralick', 'info_measure_correlation_1'),\n",
        "    'tex_haralick_imc2': ('texturas', 'haralick', 'info_measure_correlation_2'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # TEXTURAS - GLCM (12 campos)\n",
        "    # =========================================================================\n",
        "    'tex_glcm_contrast_mean': ('texturas', 'glcm', 'contrast_mean'),\n",
        "    'tex_glcm_contrast_std': ('texturas', 'glcm', 'contrast_std'),\n",
        "    'tex_glcm_dissimilarity_mean': ('texturas', 'glcm', 'dissimilarity_mean'),\n",
        "    'tex_glcm_dissimilarity_std': ('texturas', 'glcm', 'dissimilarity_std'),\n",
        "    'tex_glcm_homogeneity_mean': ('texturas', 'glcm', 'homogeneity_mean'),\n",
        "    'tex_glcm_homogeneity_std': ('texturas', 'glcm', 'homogeneity_std'),\n",
        "    'tex_glcm_energy_mean': ('texturas', 'glcm', 'energy_mean'),\n",
        "    'tex_glcm_energy_std': ('texturas', 'glcm', 'energy_std'),\n",
        "    'tex_glcm_correlation_mean': ('texturas', 'glcm', 'correlation_mean'),\n",
        "    'tex_glcm_correlation_std': ('texturas', 'glcm', 'correlation_std'),\n",
        "    'tex_glcm_asm_mean': ('texturas', 'glcm', 'ASM_mean'),\n",
        "    'tex_glcm_asm_std': ('texturas', 'glcm', 'ASM_std'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # TEXTURAS - LBP (3 campos)\n",
        "    # =========================================================================\n",
        "    'tex_lbp_mean': ('texturas', 'lbp', 'mean'),\n",
        "    'tex_lbp_std': ('texturas', 'lbp', 'std'),\n",
        "    'tex_lbp_entropy': ('texturas', 'lbp', 'entropy'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # BORDES - CANNY (3 campos)\n",
        "    # =========================================================================\n",
        "    'borde_canny_sigma1': ('bordes_caracteristicas', 'canny', 'densidad_sigma_1.0'),\n",
        "    'borde_canny_sigma2': ('bordes_caracteristicas', 'canny', 'densidad_sigma_2.0'),\n",
        "    'borde_canny_sigma3': ('bordes_caracteristicas', 'canny', 'densidad_sigma_3.0'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # BORDES - ESQUINAS (3 campos)\n",
        "    # =========================================================================\n",
        "    'borde_harris_count': ('bordes_caracteristicas', 'esquinas', 'harris'),\n",
        "    'borde_shi_tomasi_count': ('bordes_caracteristicas', 'esquinas', 'shi_tomasi'),\n",
        "    'borde_harris_densidad': ('bordes_caracteristicas', 'esquinas', 'densidad_harris'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # BORDES - GRADIENTES (5 campos)\n",
        "    # =========================================================================\n",
        "    'borde_sobel_mean': ('bordes_caracteristicas', 'gradientes', 'sobel_mean'),\n",
        "    'borde_sobel_max': ('bordes_caracteristicas', 'gradientes', 'sobel_max'),\n",
        "    'borde_sobel_std': ('bordes_caracteristicas', 'gradientes', 'sobel_std'),\n",
        "    'borde_scharr_mean': ('bordes_caracteristicas', 'gradientes', 'scharr_mean'),\n",
        "    'borde_prewitt_mean': ('bordes_caracteristicas', 'gradientes', 'prewitt_mean'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # BORDES - HOG (3 campos)\n",
        "    # =========================================================================\n",
        "    'borde_hog_mean': ('bordes_caracteristicas', 'hog', 'mean'),\n",
        "    'borde_hog_std': ('bordes_caracteristicas', 'hog', 'std'),\n",
        "    'borde_hog_max': ('bordes_caracteristicas', 'hog', 'max'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # CALIDAD - NITIDEZ (3 campos)\n",
        "    # =========================================================================\n",
        "    'calidad_nitidez_laplacian': ('calidad', 'nitidez', 'laplacian'),\n",
        "    'calidad_nitidez_tenengrad': ('calidad', 'nitidez', 'tenengrad'),\n",
        "    'calidad_nitidez_varianza': ('calidad', 'nitidez', 'varianza_normalizada'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # CALIDAD - EXPOSICION (5 campos)\n",
        "    # =========================================================================\n",
        "    'calidad_brillo_medio': ('calidad', 'exposicion', 'brillo_medio'),\n",
        "    'calidad_sobreexp_pct': ('calidad', 'exposicion', 'sobre_expuesto_pct'),\n",
        "    'calidad_subexp_pct': ('calidad', 'exposicion', 'sub_expuesto_pct'),\n",
        "    'calidad_exp_entropia': ('calidad', 'exposicion', 'entropia'),\n",
        "    'calidad_rango_dinamico': ('calidad', 'exposicion', 'rango_dinamico'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # CALIDAD - CONTRASTE (2 campos)\n",
        "    # =========================================================================\n",
        "    'calidad_contraste_rms': ('calidad', 'contraste', 'rms'),\n",
        "    'calidad_contraste_michelson': ('calidad', 'contraste', 'michelson'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # CALIDAD - BALANCE BLANCOS (4 campos)\n",
        "    # =========================================================================\n",
        "    'calidad_wb_red': ('calidad', 'balance_blancos', 'mean_red'),\n",
        "    'calidad_wb_green': ('calidad', 'balance_blancos', 'mean_green'),\n",
        "    'calidad_wb_blue': ('calidad', 'balance_blancos', 'mean_blue'),\n",
        "    'calidad_wb_desviacion': ('calidad', 'balance_blancos', 'desviacion_canales'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # CALIDAD - RUIDO (4 campos)\n",
        "    # =========================================================================\n",
        "    'calidad_ruido_laplacian': ('calidad', 'ruido', 'laplacian'),\n",
        "    'calidad_ruido_median': ('calidad', 'ruido', 'median_filter'),\n",
        "    'calidad_snr': ('calidad', 'ruido', 'snr'),\n",
        "    'calidad_snr_db': ('calidad', 'ruido', 'snr_db'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # ANALISIS DE FRECUENCIA (8 campos)\n",
        "    # =========================================================================\n",
        "    'freq_energia_baja': ('analisis_frecuencia', 'energia_frecuencia_baja'),\n",
        "    'freq_energia_media': ('analisis_frecuencia', 'energia_frecuencia_media'),\n",
        "    'freq_energia_alta': ('analisis_frecuencia', 'energia_frecuencia_alta'),\n",
        "    'freq_ratio_baja': ('analisis_frecuencia', 'ratio_baja'),\n",
        "    'freq_ratio_media': ('analisis_frecuencia', 'ratio_media'),\n",
        "    'freq_ratio_alta': ('analisis_frecuencia', 'ratio_alta'),\n",
        "    'freq_entropia_espectral': ('analisis_frecuencia', 'entropia_espectral'),\n",
        "    'freq_pico_dominante': ('analisis_frecuencia', 'pico_dominante'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # SALIENCIA VISUAL - ESPECTRAL (5 campos)\n",
        "    # =========================================================================\n",
        "    'sal_espectral_media': ('saliencia_visual', 'espectral', 'media'),\n",
        "    'sal_espectral_std': ('saliencia_visual', 'espectral', 'std'),\n",
        "    'sal_espectral_max': ('saliencia_visual', 'espectral', 'max'),\n",
        "    'sal_espectral_p90': ('saliencia_visual', 'espectral', 'percentil_90'),\n",
        "    'sal_espectral_p95': ('saliencia_visual', 'espectral', 'percentil_95'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # SALIENCIA VISUAL - DISTRIBUCION ESPACIAL (8 campos)\n",
        "    # =========================================================================\n",
        "    'sal_superior_izq': ('saliencia_visual', 'distribucion_espacial', 'saliencia_superior_izquierda'),\n",
        "    'sal_superior_der': ('saliencia_visual', 'distribucion_espacial', 'saliencia_superior_derecha'),\n",
        "    'sal_inferior_izq': ('saliencia_visual', 'distribucion_espacial', 'saliencia_inferior_izquierda'),\n",
        "    'sal_inferior_der': ('saliencia_visual', 'distribucion_espacial', 'saliencia_inferior_derecha'),\n",
        "    'sal_variabilidad_cuadrantes': ('saliencia_visual', 'distribucion_espacial', 'variabilidad_cuadrantes'),\n",
        "    'sal_centro': ('saliencia_visual', 'distribucion_espacial', 'saliencia_centro'),\n",
        "    'sal_periferia': ('saliencia_visual', 'distribucion_espacial', 'saliencia_periferia'),\n",
        "    'sal_ratio_centro_periferia': ('saliencia_visual', 'distribucion_espacial', 'ratio_centro_periferia'),\n",
        "\n",
        "    # =========================================================================\n",
        "    # SALIENCIA VISUAL - CENTROIDE (4 campos)\n",
        "    # =========================================================================\n",
        "    'sal_centroide_x': ('saliencia_visual', 'centroide', 'centroide_x_normalizado'),\n",
        "    'sal_centroide_y': ('saliencia_visual', 'centroide', 'centroide_y_normalizado'),\n",
        "    'sal_distancia_centro': ('saliencia_visual', 'centroide', 'distancia_desde_centro'),\n",
        "    'sal_area_saliente_pct': ('saliencia_visual', 'centroide', 'area_saliente_porcentaje'),\n",
        "}\n",
        "\n",
        "# Zernike moments (25 campos) - se extraen por separado\n",
        "ZERNIKE_MOMENTS = 25"
      ],
      "metadata": {
        "id": "xUCtLQovBp99"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: EXTRACTOR DE CARACTERISTICAS\n",
        "# =============================================================================\n",
        "\n",
        "class ExtractorCaracteristicas:\n",
        "    \"\"\"\n",
        "    Extrae caracteristicas exhaustivas de JSONs fotograficos.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger):\n",
        "        self.logger = logger\n",
        "\n",
        "    def _extraer_valor_anidado(self, data: Dict, keys: Tuple) -> Any:\n",
        "        \"\"\"Extrae valor de diccionario anidado siguiendo ruta de claves.\"\"\"\n",
        "        resultado = data\n",
        "        for key in keys:\n",
        "            if isinstance(key, int):\n",
        "                # Indice de lista\n",
        "                if isinstance(resultado, list) and len(resultado) > key:\n",
        "                    resultado = resultado[key]\n",
        "                else:\n",
        "                    return None\n",
        "            elif isinstance(resultado, dict) and key in resultado:\n",
        "                resultado = resultado[key]\n",
        "            else:\n",
        "                return None\n",
        "        return resultado\n",
        "\n",
        "    def extraer_caracteristicas_json(self, ruta_json: Path) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Extrae todas las caracteristicas de un JSON de fotografia.\n",
        "\n",
        "        Args:\n",
        "            ruta_json: Ruta al archivo JSON\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con ~120 caracteristicas\n",
        "        \"\"\"\n",
        "        with open(ruta_json, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Obtener nombre de foto\n",
        "        nombre = data.get('metadatos_archivo', {}).get('nombre_archivo', '')\n",
        "        nombre = nombre.replace('.jpg', '').replace('.JPG', '')\n",
        "\n",
        "        caracteristicas = {'codigo_foto': nombre}\n",
        "\n",
        "        # Extraer caracteristicas definidas\n",
        "        for nombre_col, ruta_keys in CARACTERISTICAS_EXHAUSTIVAS.items():\n",
        "            valor = self._extraer_valor_anidado(data, ruta_keys)\n",
        "\n",
        "            # Convertir a numerico si es string numerico\n",
        "            if valor is not None and isinstance(valor, str):\n",
        "                try:\n",
        "                    valor = float(valor)\n",
        "                except (ValueError, TypeError):\n",
        "                    valor = None\n",
        "\n",
        "            caracteristicas[nombre_col] = valor\n",
        "\n",
        "        # Extraer Zernike moments\n",
        "        zernike = data.get('texturas', {}).get('zernike', [])\n",
        "        for i in range(ZERNIKE_MOMENTS):\n",
        "            if i < len(zernike):\n",
        "                caracteristicas[f'tex_zernike_{i:02d}'] = zernike[i]\n",
        "            else:\n",
        "                caracteristicas[f'tex_zernike_{i:02d}'] = None\n",
        "\n",
        "        return caracteristicas\n",
        "\n",
        "    def cargar_todas_caracteristicas(self, rutas_json: List[Path]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Carga caracteristicas de todos los JSONs.\n",
        "\n",
        "        Args:\n",
        "            rutas_json: Lista de rutas a archivos JSON\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con caracteristicas por fotografia\n",
        "        \"\"\"\n",
        "        self.logger.info(f\"Extrayendo caracteristicas de {len(rutas_json)} fotografias...\")\n",
        "\n",
        "        caracteristicas_list = []\n",
        "\n",
        "        for ruta in rutas_json:\n",
        "            try:\n",
        "                caract = self.extraer_caracteristicas_json(ruta)\n",
        "                caracteristicas_list.append(caract)\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"  Error en {ruta.name}: {e}\")\n",
        "\n",
        "        df = pd.DataFrame(caracteristicas_list)\n",
        "\n",
        "        # Contar campos extraidos\n",
        "        cols_con_datos = df.notna().sum()\n",
        "        cols_completas = (cols_con_datos == len(df)).sum()\n",
        "\n",
        "        self.logger.info(f\"  Fotografias procesadas: {len(df)}\")\n",
        "        self.logger.info(f\"  Caracteristicas totales: {len(df.columns) - 1}\")  # -1 por codigo_foto\n",
        "        self.logger.info(f\"  Caracteristicas completas (sin NaN): {cols_completas}\")\n",
        "\n",
        "        return df"
      ],
      "metadata": {
        "id": "EApP2XZ6U8Sv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: CARGADOR DE METRICAS\n",
        "# =============================================================================\n",
        "\n",
        "class CargadorMetricas:\n",
        "    \"\"\"Carga y consolida CSVs de metricas de Fase 2A.\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger):\n",
        "        self.logger = logger\n",
        "\n",
        "    def cargar_csvs(self, rutas_csv: Dict[str, Path]) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Consolida multiples CSVs en un DataFrame.\n",
        "\n",
        "        Args:\n",
        "            rutas_csv: Diccionario {nombre_modelo: ruta_csv}\n",
        "\n",
        "        Returns:\n",
        "            DataFrame consolidado\n",
        "        \"\"\"\n",
        "        self.logger.info(\"Cargando CSVs de metricas de Fase 2A...\")\n",
        "\n",
        "        dataframes = []\n",
        "\n",
        "        for modelo, ruta in rutas_csv.items():\n",
        "            if not ruta.exists():\n",
        "                self.logger.warning(f\"  {modelo}: NO ENCONTRADO - {ruta}\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                df = pd.read_csv(ruta)\n",
        "\n",
        "                # Asegurar columna modelo\n",
        "                if 'modelo' not in df.columns:\n",
        "                    df['modelo'] = modelo\n",
        "\n",
        "                self.logger.info(f\"  {modelo}: {len(df)} filas, {len(df.columns)} cols\")\n",
        "                dataframes.append(df)\n",
        "\n",
        "            except Exception as e:\n",
        "                self.logger.error(f\"  Error cargando {modelo}: {e}\")\n",
        "\n",
        "        if not dataframes:\n",
        "            raise ValueError(\"No se pudieron cargar CSVs\")\n",
        "\n",
        "        df_consolidado = pd.concat(dataframes, ignore_index=True)\n",
        "        self.logger.info(f\"Total consolidado: {len(df_consolidado)} filas\")\n",
        "\n",
        "        return df_consolidado"
      ],
      "metadata": {
        "id": "DVY9TTICU_JB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE CORRELACIONES\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorCorrelaciones:\n",
        "    \"\"\"Analiza correlaciones entre caracteristicas y metricas.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def calcular_correlaciones_globales(self, df: pd.DataFrame,\n",
        "                                        metricas_objetivo: List[str] = None) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula correlaciones Pearson y Spearman entre caracteristicas y metricas.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metricas_objetivo: Lista de metricas objetivo (default: iou, dice, boundary_iou)\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con correlaciones\n",
        "        \"\"\"\n",
        "        if metricas_objetivo is None:\n",
        "            metricas_objetivo = ['iou', 'dice', 'boundary_iou']\n",
        "\n",
        "        self.logger.info(f\"Calculando correlaciones globales vs {metricas_objetivo}...\")\n",
        "\n",
        "        # Identificar columnas de caracteristicas\n",
        "        cols_excluir = ['codigo_foto', 'config_codigo', 'modelo'] + metricas_objetivo\n",
        "        cols_excluir += [c for c in df.columns if c.startswith('haralick_')]  # Haralick de mascara\n",
        "        cols_excluir += ['precision', 'recall', 'f1_score']  # Otras metricas\n",
        "\n",
        "        cols_foto = [c for c in df.columns\n",
        "                    if c not in cols_excluir\n",
        "                    and df[c].dtype in ['float64', 'int64', 'float32', 'int32']\n",
        "                    and not c.startswith('bbox_')\n",
        "                    and not c.startswith('centroide_')\n",
        "                    and c not in ['area_px', 'perimetro_px']]\n",
        "\n",
        "        correlaciones = []\n",
        "\n",
        "        for col in cols_foto:\n",
        "            for metrica in metricas_objetivo:\n",
        "                if metrica not in df.columns:\n",
        "                    continue\n",
        "\n",
        "                mask = df[col].notna() & df[metrica].notna()\n",
        "                n_obs = mask.sum()\n",
        "\n",
        "                if n_obs >= self.config.min_observaciones_correlacion:\n",
        "                    try:\n",
        "                        # Pearson\n",
        "                        r_pearson, p_pearson = stats.pearsonr(\n",
        "                            df.loc[mask, col], df.loc[mask, metrica]\n",
        "                        )\n",
        "\n",
        "                        # Spearman\n",
        "                        r_spearman, p_spearman = stats.spearmanr(\n",
        "                            df.loc[mask, col], df.loc[mask, metrica]\n",
        "                        )\n",
        "\n",
        "                        correlaciones.append({\n",
        "                            'caracteristica': col,\n",
        "                            'metrica_objetivo': metrica,\n",
        "                            'r_pearson': r_pearson,\n",
        "                            'p_pearson': p_pearson,\n",
        "                            'r_spearman': r_spearman,\n",
        "                            'p_spearman': p_spearman,\n",
        "                            'n_observaciones': n_obs,\n",
        "                            'sig_pearson': p_pearson < self.config.nivel_significancia,\n",
        "                            'sig_spearman': p_spearman < self.config.nivel_significancia\n",
        "                        })\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "        df_corr = pd.DataFrame(correlaciones)\n",
        "\n",
        "        if len(df_corr) > 0:\n",
        "            df_corr = df_corr.sort_values('r_pearson', key=abs, ascending=False)\n",
        "\n",
        "            n_sig = df_corr['sig_pearson'].sum()\n",
        "            self.logger.info(f\"  Correlaciones calculadas: {len(df_corr)}\")\n",
        "            self.logger.info(f\"  Significativas (p<0.05): {n_sig}\")\n",
        "\n",
        "        return df_corr\n",
        "\n",
        "    def calcular_correlaciones_por_modelo(self, df: pd.DataFrame,\n",
        "                                          metrica_objetivo: str = 'iou') -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula correlaciones segmentadas por modelo.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame fusionado\n",
        "            metrica_objetivo: Metrica objetivo\n",
        "\n",
        "        Returns:\n",
        "            DataFrame con correlaciones por modelo\n",
        "        \"\"\"\n",
        "        self.logger.info(f\"Calculando correlaciones por modelo vs {metrica_objetivo}...\")\n",
        "\n",
        "        cols_foto = [c for c in df.columns if c not in\n",
        "                    ['codigo_foto', 'config_codigo', 'modelo', metrica_objetivo]\n",
        "                    and df[c].dtype in ['float64', 'int64', 'float32', 'int32']]\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for modelo in df['modelo'].unique():\n",
        "            df_m = df[df['modelo'] == modelo]\n",
        "\n",
        "            for col in cols_foto:\n",
        "                mask = df_m[col].notna() & df_m[metrica_objetivo].notna()\n",
        "                n_obs = mask.sum()\n",
        "\n",
        "                if n_obs >= self.config.min_observaciones_correlacion:\n",
        "                    try:\n",
        "                        r, p = stats.pearsonr(\n",
        "                            df_m.loc[mask, col], df_m.loc[mask, metrica_objetivo]\n",
        "                        )\n",
        "\n",
        "                        resultados.append({\n",
        "                            'modelo': modelo,\n",
        "                            'caracteristica': col,\n",
        "                            'correlacion': r,\n",
        "                            'p_valor': p,\n",
        "                            'n_observaciones': n_obs,\n",
        "                            'significativo': p < self.config.nivel_significancia\n",
        "                        })\n",
        "                    except Exception:\n",
        "                        pass\n",
        "\n",
        "        return pd.DataFrame(resultados)"
      ],
      "metadata": {
        "id": "4WttFDqBVE_W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE HIPOTESIS\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorHipotesis:\n",
        "    \"\"\"Ejecuta tests de hipotesis especificas.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def _calcular_cohens_d(self, g1: pd.Series, g2: pd.Series) -> float:\n",
        "        \"\"\"Calcula Cohen's d entre dos grupos.\"\"\"\n",
        "        n1, n2 = len(g1), len(g2)\n",
        "        var1, var2 = g1.var(), g2.var()\n",
        "        pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
        "        if pooled_std == 0:\n",
        "            return 0.0\n",
        "        return (g1.mean() - g2.mean()) / pooled_std\n",
        "\n",
        "    def _interpretar_d(self, d: float) -> str:\n",
        "        \"\"\"Interpreta Cohen's d.\"\"\"\n",
        "        d_abs = abs(d)\n",
        "        if d_abs < 0.2: return \"insignificante\"\n",
        "        elif d_abs < 0.5: return \"pequeno\"\n",
        "        elif d_abs < 0.8: return \"mediano\"\n",
        "        return \"grande\"\n",
        "\n",
        "    def test_apertura_bokeh(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H1: Apertura abierta (bokeh) mejora segmentacion.\"\"\"\n",
        "        self.logger.info(\"Testing H1: Efecto de apertura (bokeh)...\")\n",
        "\n",
        "        col_apertura = 'exif_apertura'\n",
        "        if col_apertura not in df.columns:\n",
        "            return {'error': 'Columna apertura no disponible'}\n",
        "\n",
        "        mask = df[col_apertura].notna() & (df[col_apertura] > 0)\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        umbral = 2.8\n",
        "        grupo_bokeh = df_h[df_h[col_apertura] < umbral]['iou']\n",
        "        grupo_nitido = df_h[df_h[col_apertura] >= umbral]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H1: Apertura abierta (bokeh) mejora segmentacion',\n",
        "            'variable': col_apertura,\n",
        "            'umbral': umbral,\n",
        "            'grupo_bokeh': {\n",
        "                'n': len(grupo_bokeh),\n",
        "                'iou_mean': float(grupo_bokeh.mean()) if len(grupo_bokeh) > 0 else None,\n",
        "                'iou_std': float(grupo_bokeh.std()) if len(grupo_bokeh) > 0 else None\n",
        "            },\n",
        "            'grupo_nitido': {\n",
        "                'n': len(grupo_nitido),\n",
        "                'iou_mean': float(grupo_nitido.mean()) if len(grupo_nitido) > 0 else None,\n",
        "                'iou_std': float(grupo_nitido.std()) if len(grupo_nitido) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_bokeh) > 1 and len(grupo_nitido) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_bokeh, grupo_nitido)\n",
        "            d = self._calcular_cohens_d(grupo_bokeh, grupo_nitido)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_complejidad_fondo(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H2: Fondos complejos (alta entropia textural) dificultan segmentacion.\"\"\"\n",
        "        self.logger.info(\"Testing H2: Efecto de complejidad del fondo...\")\n",
        "\n",
        "        col_entropia = 'tex_haralick_entropy'\n",
        "        if col_entropia not in df.columns:\n",
        "            return {'error': 'Columna entropia no disponible'}\n",
        "\n",
        "        mask = df[col_entropia].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h[col_entropia].median()\n",
        "        grupo_simple = df_h[df_h[col_entropia] <= mediana]['iou']\n",
        "        grupo_complejo = df_h[df_h[col_entropia] > mediana]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H2: Fondos complejos dificultan segmentacion',\n",
        "            'variable': col_entropia,\n",
        "            'umbral_mediana': float(mediana),\n",
        "            'grupo_simple': {\n",
        "                'n': len(grupo_simple),\n",
        "                'iou_mean': float(grupo_simple.mean()) if len(grupo_simple) > 0 else None\n",
        "            },\n",
        "            'grupo_complejo': {\n",
        "                'n': len(grupo_complejo),\n",
        "                'iou_mean': float(grupo_complejo.mean()) if len(grupo_complejo) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_simple) > 1 and len(grupo_complejo) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_simple, grupo_complejo)\n",
        "            d = self._calcular_cohens_d(grupo_simple, grupo_complejo)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_contraste(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H3: Mayor contraste mejora segmentacion.\"\"\"\n",
        "        self.logger.info(\"Testing H3: Efecto del contraste...\")\n",
        "\n",
        "        col_contraste = 'calidad_contraste_rms'\n",
        "        if col_contraste not in df.columns:\n",
        "            return {'error': 'Columna contraste no disponible'}\n",
        "\n",
        "        mask = df[col_contraste].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h[col_contraste].median()\n",
        "        grupo_bajo = df_h[df_h[col_contraste] <= mediana]['iou']\n",
        "        grupo_alto = df_h[df_h[col_contraste] > mediana]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H3: Mayor contraste mejora segmentacion',\n",
        "            'variable': col_contraste,\n",
        "            'umbral_mediana': float(mediana),\n",
        "            'grupo_bajo': {\n",
        "                'n': len(grupo_bajo),\n",
        "                'iou_mean': float(grupo_bajo.mean()) if len(grupo_bajo) > 0 else None\n",
        "            },\n",
        "            'grupo_alto': {\n",
        "                'n': len(grupo_alto),\n",
        "                'iou_mean': float(grupo_alto.mean()) if len(grupo_alto) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_bajo) > 1 and len(grupo_alto) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_bajo, grupo_alto)\n",
        "            d = self._calcular_cohens_d(grupo_alto, grupo_bajo)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_saliencia_central(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H4: Sujeto centrado (alta saliencia central) facilita deteccion.\"\"\"\n",
        "        self.logger.info(\"Testing H4: Efecto de saliencia central...\")\n",
        "\n",
        "        col_saliencia = 'sal_centro'\n",
        "        if col_saliencia not in df.columns:\n",
        "            return {'error': 'Columna saliencia no disponible'}\n",
        "\n",
        "        mask = df[col_saliencia].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h[col_saliencia].median()\n",
        "        grupo_periferico = df_h[df_h[col_saliencia] <= mediana]['iou']\n",
        "        grupo_central = df_h[df_h[col_saliencia] > mediana]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H4: Saliencia central facilita segmentacion',\n",
        "            'variable': col_saliencia,\n",
        "            'umbral_mediana': float(mediana),\n",
        "            'grupo_periferico': {\n",
        "                'n': len(grupo_periferico),\n",
        "                'iou_mean': float(grupo_periferico.mean()) if len(grupo_periferico) > 0 else None\n",
        "            },\n",
        "            'grupo_central': {\n",
        "                'n': len(grupo_central),\n",
        "                'iou_mean': float(grupo_central.mean()) if len(grupo_central) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_periferico) > 1 and len(grupo_central) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_periferico, grupo_central)\n",
        "            d = self._calcular_cohens_d(grupo_central, grupo_periferico)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_nitidez(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H5: Mayor nitidez mejora segmentacion.\"\"\"\n",
        "        self.logger.info(\"Testing H5: Efecto de nitidez...\")\n",
        "\n",
        "        col_nitidez = 'calidad_nitidez_laplacian'\n",
        "        if col_nitidez not in df.columns:\n",
        "            return {'error': 'Columna nitidez no disponible'}\n",
        "\n",
        "        mask = df[col_nitidez].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h[col_nitidez].median()\n",
        "        grupo_borroso = df_h[df_h[col_nitidez] <= mediana]['iou']\n",
        "        grupo_nitido = df_h[df_h[col_nitidez] > mediana]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H5: Mayor nitidez mejora segmentacion',\n",
        "            'variable': col_nitidez,\n",
        "            'umbral_mediana': float(mediana),\n",
        "            'grupo_borroso': {\n",
        "                'n': len(grupo_borroso),\n",
        "                'iou_mean': float(grupo_borroso.mean()) if len(grupo_borroso) > 0 else None\n",
        "            },\n",
        "            'grupo_nitido': {\n",
        "                'n': len(grupo_nitido),\n",
        "                'iou_mean': float(grupo_nitido.mean()) if len(grupo_nitido) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_borroso) > 1 and len(grupo_nitido) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_borroso, grupo_nitido)\n",
        "            d = self._calcular_cohens_d(grupo_nitido, grupo_borroso)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def test_frecuencia_alta(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"H6: Alta frecuencia (detalles finos) afecta segmentacion.\"\"\"\n",
        "        self.logger.info(\"Testing H6: Efecto de frecuencia alta (detalles)...\")\n",
        "\n",
        "        col_freq = 'freq_ratio_alta'\n",
        "        if col_freq not in df.columns:\n",
        "            return {'error': 'Columna frecuencia no disponible'}\n",
        "\n",
        "        mask = df[col_freq].notna()\n",
        "        df_h = df[mask].copy()\n",
        "\n",
        "        mediana = df_h[col_freq].median()\n",
        "        grupo_bajo = df_h[df_h[col_freq] <= mediana]['iou']\n",
        "        grupo_alto = df_h[df_h[col_freq] > mediana]['iou']\n",
        "\n",
        "        resultado = {\n",
        "            'hipotesis': 'H6: Alta frecuencia afecta segmentacion',\n",
        "            'variable': col_freq,\n",
        "            'umbral_mediana': float(mediana),\n",
        "            'grupo_bajo_detalle': {\n",
        "                'n': len(grupo_bajo),\n",
        "                'iou_mean': float(grupo_bajo.mean()) if len(grupo_bajo) > 0 else None\n",
        "            },\n",
        "            'grupo_alto_detalle': {\n",
        "                'n': len(grupo_alto),\n",
        "                'iou_mean': float(grupo_alto.mean()) if len(grupo_alto) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if len(grupo_bajo) > 1 and len(grupo_alto) > 1:\n",
        "            t_stat, p_val = stats.ttest_ind(grupo_bajo, grupo_alto)\n",
        "            d = self._calcular_cohens_d(grupo_alto, grupo_bajo)\n",
        "\n",
        "            resultado['test_t'] = {\n",
        "                'estadistico': float(t_stat),\n",
        "                'p_valor': float(p_val),\n",
        "                'significativo': p_val < self.config.nivel_significancia\n",
        "            }\n",
        "            resultado['cohens_d'] = float(d)\n",
        "            resultado['interpretacion'] = self._interpretar_d(d)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def ejecutar_todos(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Ejecuta todos los tests de hipotesis.\"\"\"\n",
        "        return {\n",
        "            'H1_apertura_bokeh': self.test_apertura_bokeh(df),\n",
        "            'H2_complejidad_fondo': self.test_complejidad_fondo(df),\n",
        "            'H3_contraste': self.test_contraste(df),\n",
        "            'H4_saliencia_central': self.test_saliencia_central(df),\n",
        "            'H5_nitidez': self.test_nitidez(df),\n",
        "            'H6_frecuencia_alta': self.test_frecuencia_alta(df)\n",
        "        }"
      ],
      "metadata": {
        "id": "FlLDnq6sVLY7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ANALIZADOR DE EFECTO ENTRE MODELOS\n",
        "# =============================================================================\n",
        "\n",
        "class AnalizadorEfectoModelos:\n",
        "    \"\"\"Calcula tamanos de efecto entre modelos.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B, logger: logging.Logger):\n",
        "        self.config = config\n",
        "        self.logger = logger\n",
        "\n",
        "    def calcular_cohens_d_pareado(self, df: pd.DataFrame,\n",
        "                                   metrica: str = 'iou') -> pd.DataFrame:\n",
        "        \"\"\"Calcula Cohen's d para todos los pares de modelos.\"\"\"\n",
        "        self.logger.info(\"Calculando Cohen's d entre modelos...\")\n",
        "\n",
        "        modelos = sorted(df['modelo'].unique())\n",
        "        comparaciones = []\n",
        "\n",
        "        for i, m1 in enumerate(modelos):\n",
        "            for m2 in modelos[i+1:]:\n",
        "                g1 = df[df['modelo'] == m1][metrica].dropna()\n",
        "                g2 = df[df['modelo'] == m2][metrica].dropna()\n",
        "\n",
        "                if len(g1) > 1 and len(g2) > 1:\n",
        "                    n1, n2 = len(g1), len(g2)\n",
        "                    var1, var2 = g1.var(), g2.var()\n",
        "                    pooled_std = np.sqrt(((n1-1)*var1 + (n2-1)*var2) / (n1+n2-2))\n",
        "\n",
        "                    d = (g1.mean() - g2.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "                    t_stat, p_val = stats.ttest_ind(g1, g2)\n",
        "\n",
        "                    comparaciones.append({\n",
        "                        'modelo_1': m1,\n",
        "                        'modelo_2': m2,\n",
        "                        'mean_1': float(g1.mean()),\n",
        "                        'mean_2': float(g2.mean()),\n",
        "                        'n_1': n1,\n",
        "                        'n_2': n2,\n",
        "                        'cohens_d': float(d),\n",
        "                        'interpretacion': self._interpretar_d(d),\n",
        "                        't_statistic': float(t_stat),\n",
        "                        'p_valor': float(p_val)\n",
        "                    })\n",
        "\n",
        "        return pd.DataFrame(comparaciones)\n",
        "\n",
        "    def calcular_eta_cuadrado(self, df: pd.DataFrame, metrica: str = 'iou') -> Dict:\n",
        "        \"\"\"Calcula eta cuadrado (ANOVA).\"\"\"\n",
        "        self.logger.info(\"Calculando eta cuadrado (ANOVA)...\")\n",
        "\n",
        "        grupos = [df[df['modelo'] == m][metrica].dropna().values\n",
        "                  for m in df['modelo'].unique()]\n",
        "\n",
        "        f_stat, p_val = stats.f_oneway(*grupos)\n",
        "\n",
        "        grand_mean = df[metrica].mean()\n",
        "        ss_total = ((df[metrica] - grand_mean) ** 2).sum()\n",
        "\n",
        "        ss_between = 0\n",
        "        for m in df['modelo'].unique():\n",
        "            grupo = df[df['modelo'] == m][metrica]\n",
        "            ss_between += len(grupo) * (grupo.mean() - grand_mean) ** 2\n",
        "\n",
        "        eta_sq = ss_between / ss_total if ss_total > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'metrica': metrica,\n",
        "            'n_modelos': len(df['modelo'].unique()),\n",
        "            'f_statistic': float(f_stat),\n",
        "            'p_valor': float(p_val),\n",
        "            'eta_squared': float(eta_sq),\n",
        "            'interpretacion': self._interpretar_eta(eta_sq)\n",
        "        }\n",
        "\n",
        "    def _interpretar_d(self, d: float) -> str:\n",
        "        d_abs = abs(d)\n",
        "        if d_abs < 0.2: return \"insignificante\"\n",
        "        elif d_abs < 0.5: return \"pequeno\"\n",
        "        elif d_abs < 0.8: return \"mediano\"\n",
        "        return \"grande\"\n",
        "\n",
        "    def _interpretar_eta(self, eta: float) -> str:\n",
        "        if eta < 0.01: return \"insignificante\"\n",
        "        elif eta < 0.06: return \"pequeno\"\n",
        "        elif eta < 0.14: return \"mediano\"\n",
        "        return \"grande\""
      ],
      "metadata": {
        "id": "BwXwKTNCVO9e"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: GENERADOR DE ESTADISTICAS\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorEstadisticas:\n",
        "    \"\"\"Genera estadisticas descriptivas.\"\"\"\n",
        "\n",
        "    def __init__(self, logger: logging.Logger):\n",
        "        self.logger = logger\n",
        "\n",
        "    def estadisticas_por_modelo(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calcula estadisticas por modelo.\"\"\"\n",
        "        self.logger.info(\"Generando estadisticas por modelo...\")\n",
        "\n",
        "        metricas = ['iou', 'dice', 'precision', 'recall', 'boundary_iou']\n",
        "        metricas_disponibles = [m for m in metricas if m in df.columns]\n",
        "\n",
        "        stats_modelo = {}\n",
        "\n",
        "        for modelo in df['modelo'].unique():\n",
        "            df_m = df[df['modelo'] == modelo]\n",
        "\n",
        "            stats_modelo[modelo] = {\n",
        "                'n_evaluaciones': int(len(df_m)),\n",
        "                'n_configuraciones': int(df_m['config_codigo'].nunique()) if 'config_codigo' in df_m.columns else 0,\n",
        "                'n_fotos': int(df_m['codigo_foto'].nunique())\n",
        "            }\n",
        "\n",
        "            for metrica in metricas_disponibles:\n",
        "                vals = df_m[metrica].dropna()\n",
        "                if len(vals) > 0:\n",
        "                    stats_modelo[modelo][metrica] = {\n",
        "                        'mean': float(vals.mean()),\n",
        "                        'std': float(vals.std()),\n",
        "                        'min': float(vals.min()),\n",
        "                        'max': float(vals.max()),\n",
        "                        'median': float(vals.median()),\n",
        "                        'q25': float(vals.quantile(0.25)),\n",
        "                        'q75': float(vals.quantile(0.75))\n",
        "                    }\n",
        "\n",
        "        return stats_modelo\n",
        "\n",
        "    def estadisticas_por_foto(self, df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calcula estadisticas por fotografia.\"\"\"\n",
        "        self.logger.info(\"Generando estadisticas por fotografia...\")\n",
        "\n",
        "        stats_foto = {}\n",
        "\n",
        "        for foto in df['codigo_foto'].unique():\n",
        "            df_f = df[df['codigo_foto'] == foto]\n",
        "\n",
        "            stats_foto[foto] = {\n",
        "                'n_evaluaciones': int(len(df_f)),\n",
        "                'iou_mean': float(df_f['iou'].mean()),\n",
        "                'iou_std': float(df_f['iou'].std()),\n",
        "                'iou_min': float(df_f['iou'].min()),\n",
        "                'iou_max': float(df_f['iou'].max()),\n",
        "                'mejor_modelo': df_f.loc[df_f['iou'].idxmax(), 'modelo'],\n",
        "                'mejor_iou': float(df_f['iou'].max())\n",
        "            }\n",
        "\n",
        "        return stats_foto\n",
        "\n",
        "    def ranking_global(self, df: pd.DataFrame, top_n: int = 20) -> pd.DataFrame:\n",
        "        \"\"\"Genera ranking global de configuraciones.\"\"\"\n",
        "        self.logger.info(f\"Generando ranking TOP-{top_n}...\")\n",
        "\n",
        "        ranking = df.groupby(['modelo', 'config_codigo']).agg({\n",
        "            'iou': ['mean', 'std', 'min', 'max', 'count']\n",
        "        }).round(4)\n",
        "\n",
        "        ranking.columns = ['iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n_fotos']\n",
        "        ranking = ranking.reset_index()\n",
        "        ranking = ranking.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        return ranking.head(top_n)"
      ],
      "metadata": {
        "id": "qX6BFb59VUp-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CLASE: ORQUESTADOR FASE 2B\n",
        "# =============================================================================\n",
        "\n",
        "class OrquestadorFase2B:\n",
        "    \"\"\"Orquesta la ejecucion completa de Fase 2B.\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionFase2B):\n",
        "        self.config = config\n",
        "        self.logger = self._configurar_logger()\n",
        "\n",
        "        # Componentes\n",
        "        self.extractor = ExtractorCaracteristicas(self.logger)\n",
        "        self.cargador = CargadorMetricas(self.logger)\n",
        "        self.analizador_corr = AnalizadorCorrelaciones(config, self.logger)\n",
        "        self.analizador_hip = AnalizadorHipotesis(config, self.logger)\n",
        "        self.analizador_efecto = AnalizadorEfectoModelos(config, self.logger)\n",
        "        self.generador_stats = GeneradorEstadisticas(self.logger)\n",
        "\n",
        "        # Resultados\n",
        "        self.df_fusionado = None\n",
        "        self.df_caracteristicas = None\n",
        "        self.correlaciones_globales = None\n",
        "        self.correlaciones_por_modelo = None\n",
        "        self.resultados_hipotesis = None\n",
        "        self.tamano_efecto = None\n",
        "        self.estadisticas = None\n",
        "\n",
        "    def _configurar_logger(self) -> logging.Logger:\n",
        "        logger = logging.getLogger('Fase2B')\n",
        "        logger.setLevel(logging.INFO)\n",
        "        logger.handlers = []\n",
        "\n",
        "        handler = logging.StreamHandler(sys.stdout)\n",
        "        handler.setLevel(logging.INFO)\n",
        "        formatter = logging.Formatter(\n",
        "            '[%(asctime)s] %(levelname)-8s | %(message)s',\n",
        "            datefmt='%H:%M:%S'\n",
        "        )\n",
        "        handler.setFormatter(formatter)\n",
        "        logger.addHandler(handler)\n",
        "\n",
        "        return logger\n",
        "\n",
        "    def ejecutar(self, rutas_csv: Dict[str, Path], rutas_json: List[Path]) -> None:\n",
        "        \"\"\"Ejecuta el pipeline completo.\"\"\"\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(\"FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\")\n",
        "        self.logger.info(\"(VERSION EXHAUSTIVA - 152 caracteristicas fotograficas)\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "\n",
        "        inicio = datetime.now()\n",
        "\n",
        "        # Paso 1: Cargar metricas\n",
        "        self.logger.info(\"\\n[PASO 1/8] Cargando metricas de Fase 2A...\")\n",
        "        df_metricas = self.cargador.cargar_csvs(rutas_csv)\n",
        "\n",
        "        # Paso 2: Extraer caracteristicas fotograficas\n",
        "        self.logger.info(\"\\n[PASO 2/8] Extrayendo caracteristicas fotograficas (152 campos)...\")\n",
        "        self.df_caracteristicas = self.extractor.cargar_todas_caracteristicas(rutas_json)\n",
        "\n",
        "        # Paso 3: Fusionar\n",
        "        self.logger.info(\"\\n[PASO 3/8] Fusionando datasets...\")\n",
        "        self.df_fusionado = df_metricas.merge(\n",
        "            self.df_caracteristicas,\n",
        "            on='codigo_foto',\n",
        "            how='left'\n",
        "        )\n",
        "        self.logger.info(f\"  Dataset fusionado: {len(self.df_fusionado)} filas x {len(self.df_fusionado.columns)} columnas\")\n",
        "\n",
        "        # Paso 4: Correlaciones globales\n",
        "        self.logger.info(\"\\n[PASO 4/8] Calculando correlaciones globales...\")\n",
        "        self.correlaciones_globales = self.analizador_corr.calcular_correlaciones_globales(\n",
        "            self.df_fusionado, ['iou', 'dice', 'boundary_iou']\n",
        "        )\n",
        "\n",
        "        # Paso 5: Correlaciones por modelo\n",
        "        self.logger.info(\"\\n[PASO 5/8] Calculando correlaciones por modelo...\")\n",
        "        self.correlaciones_por_modelo = self.analizador_corr.calcular_correlaciones_por_modelo(\n",
        "            self.df_fusionado\n",
        "        )\n",
        "\n",
        "        # Paso 6: Tests de hipotesis\n",
        "        self.logger.info(\"\\n[PASO 6/8] Ejecutando tests de hipotesis...\")\n",
        "        self.resultados_hipotesis = self.analizador_hip.ejecutar_todos(self.df_fusionado)\n",
        "\n",
        "        # Paso 7: Tamano de efecto\n",
        "        self.logger.info(\"\\n[PASO 7/8] Calculando tamano de efecto entre modelos...\")\n",
        "        self.tamano_efecto = {\n",
        "            'cohens_d_pareado': self.analizador_efecto.calcular_cohens_d_pareado(\n",
        "                self.df_fusionado\n",
        "            ).to_dict('records'),\n",
        "            'anova_eta_squared': self.analizador_efecto.calcular_eta_cuadrado(\n",
        "                self.df_fusionado\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Paso 8: Estadisticas\n",
        "        self.logger.info(\"\\n[PASO 8/8] Generando estadisticas y guardando...\")\n",
        "        self.estadisticas = {\n",
        "            'por_modelo': self.generador_stats.estadisticas_por_modelo(self.df_fusionado),\n",
        "            'por_foto': self.generador_stats.estadisticas_por_foto(self.df_fusionado),\n",
        "            'ranking_top20': self.generador_stats.ranking_global(self.df_fusionado, 20).to_dict('records')\n",
        "        }\n",
        "\n",
        "        self._guardar_resultados()\n",
        "\n",
        "        duracion = (datetime.now() - inicio).total_seconds()\n",
        "\n",
        "        self.logger.info(\"\\n\" + \"=\" * 70)\n",
        "        self.logger.info(\"FASE 2B COMPLETADA\")\n",
        "        self.logger.info(\"=\" * 70)\n",
        "        self.logger.info(f\"Duracion: {duracion:.1f} segundos\")\n",
        "        self.logger.info(f\"Evaluaciones: {len(self.df_fusionado)}\")\n",
        "        self.logger.info(f\"Caracteristicas fotograficas: {len(self.df_caracteristicas.columns) - 1}\")\n",
        "        self.logger.info(f\"Correlaciones calculadas: {len(self.correlaciones_globales)}\")\n",
        "\n",
        "    def _guardar_resultados(self) -> None:\n",
        "        \"\"\"Guarda todos los resultados.\"\"\"\n",
        "        self.config.ruta_salida.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # CSV fusionado\n",
        "        ruta = self.config.ruta_salida / 'metricas_fusionadas.csv'\n",
        "        self.df_fusionado.to_csv(ruta, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Caracteristicas\n",
        "        ruta = self.config.ruta_salida / 'caracteristicas_fotograficas.csv'\n",
        "        self.df_caracteristicas.to_csv(ruta, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Correlaciones globales\n",
        "        ruta = self.config.ruta_salida / 'correlaciones_globales.csv'\n",
        "        self.correlaciones_globales.to_csv(ruta, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Correlaciones por modelo\n",
        "        ruta = self.config.ruta_salida / 'correlaciones_por_modelo.csv'\n",
        "        self.correlaciones_por_modelo.to_csv(ruta, index=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Tests hipotesis\n",
        "        ruta = self.config.ruta_salida / 'test_hipotesis.json'\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.resultados_hipotesis), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Tamano efecto\n",
        "        ruta = self.config.ruta_salida / 'tamano_efecto.json'\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.tamano_efecto), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "        # Estadisticas\n",
        "        ruta = self.config.ruta_salida / 'estadisticas_descriptivas.json'\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(convertir_a_serializable(self.estadisticas), f, indent=2, ensure_ascii=False)\n",
        "        self.logger.info(f\"  Guardado: {ruta}\")\n",
        "\n",
        "    def imprimir_resumen(self) -> None:\n",
        "        \"\"\"Imprime resumen de resultados.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"RESUMEN DE RESULTADOS FASE 2B\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        # Top correlaciones\n",
        "        print(\"\\nTOP 10 CORRELACIONES CON IoU:\")\n",
        "        print(\"-\" * 50)\n",
        "        df_iou = self.correlaciones_globales[\n",
        "            self.correlaciones_globales['metrica_objetivo'] == 'iou'\n",
        "        ].head(10)\n",
        "\n",
        "        for _, row in df_iou.iterrows():\n",
        "            sig = \"*\" if row['sig_pearson'] else \"\"\n",
        "            print(f\"  {row['caracteristica']:<35} r={row['r_pearson']:>7.4f} {sig}\")\n",
        "\n",
        "        # Por modelo\n",
        "        print(\"\\nRENDIMIENTO POR MODELO:\")\n",
        "        print(\"-\" * 50)\n",
        "        for modelo, stats in sorted(\n",
        "            self.estadisticas['por_modelo'].items(),\n",
        "            key=lambda x: x[1].get('iou', {}).get('mean', 0),\n",
        "            reverse=True\n",
        "        ):\n",
        "            if 'iou' in stats:\n",
        "                iou = stats['iou']\n",
        "                print(f\"  {modelo:<15} IoU={iou['mean']:.4f} +/- {iou['std']:.4f}\")\n",
        "\n",
        "        # ANOVA\n",
        "        anova = self.tamano_efecto['anova_eta_squared']\n",
        "        print(f\"\\nANOVA - Efecto del modelo:\")\n",
        "        print(f\"  eta^2 = {anova['eta_squared']:.4f} ({anova['interpretacion']})\")\n",
        "        print(f\"  El modelo explica {anova['eta_squared']*100:.1f}% de la varianza en IoU\")"
      ],
      "metadata": {
        "id": "kEvxYbNcVZ15"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCION PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def ejecutar_fase2b(ruta_base_tfm: str,\n",
        "                    rutas_csv: Dict[str, str],\n",
        "                    rutas_json: List[str]) -> OrquestadorFase2B:\n",
        "    \"\"\"\n",
        "    Ejecuta el pipeline completo de Fase 2B.\n",
        "\n",
        "    Args:\n",
        "        ruta_base_tfm: Ruta base del proyecto TFM\n",
        "        rutas_csv: Diccionario {modelo: ruta_csv}\n",
        "        rutas_json: Lista de rutas a JSONs de caracteristicas\n",
        "\n",
        "    Returns:\n",
        "        OrquestadorFase2B con resultados\n",
        "    \"\"\"\n",
        "    config = ConfiguracionFase2B(ruta_base_tfm=Path(ruta_base_tfm))\n",
        "\n",
        "    orquestador = OrquestadorFase2B(config)\n",
        "\n",
        "    rutas_csv_path = {k: Path(v) for k, v in rutas_csv.items()}\n",
        "    rutas_json_path = [Path(r) for r in rutas_json]\n",
        "\n",
        "    orquestador.ejecutar(rutas_csv_path, rutas_json_path)\n",
        "    orquestador.imprimir_resumen()\n",
        "\n",
        "    return orquestador"
      ],
      "metadata": {
        "id": "WLezKneBVdCf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PUNTO DE ENTRADA\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    RUTA_BASE_TFM = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    RUTA_FASE2A = RUTA_BASE_TFM / \"3_Analisis\" / \"fase2_evaluacion\" / \"metricas_agregadas\"\n",
        "    RUTA_CARACTERISTICAS = RUTA_BASE_TFM / \"1_Caracteristicas\" / \"json\"\n",
        "\n",
        "    # CSVs de metricas\n",
        "    rutas_csv = {\n",
        "        'yolov8': RUTA_FASE2A / \"todas_metricas.csv\",\n",
        "        'bodypix': RUTA_FASE2A / \"bodypix_todas_metricas.csv\",\n",
        "        'mask2former': RUTA_FASE2A / \"m2f_todas_metricas.csv\",\n",
        "        'oneformer': RUTA_FASE2A / \"of_todas_metricas.csv\",\n",
        "        'sam2': RUTA_FASE2A / \"s2_todas_metricas.csv\",\n",
        "        'sam2_prompts': RUTA_FASE2A / \"s2p_todas_metricas.csv\"\n",
        "    }\n",
        "\n",
        "    # JSONs de caracteristicas\n",
        "    rutas_json = sorted(RUTA_CARACTERISTICAS.glob(\"_DSC*_caracteristicas.json\"))\n",
        "\n",
        "    print(\"Verificando archivos...\")\n",
        "    for modelo, ruta in rutas_csv.items():\n",
        "        existe = \"OK\" if ruta.exists() else \"NO ENCONTRADO\"\n",
        "        print(f\"  {modelo}: {existe}\")\n",
        "    print(f\"  JSONs encontrados: {len(rutas_json)}\")\n",
        "\n",
        "    # Ejecutar\n",
        "    orquestador = ejecutar_fase2b(\n",
        "        ruta_base_tfm=str(RUTA_BASE_TFM),\n",
        "        rutas_csv={k: str(v) for k, v in rutas_csv.items()},\n",
        "        rutas_json=[str(r) for r in rutas_json]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNIMitu-Vjx4",
        "outputId": "23601e4d-bdc4-4a11-e53e-6c32d8fda9ac"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Verificando archivos...\n",
            "  yolov8: OK\n",
            "  bodypix: OK\n",
            "  mask2former: OK\n",
            "  oneformer: OK\n",
            "  sam2: OK\n",
            "  sam2_prompts: OK\n",
            "  JSONs encontrados: 20\n",
            "[22:58:27] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     | FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:FASE 2B - FUSION DE DATOS Y ANALISIS DE CORRELACIONES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     | (VERSION EXHAUSTIVA - 152 caracteristicas fotograficas)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:(VERSION EXHAUSTIVA - 152 caracteristicas fotograficas)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     | \n",
            "[PASO 1/8] Cargando metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 1/8] Cargando metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     | Cargando CSVs de metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Cargando CSVs de metricas de Fase 2A...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     |   yolov8: 400 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  yolov8: 400 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:27] INFO     |   bodypix: 480 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  bodypix: 480 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   mask2former: 135 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  mask2former: 135 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   oneformer: 517 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  oneformer: 517 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   sam2: 240 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  sam2: 240 filas, 67 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   sam2_prompts: 588 filas, 72 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  sam2_prompts: 588 filas, 72 cols\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | Total consolidado: 2360 filas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Total consolidado: 2360 filas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | \n",
            "[PASO 2/8] Extrayendo caracteristicas fotograficas (152 campos)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 2/8] Extrayendo caracteristicas fotograficas (152 campos)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | Extrayendo caracteristicas de 20 fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Extrayendo caracteristicas de 20 fotografias...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   Fotografias procesadas: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Fotografias procesadas: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   Caracteristicas totales: 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Caracteristicas totales: 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   Caracteristicas completas (sin NaN): 145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Caracteristicas completas (sin NaN): 145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | \n",
            "[PASO 3/8] Fusionando datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 3/8] Fusionando datasets...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     |   Dataset fusionado: 2360 filas x 220 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Dataset fusionado: 2360 filas x 220 columnas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | \n",
            "[PASO 4/8] Calculando correlaciones globales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 4/8] Calculando correlaciones globales...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:28] INFO     | Calculando correlaciones globales vs ['iou', 'dice', 'boundary_iou']...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando correlaciones globales vs ['iou', 'dice', 'boundary_iou']...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:32] INFO     |   Correlaciones calculadas: 528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Correlaciones calculadas: 528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:32] INFO     |   Significativas (p<0.05): 301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Significativas (p<0.05): 301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:32] INFO     | \n",
            "[PASO 5/8] Calculando correlaciones por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 5/8] Calculando correlaciones por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:32] INFO     | Calculando correlaciones por modelo vs iou...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando correlaciones por modelo vs iou...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | \n",
            "[PASO 6/8] Ejecutando tests de hipotesis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 6/8] Ejecutando tests de hipotesis...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H1: Efecto de apertura (bokeh)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H1: Efecto de apertura (bokeh)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H2: Efecto de complejidad del fondo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H2: Efecto de complejidad del fondo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H3: Efecto del contraste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H3: Efecto del contraste...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H4: Efecto de saliencia central...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H4: Efecto de saliencia central...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H5: Efecto de nitidez...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H5: Efecto de nitidez...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Testing H6: Efecto de frecuencia alta (detalles)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Testing H6: Efecto de frecuencia alta (detalles)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | \n",
            "[PASO 7/8] Calculando tamano de efecto entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 7/8] Calculando tamano de efecto entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Calculando Cohen's d entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando Cohen's d entre modelos...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Calculando eta cuadrado (ANOVA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Calculando eta cuadrado (ANOVA)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | \n",
            "[PASO 8/8] Generando estadisticas y guardando...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "[PASO 8/8] Generando estadisticas y guardando...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Generando estadisticas por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando estadisticas por modelo...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:36] INFO     | Generando estadisticas por fotografia...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando estadisticas por fotografia...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:37] INFO     | Generando ranking TOP-20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Generando ranking TOP-20...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/caracteristicas_fotograficas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/caracteristicas_fotograficas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_globales.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_globales.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_por_modelo.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/correlaciones_por_modelo.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/test_hipotesis.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/test_hipotesis.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/tamano_efecto.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/tamano_efecto.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     |   Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/estadisticas_descriptivas.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:  Guardado: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/estadisticas_descriptivas.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | \n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | FASE 2B COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:FASE 2B COMPLETADA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | ======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | Duracion: 12.5 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Duracion: 12.5 segundos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | Evaluaciones: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Evaluaciones: 2360\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | Caracteristicas fotograficas: 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Caracteristicas fotograficas: 148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:58:40] INFO     | Correlaciones calculadas: 528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:Fase2B:Correlaciones calculadas: 528\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RESUMEN DE RESULTADOS FASE 2B\n",
            "======================================================================\n",
            "\n",
            "TOP 10 CORRELACIONES CON IoU:\n",
            "--------------------------------------------------\n",
            "  chamfer_distance                    r=-0.7212 *\n",
            "  hausdorff_distance                  r=-0.6464 *\n",
            "  solidity                            r= 0.5575 *\n",
            "  compacidad                          r= 0.5444 *\n",
            "  circularity                         r= 0.5444 *\n",
            "  ratio_solidity                      r= 0.5213 *\n",
            "  rectangularity                      r= 0.4953 *\n",
            "  ratio_componente_principal          r= 0.4897 *\n",
            "  aspect_ratio                        r=-0.3943 *\n",
            "  diferencia_compacidad               r=-0.3641 *\n",
            "\n",
            "RENDIMIENTO POR MODELO:\n",
            "--------------------------------------------------\n",
            "  yolov8          IoU=0.9498 +/- 0.0527\n",
            "  oneformer       IoU=0.8790 +/- 0.2185\n",
            "  mask2former     IoU=0.6933 +/- 0.3572\n",
            "  bodypix         IoU=0.6559 +/- 0.1740\n",
            "  sam2            IoU=0.4169 +/- 0.3772\n",
            "\n",
            "ANOVA - Efecto del modelo:\n",
            "  eta^2 = 0.3797 (grande)\n",
            "  El modelo explica 38.0% de la varianza en IoU\n"
          ]
        }
      ]
    }
  ]
}