{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBDOwshurf9AGmTB06uZOa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2D: ANÁLISIS DE CONFIGURACIONES\n",
        "================================================================================\n",
        "Trabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\n",
        "en Fotografía de Retrato\n",
        "\n",
        "Autor: Jesús L. (Iesus)\n",
        "Universidad: Universitat Oberta de Catalunya (UOC)\n",
        "Máster: Data Science\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "Descripción:\n",
        "    Este módulo implementa el análisis exhaustivo de configuraciones de los\n",
        "    5 modelos de segmentación evaluados. Incluye:\n",
        "    - Ranking global y por modelo\n",
        "    - Análisis factorial por modelo (ANOVA, efectos principales e interacciones)\n",
        "    - Análisis de sensibilidad a parámetros\n",
        "    - Comparación de paradigmas arquitectónicos\n",
        "    - Tests post-hoc (Tukey HSD)\n",
        "\n",
        "Entrada:\n",
        "    - metricas_fusionadas.csv (Fase 2B)\n",
        "    - Archivos auxiliares de fases anteriores\n",
        "\n",
        "Salida:\n",
        "    - CSVs con análisis factorial por modelo\n",
        "    - Rankings globales y por modelo\n",
        "    - Análisis de sensibilidad\n",
        "    - Comparación de paradigmas\n",
        "    - JSON con resumen de hallazgos\n",
        "================================================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "rwaOW8fKVFJo",
        "outputId": "f21d6a01-0a19-4231-df35-c64762c1f7f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nFASE 2D: ANÁLISIS DE CONFIGURACIONES\\n================================================================================\\nTrabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\\nen Fotografía de Retrato\\n\\nAutor: Jesús L. (Iesus)\\nUniversidad: Universitat Oberta de Catalunya (UOC)\\nMáster: Data Science\\nFecha: Diciembre 2025\\n\\nDescripción:\\n    Este módulo implementa el análisis exhaustivo de configuraciones de los\\n    5 modelos de segmentación evaluados. Incluye:\\n    - Ranking global y por modelo\\n    - Análisis factorial por modelo (ANOVA, efectos principales e interacciones)\\n    - Análisis de sensibilidad a parámetros\\n    - Comparación de paradigmas arquitectónicos\\n    - Tests post-hoc (Tukey HSD)\\n\\nEntrada:\\n    - metricas_fusionadas.csv (Fase 2B)\\n    - Archivos auxiliares de fases anteriores\\n\\nSalida:\\n    - CSVs con análisis factorial por modelo\\n    - Rankings globales y por modelo\\n    - Análisis de sensibilidad\\n    - Comparación de paradigmas\\n    - JSON con resumen de hallazgos\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field, asdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.stats import f_oneway, tukey_hsd, kruskal, mannwhitneyu\n",
        "import logging\n",
        "\n",
        "# Configuración de warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "FZgx9oQnVHak"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN DE LOGGING\n",
        "# =============================================================================\n",
        "def configurar_logging(nivel: int = logging.INFO) -> logging.Logger:\n",
        "    \"\"\"\n",
        "    Configura el sistema de logging para el análisis.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nivel : int\n",
        "        Nivel de logging (default: logging.INFO)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    logging.Logger\n",
        "        Logger configurado\n",
        "    \"\"\"\n",
        "    # Eliminar handlers existentes para evitar duplicación en Colab\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=nivel,\n",
        "        format='[%(asctime)s] %(levelname)s - %(message)s',\n",
        "        datefmt='%H:%M:%S'\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    return logger\n",
        "\n",
        "logger = configurar_logging()"
      ],
      "metadata": {
        "id": "vGRLmCt_VKW3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN DE RUTAS\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ConfiguracionRutas:\n",
        "    \"\"\"Configuración de rutas del proyecto.\"\"\"\n",
        "\n",
        "    # Detectar entorno (Colab o local)\n",
        "    en_colab: bool = field(default_factory=lambda: 'google.colab' in sys.modules)\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.en_colab:\n",
        "            self.base = '/content/drive/MyDrive/TFM'\n",
        "            self.datos_entrada = '/content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones'\n",
        "        else:\n",
        "            # Rutas locales para desarrollo\n",
        "            self.base = '/mnt/user-data/uploads'\n",
        "            self.datos_entrada = '/mnt/user-data/uploads'\n",
        "\n",
        "        self.salida = os.path.join(\n",
        "            self.base if self.en_colab else '/home/claude',\n",
        "            '3_Analisis' if self.en_colab else '',\n",
        "            'fase2d_configuraciones'\n",
        "        )\n",
        "\n",
        "    def crear_directorios(self):\n",
        "        \"\"\"Crea los directorios de salida si no existen.\"\"\"\n",
        "        os.makedirs(self.salida, exist_ok=True)\n",
        "        logger.info(f\"Directorio de salida: {self.salida}\")"
      ],
      "metadata": {
        "id": "NC3qy2tpVOh_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ESTRUCTURAS DE DATOS\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ResultadoANOVA:\n",
        "    \"\"\"Resultado de un análisis ANOVA.\"\"\"\n",
        "    factor: str\n",
        "    f_statistic: float\n",
        "    p_valor: float\n",
        "    eta_squared: float\n",
        "    omega_squared: float\n",
        "    n_grupos: int\n",
        "    n_total: int\n",
        "    significativo: bool\n",
        "    interpretacion_efecto: str\n",
        "\n",
        "@dataclass\n",
        "class ResultadoPostHoc:\n",
        "    \"\"\"Resultado de comparación post-hoc.\"\"\"\n",
        "    grupo_1: str\n",
        "    grupo_2: str\n",
        "    diferencia_medias: float\n",
        "    p_valor: float\n",
        "    significativo: bool\n",
        "    ic_inferior: float\n",
        "    ic_superior: float\n",
        "\n",
        "@dataclass\n",
        "class AnalisisFactorial:\n",
        "    \"\"\"Resultado completo de análisis factorial para un modelo.\"\"\"\n",
        "    modelo: str\n",
        "    factores: List[str]\n",
        "    anova_resultados: List[ResultadoANOVA]\n",
        "    posthoc_resultados: List[ResultadoPostHoc]\n",
        "    mejor_configuracion: str\n",
        "    iou_mejor: float\n",
        "    estadisticas_por_nivel: Dict[str, Dict]"
      ],
      "metadata": {
        "id": "B0MZ6tG_VeDW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3kySXegLUTsg"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CLASE PRINCIPAL: ANALIZADOR DE CONFIGURACIONES\n",
        "# =============================================================================\n",
        "class AnalizadorConfiguraciones:\n",
        "    \"\"\"\n",
        "    Clase principal para el análisis de configuraciones de modelos.\n",
        "\n",
        "    Implementa análisis factorial, sensibilidad y comparación de paradigmas\n",
        "    para los modelos de segmentación evaluados.\n",
        "\n",
        "    Nota: SAM2 se analiza de forma unificada (sam2 + sam2_prompts) para\n",
        "    permitir comparación entre modo automático y modo con prompts.\n",
        "    \"\"\"\n",
        "\n",
        "    # Definición de factores por modelo\n",
        "    FACTORES_MODELO = {\n",
        "        'bodypix': {\n",
        "            'multiplicador': lambda x: x.split('_')[3],  # 050, 075\n",
        "            'nivel_sensibilidad': lambda x: '_'.join(x.split('_')[4:-1]).replace('_t0', ''),\n",
        "            'umbral': lambda x: x.split('_')[-1]\n",
        "        },\n",
        "        'mask2former': {\n",
        "            'backbone': lambda x: x.split('_')[1],  # base, large, tiny\n",
        "            'dataset': lambda x: x.split('_')[2],  # ade, coco\n",
        "            'sensibilidad': lambda x: '_'.join(x.split('_')[3:])\n",
        "        },\n",
        "        'oneformer': {\n",
        "            'dataset': lambda x: x.split('_')[1],  # ade20k, coco\n",
        "            'backbone': lambda x: x.split('_')[2],  # swin, tiny\n",
        "            'task_type': lambda x: x.split('_')[3],  # instance, panoptic, semantic\n",
        "            'umbral': lambda x: x.split('_')[4]  # t040, t060, etc\n",
        "        },\n",
        "        'sam2': {\n",
        "            'modo': lambda x: 'prompts' if 'prompts' in x else 'auto',\n",
        "            'tamano': lambda x: AnalizadorConfiguraciones._extraer_tamano_sam2(x),\n",
        "            'estrategia': lambda x: AnalizadorConfiguraciones._extraer_estrategia_sam2(x)\n",
        "        },\n",
        "        'yolov8': {\n",
        "            'tamano': lambda x: x.split('_')[1],  # nano, small, medium, large, xlarge\n",
        "            'config_sensibilidad': lambda x: x.split('_')[2]  # balanced, fast, quality, sensitive\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Paradigmas arquitectónicos\n",
        "    PARADIGMAS = {\n",
        "        'cnn_especializada': ['yolov8'],\n",
        "        'transformer_segmentacion': ['mask2former', 'oneformer'],\n",
        "        'foundation_model': ['sam2', 'sam2_prompts'],  # Incluir ambos\n",
        "        'web_ligero': ['bodypix']\n",
        "    }\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, rutas: ConfiguracionRutas):\n",
        "        \"\"\"\n",
        "        Inicializa el analizador.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            DataFrame con métricas fusionadas\n",
        "        rutas : ConfiguracionRutas\n",
        "            Configuración de rutas\n",
        "        \"\"\"\n",
        "        self.df = df.copy()\n",
        "        self.rutas = rutas\n",
        "        self.resultados = {}\n",
        "\n",
        "        # Crear columna auxiliar para análisis unificado de SAM2\n",
        "        self.df['modelo_analisis'] = self.df['modelo'].replace('sam2_prompts', 'sam2')\n",
        "\n",
        "        # Extraer factores para cada modelo\n",
        "        self._extraer_factores()\n",
        "\n",
        "        logger.info(f\"Analizador inicializado con {len(df)} evaluaciones\")\n",
        "        logger.info(f\"Modelos originales: {df['modelo'].unique().tolist()}\")\n",
        "        logger.info(f\"Modelos para análisis: {self.df['modelo_analisis'].unique().tolist()}\")\n",
        "        logger.info(f\"Configuraciones únicas: {df['config_codigo'].nunique()}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _extraer_tamano_sam2(config: str) -> str:\n",
        "        \"\"\"\n",
        "        Extrae el tamaño del modelo SAM2 de la configuración.\n",
        "\n",
        "        Patrones:\n",
        "        - Auto: sam2_{tamaño}_{config} → sam2_base_plus_balanced\n",
        "        - Prompts: sam2_prompts_{tamaño}_{estrategia} → sam2_prompts_base_plus_saliency_moderate\n",
        "        \"\"\"\n",
        "        if 'base_plus' in config:\n",
        "            return 'base_plus'\n",
        "        elif 'tiny' in config:\n",
        "            return 'tiny'\n",
        "        elif 'small' in config:\n",
        "            return 'small'\n",
        "        elif 'large' in config:\n",
        "            return 'large'\n",
        "        return 'unknown'\n",
        "\n",
        "    @staticmethod\n",
        "    def _extraer_estrategia_sam2(config: str) -> str:\n",
        "        \"\"\"\n",
        "        Extrae la estrategia de SAM2 de la configuración.\n",
        "\n",
        "        Modo automático (sam2_{tamaño}_{config}):\n",
        "        - balanced, low_cost, quality\n",
        "\n",
        "        Modo con prompts (sam2_prompts_{tamaño}_{estrategia}):\n",
        "        - bbox_heuristic, combined_aggressive, combined_moderate\n",
        "        - grid_central_aggressive, grid_central_conservative, grid_central_moderate\n",
        "        - saliency_conservative, saliency_moderate\n",
        "        \"\"\"\n",
        "        if 'prompts' not in config:\n",
        "            # Modo automático\n",
        "            if 'low_cost' in config:\n",
        "                return 'low_cost'\n",
        "            elif 'balanced' in config:\n",
        "                return 'balanced'\n",
        "            elif 'quality' in config:\n",
        "                return 'quality'\n",
        "            return 'unknown'\n",
        "        else:\n",
        "            # Modo con prompts\n",
        "            sin_prefijo = config.replace('sam2_prompts_', '')\n",
        "            for tamano in ['base_plus_', 'tiny_', 'small_', 'large_']:\n",
        "                if sin_prefijo.startswith(tamano):\n",
        "                    return sin_prefijo.replace(tamano, '', 1)\n",
        "            return sin_prefijo\n",
        "\n",
        "    def _extraer_factores(self):\n",
        "        \"\"\"Extrae los factores de cada configuración según el modelo.\"\"\"\n",
        "        logger.info(\"Extrayendo factores de configuraciones...\")\n",
        "\n",
        "        for modelo, extractores in self.FACTORES_MODELO.items():\n",
        "            # Usar modelo_analisis para incluir sam2_prompts en análisis de sam2\n",
        "            mask = self.df['modelo_analisis'] == modelo\n",
        "            if not mask.any():\n",
        "                continue\n",
        "\n",
        "            for factor, extractor in extractores.items():\n",
        "                col_name = f'factor_{factor}'\n",
        "                self.df.loc[mask, col_name] = self.df.loc[mask, 'config_codigo'].apply(\n",
        "                    lambda x: self._safe_extract(extractor, x)\n",
        "                )\n",
        "\n",
        "        # Logging de factores extraídos\n",
        "        for modelo in self.df['modelo_analisis'].unique():\n",
        "            df_modelo = self.df[self.df['modelo_analisis'] == modelo]\n",
        "            factores = [c for c in df_modelo.columns if c.startswith('factor_')]\n",
        "            for f in factores:\n",
        "                valores = df_modelo[f].dropna().unique()\n",
        "                if len(valores) > 0:\n",
        "                    logger.info(f\"  {modelo}.{f}: {sorted(valores)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _safe_extract(extractor, valor):\n",
        "        \"\"\"Extrae un factor de forma segura.\"\"\"\n",
        "        try:\n",
        "            return extractor(valor)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # RANKING DE CONFIGURACIONES\n",
        "    # =========================================================================\n",
        "    def calcular_ranking_global(self, top_n: int = 30) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula el ranking global de configuraciones por IoU.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int\n",
        "            Número de configuraciones top a incluir\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Ranking de configuraciones\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculando ranking global TOP-{top_n}...\")\n",
        "\n",
        "        # Agrupar por configuración (usar modelo original, no modelo_analisis)\n",
        "        ranking = self.df.groupby(['modelo', 'config_codigo']).agg({\n",
        "            'iou': ['mean', 'std', 'min', 'max', 'count'],\n",
        "            'dice': 'mean',\n",
        "            'precision': 'mean',\n",
        "            'recall': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Aplanar columnas\n",
        "        ranking.columns = [\n",
        "            'modelo', 'config_codigo',\n",
        "            'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n_fotos',\n",
        "            'dice_mean', 'precision_mean', 'recall_mean'\n",
        "        ]\n",
        "\n",
        "        # Calcular coeficiente de variación\n",
        "        ranking['iou_cv'] = ranking['iou_std'] / ranking['iou_mean']\n",
        "\n",
        "        # Ordenar por IoU medio descendente\n",
        "        ranking = ranking.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        # Agregar posición en ranking\n",
        "        ranking['posicion'] = range(1, len(ranking) + 1)\n",
        "\n",
        "        # Guardar ranking completo\n",
        "        self.resultados['ranking_global'] = ranking.copy()\n",
        "\n",
        "        # Retornar top N\n",
        "        return ranking.head(top_n)\n",
        "\n",
        "    def calcular_ranking_por_modelo(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula la mejor configuración por modelo.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Mejor configuración de cada modelo\n",
        "        \"\"\"\n",
        "        logger.info(\"Calculando mejor configuración por modelo...\")\n",
        "\n",
        "        mejores = []\n",
        "\n",
        "        # Uso modelo original para mantener distinción sam2 vs sam2_prompts\n",
        "        for modelo in self.df['modelo'].unique():\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "\n",
        "            stats_config = df_modelo.groupby('config_codigo').agg({\n",
        "                'iou': ['mean', 'std', 'min', 'max', 'count']\n",
        "            }).reset_index()\n",
        "            stats_config.columns = ['config_codigo', 'iou_mean', 'iou_std',\n",
        "                                    'iou_min', 'iou_max', 'n_fotos']\n",
        "\n",
        "            mejor = stats_config.loc[stats_config['iou_mean'].idxmax()]\n",
        "\n",
        "            mejores.append({\n",
        "                'modelo': modelo,\n",
        "                'mejor_config': mejor['config_codigo'],\n",
        "                'iou_mean': mejor['iou_mean'],\n",
        "                'iou_std': mejor['iou_std'],\n",
        "                'iou_min': mejor['iou_min'],\n",
        "                'iou_max': mejor['iou_max'],\n",
        "                'n_fotos': int(mejor['n_fotos']),\n",
        "                'n_configuraciones_total': df_modelo['config_codigo'].nunique()\n",
        "            })\n",
        "\n",
        "        resultado = pd.DataFrame(mejores)\n",
        "        resultado = resultado.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        self.resultados['ranking_por_modelo'] = resultado\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    # =========================================================================\n",
        "    # ANÁLISIS FACTORIAL POR MODELO\n",
        "    # =========================================================================\n",
        "    def _calcular_anova(self, df: pd.DataFrame, factor: str,\n",
        "                        metrica: str = 'iou') -> ResultadoANOVA:\n",
        "        \"\"\"\n",
        "        Calcula ANOVA de un factor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Datos del modelo\n",
        "        factor : str\n",
        "            Nombre del factor (columna)\n",
        "        metrica : str\n",
        "            Métrica a analizar\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ResultadoANOVA\n",
        "            Resultado del análisis\n",
        "        \"\"\"\n",
        "        col_factor = f'factor_{factor}' if not factor.startswith('factor_') else factor\n",
        "\n",
        "        if col_factor not in df.columns:\n",
        "            return None\n",
        "\n",
        "        df_clean = df[[col_factor, metrica]].dropna()\n",
        "\n",
        "        if df_clean[col_factor].nunique() < 2:\n",
        "            return None\n",
        "\n",
        "        grupos = [grupo[metrica].values for _, grupo in df_clean.groupby(col_factor)]\n",
        "\n",
        "        if len(grupos) < 2:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            f_stat, p_valor = f_oneway(*grupos)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "        n_total = len(df_clean)\n",
        "        n_grupos = len(grupos)\n",
        "\n",
        "        grand_mean = df_clean[metrica].mean()\n",
        "        ss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in grupos)\n",
        "        ss_total = ((df_clean[metrica] - grand_mean)**2).sum()\n",
        "        ss_within = ss_total - ss_between\n",
        "\n",
        "        eta_sq = ss_between / ss_total if ss_total > 0 else 0\n",
        "\n",
        "        df_between = n_grupos - 1\n",
        "        ms_within = ss_within / (n_total - n_grupos) if (n_total - n_grupos) > 0 else 0\n",
        "        omega_sq = (ss_between - df_between * ms_within) / (ss_total + ms_within)\n",
        "        omega_sq = max(0, omega_sq)\n",
        "\n",
        "        if eta_sq < 0.01:\n",
        "            interpretacion = 'insignificante'\n",
        "        elif eta_sq < 0.06:\n",
        "            interpretacion = 'pequeno'\n",
        "        elif eta_sq < 0.14:\n",
        "            interpretacion = 'mediano'\n",
        "        else:\n",
        "            interpretacion = 'grande'\n",
        "\n",
        "        return ResultadoANOVA(\n",
        "            factor=factor,\n",
        "            f_statistic=float(f_stat),\n",
        "            p_valor=float(p_valor),\n",
        "            eta_squared=float(eta_sq),\n",
        "            omega_squared=float(omega_sq),\n",
        "            n_grupos=n_grupos,\n",
        "            n_total=n_total,\n",
        "            significativo=p_valor < 0.05,\n",
        "            interpretacion_efecto=interpretacion\n",
        "        )\n",
        "\n",
        "    def _calcular_posthoc_tukey(self, df: pd.DataFrame, factor: str,\n",
        "                                 metrica: str = 'iou') -> List[ResultadoPostHoc]:\n",
        "        \"\"\"\n",
        "        Calcula comparaciones post-hoc Tukey HSD.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Datos del modelo\n",
        "        factor : str\n",
        "            Nombre del factor\n",
        "        metrica : str\n",
        "            Métrica a analizar\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[ResultadoPostHoc]\n",
        "            Lista de comparaciones pareadas\n",
        "        \"\"\"\n",
        "        col_factor = f'factor_{factor}' if not factor.startswith('factor_') else factor\n",
        "\n",
        "        if col_factor not in df.columns:\n",
        "            return []\n",
        "\n",
        "        df_clean = df[[col_factor, metrica]].dropna()\n",
        "\n",
        "        if df_clean[col_factor].nunique() < 2:\n",
        "            return []\n",
        "\n",
        "        grupos = df_clean.groupby(col_factor)[metrica].apply(list).to_dict()\n",
        "        nombres = list(grupos.keys())\n",
        "        datos = [np.array(grupos[n]) for n in nombres]\n",
        "\n",
        "        if len(datos) < 2:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            resultado_tukey = tukey_hsd(*datos)\n",
        "        except Exception:\n",
        "            return []\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for i in range(len(nombres)):\n",
        "            for j in range(i + 1, len(nombres)):\n",
        "                diff = np.mean(datos[i]) - np.mean(datos[j])\n",
        "                p_val = resultado_tukey.pvalue[i, j]\n",
        "                ci = resultado_tukey.confidence_interval(confidence_level=0.95)\n",
        "                ci_low = ci.low[i, j]\n",
        "                ci_high = ci.high[i, j]\n",
        "\n",
        "                resultados.append(ResultadoPostHoc(\n",
        "                    grupo_1=str(nombres[i]),\n",
        "                    grupo_2=str(nombres[j]),\n",
        "                    diferencia_medias=float(diff),\n",
        "                    p_valor=float(p_val),\n",
        "                    significativo=p_val < 0.05,\n",
        "                    ic_inferior=float(ci_low),\n",
        "                    ic_superior=float(ci_high)\n",
        "                ))\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_bodypix(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para BodyPix.\n",
        "\n",
        "        Factores:\n",
        "        - multiplicador: 050, 075\n",
        "        - nivel_sensibilidad: ultra_sensible, sensibilidad_alta, sensibilidad_media, baja_sensibilidad\n",
        "        - umbral: valores numéricos\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando BodyPix...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'bodypix'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'bodypix',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        for factor in ['multiplicador', 'nivel_sensibilidad', 'umbral']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        if 'factor_multiplicador' in df_modelo.columns and 'factor_nivel_sensibilidad' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_multiplicador', 'factor_nivel_sensibilidad']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['multiplicador', 'nivel_sensibilidad', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_multiplicador_sensibilidad'] = interaccion.to_dict('records')\n",
        "\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_mask2former(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para Mask2Former.\n",
        "\n",
        "        Factores:\n",
        "        - backbone: base, large, tiny\n",
        "        - dataset: ade, coco\n",
        "        - sensibilidad: varios niveles\n",
        "\n",
        "        Hallazgo crítico esperado: COCO produce IoU=0 en muchas configuraciones\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando Mask2Former...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'mask2former'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'mask2former',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        configs_cero = df_modelo.groupby('config_codigo')['iou'].mean()\n",
        "        configs_cero = configs_cero[configs_cero == 0].index.tolist()\n",
        "        resultados['configuraciones_iou_cero'] = configs_cero\n",
        "        resultados['n_configs_iou_cero'] = len(configs_cero)\n",
        "\n",
        "        for factor in ['backbone', 'dataset', 'sensibilidad']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        if 'factor_dataset' in df_modelo.columns:\n",
        "            comparacion_dataset = df_modelo.groupby('factor_dataset').agg({\n",
        "                'iou': ['mean', 'std', 'min', 'max', 'count'],\n",
        "                'config_codigo': 'nunique'\n",
        "            }).reset_index()\n",
        "            comparacion_dataset.columns = [\n",
        "                'dataset', 'iou_mean', 'iou_std', 'iou_min', 'iou_max',\n",
        "                'n_evaluaciones', 'n_configuraciones'\n",
        "            ]\n",
        "            resultados['comparacion_ade_coco'] = comparacion_dataset.to_dict('records')\n",
        "\n",
        "            ade_data = df_modelo[df_modelo['factor_dataset'] == 'ade']['iou']\n",
        "            coco_data = df_modelo[df_modelo['factor_dataset'] == 'coco']['iou']\n",
        "\n",
        "            if len(ade_data) > 0 and len(coco_data) > 0:\n",
        "                t_stat, p_val = stats.ttest_ind(ade_data, coco_data)\n",
        "                pooled_std = np.sqrt((ade_data.std()**2 + coco_data.std()**2) / 2)\n",
        "                cohens_d = (ade_data.mean() - coco_data.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "                resultados['test_ade_vs_coco'] = {\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'ade_mean': float(ade_data.mean()),\n",
        "                    'coco_mean': float(coco_data.mean()),\n",
        "                    'diferencia': float(ade_data.mean() - coco_data.mean())\n",
        "                }\n",
        "\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_oneformer(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para OneFormer.\n",
        "\n",
        "        Factores:\n",
        "        - dataset: ade20k, coco\n",
        "        - backbone: swin, tiny\n",
        "        - task_type: instance, panoptic, semantic\n",
        "        - umbral: t040, t060, t075, t085\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando OneFormer...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'oneformer'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'oneformer',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        for factor in ['dataset', 'backbone', 'task_type', 'umbral']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        if all(f'factor_{f}' in df_modelo.columns for f in ['dataset', 'backbone', 'task_type']):\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_dataset', 'factor_backbone', 'factor_task_type']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['dataset', 'backbone', 'task_type', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_completa'] = interaccion.to_dict('records')\n",
        "\n",
        "        if 'factor_task_type' in df_modelo.columns and 'factor_umbral' in df_modelo.columns:\n",
        "            sensibilidad_umbral = df_modelo.groupby(\n",
        "                ['factor_task_type', 'factor_umbral']\n",
        "            )['iou'].agg(['mean', 'std']).reset_index()\n",
        "            sensibilidad_umbral.columns = ['task_type', 'umbral', 'iou_mean', 'iou_std']\n",
        "            resultados['sensibilidad_umbral_por_task'] = sensibilidad_umbral.to_dict('records')\n",
        "\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_sam2(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para SAM2.\n",
        "\n",
        "        Incluye tanto sam2 (modo auto) como sam2_prompts (modo con prompts).\n",
        "\n",
        "        Factores:\n",
        "        - modo: auto, prompts\n",
        "        - tamano: tiny, small, base_plus, large\n",
        "        - estrategia: varias según el modo\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando SAM2 (auto + prompts)...\")\n",
        "\n",
        "        # Incluir tanto sam2 como sam2_prompts\n",
        "        df_modelo = self.df[self.df['modelo'].isin(['sam2', 'sam2_prompts'])].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'sam2',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'n_evaluaciones_auto': len(df_modelo[df_modelo['modelo'] == 'sam2']),\n",
        "            'n_evaluaciones_prompts': len(df_modelo[df_modelo['modelo'] == 'sam2_prompts']),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Análisis por factor principal\n",
        "        for factor in ['modo', 'tamano']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Análisis detallado: auto vs prompts\n",
        "        if 'factor_modo' in df_modelo.columns:\n",
        "            auto_data = df_modelo[df_modelo['factor_modo'] == 'auto']['iou']\n",
        "            prompts_data = df_modelo[df_modelo['factor_modo'] == 'prompts']['iou']\n",
        "\n",
        "            if len(auto_data) > 0 and len(prompts_data) > 0:\n",
        "                t_stat, p_val = stats.ttest_ind(auto_data, prompts_data)\n",
        "                pooled_std = np.sqrt((auto_data.std()**2 + prompts_data.std()**2) / 2)\n",
        "                cohens_d = (prompts_data.mean() - auto_data.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "                resultados['comparacion_auto_prompts'] = {\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'auto_mean': float(auto_data.mean()),\n",
        "                    'auto_std': float(auto_data.std()),\n",
        "                    'prompts_mean': float(prompts_data.mean()),\n",
        "                    'prompts_std': float(prompts_data.std()),\n",
        "                    'diferencia': float(prompts_data.mean() - auto_data.mean()),\n",
        "                    'mejora_porcentual': float((prompts_data.mean() - auto_data.mean()) / auto_data.mean() * 100) if auto_data.mean() > 0 else None\n",
        "                }\n",
        "\n",
        "        # Análisis de estrategias de prompts\n",
        "        df_prompts = df_modelo[df_modelo['factor_modo'] == 'prompts'].copy()\n",
        "        if len(df_prompts) > 0 and 'factor_estrategia' in df_prompts.columns:\n",
        "            stats_estrategia = df_prompts.groupby('factor_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_estrategia.columns = ['estrategia', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            stats_estrategia = stats_estrategia.sort_values('iou_mean', ascending=False)\n",
        "            resultados['estrategias_prompts'] = stats_estrategia.to_dict('records')\n",
        "\n",
        "            anova_estrategia = self._calcular_anova(df_prompts, 'estrategia')\n",
        "            if anova_estrategia:\n",
        "                resultados['anova_estrategias'] = asdict(anova_estrategia)\n",
        "\n",
        "            # Categorizar estrategias por tipo\n",
        "            def categorizar_estrategia(est):\n",
        "                if pd.isna(est):\n",
        "                    return 'otra'\n",
        "                if 'saliency' in str(est):\n",
        "                    return 'saliencia'\n",
        "                elif 'grid' in str(est):\n",
        "                    return 'grid'\n",
        "                elif 'combined' in str(est):\n",
        "                    return 'combinada'\n",
        "                elif 'bbox' in str(est):\n",
        "                    return 'bbox'\n",
        "                return 'otra'\n",
        "\n",
        "            df_prompts['categoria_estrategia'] = df_prompts['factor_estrategia'].apply(categorizar_estrategia)\n",
        "\n",
        "            stats_categoria = df_prompts.groupby('categoria_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_categoria.columns = ['categoria', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            stats_categoria = stats_categoria.sort_values('iou_mean', ascending=False)\n",
        "            resultados['categorias_estrategia'] = stats_categoria.to_dict('records')\n",
        "\n",
        "            # ANOVA por categoría\n",
        "            if df_prompts['categoria_estrategia'].nunique() >= 2:\n",
        "                anova_categoria = self._calcular_anova(df_prompts, 'categoria_estrategia')\n",
        "                if anova_categoria:\n",
        "                    resultados['anova_categorias'] = asdict(anova_categoria)\n",
        "\n",
        "        # Análisis modo automático por configuración\n",
        "        df_auto = df_modelo[df_modelo['factor_modo'] == 'auto'].copy()\n",
        "        if len(df_auto) > 0 and 'factor_estrategia' in df_auto.columns:\n",
        "            stats_auto = df_auto.groupby('factor_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_auto.columns = ['config_auto', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['configuraciones_auto'] = stats_auto.to_dict('records')\n",
        "\n",
        "        # Interacción modo × tamaño\n",
        "        if 'factor_modo' in df_modelo.columns and 'factor_tamano' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_modo', 'factor_tamano']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['modo', 'tamano', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_modo_tamano'] = interaccion.to_dict('records')\n",
        "\n",
        "        # Análisis por tamaño SOLO en modo prompts\n",
        "        if len(df_prompts) > 0 and 'factor_tamano' in df_prompts.columns:\n",
        "            stats_tamano_prompts = df_prompts.groupby('factor_tamano')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_tamano_prompts.columns = ['tamano', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            resultados['tamano_en_prompts'] = stats_tamano_prompts.to_dict('records')\n",
        "\n",
        "            anova_tamano_prompts = self._calcular_anova(df_prompts, 'tamano')\n",
        "            if anova_tamano_prompts:\n",
        "                resultados['anova_tamano_prompts'] = asdict(anova_tamano_prompts)\n",
        "\n",
        "        # Análisis cruzado: mejor estrategia por tamaño\n",
        "        if len(df_prompts) > 0 and 'factor_tamano' in df_prompts.columns and 'factor_estrategia' in df_prompts.columns:\n",
        "            mejor_por_tamano = []\n",
        "            for tamano in df_prompts['factor_tamano'].dropna().unique():\n",
        "                df_tam = df_prompts[df_prompts['factor_tamano'] == tamano]\n",
        "                if len(df_tam) > 0:\n",
        "                    stats_est = df_tam.groupby('factor_estrategia')['iou'].mean()\n",
        "                    if len(stats_est) > 0:\n",
        "                        mejor_est = stats_est.idxmax()\n",
        "                        mejor_iou = stats_est.max()\n",
        "                        mejor_por_tamano.append({\n",
        "                            'tamano': tamano,\n",
        "                            'mejor_estrategia': mejor_est,\n",
        "                            'iou_mean': float(mejor_iou)\n",
        "                        })\n",
        "            resultados['mejor_estrategia_por_tamano'] = mejor_por_tamano\n",
        "\n",
        "        # Mejor configuración global\n",
        "        stats_config = df_modelo.groupby('config_codigo')['iou'].mean()\n",
        "        mejor = stats_config.idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(stats_config.max())\n",
        "\n",
        "        # Hallazgo clave: saliencia como mejor enfoque\n",
        "        if 'estrategias_prompts' in resultados and len(resultados['estrategias_prompts']) > 0:\n",
        "            top_estrategia = resultados['estrategias_prompts'][0]\n",
        "            resultados['hallazgo_clave'] = {\n",
        "                'mejor_estrategia': top_estrategia['estrategia'],\n",
        "                'iou': top_estrategia['iou_mean'],\n",
        "                'es_saliencia': 'saliency' in str(top_estrategia['estrategia']),\n",
        "                'interpretacion': 'Las estrategias basadas en saliencia visual superan significativamente a otras aproximaciones, validando el uso de conocimiento de dominio fotografico.'\n",
        "            }\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_yolov8(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para YOLOv8.\n",
        "\n",
        "        Factores:\n",
        "        - tamano: nano, small, medium, large, xlarge\n",
        "        - config_sensibilidad: balanced, fast, quality, sensitive\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando YOLOv8...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'yolov8'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'yolov8',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        for factor in ['tamano', 'config_sensibilidad']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            if factor == 'tamano':\n",
        "                orden_tamano = ['nano', 'small', 'medium', 'large', 'xlarge']\n",
        "                stats_nivel['orden'] = stats_nivel[factor].map(\n",
        "                    {t: i for i, t in enumerate(orden_tamano)}\n",
        "                )\n",
        "                stats_nivel = stats_nivel.sort_values('orden').drop('orden', axis=1)\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        if 'factor_tamano' in df_modelo.columns and 'factor_config_sensibilidad' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_tamano', 'factor_config_sensibilidad']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['tamano', 'config_sensibilidad', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_tamano_sensibilidad'] = interaccion.to_dict('records')\n",
        "\n",
        "        if 'factor_tamano' in df_modelo.columns:\n",
        "            orden_tamano = ['nano', 'small', 'medium', 'large', 'xlarge']\n",
        "            iou_por_tamano = df_modelo.groupby('factor_tamano')['iou'].mean()\n",
        "\n",
        "            mejoras = []\n",
        "            for i in range(1, len(orden_tamano)):\n",
        "                if orden_tamano[i] in iou_por_tamano.index and orden_tamano[i-1] in iou_por_tamano.index:\n",
        "                    mejora = iou_por_tamano[orden_tamano[i]] - iou_por_tamano[orden_tamano[i-1]]\n",
        "                    mejoras.append({\n",
        "                        'de': orden_tamano[i-1],\n",
        "                        'a': orden_tamano[i],\n",
        "                        'mejora_iou': float(mejora),\n",
        "                        'mejora_porcentual': float(mejora / iou_por_tamano[orden_tamano[i-1]] * 100)\n",
        "                    })\n",
        "\n",
        "            resultados['analisis_rendimientos_decrecientes'] = mejoras\n",
        "\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    # =========================================================================\n",
        "    # COMPARACIÓN DE PARADIGMAS ARQUITECTÓNICOS\n",
        "    # =========================================================================\n",
        "    def comparar_paradigmas(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Compara los paradigmas arquitectónicos.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados de la comparación\n",
        "        \"\"\"\n",
        "        logger.info(\"Comparando paradigmas arquitectónicos...\")\n",
        "\n",
        "        resultados = {\n",
        "            'paradigmas': {},\n",
        "            'comparaciones_pareadas': []\n",
        "        }\n",
        "\n",
        "        def asignar_paradigma(modelo):\n",
        "            for paradigma, modelos in self.PARADIGMAS.items():\n",
        "                if modelo in modelos:\n",
        "                    return paradigma\n",
        "            return 'unknown'\n",
        "\n",
        "        self.df['paradigma'] = self.df['modelo'].apply(asignar_paradigma)\n",
        "\n",
        "        for paradigma in self.PARADIGMAS.keys():\n",
        "            df_paradigma = self.df[self.df['paradigma'] == paradigma]\n",
        "            if len(df_paradigma) == 0:\n",
        "                continue\n",
        "\n",
        "            resultados['paradigmas'][paradigma] = {\n",
        "                'modelos': self.PARADIGMAS[paradigma],\n",
        "                'n_evaluaciones': len(df_paradigma),\n",
        "                'n_configuraciones': df_paradigma['config_codigo'].nunique(),\n",
        "                'iou_mean': float(df_paradigma['iou'].mean()),\n",
        "                'iou_std': float(df_paradigma['iou'].std()),\n",
        "                'iou_median': float(df_paradigma['iou'].median()),\n",
        "                'iou_min': float(df_paradigma['iou'].min()),\n",
        "                'iou_max': float(df_paradigma['iou'].max())\n",
        "            }\n",
        "\n",
        "        anova_paradigma = self._calcular_anova(self.df, 'paradigma')\n",
        "        if anova_paradigma:\n",
        "            resultados['anova_paradigmas'] = asdict(anova_paradigma)\n",
        "\n",
        "        paradigmas_lista = list(self.PARADIGMAS.keys())\n",
        "        for i in range(len(paradigmas_lista)):\n",
        "            for j in range(i + 1, len(paradigmas_lista)):\n",
        "                p1, p2 = paradigmas_lista[i], paradigmas_lista[j]\n",
        "\n",
        "                datos_p1 = self.df[self.df['paradigma'] == p1]['iou']\n",
        "                datos_p2 = self.df[self.df['paradigma'] == p2]['iou']\n",
        "\n",
        "                if len(datos_p1) == 0 or len(datos_p2) == 0:\n",
        "                    continue\n",
        "\n",
        "                t_stat, p_val = stats.ttest_ind(datos_p1, datos_p2)\n",
        "\n",
        "                pooled_std = np.sqrt((datos_p1.std()**2 + datos_p2.std()**2) / 2)\n",
        "                cohens_d = (datos_p1.mean() - datos_p2.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "\n",
        "                resultados['comparaciones_pareadas'].append({\n",
        "                    'paradigma_1': p1,\n",
        "                    'paradigma_2': p2,\n",
        "                    'media_1': float(datos_p1.mean()),\n",
        "                    'media_2': float(datos_p2.mean()),\n",
        "                    'diferencia': float(datos_p1.mean() - datos_p2.mean()),\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'significativo': p_val < 0.05\n",
        "                })\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    # =========================================================================\n",
        "    # ANÁLISIS DE SENSIBILIDAD GLOBAL\n",
        "    # =========================================================================\n",
        "    def analizar_sensibilidad_umbrales(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Analiza la sensibilidad a umbrales de confianza para todos los modelos.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Resultados de sensibilidad\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando sensibilidad a umbrales...\")\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer']:\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "\n",
        "            col_umbral = 'factor_umbral' if modelo in ['oneformer', 'bodypix'] else 'factor_sensibilidad'\n",
        "\n",
        "            if col_umbral not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            for umbral in df_modelo[col_umbral].dropna().unique():\n",
        "                mask = df_modelo[col_umbral] == umbral\n",
        "                datos = df_modelo.loc[mask, 'iou']\n",
        "\n",
        "                resultados.append({\n",
        "                    'modelo': modelo,\n",
        "                    'umbral': umbral,\n",
        "                    'iou_mean': float(datos.mean()),\n",
        "                    'iou_std': float(datos.std()),\n",
        "                    'iou_min': float(datos.min()),\n",
        "                    'iou_max': float(datos.max()),\n",
        "                    'n': len(datos)\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(resultados)\n",
        "\n",
        "    def analizar_sensibilidad_tamano(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Analiza la sensibilidad al tamaño del modelo.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Resultados de sensibilidad al tamaño\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando sensibilidad al tamaño del modelo...\")\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        # Incluir sam2 y sam2_prompts para análisis de tamaño\n",
        "        for modelo_grupo in [['sam2', 'sam2_prompts'], ['yolov8']]:\n",
        "            df_modelo = self.df[self.df['modelo'].isin(modelo_grupo)]\n",
        "            col_tamano = 'factor_tamano'\n",
        "\n",
        "            if col_tamano not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            # Nombre del modelo para el resultado\n",
        "            nombre_modelo = 'sam2' if 'sam2' in modelo_grupo else modelo_grupo[0]\n",
        "\n",
        "            for tamano in df_modelo[col_tamano].dropna().unique():\n",
        "                mask = df_modelo[col_tamano] == tamano\n",
        "                datos = df_modelo.loc[mask, 'iou']\n",
        "\n",
        "                resultados.append({\n",
        "                    'modelo': nombre_modelo,\n",
        "                    'tamano': tamano,\n",
        "                    'iou_mean': float(datos.mean()),\n",
        "                    'iou_std': float(datos.std()),\n",
        "                    'iou_min': float(datos.min()),\n",
        "                    'iou_max': float(datos.max()),\n",
        "                    'n': len(datos)\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(resultados)\n",
        "\n",
        "    # =========================================================================\n",
        "    # EJECUCIÓN COMPLETA\n",
        "    # =========================================================================\n",
        "    def ejecutar_analisis_completo(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Ejecuta todos los análisis de la Fase 2D.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Todos los resultados\n",
        "        \"\"\"\n",
        "        logger.info(\"=\"*60)\n",
        "        logger.info(\"INICIANDO ANALISIS FASE 2D: CONFIGURACIONES\")\n",
        "        logger.info(\"=\"*60)\n",
        "\n",
        "        # 1. Rankings\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"1. Calculando rankings...\")\n",
        "        ranking_global = self.calcular_ranking_global(top_n=30)\n",
        "        ranking_modelo = self.calcular_ranking_por_modelo()\n",
        "\n",
        "        # 2. Análisis por modelo\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"2. Analisis factorial por modelo...\")\n",
        "        self.resultados['bodypix'] = self.analizar_bodypix()\n",
        "        self.resultados['mask2former'] = self.analizar_mask2former()\n",
        "        self.resultados['oneformer'] = self.analizar_oneformer()\n",
        "        self.resultados['sam2'] = self.analizar_sam2()\n",
        "        self.resultados['yolov8'] = self.analizar_yolov8()\n",
        "\n",
        "        # 3. Comparación de paradigmas\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"3. Comparando paradigmas arquitectonicos...\")\n",
        "        self.resultados['paradigmas'] = self.comparar_paradigmas()\n",
        "\n",
        "        # 4. Análisis de sensibilidad\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"4. Analisis de sensibilidad...\")\n",
        "        self.resultados['sensibilidad_umbrales'] = self.analizar_sensibilidad_umbrales()\n",
        "        self.resultados['sensibilidad_tamano'] = self.analizar_sensibilidad_tamano()\n",
        "\n",
        "        # 5. Resumen de hallazgos\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"5. Generando resumen...\")\n",
        "        self.resultados['resumen'] = self._generar_resumen()\n",
        "\n",
        "        logger.info(\"\\n\" + \"=\"*60)\n",
        "        logger.info(\"ANALISIS FASE 2D COMPLETADO\")\n",
        "        logger.info(\"=\"*60)\n",
        "\n",
        "        return self.resultados\n",
        "\n",
        "    def _generar_resumen(self) -> Dict:\n",
        "        \"\"\"Genera un resumen de los hallazgos principales.\"\"\"\n",
        "\n",
        "        resumen = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'total_evaluaciones': len(self.df),\n",
        "            'total_configuraciones': self.df['config_codigo'].nunique(),\n",
        "            'total_fotografias': self.df['codigo_foto'].nunique(),\n",
        "            'modelos_analizados': self.df['modelo'].unique().tolist()\n",
        "        }\n",
        "\n",
        "        mejor_por_modelo = self.resultados.get('ranking_por_modelo')\n",
        "        if mejor_por_modelo is not None and len(mejor_por_modelo) > 0:\n",
        "            mejor = mejor_por_modelo.iloc[0]\n",
        "            resumen['mejor_modelo_global'] = {\n",
        "                'modelo': mejor['modelo'],\n",
        "                'configuracion': mejor['mejor_config'],\n",
        "                'iou_mean': float(mejor['iou_mean'])\n",
        "            }\n",
        "\n",
        "        resumen['hallazgos_modelo'] = {}\n",
        "\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                res = self.resultados[modelo]\n",
        "                hallazgo = {\n",
        "                    'mejor_configuracion': res.get('mejor_configuracion'),\n",
        "                    'iou_mejor': res.get('iou_mejor')\n",
        "                }\n",
        "\n",
        "                factores_sig = []\n",
        "                for factor, datos in res.get('factores', {}).items():\n",
        "                    if datos.get('anova') and datos['anova'].get('significativo'):\n",
        "                        factores_sig.append({\n",
        "                            'factor': factor,\n",
        "                            'eta_squared': datos['anova']['eta_squared'],\n",
        "                            'interpretacion': datos['anova']['interpretacion_efecto']\n",
        "                        })\n",
        "                hallazgo['factores_significativos'] = factores_sig\n",
        "\n",
        "                resumen['hallazgos_modelo'][modelo] = hallazgo\n",
        "\n",
        "        return resumen\n",
        "\n",
        "    # =========================================================================\n",
        "    # EXPORTACIÓN DE RESULTADOS\n",
        "    # =========================================================================\n",
        "    @staticmethod\n",
        "    def _convertir_tipos_json(obj):\n",
        "        \"\"\"Convierte tipos numpy a tipos nativos de Python para JSON.\"\"\"\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: AnalizadorConfiguraciones._convertir_tipos_json(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [AnalizadorConfiguraciones._convertir_tipos_json(item) for item in obj]\n",
        "        elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, (np.bool_, bool)):\n",
        "            return bool(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif pd.isna(obj):\n",
        "            return None\n",
        "        return obj\n",
        "\n",
        "    def exportar_resultados(self):\n",
        "        \"\"\"Exporta todos los resultados a archivos.\"\"\"\n",
        "\n",
        "        logger.info(\"Exportando resultados...\")\n",
        "        self.rutas.crear_directorios()\n",
        "\n",
        "        # 1. Ranking global\n",
        "        if 'ranking_global' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'ranking_global_top30.csv')\n",
        "            self.resultados['ranking_global'].head(30).to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 2. Ranking por modelo\n",
        "        if 'ranking_por_modelo' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'ranking_por_modelo.csv')\n",
        "            self.resultados['ranking_por_modelo'].to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 3. Análisis por modelo (JSON)\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                ruta = os.path.join(self.rutas.salida, f'factores_{modelo}.json')\n",
        "                datos_convertidos = self._convertir_tipos_json(self.resultados[modelo])\n",
        "                with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 4. Comparación de paradigmas\n",
        "        if 'paradigmas' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'comparacion_paradigmas.json')\n",
        "            datos_convertidos = self._convertir_tipos_json(self.resultados['paradigmas'])\n",
        "            with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 5. Sensibilidad umbrales\n",
        "        if 'sensibilidad_umbrales' in self.resultados:\n",
        "            df_sens = self.resultados['sensibilidad_umbrales']\n",
        "            if isinstance(df_sens, pd.DataFrame) and len(df_sens) > 0:\n",
        "                ruta = os.path.join(self.rutas.salida, 'sensibilidad_umbrales.csv')\n",
        "                df_sens.to_csv(ruta, index=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 6. Sensibilidad tamaño\n",
        "        if 'sensibilidad_tamano' in self.resultados:\n",
        "            df_sens = self.resultados['sensibilidad_tamano']\n",
        "            if isinstance(df_sens, pd.DataFrame) and len(df_sens) > 0:\n",
        "                ruta = os.path.join(self.rutas.salida, 'sensibilidad_tamano.csv')\n",
        "                df_sens.to_csv(ruta, index=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 7. Resumen general\n",
        "        if 'resumen' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'resumen_fase2d.json')\n",
        "            datos_convertidos = self._convertir_tipos_json(self.resultados['resumen'])\n",
        "            with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 8. ANOVA consolidado\n",
        "        anova_consolidado = []\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                for factor, datos in self.resultados[modelo].get('factores', {}).items():\n",
        "                    if datos.get('anova'):\n",
        "                        anova_data = datos['anova'].copy()\n",
        "                        anova_data['modelo'] = modelo\n",
        "                        anova_consolidado.append(anova_data)\n",
        "\n",
        "        if anova_consolidado:\n",
        "            df_anova = pd.DataFrame(anova_consolidado)\n",
        "            ruta = os.path.join(self.rutas.salida, 'anova_por_modelo.csv')\n",
        "            df_anova.to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 9. Post-hoc Tukey consolidado\n",
        "        posthoc_consolidado = []\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                for factor, datos in self.resultados[modelo].get('factores', {}).items():\n",
        "                    for ph in datos.get('posthoc', []):\n",
        "                        ph_data = ph.copy()\n",
        "                        ph_data['modelo'] = modelo\n",
        "                        ph_data['factor'] = factor\n",
        "                        posthoc_consolidado.append(ph_data)\n",
        "\n",
        "        if posthoc_consolidado:\n",
        "            df_posthoc = pd.DataFrame(posthoc_consolidado)\n",
        "            ruta = os.path.join(self.rutas.salida, 'posthoc_tukey.csv')\n",
        "            df_posthoc.to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        logger.info(\"Exportacion completada.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN PRINCIPAL\n",
        "# =============================================================================\n",
        "def ejecutar_fase2d(ruta_metricas: str = None) -> Dict:\n",
        "    \"\"\"\n",
        "    Ejecuta la Fase 2D completa.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ruta_metricas : str, optional\n",
        "        Ruta al archivo metricas_fusionadas.csv\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "        Resultados del análisis\n",
        "    \"\"\"\n",
        "    # Configurar rutas\n",
        "    rutas = ConfiguracionRutas()\n",
        "\n",
        "    # Determinar ruta de entrada\n",
        "    if ruta_metricas is None:\n",
        "        ruta_metricas = os.path.join(rutas.datos_entrada, 'metricas_fusionadas.csv')\n",
        "\n",
        "    logger.info(f\"Cargando datos desde: {ruta_metricas}\")\n",
        "\n",
        "    # Cargar datos\n",
        "    if not os.path.exists(ruta_metricas):\n",
        "        raise FileNotFoundError(f\"No se encontró el archivo: {ruta_metricas}\")\n",
        "\n",
        "    df = pd.read_csv(ruta_metricas)\n",
        "    logger.info(f\"Datos cargados: {len(df)} filas, {len(df.columns)} columnas\")\n",
        "\n",
        "    # Crear analizador y ejecutar\n",
        "    analizador = AnalizadorConfiguraciones(df, rutas)\n",
        "    resultados = analizador.ejecutar_analisis_completo()\n",
        "\n",
        "    # Exportar resultados\n",
        "    analizador.exportar_resultados()\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "rPxvgdkkV3Kj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN\n",
        "# =============================================================================\n",
        "if __name__ == '__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Ejecutar análisis\n",
        "    resultados = ejecutar_fase2d()\n",
        "\n",
        "    # Mostrar resumen\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESUMEN DE FASE 2D\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if 'resumen' in resultados:\n",
        "        resumen = resultados['resumen']\n",
        "        print(f\"Total evaluaciones: {resumen['total_evaluaciones']}\")\n",
        "        print(f\"Total configuraciones: {resumen['total_configuraciones']}\")\n",
        "        print(f\"Modelos analizados: {resumen['modelos_analizados']}\")\n",
        "\n",
        "        if 'mejor_modelo_global' in resumen:\n",
        "            mejor = resumen['mejor_modelo_global']\n",
        "            print(f\"\\nMejor modelo: {mejor['modelo']}\")\n",
        "            print(f\"Mejor configuración: {mejor['configuracion']}\")\n",
        "            print(f\"IoU: {mejor['iou_mean']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usG3_COFV5jH",
        "outputId": "35ed0684-531e-40c2-cd41-ca04b9f8ea6c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:15:09] INFO - Cargando datos desde: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:15:11] INFO - Datos cargados: 2360 filas, 220 columnas\n",
            "[22:15:11] INFO - Extrayendo factores de configuraciones...\n",
            "[22:15:11] INFO -   yolov8.factor_tamano: ['large', 'medium', 'nano', 'small', 'xlarge']\n",
            "[22:15:11] INFO -   yolov8.factor_config_sensibilidad: ['balanced', 'fast', 'quality', 'sensitive']\n",
            "[22:15:11] INFO -   bodypix.factor_multiplicador: ['050', '075']\n",
            "[22:15:11] INFO -   bodypix.factor_nivel_sensibilidad: ['baja_sensibilidad', 'sensibilidad_alta', 'sensibilidad_media', 'ultra_sensible']\n",
            "[22:15:11] INFO -   bodypix.factor_umbral: ['1', '15', '2', '25', '3', '4', '5']\n",
            "[22:15:11] INFO -   mask2former.factor_backbone: ['base', 'large', 'tiny']\n",
            "[22:15:11] INFO -   mask2former.factor_dataset: ['ade', 'coco']\n",
            "[22:15:11] INFO -   mask2former.factor_sensibilidad: ['alta_sensibilidad', 'baja_sensibilidad', 'experimental_coco', 'maxima_sensibilidad', 'media_sensibilidad']\n",
            "[22:15:11] INFO -   oneformer.factor_umbral: ['t040', 't060', 't075', 't085']\n",
            "[22:15:11] INFO -   oneformer.factor_backbone: ['swin', 'tiny']\n",
            "[22:15:11] INFO -   oneformer.factor_dataset: ['ade20k', 'coco']\n",
            "[22:15:11] INFO -   oneformer.factor_task_type: ['instance', 'panoptic', 'semantic']\n",
            "[22:15:11] INFO -   sam2.factor_modo: ['auto', 'prompts']\n",
            "[22:15:11] INFO -   sam2.factor_tamano: ['base_plus', 'large', 'small', 'tiny']\n",
            "[22:15:11] INFO -   sam2.factor_estrategia: ['balanced', 'bbox_heuristic', 'combined_aggressive', 'combined_moderate', 'grid_central_aggressive', 'grid_central_conservative', 'grid_central_moderate', 'low_cost', 'quality', 'saliency_conservative', 'saliency_moderate']\n",
            "[22:15:11] INFO - Analizador inicializado con 2360 evaluaciones\n",
            "[22:15:11] INFO - Modelos originales: ['yolov8', 'bodypix', 'mask2former', 'oneformer', 'sam2', 'sam2_prompts']\n",
            "[22:15:11] INFO - Modelos para análisis: ['yolov8', 'bodypix', 'mask2former', 'oneformer', 'sam2']\n",
            "[22:15:11] INFO - Configuraciones únicas: 143\n",
            "[22:15:11] INFO - ============================================================\n",
            "[22:15:11] INFO - INICIANDO ANALISIS FASE 2D: CONFIGURACIONES\n",
            "[22:15:11] INFO - ============================================================\n",
            "[22:15:11] INFO - \n",
            "----------------------------------------\n",
            "[22:15:11] INFO - 1. Calculando rankings...\n",
            "[22:15:11] INFO - Calculando ranking global TOP-30...\n",
            "[22:15:11] INFO - Calculando mejor configuración por modelo...\n",
            "[22:15:11] INFO - \n",
            "----------------------------------------\n",
            "[22:15:11] INFO - 2. Analisis factorial por modelo...\n",
            "[22:15:11] INFO - Analizando BodyPix...\n",
            "[22:15:11] INFO - Analizando Mask2Former...\n",
            "[22:15:12] INFO - Analizando OneFormer...\n",
            "[22:15:13] INFO - Analizando SAM2 (auto + prompts)...\n",
            "[22:15:13] INFO - Analizando YOLOv8...\n",
            "[22:15:14] INFO - \n",
            "----------------------------------------\n",
            "[22:15:14] INFO - 3. Comparando paradigmas arquitectonicos...\n",
            "[22:15:14] INFO - Comparando paradigmas arquitectónicos...\n",
            "[22:15:14] INFO - \n",
            "----------------------------------------\n",
            "[22:15:14] INFO - 4. Analisis de sensibilidad...\n",
            "[22:15:14] INFO - Analizando sensibilidad a umbrales...\n",
            "[22:15:14] INFO - Analizando sensibilidad al tamaño del modelo...\n",
            "[22:15:14] INFO - \n",
            "----------------------------------------\n",
            "[22:15:14] INFO - 5. Generando resumen...\n",
            "[22:15:14] INFO - \n",
            "============================================================\n",
            "[22:15:14] INFO - ANALISIS FASE 2D COMPLETADO\n",
            "[22:15:14] INFO - ============================================================\n",
            "[22:15:14] INFO - Exportando resultados...\n",
            "[22:15:14] INFO - Directorio de salida: /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/ranking_global_top30.csv\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/ranking_por_modelo.csv\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_bodypix.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_mask2former.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_oneformer.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_sam2.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_yolov8.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/comparacion_paradigmas.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/sensibilidad_umbrales.csv\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/sensibilidad_tamano.csv\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/resumen_fase2d.json\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/anova_por_modelo.csv\n",
            "[22:15:14] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/posthoc_tukey.csv\n",
            "[22:15:14] INFO - Exportacion completada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RESUMEN DE FASE 2D\n",
            "============================================================\n",
            "Total evaluaciones: 2360\n",
            "Total configuraciones: 143\n",
            "Modelos analizados: ['yolov8', 'bodypix', 'mask2former', 'oneformer', 'sam2', 'sam2_prompts']\n",
            "\n",
            "Mejor modelo: oneformer\n",
            "Mejor configuración: oneformer_coco_swin_semantic_t040\n",
            "IoU: 0.9674\n"
          ]
        }
      ]
    }
  ]
}