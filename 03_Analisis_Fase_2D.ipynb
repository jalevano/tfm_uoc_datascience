{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAYu90IeBxJJWRIlWSCEjc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_Analisis_Fase_2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "FASE 2D: ANÁLISIS DE CONFIGURACIONES\n",
        "================================================================================\n",
        "Trabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\n",
        "en Fotografía de Retrato\n",
        "\n",
        "Autor: Jesús L. (Iesus)\n",
        "Universidad: Universitat Oberta de Catalunya (UOC)\n",
        "Máster: Data Science\n",
        "Fecha: Diciembre 2025\n",
        "\n",
        "Descripción:\n",
        "    Este módulo implementa el análisis exhaustivo de configuraciones de los\n",
        "    5 modelos de segmentación evaluados. Incluye:\n",
        "    - Ranking global y por modelo\n",
        "    - Análisis factorial por modelo (ANOVA, efectos principales e interacciones)\n",
        "    - Análisis de sensibilidad a parámetros\n",
        "    - Comparación de paradigmas arquitectónicos\n",
        "    - Tests post-hoc (Tukey HSD)\n",
        "\n",
        "Entrada:\n",
        "    - metricas_fusionadas.csv (Fase 2B)\n",
        "    - Archivos auxiliares de fases anteriores\n",
        "\n",
        "Salida:\n",
        "    - CSVs con análisis factorial por modelo\n",
        "    - Rankings globales y por modelo\n",
        "    - Análisis de sensibilidad\n",
        "    - Comparación de paradigmas\n",
        "    - JSON con resumen de hallazgos\n",
        "================================================================================\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "rwaOW8fKVFJo",
        "outputId": "862cacd3-390e-4b5d-c441-023306f6e84c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nFASE 2D: ANÁLISIS DE CONFIGURACIONES\\n================================================================================\\nTrabajo Fin de Máster - Evaluación Comparativa de Técnicas de Segmentación\\nen Fotografía de Retrato\\n\\nAutor: Jesús L. (Iesus)\\nUniversidad: Universitat Oberta de Catalunya (UOC)\\nMáster: Data Science\\nFecha: Diciembre 2025\\n\\nDescripción:\\n    Este módulo implementa el análisis exhaustivo de configuraciones de los\\n    5 modelos de segmentación evaluados. Incluye:\\n    - Ranking global y por modelo\\n    - Análisis factorial por modelo (ANOVA, efectos principales e interacciones)\\n    - Análisis de sensibilidad a parámetros\\n    - Comparación de paradigmas arquitectónicos\\n    - Tests post-hoc (Tukey HSD)\\n\\nEntrada:\\n    - metricas_fusionadas.csv (Fase 2B)\\n    - Archivos auxiliares de fases anteriores\\n\\nSalida:\\n    - CSVs con análisis factorial por modelo\\n    - Rankings globales y por modelo\\n    - Análisis de sensibilidad\\n    - Comparación de paradigmas\\n    - JSON con resumen de hallazgos\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field, asdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.stats import f_oneway, tukey_hsd, kruskal, mannwhitneyu\n",
        "import logging\n",
        "\n",
        "# Configuración de warnings\n",
        "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "FZgx9oQnVHak"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN DE LOGGING\n",
        "# =============================================================================\n",
        "def configurar_logging(nivel: int = logging.INFO) -> logging.Logger:\n",
        "    \"\"\"\n",
        "    Configura el sistema de logging para el análisis.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    nivel : int\n",
        "        Nivel de logging (default: logging.INFO)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    logging.Logger\n",
        "        Logger configurado\n",
        "    \"\"\"\n",
        "    # Eliminar handlers existentes para evitar duplicación en Colab\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "\n",
        "    logging.basicConfig(\n",
        "        level=nivel,\n",
        "        format='[%(asctime)s] %(levelname)s - %(message)s',\n",
        "        datefmt='%H:%M:%S'\n",
        "    )\n",
        "\n",
        "    logger = logging.getLogger(__name__)\n",
        "    return logger\n",
        "\n",
        "logger = configurar_logging()"
      ],
      "metadata": {
        "id": "vGRLmCt_VKW3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN DE RUTAS\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ConfiguracionRutas:\n",
        "    \"\"\"Configuración de rutas del proyecto.\"\"\"\n",
        "\n",
        "    # Detectar entorno (Colab o local)\n",
        "    en_colab: bool = field(default_factory=lambda: 'google.colab' in sys.modules)\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.en_colab:\n",
        "            self.base = '/content/drive/MyDrive/TFM'\n",
        "            self.datos_entrada = '/content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones'\n",
        "        else:\n",
        "            # Rutas locales para desarrollo\n",
        "            self.base = '/mnt/user-data/uploads'\n",
        "            self.datos_entrada = '/mnt/user-data/uploads'\n",
        "\n",
        "        self.salida = os.path.join(\n",
        "            self.base if self.en_colab else '/home/claude',\n",
        "            '3_Analisis' if self.en_colab else '',\n",
        "            'fase2d_configuraciones'\n",
        "        )\n",
        "\n",
        "    def crear_directorios(self):\n",
        "        \"\"\"Crea los directorios de salida si no existen.\"\"\"\n",
        "        os.makedirs(self.salida, exist_ok=True)\n",
        "        logger.info(f\"Directorio de salida: {self.salida}\")"
      ],
      "metadata": {
        "id": "NC3qy2tpVOh_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# ESTRUCTURAS DE DATOS\n",
        "# =============================================================================\n",
        "@dataclass\n",
        "class ResultadoANOVA:\n",
        "    \"\"\"Resultado de un análisis ANOVA.\"\"\"\n",
        "    factor: str\n",
        "    f_statistic: float\n",
        "    p_valor: float\n",
        "    eta_squared: float\n",
        "    omega_squared: float\n",
        "    n_grupos: int\n",
        "    n_total: int\n",
        "    significativo: bool\n",
        "    interpretacion_efecto: str\n",
        "\n",
        "@dataclass\n",
        "class ResultadoPostHoc:\n",
        "    \"\"\"Resultado de comparación post-hoc.\"\"\"\n",
        "    grupo_1: str\n",
        "    grupo_2: str\n",
        "    diferencia_medias: float\n",
        "    p_valor: float\n",
        "    significativo: bool\n",
        "    ic_inferior: float\n",
        "    ic_superior: float\n",
        "\n",
        "@dataclass\n",
        "class AnalisisFactorial:\n",
        "    \"\"\"Resultado completo de análisis factorial para un modelo.\"\"\"\n",
        "    modelo: str\n",
        "    factores: List[str]\n",
        "    anova_resultados: List[ResultadoANOVA]\n",
        "    posthoc_resultados: List[ResultadoPostHoc]\n",
        "    mejor_configuracion: str\n",
        "    iou_mejor: float\n",
        "    estadisticas_por_nivel: Dict[str, Dict]"
      ],
      "metadata": {
        "id": "B0MZ6tG_VeDW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3kySXegLUTsg"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CLASE PRINCIPAL: ANALIZADOR DE CONFIGURACIONES\n",
        "# =============================================================================\n",
        "class AnalizadorConfiguraciones:\n",
        "    \"\"\"\n",
        "    Clase principal para el análisis de configuraciones de modelos.\n",
        "\n",
        "    Implementa análisis factorial, sensibilidad y comparación de paradigmas\n",
        "    para los 5 modelos de segmentación evaluados.\n",
        "    \"\"\"\n",
        "\n",
        "    # Definición de factores por modelo\n",
        "    FACTORES_MODELO = {\n",
        "        'bodypix': {\n",
        "            'multiplicador': lambda x: x.split('_')[3],  # 050, 075\n",
        "            'nivel_sensibilidad': lambda x: '_'.join(x.split('_')[4:-1]).replace('_t0', ''),  # baja_sensibilidad, etc\n",
        "            'umbral': lambda x: x.split('_')[-1]  # 3, 4, 5, etc\n",
        "        },\n",
        "        'mask2former': {\n",
        "            'backbone': lambda x: x.split('_')[1],  # base, large, tiny\n",
        "            'dataset': lambda x: x.split('_')[2],  # ade, coco\n",
        "            'sensibilidad': lambda x: '_'.join(x.split('_')[3:])  # baja_sensibilidad, etc\n",
        "        },\n",
        "        'oneformer': {\n",
        "            'dataset': lambda x: x.split('_')[1],  # ade20k, coco\n",
        "            'backbone': lambda x: x.split('_')[2],  # swin, tiny\n",
        "            'task_type': lambda x: x.split('_')[3],  # instance, panoptic, semantic\n",
        "            'umbral': lambda x: x.split('_')[4]  # t040, t060, etc\n",
        "        },\n",
        "        'sam2': {\n",
        "            'modo': lambda x: 'prompts' if 'prompts' in x else 'auto',\n",
        "            'tamano': lambda x: AnalizadorConfiguraciones._extraer_tamano_sam2(x),\n",
        "            'estrategia': lambda x: AnalizadorConfiguraciones._extraer_estrategia_sam2(x)\n",
        "        },\n",
        "        'yolov8': {\n",
        "            'tamano': lambda x: x.split('_')[1],  # nano, small, medium, large, xlarge\n",
        "            'config_sensibilidad': lambda x: x.split('_')[2]  # balanced, fast, quality, sensitive\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Paradigmas arquitectónicos\n",
        "    PARADIGMAS = {\n",
        "        'cnn_especializada': ['yolov8'],\n",
        "        'transformer_segmentacion': ['mask2former', 'oneformer'],\n",
        "        'foundation_model': ['sam2'],\n",
        "        'web_ligero': ['bodypix']\n",
        "    }\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, rutas: ConfiguracionRutas):\n",
        "        \"\"\"\n",
        "        Inicializa el analizador.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            DataFrame con métricas fusionadas\n",
        "        rutas : ConfiguracionRutas\n",
        "            Configuración de rutas\n",
        "        \"\"\"\n",
        "        self.df = df.copy()\n",
        "        self.rutas = rutas\n",
        "        self.resultados = {}\n",
        "\n",
        "        # Extraer factores para cada modelo\n",
        "        self._extraer_factores()\n",
        "\n",
        "        logger.info(f\"Analizador inicializado con {len(df)} evaluaciones\")\n",
        "        logger.info(f\"Modelos: {df['modelo'].unique().tolist()}\")\n",
        "        logger.info(f\"Configuraciones únicas: {df['config_codigo'].nunique()}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _extraer_tamano_sam2(config: str) -> str:\n",
        "        \"\"\"\n",
        "        Extrae el tamaño del modelo SAM2 de la configuración.\n",
        "\n",
        "        Patrones:\n",
        "        - Auto: sam2_{tamaño}_{config} → sam2_base_plus_balanced\n",
        "        - Prompts: sam2_prompts_{tamaño}_{estrategia} → sam2_prompts_base_plus_saliency_moderate\n",
        "        \"\"\"\n",
        "        # base_plus debe ir primero porque contiene 'base'\n",
        "        if 'base_plus' in config:\n",
        "            return 'base_plus'\n",
        "        elif 'tiny' in config:\n",
        "            return 'tiny'\n",
        "        elif 'small' in config:\n",
        "            return 'small'\n",
        "        elif 'large' in config:\n",
        "            return 'large'\n",
        "        return 'unknown'\n",
        "\n",
        "    @staticmethod\n",
        "    def _extraer_estrategia_sam2(config: str) -> str:\n",
        "        \"\"\"\n",
        "        Extrae la estrategia de SAM2 de la configuración.\n",
        "\n",
        "        Modo automático (sam2_{tamaño}_{config}):\n",
        "        - balanced, low_cost, quality\n",
        "\n",
        "        Modo con prompts (sam2_prompts_{tamaño}_{estrategia}):\n",
        "        - bbox_heuristic, combined_aggressive, combined_moderate\n",
        "        - grid_central_aggressive, grid_central_conservative, grid_central_moderate\n",
        "        - saliency_conservative, saliency_moderate\n",
        "        \"\"\"\n",
        "        if 'prompts' not in config:\n",
        "            # Modo automático: sam2_{tamaño}_{config}\n",
        "            # Ejemplos: sam2_base_plus_balanced, sam2_tiny_quality, sam2_large_low_cost\n",
        "            if 'low_cost' in config:\n",
        "                return 'low_cost'\n",
        "            elif 'balanced' in config:\n",
        "                return 'balanced'\n",
        "            elif 'quality' in config:\n",
        "                return 'quality'\n",
        "            return 'unknown'\n",
        "        else:\n",
        "            # Modo con prompts: sam2_prompts_{tamaño}_{estrategia}\n",
        "            # Ejemplos: sam2_prompts_base_plus_saliency_moderate\n",
        "            #           sam2_prompts_tiny_grid_central_conservative\n",
        "\n",
        "            # Eliminar prefijo \"sam2_prompts_\"\n",
        "            sin_prefijo = config.replace('sam2_prompts_', '')\n",
        "\n",
        "            # Eliminar el tamaño del modelo\n",
        "            for tamano in ['base_plus_', 'tiny_', 'small_', 'large_']:\n",
        "                if sin_prefijo.startswith(tamano):\n",
        "                    return sin_prefijo.replace(tamano, '', 1)\n",
        "\n",
        "            return sin_prefijo\n",
        "\n",
        "        return 'unknown'\n",
        "\n",
        "    def _extraer_factores(self):\n",
        "        \"\"\"Extrae los factores de cada configuración según el modelo.\"\"\"\n",
        "        logger.info(\"Extrayendo factores de configuraciones...\")\n",
        "\n",
        "        for modelo, extractores in self.FACTORES_MODELO.items():\n",
        "            mask = self.df['modelo'] == modelo\n",
        "            if not mask.any():\n",
        "                continue\n",
        "\n",
        "            for factor, extractor in extractores.items():\n",
        "                col_name = f'factor_{factor}'\n",
        "                self.df.loc[mask, col_name] = self.df.loc[mask, 'config_codigo'].apply(\n",
        "                    lambda x: self._safe_extract(extractor, x)\n",
        "                )\n",
        "\n",
        "        # Logging de factores extraídos\n",
        "        for modelo in self.df['modelo'].unique():\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "            factores = [c for c in df_modelo.columns if c.startswith('factor_')]\n",
        "            for f in factores:\n",
        "                valores = df_modelo[f].dropna().unique()\n",
        "                if len(valores) > 0:\n",
        "                    logger.info(f\"  {modelo}.{f}: {sorted(valores)}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _safe_extract(extractor, valor):\n",
        "        \"\"\"Extrae un factor de forma segura.\"\"\"\n",
        "        try:\n",
        "            return extractor(valor)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    # =========================================================================\n",
        "    # RANKING DE CONFIGURACIONES\n",
        "    # =========================================================================\n",
        "    def calcular_ranking_global(self, top_n: int = 30) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula el ranking global de configuraciones por IoU.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        top_n : int\n",
        "            Número de configuraciones top a incluir\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Ranking de configuraciones\n",
        "        \"\"\"\n",
        "        logger.info(f\"Calculando ranking global TOP-{top_n}...\")\n",
        "\n",
        "        # Agrupar por configuración\n",
        "        ranking = self.df.groupby(['modelo', 'config_codigo']).agg({\n",
        "            'iou': ['mean', 'std', 'min', 'max', 'count'],\n",
        "            'dice': 'mean',\n",
        "            'precision': 'mean',\n",
        "            'recall': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Aplanar columnas\n",
        "        ranking.columns = [\n",
        "            'modelo', 'config_codigo',\n",
        "            'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n_fotos',\n",
        "            'dice_mean', 'precision_mean', 'recall_mean'\n",
        "        ]\n",
        "\n",
        "        # Calcular coeficiente de variación\n",
        "        ranking['iou_cv'] = ranking['iou_std'] / ranking['iou_mean']\n",
        "\n",
        "        # Ordenar por IoU medio descendente\n",
        "        ranking = ranking.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        # Agregar posición en ranking\n",
        "        ranking['posicion'] = range(1, len(ranking) + 1)\n",
        "\n",
        "        # Guardar ranking completo\n",
        "        self.resultados['ranking_global'] = ranking.copy()\n",
        "\n",
        "        # Retornar top N\n",
        "        return ranking.head(top_n)\n",
        "\n",
        "    def calcular_ranking_por_modelo(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Calcula la mejor configuración por modelo.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Mejor configuración de cada modelo\n",
        "        \"\"\"\n",
        "        logger.info(\"Calculando mejor configuración por modelo...\")\n",
        "\n",
        "        mejores = []\n",
        "\n",
        "        for modelo in self.df['modelo'].unique():\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "\n",
        "            # Mejor por IoU medio\n",
        "            stats_config = df_modelo.groupby('config_codigo').agg({\n",
        "                'iou': ['mean', 'std', 'min', 'max', 'count']\n",
        "            }).reset_index()\n",
        "            stats_config.columns = ['config_codigo', 'iou_mean', 'iou_std',\n",
        "                                    'iou_min', 'iou_max', 'n_fotos']\n",
        "\n",
        "            mejor = stats_config.loc[stats_config['iou_mean'].idxmax()]\n",
        "\n",
        "            mejores.append({\n",
        "                'modelo': modelo,\n",
        "                'mejor_config': mejor['config_codigo'],\n",
        "                'iou_mean': mejor['iou_mean'],\n",
        "                'iou_std': mejor['iou_std'],\n",
        "                'iou_min': mejor['iou_min'],\n",
        "                'iou_max': mejor['iou_max'],\n",
        "                'n_fotos': int(mejor['n_fotos']),\n",
        "                'n_configuraciones_total': df_modelo['config_codigo'].nunique()\n",
        "            })\n",
        "\n",
        "        resultado = pd.DataFrame(mejores)\n",
        "        resultado = resultado.sort_values('iou_mean', ascending=False)\n",
        "\n",
        "        self.resultados['ranking_por_modelo'] = resultado\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    # =========================================================================\n",
        "    # ANÁLISIS FACTORIAL POR MODELO\n",
        "    # =========================================================================\n",
        "    def _calcular_anova(self, df: pd.DataFrame, factor: str,\n",
        "                        metrica: str = 'iou') -> ResultadoANOVA:\n",
        "        \"\"\"\n",
        "        Calcula ANOVA de un factor.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Datos del modelo\n",
        "        factor : str\n",
        "            Nombre del factor (columna)\n",
        "        metrica : str\n",
        "            Métrica a analizar\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        ResultadoANOVA\n",
        "            Resultado del análisis\n",
        "        \"\"\"\n",
        "        col_factor = f'factor_{factor}' if not factor.startswith('factor_') else factor\n",
        "\n",
        "        if col_factor not in df.columns:\n",
        "            return None\n",
        "\n",
        "        # Filtrar NaN\n",
        "        df_clean = df[[col_factor, metrica]].dropna()\n",
        "\n",
        "        if df_clean[col_factor].nunique() < 2:\n",
        "            return None\n",
        "\n",
        "        # Preparar grupos\n",
        "        grupos = [grupo[metrica].values for _, grupo in df_clean.groupby(col_factor)]\n",
        "\n",
        "        if len(grupos) < 2:\n",
        "            return None\n",
        "\n",
        "        # ANOVA\n",
        "        try:\n",
        "            f_stat, p_valor = f_oneway(*grupos)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "        # Calcular eta-squared y omega-squared\n",
        "        n_total = len(df_clean)\n",
        "        n_grupos = len(grupos)\n",
        "\n",
        "        # Suma de cuadrados\n",
        "        grand_mean = df_clean[metrica].mean()\n",
        "        ss_between = sum(len(g) * (g.mean() - grand_mean)**2 for g in grupos)\n",
        "        ss_total = ((df_clean[metrica] - grand_mean)**2).sum()\n",
        "        ss_within = ss_total - ss_between\n",
        "\n",
        "        # Eta-squared\n",
        "        eta_sq = ss_between / ss_total if ss_total > 0 else 0\n",
        "\n",
        "        # Omega-squared (menos sesgado)\n",
        "        df_between = n_grupos - 1\n",
        "        ms_within = ss_within / (n_total - n_grupos) if (n_total - n_grupos) > 0 else 0\n",
        "        omega_sq = (ss_between - df_between * ms_within) / (ss_total + ms_within)\n",
        "        omega_sq = max(0, omega_sq)  # No puede ser negativo\n",
        "\n",
        "        # Interpretación del tamaño del efecto\n",
        "        if eta_sq < 0.01:\n",
        "            interpretacion = 'insignificante'\n",
        "        elif eta_sq < 0.06:\n",
        "            interpretacion = 'pequeno'\n",
        "        elif eta_sq < 0.14:\n",
        "            interpretacion = 'mediano'\n",
        "        else:\n",
        "            interpretacion = 'grande'\n",
        "\n",
        "        return ResultadoANOVA(\n",
        "            factor=factor,\n",
        "            f_statistic=float(f_stat),\n",
        "            p_valor=float(p_valor),\n",
        "            eta_squared=float(eta_sq),\n",
        "            omega_squared=float(omega_sq),\n",
        "            n_grupos=n_grupos,\n",
        "            n_total=n_total,\n",
        "            significativo=p_valor < 0.05,\n",
        "            interpretacion_efecto=interpretacion\n",
        "        )\n",
        "\n",
        "    def _calcular_posthoc_tukey(self, df: pd.DataFrame, factor: str,\n",
        "                                 metrica: str = 'iou') -> List[ResultadoPostHoc]:\n",
        "        \"\"\"\n",
        "        Calcula comparaciones post-hoc Tukey HSD.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        df : pd.DataFrame\n",
        "            Datos del modelo\n",
        "        factor : str\n",
        "            Nombre del factor\n",
        "        metrica : str\n",
        "            Métrica a analizar\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        List[ResultadoPostHoc]\n",
        "            Lista de comparaciones pareadas\n",
        "        \"\"\"\n",
        "        col_factor = f'factor_{factor}' if not factor.startswith('factor_') else factor\n",
        "\n",
        "        if col_factor not in df.columns:\n",
        "            return []\n",
        "\n",
        "        df_clean = df[[col_factor, metrica]].dropna()\n",
        "\n",
        "        if df_clean[col_factor].nunique() < 2:\n",
        "            return []\n",
        "\n",
        "        # Preparar datos para Tukey\n",
        "        grupos = df_clean.groupby(col_factor)[metrica].apply(list).to_dict()\n",
        "        nombres = list(grupos.keys())\n",
        "        datos = [np.array(grupos[n]) for n in nombres]\n",
        "\n",
        "        if len(datos) < 2:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            resultado_tukey = tukey_hsd(*datos)\n",
        "        except Exception:\n",
        "            return []\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        # Extraer comparaciones\n",
        "        for i in range(len(nombres)):\n",
        "            for j in range(i + 1, len(nombres)):\n",
        "                diff = np.mean(datos[i]) - np.mean(datos[j])\n",
        "\n",
        "                # Obtener p-valor de la matriz\n",
        "                p_val = resultado_tukey.pvalue[i, j]\n",
        "\n",
        "                # Intervalo de confianza aproximado\n",
        "                ci = resultado_tukey.confidence_interval(confidence_level=0.95)\n",
        "                ci_low = ci.low[i, j]\n",
        "                ci_high = ci.high[i, j]\n",
        "\n",
        "                resultados.append(ResultadoPostHoc(\n",
        "                    grupo_1=str(nombres[i]),\n",
        "                    grupo_2=str(nombres[j]),\n",
        "                    diferencia_medias=float(diff),\n",
        "                    p_valor=float(p_val),\n",
        "                    significativo=p_val < 0.05,\n",
        "                    ic_inferior=float(ci_low),\n",
        "                    ic_superior=float(ci_high)\n",
        "                ))\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_bodypix(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para BodyPix.\n",
        "\n",
        "        Factores:\n",
        "        - multiplicador: 050, 075\n",
        "        - nivel_sensibilidad: ultra_sensible, sensibilidad_alta, sensibilidad_media, baja_sensibilidad\n",
        "        - umbral: valores numéricos\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando BodyPix...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'bodypix'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'bodypix',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Estadísticas por factor\n",
        "        for factor in ['multiplicador', 'nivel_sensibilidad', 'umbral']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            # ANOVA\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            # Estadísticas por nivel\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            # Post-hoc si es significativo\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Interacción multiplicador × nivel_sensibilidad\n",
        "        if 'factor_multiplicador' in df_modelo.columns and 'factor_nivel_sensibilidad' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_multiplicador', 'factor_nivel_sensibilidad']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['multiplicador', 'nivel_sensibilidad', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_multiplicador_sensibilidad'] = interaccion.to_dict('records')\n",
        "\n",
        "        # Mejor configuración\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_mask2former(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para Mask2Former.\n",
        "\n",
        "        Factores:\n",
        "        - backbone: base, large, tiny\n",
        "        - dataset: ade, coco\n",
        "        - sensibilidad: varios niveles\n",
        "\n",
        "        Hallazgo crítico esperado: COCO produce IoU=0 en muchas configuraciones\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando Mask2Former...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'mask2former'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'mask2former',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Detectar configuraciones con IoU=0 (hallazgo crítico)\n",
        "        configs_cero = df_modelo.groupby('config_codigo')['iou'].mean()\n",
        "        configs_cero = configs_cero[configs_cero == 0].index.tolist()\n",
        "        resultados['configuraciones_iou_cero'] = configs_cero\n",
        "        resultados['n_configs_iou_cero'] = len(configs_cero)\n",
        "\n",
        "        # Análisis por factor\n",
        "        for factor in ['backbone', 'dataset', 'sensibilidad']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Análisis específico ADE vs COCO\n",
        "        if 'factor_dataset' in df_modelo.columns:\n",
        "            comparacion_dataset = df_modelo.groupby('factor_dataset').agg({\n",
        "                'iou': ['mean', 'std', 'min', 'max', 'count'],\n",
        "                'config_codigo': 'nunique'\n",
        "            }).reset_index()\n",
        "            comparacion_dataset.columns = [\n",
        "                'dataset', 'iou_mean', 'iou_std', 'iou_min', 'iou_max',\n",
        "                'n_evaluaciones', 'n_configuraciones'\n",
        "            ]\n",
        "            resultados['comparacion_ade_coco'] = comparacion_dataset.to_dict('records')\n",
        "\n",
        "            # Test específico ADE vs COCO\n",
        "            ade_data = df_modelo[df_modelo['factor_dataset'] == 'ade']['iou']\n",
        "            coco_data = df_modelo[df_modelo['factor_dataset'] == 'coco']['iou']\n",
        "\n",
        "            if len(ade_data) > 0 and len(coco_data) > 0:\n",
        "                t_stat, p_val = stats.ttest_ind(ade_data, coco_data)\n",
        "                cohens_d = (ade_data.mean() - coco_data.mean()) / np.sqrt(\n",
        "                    (ade_data.std()**2 + coco_data.std()**2) / 2\n",
        "                )\n",
        "                resultados['test_ade_vs_coco'] = {\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'ade_mean': float(ade_data.mean()),\n",
        "                    'coco_mean': float(coco_data.mean()),\n",
        "                    'diferencia': float(ade_data.mean() - coco_data.mean())\n",
        "                }\n",
        "\n",
        "        # Mejor configuración\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_oneformer(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para OneFormer.\n",
        "\n",
        "        Factores:\n",
        "        - dataset: ade20k, coco\n",
        "        - backbone: swin, tiny\n",
        "        - task_type: instance, panoptic, semantic\n",
        "        - umbral: t040, t060, t075, t085\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando OneFormer...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'oneformer'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'oneformer',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Análisis por factor\n",
        "        for factor in ['dataset', 'backbone', 'task_type', 'umbral']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Interacción dataset × backbone × task_type\n",
        "        if all(f'factor_{f}' in df_modelo.columns for f in ['dataset', 'backbone', 'task_type']):\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_dataset', 'factor_backbone', 'factor_task_type']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['dataset', 'backbone', 'task_type', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_completa'] = interaccion.to_dict('records')\n",
        "\n",
        "        # Análisis de sensibilidad al umbral por task_type\n",
        "        if 'factor_task_type' in df_modelo.columns and 'factor_umbral' in df_modelo.columns:\n",
        "            sensibilidad_umbral = df_modelo.groupby(\n",
        "                ['factor_task_type', 'factor_umbral']\n",
        "            )['iou'].agg(['mean', 'std']).reset_index()\n",
        "            sensibilidad_umbral.columns = ['task_type', 'umbral', 'iou_mean', 'iou_std']\n",
        "            resultados['sensibilidad_umbral_por_task'] = sensibilidad_umbral.to_dict('records')\n",
        "\n",
        "        # Mejor configuración\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_sam2(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para SAM2.\n",
        "\n",
        "        Factores:\n",
        "        - modo: auto, prompts\n",
        "        - tamano: tiny, small, base_plus, large\n",
        "        - estrategia: varias según el modo\n",
        "\n",
        "        Categorías de estrategias de prompts:\n",
        "        - Basadas en saliencia: saliency_conservative, saliency_moderate\n",
        "        - Basadas en grid: grid_central_conservative, grid_central_moderate, grid_central_aggressive\n",
        "        - Combinadas: combined_moderate, combined_aggressive\n",
        "        - Basadas en bbox: bbox_heuristic\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando SAM2...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'sam2'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'sam2',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Análisis por factor principal\n",
        "        for factor in ['modo', 'tamano']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Análisis detallado: auto vs prompts\n",
        "        if 'factor_modo' in df_modelo.columns:\n",
        "            auto_data = df_modelo[df_modelo['factor_modo'] == 'auto']['iou']\n",
        "            prompts_data = df_modelo[df_modelo['factor_modo'] == 'prompts']['iou']\n",
        "\n",
        "            if len(auto_data) > 0 and len(prompts_data) > 0:\n",
        "                t_stat, p_val = stats.ttest_ind(auto_data, prompts_data)\n",
        "                cohens_d = (prompts_data.mean() - auto_data.mean()) / np.sqrt(\n",
        "                    (auto_data.std()**2 + prompts_data.std()**2) / 2\n",
        "                )\n",
        "                resultados['comparacion_auto_prompts'] = {\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'auto_mean': float(auto_data.mean()),\n",
        "                    'auto_std': float(auto_data.std()),\n",
        "                    'prompts_mean': float(prompts_data.mean()),\n",
        "                    'prompts_std': float(prompts_data.std()),\n",
        "                    'diferencia': float(prompts_data.mean() - auto_data.mean()),\n",
        "                    'mejora_porcentual': float((prompts_data.mean() - auto_data.mean()) / auto_data.mean() * 100) if auto_data.mean() > 0 else None\n",
        "                }\n",
        "\n",
        "        # Análisis de estrategias de prompts\n",
        "        df_prompts = df_modelo[df_modelo['factor_modo'] == 'prompts'].copy()\n",
        "        if len(df_prompts) > 0 and 'factor_estrategia' in df_prompts.columns:\n",
        "            stats_estrategia = df_prompts.groupby('factor_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_estrategia.columns = ['estrategia', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            stats_estrategia = stats_estrategia.sort_values('iou_mean', ascending=False)\n",
        "            resultados['estrategias_prompts'] = stats_estrategia.to_dict('records')\n",
        "\n",
        "            # ANOVA de estrategias\n",
        "            anova_estrategia = self._calcular_anova(df_prompts, 'estrategia')\n",
        "            if anova_estrategia:\n",
        "                resultados['anova_estrategias'] = asdict(anova_estrategia)\n",
        "\n",
        "            # Categorizar estrategias por tipo\n",
        "            def categorizar_estrategia(est):\n",
        "                if 'saliency' in est:\n",
        "                    return 'saliencia'\n",
        "                elif 'grid' in est:\n",
        "                    return 'grid'\n",
        "                elif 'combined' in est:\n",
        "                    return 'combinada'\n",
        "                elif 'bbox' in est:\n",
        "                    return 'bbox'\n",
        "                return 'otra'\n",
        "\n",
        "            df_prompts['categoria_estrategia'] = df_prompts['factor_estrategia'].apply(categorizar_estrategia)\n",
        "\n",
        "            # Estadísticas por categoría\n",
        "            stats_categoria = df_prompts.groupby('categoria_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_categoria.columns = ['categoria', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            stats_categoria = stats_categoria.sort_values('iou_mean', ascending=False)\n",
        "            resultados['categorias_estrategia'] = stats_categoria.to_dict('records')\n",
        "\n",
        "            # ANOVA por categoría\n",
        "            anova_categoria = self._calcular_anova(df_prompts, 'categoria_estrategia')\n",
        "            if anova_categoria:\n",
        "                resultados['anova_categorias'] = asdict(anova_categoria)\n",
        "\n",
        "        # Análisis modo automático por configuración\n",
        "        df_auto = df_modelo[df_modelo['factor_modo'] == 'auto'].copy()\n",
        "        if len(df_auto) > 0 and 'factor_estrategia' in df_auto.columns:\n",
        "            stats_auto = df_auto.groupby('factor_estrategia')['iou'].agg([\n",
        "                'mean', 'std', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_auto.columns = ['config_auto', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['configuraciones_auto'] = stats_auto.to_dict('records')\n",
        "\n",
        "        # Interacción modo × tamaño\n",
        "        if 'factor_modo' in df_modelo.columns and 'factor_tamano' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_modo', 'factor_tamano']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['modo', 'tamano', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_modo_tamano'] = interaccion.to_dict('records')\n",
        "\n",
        "        # Análisis por tamaño SOLO en modo prompts (donde importa más)\n",
        "        if len(df_prompts) > 0 and 'factor_tamano' in df_prompts.columns:\n",
        "            stats_tamano_prompts = df_prompts.groupby('factor_tamano')['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_tamano_prompts.columns = ['tamano', 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "            resultados['tamano_en_prompts'] = stats_tamano_prompts.to_dict('records')\n",
        "\n",
        "            # ANOVA tamaño en prompts\n",
        "            anova_tamano_prompts = self._calcular_anova(df_prompts, 'tamano')\n",
        "            if anova_tamano_prompts:\n",
        "                resultados['anova_tamano_prompts'] = asdict(anova_tamano_prompts)\n",
        "\n",
        "        # Análisis cruzado: mejor estrategia por tamaño\n",
        "        if len(df_prompts) > 0:\n",
        "            mejor_por_tamano = []\n",
        "            for tamano in df_prompts['factor_tamano'].unique():\n",
        "                df_tam = df_prompts[df_prompts['factor_tamano'] == tamano]\n",
        "                if len(df_tam) > 0:\n",
        "                    mejor_est = df_tam.groupby('factor_estrategia')['iou'].mean().idxmax()\n",
        "                    mejor_iou = df_tam.groupby('factor_estrategia')['iou'].mean().max()\n",
        "                    mejor_por_tamano.append({\n",
        "                        'tamano': tamano,\n",
        "                        'mejor_estrategia': mejor_est,\n",
        "                        'iou_mean': float(mejor_iou)\n",
        "                    })\n",
        "            resultados['mejor_estrategia_por_tamano'] = mejor_por_tamano\n",
        "\n",
        "        # Mejor configuración global\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        # Hallazgo clave: saliencia como mejor enfoque\n",
        "        if 'estrategias_prompts' in resultados and len(resultados['estrategias_prompts']) > 0:\n",
        "            top_estrategia = resultados['estrategias_prompts'][0]\n",
        "            resultados['hallazgo_clave'] = {\n",
        "                'mejor_estrategia': top_estrategia['estrategia'],\n",
        "                'iou': top_estrategia['iou_mean'],\n",
        "                'es_saliencia': 'saliency' in top_estrategia['estrategia'],\n",
        "                'interpretacion': 'Las estrategias basadas en saliencia visual superan significativamente a otras aproximaciones, validando el uso de conocimiento de dominio fotográfico.'\n",
        "            }\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def analizar_yolov8(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Análisis factorial completo para YOLOv8.\n",
        "\n",
        "        Factores:\n",
        "        - tamano: nano, small, medium, large, xlarge\n",
        "        - config_sensibilidad: balanced, fast, quality, sensitive\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados del análisis\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando YOLOv8...\")\n",
        "\n",
        "        df_modelo = self.df[self.df['modelo'] == 'yolov8'].copy()\n",
        "\n",
        "        resultados = {\n",
        "            'modelo': 'yolov8',\n",
        "            'n_evaluaciones': len(df_modelo),\n",
        "            'n_configuraciones': df_modelo['config_codigo'].nunique(),\n",
        "            'factores': {}\n",
        "        }\n",
        "\n",
        "        # Análisis por factor\n",
        "        for factor in ['tamano', 'config_sensibilidad']:\n",
        "            col = f'factor_{factor}'\n",
        "            if col not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            anova = self._calcular_anova(df_modelo, factor)\n",
        "\n",
        "            stats_nivel = df_modelo.groupby(col)['iou'].agg([\n",
        "                'mean', 'std', 'min', 'max', 'count'\n",
        "            ]).reset_index()\n",
        "            stats_nivel.columns = [factor, 'iou_mean', 'iou_std', 'iou_min', 'iou_max', 'n']\n",
        "\n",
        "            # Ordenar tamaños de forma lógica\n",
        "            if factor == 'tamano':\n",
        "                orden_tamano = ['nano', 'small', 'medium', 'large', 'xlarge']\n",
        "                stats_nivel['orden'] = stats_nivel[factor].map(\n",
        "                    {t: i for i, t in enumerate(orden_tamano)}\n",
        "                )\n",
        "                stats_nivel = stats_nivel.sort_values('orden').drop('orden', axis=1)\n",
        "\n",
        "            posthoc = []\n",
        "            if anova and anova.significativo:\n",
        "                posthoc = self._calcular_posthoc_tukey(df_modelo, factor)\n",
        "\n",
        "            resultados['factores'][factor] = {\n",
        "                'anova': asdict(anova) if anova else None,\n",
        "                'estadisticas_nivel': stats_nivel.to_dict('records'),\n",
        "                'posthoc': [asdict(p) for p in posthoc]\n",
        "            }\n",
        "\n",
        "        # Interacción tamaño × sensibilidad\n",
        "        if 'factor_tamano' in df_modelo.columns and 'factor_config_sensibilidad' in df_modelo.columns:\n",
        "            interaccion = df_modelo.groupby(\n",
        "                ['factor_tamano', 'factor_config_sensibilidad']\n",
        "            )['iou'].agg(['mean', 'std', 'count']).reset_index()\n",
        "            interaccion.columns = ['tamano', 'config_sensibilidad', 'iou_mean', 'iou_std', 'n']\n",
        "            resultados['interaccion_tamano_sensibilidad'] = interaccion.to_dict('records')\n",
        "\n",
        "        # Análisis de punto de inflexión (rendimientos decrecientes)\n",
        "        if 'factor_tamano' in df_modelo.columns:\n",
        "            orden_tamano = ['nano', 'small', 'medium', 'large', 'xlarge']\n",
        "            iou_por_tamano = df_modelo.groupby('factor_tamano')['iou'].mean()\n",
        "\n",
        "            mejoras = []\n",
        "            for i in range(1, len(orden_tamano)):\n",
        "                if orden_tamano[i] in iou_por_tamano.index and orden_tamano[i-1] in iou_por_tamano.index:\n",
        "                    mejora = iou_por_tamano[orden_tamano[i]] - iou_por_tamano[orden_tamano[i-1]]\n",
        "                    mejoras.append({\n",
        "                        'de': orden_tamano[i-1],\n",
        "                        'a': orden_tamano[i],\n",
        "                        'mejora_iou': float(mejora),\n",
        "                        'mejora_porcentual': float(mejora / iou_por_tamano[orden_tamano[i-1]] * 100)\n",
        "                    })\n",
        "\n",
        "            resultados['analisis_rendimientos_decrecientes'] = mejoras\n",
        "\n",
        "        # Mejor configuración\n",
        "        mejor = df_modelo.groupby('config_codigo')['iou'].mean().idxmax()\n",
        "        resultados['mejor_configuracion'] = mejor\n",
        "        resultados['iou_mejor'] = float(df_modelo.groupby('config_codigo')['iou'].mean().max())\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    # =========================================================================\n",
        "    # COMPARACIÓN DE PARADIGMAS ARQUITECTÓNICOS\n",
        "    # =========================================================================\n",
        "    def comparar_paradigmas(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Compara los paradigmas arquitectónicos.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Resultados de la comparación\n",
        "        \"\"\"\n",
        "        logger.info(\"Comparando paradigmas arquitectónicos...\")\n",
        "\n",
        "        resultados = {\n",
        "            'paradigmas': {},\n",
        "            'comparaciones_pareadas': []\n",
        "        }\n",
        "\n",
        "        # Asignar paradigma a cada evaluación\n",
        "        def asignar_paradigma(modelo):\n",
        "            for paradigma, modelos in self.PARADIGMAS.items():\n",
        "                if modelo in modelos:\n",
        "                    return paradigma\n",
        "            return 'unknown'\n",
        "\n",
        "        self.df['paradigma'] = self.df['modelo'].apply(asignar_paradigma)\n",
        "\n",
        "        # Estadísticas por paradigma\n",
        "        for paradigma in self.PARADIGMAS.keys():\n",
        "            df_paradigma = self.df[self.df['paradigma'] == paradigma]\n",
        "            if len(df_paradigma) == 0:\n",
        "                continue\n",
        "\n",
        "            resultados['paradigmas'][paradigma] = {\n",
        "                'modelos': self.PARADIGMAS[paradigma],\n",
        "                'n_evaluaciones': len(df_paradigma),\n",
        "                'n_configuraciones': df_paradigma['config_codigo'].nunique(),\n",
        "                'iou_mean': float(df_paradigma['iou'].mean()),\n",
        "                'iou_std': float(df_paradigma['iou'].std()),\n",
        "                'iou_median': float(df_paradigma['iou'].median()),\n",
        "                'iou_min': float(df_paradigma['iou'].min()),\n",
        "                'iou_max': float(df_paradigma['iou'].max())\n",
        "            }\n",
        "\n",
        "        # ANOVA entre paradigmas\n",
        "        anova_paradigma = self._calcular_anova(self.df, 'paradigma')\n",
        "        if anova_paradigma:\n",
        "            resultados['anova_paradigmas'] = asdict(anova_paradigma)\n",
        "\n",
        "        # Comparaciones pareadas entre paradigmas\n",
        "        paradigmas_lista = list(self.PARADIGMAS.keys())\n",
        "        for i in range(len(paradigmas_lista)):\n",
        "            for j in range(i + 1, len(paradigmas_lista)):\n",
        "                p1, p2 = paradigmas_lista[i], paradigmas_lista[j]\n",
        "\n",
        "                datos_p1 = self.df[self.df['paradigma'] == p1]['iou']\n",
        "                datos_p2 = self.df[self.df['paradigma'] == p2]['iou']\n",
        "\n",
        "                if len(datos_p1) == 0 or len(datos_p2) == 0:\n",
        "                    continue\n",
        "\n",
        "                t_stat, p_val = stats.ttest_ind(datos_p1, datos_p2)\n",
        "\n",
        "                # Cohen's d\n",
        "                pooled_std = np.sqrt((datos_p1.std()**2 + datos_p2.std()**2) / 2)\n",
        "                cohens_d = (datos_p1.mean() - datos_p2.mean()) / pooled_std if pooled_std > 0 else 0\n",
        "\n",
        "                resultados['comparaciones_pareadas'].append({\n",
        "                    'paradigma_1': p1,\n",
        "                    'paradigma_2': p2,\n",
        "                    'media_1': float(datos_p1.mean()),\n",
        "                    'media_2': float(datos_p2.mean()),\n",
        "                    'diferencia': float(datos_p1.mean() - datos_p2.mean()),\n",
        "                    't_statistic': float(t_stat),\n",
        "                    'p_valor': float(p_val),\n",
        "                    'cohens_d': float(cohens_d),\n",
        "                    'significativo': p_val < 0.05\n",
        "                })\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    # =========================================================================\n",
        "    # ANÁLISIS DE SENSIBILIDAD GLOBAL\n",
        "    # =========================================================================\n",
        "    def analizar_sensibilidad_umbrales(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Analiza la sensibilidad a umbrales de confianza para todos los modelos.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Resultados de sensibilidad\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando sensibilidad a umbrales...\")\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        # Modelos con umbrales explícitos\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer']:\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "\n",
        "            col_umbral = f'factor_umbral' if modelo == 'oneformer' else f'factor_sensibilidad'\n",
        "            if modelo == 'bodypix':\n",
        "                col_umbral = 'factor_umbral'\n",
        "\n",
        "            if col_umbral not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            for umbral in df_modelo[col_umbral].dropna().unique():\n",
        "                mask = df_modelo[col_umbral] == umbral\n",
        "                datos = df_modelo.loc[mask, 'iou']\n",
        "\n",
        "                resultados.append({\n",
        "                    'modelo': modelo,\n",
        "                    'umbral': umbral,\n",
        "                    'iou_mean': float(datos.mean()),\n",
        "                    'iou_std': float(datos.std()),\n",
        "                    'iou_min': float(datos.min()),\n",
        "                    'iou_max': float(datos.max()),\n",
        "                    'n': len(datos)\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(resultados)\n",
        "\n",
        "    def analizar_sensibilidad_tamano(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Analiza la sensibilidad al tamaño del modelo.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        pd.DataFrame\n",
        "            Resultados de sensibilidad al tamaño\n",
        "        \"\"\"\n",
        "        logger.info(\"Analizando sensibilidad al tamaño del modelo...\")\n",
        "\n",
        "        resultados = []\n",
        "\n",
        "        # Modelos con variantes de tamaño\n",
        "        for modelo in ['sam2', 'yolov8']:\n",
        "            df_modelo = self.df[self.df['modelo'] == modelo]\n",
        "            col_tamano = 'factor_tamano'\n",
        "\n",
        "            if col_tamano not in df_modelo.columns:\n",
        "                continue\n",
        "\n",
        "            for tamano in df_modelo[col_tamano].dropna().unique():\n",
        "                mask = df_modelo[col_tamano] == tamano\n",
        "                datos = df_modelo.loc[mask, 'iou']\n",
        "\n",
        "                resultados.append({\n",
        "                    'modelo': modelo,\n",
        "                    'tamano': tamano,\n",
        "                    'iou_mean': float(datos.mean()),\n",
        "                    'iou_std': float(datos.std()),\n",
        "                    'iou_min': float(datos.min()),\n",
        "                    'iou_max': float(datos.max()),\n",
        "                    'n': len(datos)\n",
        "                })\n",
        "\n",
        "        return pd.DataFrame(resultados)\n",
        "\n",
        "    # =========================================================================\n",
        "    # EJECUCIÓN COMPLETA\n",
        "    # =========================================================================\n",
        "    def ejecutar_analisis_completo(self) -> Dict:\n",
        "        \"\"\"\n",
        "        Ejecuta todos los análisis de la Fase 2D.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Dict\n",
        "            Todos los resultados\n",
        "        \"\"\"\n",
        "        logger.info(\"=\"*60)\n",
        "        logger.info(\"INICIANDO ANÁLISIS FASE 2D: CONFIGURACIONES\")\n",
        "        logger.info(\"=\"*60)\n",
        "\n",
        "        # 1. Rankings\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"1. Calculando rankings...\")\n",
        "        ranking_global = self.calcular_ranking_global(top_n=30)\n",
        "        ranking_modelo = self.calcular_ranking_por_modelo()\n",
        "\n",
        "        # 2. Análisis por modelo\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"2. Análisis factorial por modelo...\")\n",
        "        self.resultados['bodypix'] = self.analizar_bodypix()\n",
        "        self.resultados['mask2former'] = self.analizar_mask2former()\n",
        "        self.resultados['oneformer'] = self.analizar_oneformer()\n",
        "        self.resultados['sam2'] = self.analizar_sam2()\n",
        "        self.resultados['yolov8'] = self.analizar_yolov8()\n",
        "\n",
        "        # 3. Comparación de paradigmas\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"3. Comparando paradigmas arquitectónicos...\")\n",
        "        self.resultados['paradigmas'] = self.comparar_paradigmas()\n",
        "\n",
        "        # 4. Análisis de sensibilidad\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"4. Análisis de sensibilidad...\")\n",
        "        self.resultados['sensibilidad_umbrales'] = self.analizar_sensibilidad_umbrales()\n",
        "        self.resultados['sensibilidad_tamano'] = self.analizar_sensibilidad_tamano()\n",
        "\n",
        "        # 5. Resumen de hallazgos\n",
        "        logger.info(\"\\n\" + \"-\"*40)\n",
        "        logger.info(\"5. Generando resumen...\")\n",
        "        self.resultados['resumen'] = self._generar_resumen()\n",
        "\n",
        "        logger.info(\"\\n\" + \"=\"*60)\n",
        "        logger.info(\"ANÁLISIS FASE 2D COMPLETADO\")\n",
        "        logger.info(\"=\"*60)\n",
        "\n",
        "        return self.resultados\n",
        "\n",
        "    def _generar_resumen(self) -> Dict:\n",
        "        \"\"\"Genera un resumen de los hallazgos principales.\"\"\"\n",
        "\n",
        "        resumen = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'total_evaluaciones': len(self.df),\n",
        "            'total_configuraciones': self.df['config_codigo'].nunique(),\n",
        "            'total_fotografias': self.df['codigo_foto'].nunique(),\n",
        "            'modelos_analizados': self.df['modelo'].unique().tolist()\n",
        "        }\n",
        "\n",
        "        # Mejor modelo global\n",
        "        mejor_por_modelo = self.resultados.get('ranking_por_modelo')\n",
        "        if mejor_por_modelo is not None and len(mejor_por_modelo) > 0:\n",
        "            mejor = mejor_por_modelo.iloc[0]\n",
        "            resumen['mejor_modelo_global'] = {\n",
        "                'modelo': mejor['modelo'],\n",
        "                'configuracion': mejor['mejor_config'],\n",
        "                'iou_mean': float(mejor['iou_mean'])\n",
        "            }\n",
        "\n",
        "        # Hallazgos por modelo\n",
        "        resumen['hallazgos_modelo'] = {}\n",
        "\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                res = self.resultados[modelo]\n",
        "                hallazgo = {\n",
        "                    'mejor_configuracion': res.get('mejor_configuracion'),\n",
        "                    'iou_mejor': res.get('iou_mejor')\n",
        "                }\n",
        "\n",
        "                # Factores significativos\n",
        "                factores_sig = []\n",
        "                for factor, datos in res.get('factores', {}).items():\n",
        "                    if datos.get('anova') and datos['anova'].get('significativo'):\n",
        "                        factores_sig.append({\n",
        "                            'factor': factor,\n",
        "                            'eta_squared': datos['anova']['eta_squared'],\n",
        "                            'interpretacion': datos['anova']['interpretacion_efecto']\n",
        "                        })\n",
        "                hallazgo['factores_significativos'] = factores_sig\n",
        "\n",
        "                resumen['hallazgos_modelo'][modelo] = hallazgo\n",
        "\n",
        "        return resumen\n",
        "\n",
        "    # =========================================================================\n",
        "    # EXPORTACIÓN DE RESULTADOS\n",
        "    # =========================================================================\n",
        "    @staticmethod\n",
        "    def _convertir_tipos_json(obj):\n",
        "        \"\"\"Convierte tipos numpy a tipos nativos de Python para JSON.\"\"\"\n",
        "        if isinstance(obj, dict):\n",
        "            return {k: AnalizadorConfiguraciones._convertir_tipos_json(v) for k, v in obj.items()}\n",
        "        elif isinstance(obj, list):\n",
        "            return [AnalizadorConfiguraciones._convertir_tipos_json(item) for item in obj]\n",
        "        elif isinstance(obj, (np.integer, np.int64, np.int32)):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, (np.floating, np.float64, np.float32)):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, (np.bool_, bool)):\n",
        "            return bool(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif pd.isna(obj):\n",
        "            return None\n",
        "        return obj\n",
        "\n",
        "    def exportar_resultados(self):\n",
        "        \"\"\"Exporta todos los resultados a archivos.\"\"\"\n",
        "\n",
        "        logger.info(\"Exportando resultados...\")\n",
        "        self.rutas.crear_directorios()\n",
        "\n",
        "        # 1. Ranking global\n",
        "        if 'ranking_global' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'ranking_global_top30.csv')\n",
        "            self.resultados['ranking_global'].head(30).to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 2. Ranking por modelo\n",
        "        if 'ranking_por_modelo' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'ranking_por_modelo.csv')\n",
        "            self.resultados['ranking_por_modelo'].to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 3. Análisis por modelo (JSON)\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                ruta = os.path.join(self.rutas.salida, f'factores_{modelo}.json')\n",
        "                datos_convertidos = self._convertir_tipos_json(self.resultados[modelo])\n",
        "                with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 4. Comparación de paradigmas\n",
        "        if 'paradigmas' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'comparacion_paradigmas.json')\n",
        "            datos_convertidos = self._convertir_tipos_json(self.resultados['paradigmas'])\n",
        "            with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 5. Sensibilidad umbrales\n",
        "        if 'sensibilidad_umbrales' in self.resultados:\n",
        "            df_sens = self.resultados['sensibilidad_umbrales']\n",
        "            if isinstance(df_sens, pd.DataFrame) and len(df_sens) > 0:\n",
        "                ruta = os.path.join(self.rutas.salida, 'sensibilidad_umbrales.csv')\n",
        "                df_sens.to_csv(ruta, index=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 6. Sensibilidad tamaño\n",
        "        if 'sensibilidad_tamano' in self.resultados:\n",
        "            df_sens = self.resultados['sensibilidad_tamano']\n",
        "            if isinstance(df_sens, pd.DataFrame) and len(df_sens) > 0:\n",
        "                ruta = os.path.join(self.rutas.salida, 'sensibilidad_tamano.csv')\n",
        "                df_sens.to_csv(ruta, index=False)\n",
        "                logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 7. Resumen general\n",
        "        if 'resumen' in self.resultados:\n",
        "            ruta = os.path.join(self.rutas.salida, 'resumen_fase2d.json')\n",
        "            datos_convertidos = self._convertir_tipos_json(self.resultados['resumen'])\n",
        "            with open(ruta, 'w', encoding='utf-8') as f:\n",
        "                json.dump(datos_convertidos, f, indent=2, ensure_ascii=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 8. ANOVA consolidado\n",
        "        anova_consolidado = []\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                for factor, datos in self.resultados[modelo].get('factores', {}).items():\n",
        "                    if datos.get('anova'):\n",
        "                        anova_data = datos['anova'].copy()\n",
        "                        anova_data['modelo'] = modelo\n",
        "                        anova_consolidado.append(anova_data)\n",
        "\n",
        "        if anova_consolidado:\n",
        "            df_anova = pd.DataFrame(anova_consolidado)\n",
        "            ruta = os.path.join(self.rutas.salida, 'anova_por_modelo.csv')\n",
        "            df_anova.to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        # 9. Post-hoc Tukey consolidado\n",
        "        posthoc_consolidado = []\n",
        "        for modelo in ['bodypix', 'mask2former', 'oneformer', 'sam2', 'yolov8']:\n",
        "            if modelo in self.resultados:\n",
        "                for factor, datos in self.resultados[modelo].get('factores', {}).items():\n",
        "                    for ph in datos.get('posthoc', []):\n",
        "                        ph_data = ph.copy()\n",
        "                        ph_data['modelo'] = modelo\n",
        "                        ph_data['factor'] = factor\n",
        "                        posthoc_consolidado.append(ph_data)\n",
        "\n",
        "        if posthoc_consolidado:\n",
        "            df_posthoc = pd.DataFrame(posthoc_consolidado)\n",
        "            ruta = os.path.join(self.rutas.salida, 'posthoc_tukey.csv')\n",
        "            df_posthoc.to_csv(ruta, index=False)\n",
        "            logger.info(f\"  -> {ruta}\")\n",
        "\n",
        "        logger.info(\"Exportación completada.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN PRINCIPAL\n",
        "# =============================================================================\n",
        "def ejecutar_fase2d(ruta_metricas: str = None) -> Dict:\n",
        "    \"\"\"\n",
        "    Ejecuta la Fase 2D completa.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    ruta_metricas : str, optional\n",
        "        Ruta al archivo metricas_fusionadas.csv\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "        Resultados del análisis\n",
        "    \"\"\"\n",
        "    # Configurar rutas\n",
        "    rutas = ConfiguracionRutas()\n",
        "\n",
        "    # Determinar ruta de entrada\n",
        "    if ruta_metricas is None:\n",
        "        ruta_metricas = os.path.join(rutas.datos_entrada, 'metricas_fusionadas.csv')\n",
        "\n",
        "    logger.info(f\"Cargando datos desde: {ruta_metricas}\")\n",
        "\n",
        "    # Cargar datos\n",
        "    if not os.path.exists(ruta_metricas):\n",
        "        raise FileNotFoundError(f\"No se encontró el archivo: {ruta_metricas}\")\n",
        "\n",
        "    df = pd.read_csv(ruta_metricas)\n",
        "    logger.info(f\"Datos cargados: {len(df)} filas, {len(df.columns)} columnas\")\n",
        "\n",
        "    # Crear analizador y ejecutar\n",
        "    analizador = AnalizadorConfiguraciones(df, rutas)\n",
        "    resultados = analizador.ejecutar_analisis_completo()\n",
        "\n",
        "    # Exportar resultados\n",
        "    analizador.exportar_resultados()\n",
        "\n",
        "    return resultados"
      ],
      "metadata": {
        "id": "rPxvgdkkV3Kj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MAIN\n",
        "# =============================================================================\n",
        "if __name__ == '__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Ejecutar análisis\n",
        "    resultados = ejecutar_fase2d()\n",
        "\n",
        "    # Mostrar resumen\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"RESUMEN DE FASE 2D\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    if 'resumen' in resultados:\n",
        "        resumen = resultados['resumen']\n",
        "        print(f\"Total evaluaciones: {resumen['total_evaluaciones']}\")\n",
        "        print(f\"Total configuraciones: {resumen['total_configuraciones']}\")\n",
        "        print(f\"Modelos analizados: {resumen['modelos_analizados']}\")\n",
        "\n",
        "        if 'mejor_modelo_global' in resumen:\n",
        "            mejor = resumen['mejor_modelo_global']\n",
        "            print(f\"\\nMejor modelo: {mejor['modelo']}\")\n",
        "            print(f\"Mejor configuración: {mejor['configuracion']}\")\n",
        "            print(f\"IoU: {mejor['iou_mean']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usG3_COFV5jH",
        "outputId": "7a1adc4c-fd11-4c18-8bc2-d189b940ee4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:43:21] INFO - Cargando datos desde: /content/drive/MyDrive/TFM/3_Analisis/fase2b_correlaciones/metricas_fusionadas.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[22:43:21] INFO - Datos cargados: 2360 filas, 220 columnas\n",
            "[22:43:21] INFO - Extrayendo factores de configuraciones...\n",
            "[22:43:21] INFO -   yolov8.factor_tamano: ['large', 'medium', 'nano', 'small', 'xlarge']\n",
            "[22:43:21] INFO -   yolov8.factor_config_sensibilidad: ['balanced', 'fast', 'quality', 'sensitive']\n",
            "[22:43:21] INFO -   bodypix.factor_multiplicador: ['050', '075']\n",
            "[22:43:21] INFO -   bodypix.factor_nivel_sensibilidad: ['baja_sensibilidad', 'sensibilidad_alta', 'sensibilidad_media', 'ultra_sensible']\n",
            "[22:43:21] INFO -   bodypix.factor_umbral: ['1', '15', '2', '25', '3', '4', '5']\n",
            "[22:43:21] INFO -   mask2former.factor_backbone: ['base', 'large', 'tiny']\n",
            "[22:43:21] INFO -   mask2former.factor_dataset: ['ade', 'coco']\n",
            "[22:43:21] INFO -   mask2former.factor_sensibilidad: ['alta_sensibilidad', 'baja_sensibilidad', 'experimental_coco', 'maxima_sensibilidad', 'media_sensibilidad']\n",
            "[22:43:21] INFO -   oneformer.factor_umbral: ['t040', 't060', 't075', 't085']\n",
            "[22:43:21] INFO -   oneformer.factor_backbone: ['swin', 'tiny']\n",
            "[22:43:21] INFO -   oneformer.factor_dataset: ['ade20k', 'coco']\n",
            "[22:43:21] INFO -   oneformer.factor_task_type: ['instance', 'panoptic', 'semantic']\n",
            "[22:43:21] INFO -   sam2.factor_modo: ['auto', 'prompts']\n",
            "[22:43:21] INFO -   sam2.factor_tamano: ['base_plus', 'large', 'small', 'tiny']\n",
            "[22:43:21] INFO -   sam2.factor_estrategia: ['balanced', 'bbox_heuristic', 'combined_aggressive', 'combined_moderate', 'grid_central_aggressive', 'grid_central_conservative', 'grid_central_moderate', 'low_cost', 'quality', 'saliency_conservative', 'saliency_moderate']\n",
            "[22:43:21] INFO - Analizador inicializado con 2360 evaluaciones\n",
            "[22:43:21] INFO - Modelos: ['yolov8', 'bodypix', 'mask2former', 'oneformer', 'sam2']\n",
            "[22:43:21] INFO - Configuraciones únicas: 143\n",
            "[22:43:21] INFO - ============================================================\n",
            "[22:43:21] INFO - INICIANDO ANÁLISIS FASE 2D: CONFIGURACIONES\n",
            "[22:43:21] INFO - ============================================================\n",
            "[22:43:21] INFO - \n",
            "----------------------------------------\n",
            "[22:43:21] INFO - 1. Calculando rankings...\n",
            "[22:43:21] INFO - Calculando ranking global TOP-30...\n",
            "[22:43:21] INFO - Calculando mejor configuración por modelo...\n",
            "[22:43:21] INFO - \n",
            "----------------------------------------\n",
            "[22:43:21] INFO - 2. Análisis factorial por modelo...\n",
            "[22:43:21] INFO - Analizando BodyPix...\n",
            "[22:43:21] INFO - Analizando Mask2Former...\n",
            "[22:43:22] INFO - Analizando OneFormer...\n",
            "[22:43:23] INFO - Analizando SAM2...\n",
            "[22:43:24] INFO - Analizando YOLOv8...\n",
            "[22:43:24] INFO - \n",
            "----------------------------------------\n",
            "[22:43:24] INFO - 3. Comparando paradigmas arquitectónicos...\n",
            "[22:43:24] INFO - Comparando paradigmas arquitectónicos...\n",
            "[22:43:24] INFO - \n",
            "----------------------------------------\n",
            "[22:43:24] INFO - 4. Análisis de sensibilidad...\n",
            "[22:43:24] INFO - Analizando sensibilidad a umbrales...\n",
            "[22:43:24] INFO - Analizando sensibilidad al tamaño del modelo...\n",
            "[22:43:24] INFO - \n",
            "----------------------------------------\n",
            "[22:43:24] INFO - 5. Generando resumen...\n",
            "[22:43:24] INFO - \n",
            "============================================================\n",
            "[22:43:24] INFO - ANÁLISIS FASE 2D COMPLETADO\n",
            "[22:43:24] INFO - ============================================================\n",
            "[22:43:24] INFO - Exportando resultados...\n",
            "[22:43:24] INFO - Directorio de salida: /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/ranking_global_top30.csv\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/ranking_por_modelo.csv\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_bodypix.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_mask2former.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_oneformer.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_sam2.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/factores_yolov8.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/comparacion_paradigmas.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/sensibilidad_umbrales.csv\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/sensibilidad_tamano.csv\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/resumen_fase2d.json\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/anova_por_modelo.csv\n",
            "[22:43:24] INFO -   -> /content/drive/MyDrive/TFM/3_Analisis/fase2d_configuraciones/posthoc_tukey.csv\n",
            "[22:43:24] INFO - Exportación completada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "RESUMEN DE FASE 2D\n",
            "============================================================\n",
            "Total evaluaciones: 2360\n",
            "Total configuraciones: 143\n",
            "Modelos analizados: ['yolov8', 'bodypix', 'mask2former', 'oneformer', 'sam2']\n",
            "\n",
            "Mejor modelo: oneformer\n",
            "Mejor configuración: oneformer_coco_swin_semantic_t040\n",
            "IoU: 0.9674\n"
          ]
        }
      ]
    }
  ]
}