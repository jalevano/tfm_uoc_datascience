{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2ieL4WemBrgjBKjBeSCWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/00_CVAT_Ground_Truth.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "xTFA-X5qQbO3",
        "outputId": "35befaa0-cbf6-4dbe-97be-b3c31e4d6ae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCONVERSIÓN DE ANOTACIONES CVAT A MÁSCARAS GROUND TRUTH NPZ\\n\\nTrabajo Fin de Máster: Evaluación Comparativa de Técnicas de Segmentación \\nen Fotografía de Retrato\\n\\nAutor: Jesús L.\\nInstitución: Universidad Oberta de Cataluña (UOC)\\nFecha: Noviembre 2025\\n\\nDESCRIPCIÓN:\\nEste módulo implementa la conversión de anotaciones manuales realizadas en CVAT\\n(Computer Vision Annotation Tool) al formato de máscaras binarias NPZ utilizado\\nen el sistema de evaluación del TFM. Las anotaciones en formato COCO se \\ntransforman en máscaras de segmentación compatibles con los evaluadores \\ndesarrollados para SAM 2.0, YOLOv8-seg, Mask2Former, OneFormer y BodyPix.\\n\\nOBJETIVO:\\nGenerar máscaras ground truth de alta calidad para la evaluación cuantitativa\\nobjetiva de los modelos de segmentación implementados, calculando métricas\\ncomo IoU (Intersection over Union), Precision, Recall y F1-Score.\\n\\nPROCESO:\\n1. Montaje de Google Drive y acceso al directorio del proyecto\\n2. Carga y validación de anotaciones COCO exportadas desde CVAT\\n3. Conversión de polígonos de segmentación a máscaras binarias\\n4. Validación de calidad de las anotaciones generadas\\n5. Guardado en formato NPZ compatible con los evaluadores existentes\\n\\nESTRUCTURA DE DATOS:\\n\\nEntrada (COCO format):\\n    - instances_default.json: Anotaciones exportadas desde CVAT\\n    - Contiene: imágenes, anotaciones (polígonos), categorías\\n    - Ubicación: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/\\n\\nSalida (NPZ format):\\n    - {imagen_nombre}_gt.npz: Máscara ground truth por imagen\\n    - Estructura:\\n        * masks: np.ndarray [H, W] normalizado [0, 1]\\n        * scores: np.array([1.0]) - confianza 100% (ground truth)\\n        * metadata: JSON con información de la anotación\\n    - Ubicación: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks/\\n\\nMETODOLOGÍA:\\nLa conversión de polígonos a máscaras binarias se realiza mediante rasterización\\nutilizando PIL.ImageDraw. Para imágenes con múltiples personas, las máscaras\\nindividuales se combinan mediante operación OR lógica, generando una máscara\\nunificada que representa todas las instancias de personas en la imagen.\\n\\nVALIDACIÓN DE CALIDAD:\\nSe implementan verificaciones automáticas de calidad que evalúan:\\n    - Cobertura de la máscara (porcentaje de píxeles anotados)\\n    - Número de regiones conectadas (detección de fragmentación)\\n    - Presencia de huecos internos en la máscara\\n    - Validez general basada en umbrales empíricos para fotografía de retrato\\n\\nCOMPATIBILIDAD:\\nEl formato de salida NPZ es compatible con el sistema de checkpointing\\nimplementado en todos los evaluadores del TFM, permitiendo integración\\ndirecta con el pipeline de análisis cuantitativo desarrollado en el Notebook 3.\\n\\nREFERENCIAS:\\n- COCO format: https://cocodataset.org/#format-data\\n- CVAT documentation: https://opencv.github.io/cvat/\\n- Shapely geometry: https://shapely.readthedocs.io/\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"\n",
        "CONVERSIÓN DE ANOTACIONES CVAT A MÁSCARAS GROUND TRUTH NPZ\n",
        "\n",
        "Trabajo Fin de Máster: Evaluación Comparativa de Técnicas de Segmentación\n",
        "en Fotografía de Retrato\n",
        "\n",
        "Autor: Jesús L.\n",
        "Institución: Universidad Oberta de Cataluña (UOC)\n",
        "Fecha: Noviembre 2025\n",
        "\n",
        "DESCRIPCIÓN:\n",
        "Este módulo implementa la conversión de anotaciones manuales realizadas en CVAT\n",
        "(Computer Vision Annotation Tool) al formato de máscaras binarias NPZ utilizado\n",
        "en el sistema de evaluación del TFM. Las anotaciones en formato COCO se\n",
        "transforman en máscaras de segmentación compatibles con los evaluadores\n",
        "desarrollados para SAM 2.0, YOLOv8-seg, Mask2Former, OneFormer y BodyPix.\n",
        "\n",
        "OBJETIVO:\n",
        "Generar máscaras ground truth de alta calidad para la evaluación cuantitativa\n",
        "objetiva de los modelos de segmentación implementados, calculando métricas\n",
        "como IoU (Intersection over Union), Precision, Recall y F1-Score.\n",
        "\n",
        "PROCESO:\n",
        "1. Montaje de Google Drive y acceso al directorio del proyecto\n",
        "2. Carga y validación de anotaciones COCO exportadas desde CVAT\n",
        "3. Conversión de polígonos de segmentación a máscaras binarias\n",
        "4. Validación de calidad de las anotaciones generadas\n",
        "5. Guardado en formato NPZ compatible con los evaluadores existentes\n",
        "\n",
        "ESTRUCTURA DE DATOS:\n",
        "\n",
        "Entrada (COCO format):\n",
        "    - instances_default.json: Anotaciones exportadas desde CVAT\n",
        "    - Contiene: imágenes, anotaciones (polígonos), categorías\n",
        "    - Ubicación: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/\n",
        "\n",
        "Salida (NPZ format):\n",
        "    - {imagen_nombre}_gt.npz: Máscara ground truth por imagen\n",
        "    - Estructura:\n",
        "        * masks: np.ndarray [H, W] normalizado [0, 1]\n",
        "        * scores: np.array([1.0]) - confianza 100% (ground truth)\n",
        "        * metadata: JSON con información de la anotación\n",
        "    - Ubicación: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks/\n",
        "\n",
        "METODOLOGÍA:\n",
        "La conversión de polígonos a máscaras binarias se realiza mediante rasterización\n",
        "utilizando PIL.ImageDraw. Para imágenes con múltiples personas, las máscaras\n",
        "individuales se combinan mediante operación OR lógica, generando una máscara\n",
        "unificada que representa todas las instancias de personas en la imagen.\n",
        "\n",
        "VALIDACIÓN DE CALIDAD:\n",
        "Se implementan verificaciones automáticas de calidad que evalúan:\n",
        "    - Cobertura de la máscara (porcentaje de píxeles anotados)\n",
        "    - Número de regiones conectadas (detección de fragmentación)\n",
        "    - Presencia de huecos internos en la máscara\n",
        "    - Validez general basada en umbrales empíricos para fotografía de retrato\n",
        "\n",
        "COMPATIBILIDAD:\n",
        "El formato de salida NPZ es compatible con el sistema de checkpointing\n",
        "implementado en todos los evaluadores del TFM, permitiendo integración\n",
        "directa con el pipeline de análisis cuantitativo desarrollado en el Notebook 3.\n",
        "\n",
        "REFERENCIAS:\n",
        "- COCO format: https://cocodataset.org/#format-data\n",
        "- CVAT documentation: https://opencv.github.io/cvat/\n",
        "- Shapely geometry: https://shapely.readthedocs.io/\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "import cv2\n",
        "import warnings\n",
        "\n",
        "# Suprimir warnings de deprecación para mantener output limpio\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4eoxA6T0R1lF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CONFIGURACIÓN Y MONTAJE DE GOOGLE DRIVE\n",
        "# ==============================================================================\n",
        "\n",
        "def setup_google_drive():\n",
        "    \"\"\"\n",
        "    Configura el acceso a Google Drive desde Google Colab.\n",
        "\n",
        "    Monta el sistema de archivos de Google Drive en /content/drive/\n",
        "    permitiendo acceso directo a los archivos del proyecto TFM.\n",
        "\n",
        "    Returns:\n",
        "        Path: Ruta base al directorio del proyecto en Google Drive\n",
        "\n",
        "    Raises:\n",
        "        RuntimeError: Si no se está ejecutando en Google Colab\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        print(\"Montando Google Drive...\")\n",
        "        drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "        base_path = Path('/content/drive/MyDrive/TFM/0_Imagenes_CVAT')\n",
        "\n",
        "        if not base_path.exists():\n",
        "            raise FileNotFoundError(\n",
        "                f\"No se encuentra el directorio del proyecto: {base_path}\\n\"\n",
        "                \"Verifique que la estructura de carpetas sea correcta.\"\n",
        "            )\n",
        "\n",
        "        print(f\"Google Drive montado correctamente.\")\n",
        "        print(f\"Directorio del proyecto: {base_path}\")\n",
        "        return base_path\n",
        "\n",
        "    except ImportError:\n",
        "        raise RuntimeError(\n",
        "            \"Este script está diseñado para ejecutarse en Google Colab.\\n\"\n",
        "            \"Para ejecución local, modifique la función setup_google_drive().\"\n",
        "        )"
      ],
      "metadata": {
        "id": "ZyXXtuS_R2aF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CONVERSIÓN DE GEOMETRÍAS\n",
        "# ==============================================================================\n",
        "\n",
        "def polygon_to_mask(polygon: List[float],\n",
        "                    image_size: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convierte un polígono en formato COCO a máscara binaria mediante rasterización.\n",
        "\n",
        "    El formato COCO representa polígonos como listas planas de coordenadas\n",
        "    [x1, y1, x2, y2, ..., xn, yn]. Esta función convierte estas coordenadas\n",
        "    en una máscara binaria del tamaño especificado.\n",
        "\n",
        "    Args:\n",
        "        polygon: Lista de coordenadas en formato COCO [x1,y1,x2,y2,...]\n",
        "        image_size: Tupla (width, height) del tamaño de la imagen destino\n",
        "\n",
        "    Returns:\n",
        "        Máscara binaria como numpy array de shape (height, width) con valores\n",
        "        0 (fondo) y 255 (persona)\n",
        "\n",
        "    Notes:\n",
        "        - Se requieren mínimo 3 puntos para formar un polígono válido\n",
        "        - Utiliza PIL.ImageDraw para rasterización eficiente\n",
        "        - El polígono se rellena completamente (no solo el contorno)\n",
        "    \"\"\"\n",
        "    # Crear imagen vacía para la máscara\n",
        "    mask = Image.new('L', image_size, 0)\n",
        "    draw = ImageDraw.Draw(mask)\n",
        "\n",
        "    # Convertir lista plana a lista de tuplas (x, y)\n",
        "    points = [(polygon[i], polygon[i+1]) for i in range(0, len(polygon), 2)]\n",
        "\n",
        "    # Validar número mínimo de puntos para polígono válido\n",
        "    if len(points) >= 3:\n",
        "        draw.polygon(points, fill=255)\n",
        "    else:\n",
        "        warnings.warn(\n",
        "            f\"Polígono con {len(points)} puntos ignorado (mínimo 3 requeridos)\"\n",
        "        )\n",
        "\n",
        "    return np.array(mask)\n",
        "\n",
        "\n",
        "def rle_to_mask(rle: Dict, image_size: Tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Convierte Run Length Encoding (RLE) a máscara binaria.\n",
        "\n",
        "    Aunque CVAT típicamente exporta polígonos, algunos formatos o\n",
        "    configuraciones pueden utilizar RLE para compresión eficiente.\n",
        "    Esta función proporciona compatibilidad con ambos formatos.\n",
        "\n",
        "    Args:\n",
        "        rle: Diccionario con formato RLE de COCO ('counts' y 'size')\n",
        "        image_size: Tupla (width, height) del tamaño de imagen\n",
        "\n",
        "    Returns:\n",
        "        Máscara binaria como numpy array\n",
        "\n",
        "    Requires:\n",
        "        pycocotools (instalado via: pip install pycocotools)\n",
        "\n",
        "    Notes:\n",
        "        RLE es más eficiente para almacenamiento pero menos común en\n",
        "        exportaciones estándar de CVAT para tareas de segmentación manual.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from pycocotools import mask as mask_utils\n",
        "\n",
        "        if isinstance(rle, dict):\n",
        "            mask = mask_utils.decode(rle)\n",
        "        else:\n",
        "            # RLE compacto (formato alternativo)\n",
        "            mask = mask_utils.decode({\n",
        "                'counts': rle,\n",
        "                'size': image_size[::-1]\n",
        "            })\n",
        "\n",
        "        return mask\n",
        "\n",
        "    except ImportError:\n",
        "        raise ImportError(\n",
        "            \"pycocotools no está instalado. Ejecute:\\n\"\n",
        "            \"pip install pycocotools\"\n",
        "        )"
      ],
      "metadata": {
        "id": "4Q-xwysxSWGv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# VALIDACIÓN DE CALIDAD\n",
        "# ==============================================================================\n",
        "\n",
        "def validate_mask_quality(mask: np.ndarray,\n",
        "                         image_size: Tuple[int, int],\n",
        "                         image_name: str = \"unknown\") -> Dict:\n",
        "    \"\"\"\n",
        "    Valida la calidad de una máscara ground truth mediante análisis geométrico.\n",
        "\n",
        "    Implementa heurísticas de validación basadas en características esperadas\n",
        "    de fotografía de retrato. Detecta potenciales problemas de anotación como\n",
        "    fragmentación excesiva, cobertura anómala o presencia de huecos internos.\n",
        "\n",
        "    Args:\n",
        "        mask: Máscara binaria a validar (valores 0-255)\n",
        "        image_size: Tupla (width, height) de la imagen original\n",
        "        image_name: Nombre de la imagen para reporting\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con métricas de calidad:\n",
        "            - coverage_percent: Porcentaje de píxeles anotados\n",
        "            - num_regions: Número de componentes conectados (personas separadas)\n",
        "            - has_holes: Presencia de huecos internos en las máscaras\n",
        "            - is_valid: Validación global basada en umbrales empíricos\n",
        "            - warnings: Lista de advertencias detectadas\n",
        "\n",
        "    Notes:\n",
        "        Umbrales de validación basados en análisis empírico de fotografía\n",
        "        de retrato típica:\n",
        "            - Cobertura: 10-90% (persona visible sin dominar completamente)\n",
        "            - Regiones: 1-3 (retratos individuales o grupales pequeños)\n",
        "            - Huecos: Aceptables pero reportados para revisión manual\n",
        "    \"\"\"\n",
        "    total_pixels = image_size[0] * image_size[1]\n",
        "    mask_pixels = np.sum(mask > 0)\n",
        "    coverage = mask_pixels / total_pixels\n",
        "\n",
        "    # Detectar componentes conectados mediante análisis de conectividad\n",
        "    # Utiliza conectividad-8 (incluye diagonales) apropiada para segmentación\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
        "        mask.astype(np.uint8),\n",
        "        connectivity=8\n",
        "    )\n",
        "\n",
        "    # Número de regiones excluyendo el fondo (label 0)\n",
        "    num_regions = num_labels - 1\n",
        "\n",
        "    # Detectar huecos internos mediante análisis de contornos jerárquico\n",
        "    # RETR_CCOMP recupera jerarquía de dos niveles: externos e internos\n",
        "    contours, hierarchy = cv2.findContours(\n",
        "        mask.astype(np.uint8),\n",
        "        cv2.RETR_CCOMP,\n",
        "        cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    # Huecos presentes si existen contornos internos (hijos en jerarquía)\n",
        "    has_holes = (\n",
        "        hierarchy is not None and\n",
        "        np.any(hierarchy[0, :, 3] != -1)\n",
        "    )\n",
        "\n",
        "    # Compilar advertencias basadas en análisis\n",
        "    warnings_list = []\n",
        "\n",
        "    if coverage < 0.05:\n",
        "        warnings_list.append(\"Cobertura muy baja (<5%). Verificar anotación.\")\n",
        "    elif coverage > 0.95:\n",
        "        warnings_list.append(\"Cobertura muy alta (>95%). Posible error.\")\n",
        "\n",
        "    if num_regions > 5:\n",
        "        warnings_list.append(\n",
        "            f\"Fragmentación alta ({num_regions} regiones). \"\n",
        "            \"Revisar continuidad de la anotación.\"\n",
        "        )\n",
        "\n",
        "    if has_holes:\n",
        "        warnings_list.append(\n",
        "            \"Huecos internos detectados. Verificar si es intencional \"\n",
        "            \"(ej. brazos formando hueco).\"\n",
        "        )\n",
        "\n",
        "    # Validación global basada en umbrales empíricos\n",
        "    # Cobertura razonable para retratos: entre 10% y 90%\n",
        "    is_valid = 0.10 < coverage < 0.90\n",
        "\n",
        "    return {\n",
        "        'image_name': image_name,\n",
        "        'coverage_percent': coverage * 100,\n",
        "        'num_regions': num_regions,\n",
        "        'has_holes': has_holes,\n",
        "        'is_valid': is_valid,\n",
        "        'warnings': warnings_list\n",
        "    }"
      ],
      "metadata": {
        "id": "iQl3dB-bTDQB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# CONVERSIÓN PRINCIPAL\n",
        "# ==============================================================================\n",
        "\n",
        "def cvat_coco_to_ground_truth(coco_json_path: Path,\n",
        "                               output_dir: Path,\n",
        "                               validate: bool = True,\n",
        "                               verbose: bool = True) -> Dict:\n",
        "    \"\"\"\n",
        "    Convierte exportación COCO de CVAT a máscaras NPZ ground truth.\n",
        "\n",
        "    Función principal que orquesta el proceso completo de conversión desde\n",
        "    anotaciones en formato COCO (exportadas de CVAT) hasta máscaras binarias\n",
        "    en formato NPZ compatible con el sistema de evaluación del TFM.\n",
        "\n",
        "    Args:\n",
        "        coco_json_path: Ruta al archivo instances_default.json de CVAT\n",
        "        output_dir: Directorio donde guardar las máscaras NPZ generadas\n",
        "        validate: Si True, ejecuta validación de calidad de anotaciones\n",
        "        verbose: Si True, muestra información detallada del proceso\n",
        "\n",
        "    Returns:\n",
        "        Diccionario con estadísticas del proceso:\n",
        "            - total_images: Número de imágenes procesadas\n",
        "            - total_annotations: Número total de personas anotadas\n",
        "            - images_single_person: Imágenes con una sola persona\n",
        "            - images_multiple_persons: Imágenes con múltiples personas\n",
        "            - quality_warnings: Lista de advertencias de calidad detectadas\n",
        "            - processing_time: Tiempo total de procesamiento\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo COCO\n",
        "        ValueError: Si el formato COCO es inválido\n",
        "\n",
        "    Notes:\n",
        "        - Soporta múltiples personas por imagen (máscaras combinadas)\n",
        "        - Mantiene compatibilidad con formato NPZ de evaluadores existentes\n",
        "        - Genera metadata completa para trazabilidad\n",
        "        - Implementa checkpoint automático (guarda progresivamente)\n",
        "\n",
        "    \"\"\"\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Validar existencia del archivo de entrada\n",
        "    if not coco_json_path.exists():\n",
        "        raise FileNotFoundError(\n",
        "            f\"No se encuentra el archivo de anotaciones COCO: {coco_json_path}\"\n",
        "        )\n",
        "\n",
        "    if verbose:\n",
        "        print(\"=\" * 80)\n",
        "        print(\"CONVERSIÓN DE ANOTACIONES CVAT A GROUND TRUTH\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nArchivo de entrada: {coco_json_path}\")\n",
        "        print(f\"Directorio de salida: {output_dir}\")\n",
        "        print(\"\\nCargando anotaciones COCO...\")\n",
        "\n",
        "    # Cargar archivo JSON con manejo de errores\n",
        "    try:\n",
        "        with open(coco_json_path, 'r', encoding='utf-8') as f:\n",
        "            coco_data = json.load(f)\n",
        "    except json.JSONDecodeError as e:\n",
        "        raise ValueError(\n",
        "            f\"Error al parsear archivo COCO: {e}\\n\"\n",
        "            \"Verifique que el archivo JSON esté bien formado.\"\n",
        "        )\n",
        "\n",
        "    # Validar estructura básica del formato COCO\n",
        "    required_keys = ['images', 'annotations', 'categories']\n",
        "    missing_keys = [key for key in required_keys if key not in coco_data]\n",
        "    if missing_keys:\n",
        "        raise ValueError(\n",
        "            f\"Formato COCO inválido. Faltan claves: {missing_keys}\"\n",
        "        )\n",
        "\n",
        "    # Construir índice de imágenes para acceso eficiente O(1)\n",
        "    images_map = {img['id']: img for img in coco_data['images']}\n",
        "\n",
        "    # Agrupar anotaciones por imagen\n",
        "    # Estructura: {image_id: [annotation1, annotation2, ...]}\n",
        "    annotations_by_image = {}\n",
        "    for ann in coco_data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in annotations_by_image:\n",
        "            annotations_by_image[img_id] = []\n",
        "        annotations_by_image[img_id].append(ann)\n",
        "\n",
        "    # Crear directorio de salida si no existe\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Inicializar estadísticas del proceso\n",
        "    stats = {\n",
        "        'total_images': len(annotations_by_image),\n",
        "        'total_annotations': sum(len(anns) for anns in annotations_by_image.values()),\n",
        "        'images_single_person': 0,\n",
        "        'images_multiple_persons': 0,\n",
        "        'quality_warnings': [],\n",
        "        'processing_time': 0\n",
        "    }\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nDataset: {stats['total_images']} imágenes con \"\n",
        "              f\"{stats['total_annotations']} anotaciones\")\n",
        "        print(\"\\nGenerando máscaras ground truth...\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    # Procesar cada imagen con barra de progreso\n",
        "    for img_id, annotations in tqdm(\n",
        "        annotations_by_image.items(),\n",
        "        disable=not verbose,\n",
        "        desc=\"Procesando imágenes\",\n",
        "        unit=\"img\"\n",
        "    ):\n",
        "        image_info = images_map[img_id]\n",
        "        image_size = (image_info['width'], image_info['height'])\n",
        "        filename_base = Path(image_info['file_name']).stem\n",
        "\n",
        "        # Inicializar máscara combinada para todas las personas\n",
        "        # Dtype uint8 para eficiencia de memoria\n",
        "        combined_mask = np.zeros(image_size[::-1], dtype=np.uint8)\n",
        "\n",
        "        # Contabilizar número de personas en esta imagen\n",
        "        num_persons = len(annotations)\n",
        "        if num_persons == 1:\n",
        "            stats['images_single_person'] += 1\n",
        "        else:\n",
        "            stats['images_multiple_persons'] += 1\n",
        "\n",
        "        # Procesar cada anotación (persona) en la imagen\n",
        "        for ann in annotations:\n",
        "            if 'segmentation' not in ann or not ann['segmentation']:\n",
        "                warnings.warn(\n",
        "                    f\"Anotación sin segmentación en imagen {filename_base}, \"\n",
        "                    f\"annotation_id: {ann.get('id', 'unknown')}\"\n",
        "                )\n",
        "                continue\n",
        "\n",
        "            # Procesar cada segmento (puede haber múltiples polígonos por persona)\n",
        "            for seg in ann['segmentation']:\n",
        "                person_mask = None\n",
        "\n",
        "                if isinstance(seg, list):\n",
        "                    # Formato polígono (más común en CVAT)\n",
        "                    person_mask = polygon_to_mask(seg, image_size)\n",
        "                elif isinstance(seg, dict):\n",
        "                    # Formato RLE (menos común pero soportado)\n",
        "                    person_mask = rle_to_mask(seg, image_size)\n",
        "                else:\n",
        "                    warnings.warn(\n",
        "                        f\"Formato de segmentación desconocido en {filename_base}: \"\n",
        "                        f\"{type(seg)}\"\n",
        "                    )\n",
        "                    continue\n",
        "\n",
        "                if person_mask is not None:\n",
        "                    # Combinar máscaras mediante OR lógico (unión de regiones)\n",
        "                    # Esto permite múltiples personas en la misma imagen\n",
        "                    combined_mask = np.maximum(combined_mask, person_mask)\n",
        "\n",
        "        # Validar calidad de la máscara generada\n",
        "        if validate and np.any(combined_mask):\n",
        "            quality = validate_mask_quality(\n",
        "                combined_mask,\n",
        "                image_size,\n",
        "                filename_base\n",
        "            )\n",
        "\n",
        "            # Registrar advertencias de calidad\n",
        "            if quality['warnings']:\n",
        "                for warning in quality['warnings']:\n",
        "                    warning_msg = f\"{filename_base}: {warning}\"\n",
        "                    stats['quality_warnings'].append(warning_msg)\n",
        "                    if verbose:\n",
        "                        print(f\"\\nAdvertencia: {warning_msg}\")\n",
        "\n",
        "            # Reportar métricas de calidad en modo verbose\n",
        "            if verbose and not quality['is_valid']:\n",
        "                print(f\"\\nAtención - {filename_base}:\")\n",
        "                print(f\"  Cobertura: {quality['coverage_percent']:.2f}%\")\n",
        "                print(f\"  Regiones: {quality['num_regions']}\")\n",
        "                print(f\"  Huecos: {'Sí' if quality['has_holes'] else 'No'}\")\n",
        "\n",
        "        # Construir metadata completa para trazabilidad\n",
        "        metadata = {\n",
        "            'image_file': image_info['file_name'],\n",
        "            'image_size': image_size,\n",
        "            'annotation_source': 'cvat_manual_ground_truth',\n",
        "            'num_persons': num_persons,\n",
        "            'cvat_image_id': img_id,\n",
        "            'annotator': 'jesus_alejandro',\n",
        "            'project': 'TFM_Segmentacion_Retratos',\n",
        "            'institution': 'Universidad Oberta de Cataluña (UOC)',\n",
        "            'creation_date': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        }\n",
        "\n",
        "        # Definir ruta de salida\n",
        "        output_file = output_dir / f\"{filename_base}_gt.npz\"\n",
        "\n",
        "        # Guardar en formato NPZ compatible con evaluadores\n",
        "        np.savez_compressed(\n",
        "            output_file,\n",
        "            masks=combined_mask.astype(np.float32) / 255.0,  # Normalizar [0,1]\n",
        "            scores=np.array([1.0]),  # Confianza 100% (ground truth)\n",
        "            metadata=json.dumps(metadata)\n",
        "        )\n",
        "\n",
        "    # Calcular tiempo total de procesamiento\n",
        "    stats['processing_time'] = time.time() - start_time\n",
        "\n",
        "    # Generar reporte final\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"CONVERSIÓN COMPLETADA\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nEstadísticas:\")\n",
        "        print(f\"  Imágenes procesadas: {stats['total_images']}\")\n",
        "        print(f\"  Total personas anotadas: {stats['total_annotations']}\")\n",
        "        print(f\"  Promedio personas/imagen: \"\n",
        "              f\"{stats['total_annotations']/stats['total_images']:.2f}\")\n",
        "        print(f\"  Imágenes con 1 persona: {stats['images_single_person']}\")\n",
        "        print(f\"  Imágenes con múltiples personas: \"\n",
        "              f\"{stats['images_multiple_persons']}\")\n",
        "        print(f\"  Tiempo de procesamiento: {stats['processing_time']:.2f} segundos\")\n",
        "\n",
        "        if stats['quality_warnings']:\n",
        "            print(f\"\\nAdvertencias de calidad: {len(stats['quality_warnings'])}\")\n",
        "            print(\"Primeras 5 advertencias:\")\n",
        "            for warning in stats['quality_warnings'][:5]:\n",
        "                print(f\"  - {warning}\")\n",
        "            if len(stats['quality_warnings']) > 5:\n",
        "                print(f\"  ... y {len(stats['quality_warnings']) - 5} más\")\n",
        "        else:\n",
        "            print(\"\\nNo se detectaron advertencias de calidad.\")\n",
        "\n",
        "        print(f\"\\nMáscaras guardadas en: {output_dir}\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "SrKID-3PTQPr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FUNCIÓN PRINCIPAL DE EJECUCIÓN\n",
        "# ==============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Función principal que ejecuta el pipeline completo de conversión.\n",
        "\n",
        "    Orquesta el proceso completo:\n",
        "    1. Montaje de Google Drive\n",
        "    2. Validación de estructura de directorios\n",
        "    3. Conversión de anotaciones COCO a máscaras NPZ\n",
        "    4. Generación de reporte de resultados\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentran los archivos o directorios\n",
        "        RuntimeError: Si ocurre un error durante la conversión\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Configurar acceso a Google Drive\n",
        "        base_path = setup_google_drive()\n",
        "\n",
        "        # Definir rutas del proyecto\n",
        "        coco_json_path = base_path / 'instances_Validation.json'\n",
        "        output_dir = base_path / 'ground_truth_masks'\n",
        "\n",
        "        print(f\"\\nRutas configuradas:\")\n",
        "        print(f\"  Base: {base_path}\")\n",
        "        print(f\"  Anotaciones COCO: {coco_json_path}\")\n",
        "        print(f\"  Salida máscaras: {output_dir}\")\n",
        "\n",
        "        # Validar existencia del archivo de anotaciones\n",
        "        if not coco_json_path.exists():\n",
        "            raise FileNotFoundError(\n",
        "                f\"\\nNo se encuentra el archivo de anotaciones COCO.\\n\"\n",
        "            )\n",
        "\n",
        "        print(\"\\nValidación completada. Iniciando conversión...\\n\")\n",
        "\n",
        "        # Ejecutar conversión\n",
        "        stats = cvat_coco_to_ground_truth(\n",
        "            coco_json_path=coco_json_path,\n",
        "            output_dir=output_dir,\n",
        "            validate=True,\n",
        "            verbose=True\n",
        "        )\n",
        "\n",
        "        # Reporte final de éxito\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"PROCESO COMPLETADO EXITOSAMENTE\")\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"\\nResumen de resultados:\")\n",
        "        print(f\"  Total de máscaras ground truth generadas: {stats['total_images']}\")\n",
        "        print(f\"  Ubicación: {output_dir}\")\n",
        "        print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "        return stats\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"\\nError de archivo no encontrado:\")\n",
        "        print(str(e))\n",
        "        raise\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError durante la conversión:\")\n",
        "        print(f\"  Tipo: {type(e).__name__}\")\n",
        "        print(f\"  Mensaje: {str(e)}\")\n",
        "        import traceback\n",
        "        print(\"\\nTraceback completo:\")\n",
        "        traceback.print_exc()\n",
        "        raise"
      ],
      "metadata": {
        "id": "NBvhaiKoUFzo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# PUNTO DE ENTRADA\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7jZaFCiU7O0",
        "outputId": "4da68a26-0ac2-4a66-997a-ed0101e75a4a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive montado correctamente.\n",
            "Directorio del proyecto: /content/drive/MyDrive/TFM/0_Imagenes_CVAT\n",
            "\n",
            "Rutas configuradas:\n",
            "  Base: /content/drive/MyDrive/TFM/0_Imagenes_CVAT\n",
            "  Anotaciones COCO: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/instances_Validation.json\n",
            "  Salida máscaras: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks\n",
            "\n",
            "Validación completada. Iniciando conversión...\n",
            "\n",
            "================================================================================\n",
            "CONVERSIÓN DE ANOTACIONES CVAT A GROUND TRUTH\n",
            "================================================================================\n",
            "\n",
            "Archivo de entrada: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/instances_Validation.json\n",
            "Directorio de salida: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks\n",
            "\n",
            "Cargando anotaciones COCO...\n",
            "\n",
            "Dataset: 20 imágenes con 20 anotaciones\n",
            "\n",
            "Generando máscaras ground truth...\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:   5%|▌         | 1/20 [00:01<00:19,  1.04s/img]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0036: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:  15%|█▌        | 3/20 [00:02<00:15,  1.08img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0084: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando imágenes:  20%|██        | 4/20 [00:04<00:16,  1.04s/img]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0119: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:  30%|███       | 6/20 [00:06<00:16,  1.16s/img]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0143: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:  40%|████      | 8/20 [00:08<00:12,  1.01s/img]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0281: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcesando imágenes:  45%|████▌     | 9/20 [00:09<00:10,  1.02img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0283: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:  55%|█████▌    | 11/20 [00:10<00:08,  1.08img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0441: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes:  75%|███████▌  | 15/20 [00:14<00:04,  1.13img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Advertencia: _DSC0584: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando imágenes: 100%|██████████| 20/20 [00:19<00:00,  1.01img/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "CONVERSIÓN COMPLETADA\n",
            "================================================================================\n",
            "\n",
            "Estadísticas:\n",
            "  Imágenes procesadas: 20\n",
            "  Total personas anotadas: 20\n",
            "  Promedio personas/imagen: 1.00\n",
            "  Imágenes con 1 persona: 20\n",
            "  Imágenes con múltiples personas: 0\n",
            "  Tiempo de procesamiento: 20.79 segundos\n",
            "\n",
            "Advertencias de calidad: 8\n",
            "Primeras 5 advertencias:\n",
            "  - _DSC0036: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n",
            "  - _DSC0084: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n",
            "  - _DSC0119: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n",
            "  - _DSC0143: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n",
            "  - _DSC0281: Huecos internos detectados. Verificar si es intencional (ej. brazos formando hueco).\n",
            "  ... y 3 más\n",
            "\n",
            "Máscaras guardadas en: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "PROCESO COMPLETADO EXITOSAMENTE\n",
            "================================================================================\n",
            "\n",
            "Resumen de resultados:\n",
            "  Total de máscaras ground truth generadas: 20\n",
            "  Ubicación: /content/drive/MyDrive/TFM/0_Imagenes_CVAT/ground_truth_masks\n",
            "================================================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}