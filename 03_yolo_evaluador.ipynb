{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jalevano/tfm_uoc_datascience/blob/main/03_yolo_evaluador.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "m3vwYzMZ7JSs",
        "outputId": "cb5965a3-dc1a-44ed-bf1e-c92a12316705"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n================================================================================\\nEVALUADOR YOLOv8-SEGMENTATION OPTIMIZADO PARA FOTOGRAFÍA DE RETRATO\\n================================================================================\\nSistema de evaluación para modelos YOLOv8-seg con estructura estandarizada\\ny optimizaciones específicas para fotografía de retrato.\\n\\nCARACTERÍSTICAS PRINCIPALES:\\n- Procesamiento incremental con sistema de checkpoint robusto\\n- Gestión óptima de memoria para Google Colab gratuito\\n- Guardado automático después de cada imagen procesada\\n- Configuraciones optimizadas para fotografía de retrato\\n- Filtrado inteligente de personas basado en heurísticas del estado del arte\\n- Post-procesamiento avanzado: NMS, área, aspect ratio, posición\\n- Visualizaciones 3-panel avanzadas (Original + Detecciones + Máscaras)\\n- NPZ completo con todas las máscaras y scores para análisis posterior\\n- JSON ligero con métricas de rendimiento\\n\\nOPTIMIZACIONES PARA RETRATO:\\n- Configuraciones IOU/CONF específicas para personas\\n- Filtrado por área: 5%-90% de la imagen (personas significativas)\\n- Filtrado por aspect ratio: 0.3-1.5 (personas son más altas que anchas)\\n- Priorización de detecciones centrales\\n- NMS agresivo para evitar duplicados en retratos\\n- 3 configuraciones predefinidas: fast, balanced, quality\\n\\nALMACENAMIENTO NPZ (por imagen y umbral):\\n- masks: Máscaras binarias (N, H, W) en uint8\\n\\nNota: Imagen original en /TFM/0_Imagenes/\\n      Geometría calculada en notebook 03 con Shapely/Mahotas\\n      Resto de información en JSON por imagen\\n\\nVISUALIZACIONES 3-PANEL:\\n- Panel 1: Imagen original sin modificar\\n- Panel 2: Bounding boxes + IDs + scores de confianza\\n- Panel 3: Máscaras coloreadas con overlay semi-transparente\\n\\nESTRUCTURA DE SALIDA:\\n/TFM/2_Modelos/yolov8/evaluacion/\\n├── {modelo}_{config}/\\n│   ├── json/                         # UN JSON POR IMAGEN\\n│   ├── mascaras/                     # UN NPZ POR IMAGEN\\n│   ├── visualizaciones/              # UN PNG POR IMAGEN\\n│   └── checkpoint.json               # Estado del procesamiento\\n\\nEntrada: Imágenes desde /TFM/0_Imagenes/\\nSalida: JSON, máscaras NPZ completas y visualizaciones en estructura organizada\\n\\nReferencias:\\n- Jocher et al. (2023) \"Ultralytics YOLOv8\"\\n- Lin et al. (2014) \"Microsoft COCO: Common Objects in Context\"\\n- Dollar et al. (2012) \"Pedestrian Detection: An Evaluation\"\\n\\nAutor: Jesús L.\\nProyecto: TFM - Evaluación Comparativa de Técnicas de Segmentación\\nUniversidad: Universidad Oberta de Cataluña (UOC)\\nFecha: Octubre 2025\\n================================================================================\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "================================================================================\n",
        "EVALUADOR YOLOv8-SEGMENTATION OPTIMIZADO PARA FOTOGRAFÍA DE RETRATO\n",
        "================================================================================\n",
        "Sistema de evaluación para modelos YOLOv8-seg con estructura estandarizada\n",
        "y optimizaciones específicas para fotografía de retrato.\n",
        "\n",
        "CARACTERÍSTICAS PRINCIPALES:\n",
        "- Procesamiento incremental con sistema de checkpoint robusto\n",
        "- Gestión óptima de memoria para Google Colab gratuito\n",
        "- Guardado automático después de cada imagen procesada\n",
        "- Configuraciones optimizadas para fotografía de retrato\n",
        "- Filtrado inteligente de personas basado en heurísticas del estado del arte\n",
        "- Post-procesamiento avanzado: NMS, área, aspect ratio, posición\n",
        "- Visualizaciones 3-panel avanzadas (Original + Detecciones + Máscaras)\n",
        "- NPZ completo con todas las máscaras y scores para análisis posterior\n",
        "- JSON ligero con métricas de rendimiento\n",
        "\n",
        "OPTIMIZACIONES PARA RETRATO:\n",
        "- Configuraciones IOU/CONF específicas para personas\n",
        "- Filtrado por área: 5%-90% de la imagen (personas significativas)\n",
        "- Filtrado por aspect ratio: 0.3-1.5 (personas son más altas que anchas)\n",
        "- Priorización de detecciones centrales\n",
        "- NMS agresivo para evitar duplicados en retratos\n",
        "- 3 configuraciones predefinidas: fast, balanced, quality\n",
        "\n",
        "ALMACENAMIENTO NPZ (por imagen y umbral):\n",
        "- masks: Máscaras binarias (N, H, W) en uint8\n",
        "\n",
        "Nota: Imagen original en /TFM/0_Imagenes/\n",
        "      Geometría calculada en notebook 03 con Shapely/Mahotas\n",
        "      Resto de información en JSON por imagen\n",
        "\n",
        "VISUALIZACIONES 3-PANEL:\n",
        "- Panel 1: Imagen original sin modificar\n",
        "- Panel 2: Bounding boxes + IDs + scores de confianza\n",
        "- Panel 3: Máscaras coloreadas con overlay semi-transparente\n",
        "\n",
        "ESTRUCTURA DE SALIDA:\n",
        "/TFM/2_Modelos/yolov8/evaluacion/\n",
        "├── {modelo}_{config}/\n",
        "│   ├── json/                         # UN JSON POR IMAGEN\n",
        "│   ├── mascaras/                     # UN NPZ POR IMAGEN\n",
        "│   ├── visualizaciones/              # UN PNG POR IMAGEN\n",
        "│   └── checkpoint.json               # Estado del procesamiento\n",
        "\n",
        "Entrada: Imágenes desde /TFM/0_Imagenes/\n",
        "Salida: JSON, máscaras NPZ completas y visualizaciones en estructura organizada\n",
        "\n",
        "Referencias:\n",
        "- Jocher et al. (2023) \"Ultralytics YOLOv8\"\n",
        "- Lin et al. (2014) \"Microsoft COCO: Common Objects in Context\"\n",
        "- Dollar et al. (2012) \"Pedestrian Detection: An Evaluation\"\n",
        "\n",
        "Autor: Jesús L.\n",
        "Proyecto: TFM - Evaluación Comparativa de Técnicas de Segmentación\n",
        "Universidad: Universidad Oberta de Cataluña (UOC)\n",
        "Fecha: Octubre 2025\n",
        "================================================================================\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# INSTALACIÓN DE DEPENDENCIAS (EJECUTAR EN COLAB)\n",
        "# =============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"INSTALANDO DEPENDENCIAS PARA YOLOv8-SEGMENTATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Instalar ultralytics (incluye YOLOv8)\n",
        "print(\"\\n[1/3] Instalando Ultralytics YOLOv8...\")\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"ultralytics\"])\n",
        "\n",
        "# Dependencias adicionales\n",
        "print(\"[2/3] Instalando librerías de procesamiento...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"opencv-python\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"Pillow\"])\n",
        "\n",
        "print(\"[3/3] Verificando PyTorch y otras dependencias...\")\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch\", \"torchvision\"])\n",
        "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"matplotlib\", \"numpy\", \"scipy\"])\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"OK DEPENDENCIAS INSTALADAS CORRECTAMENTE\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# =============================================================================\n",
        "# MONTAR GOOGLE DRIVE\n",
        "# =============================================================================\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    IN_COLAB = True\n",
        "    print(\"OK Google Drive montado correctamente\\n\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"ADVERTENCIA No estamos en Google Colab\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJdOLkxm-yg8",
        "outputId": "0de2b46f-fc53-4415-a743-49daff6b8624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "INSTALANDO DEPENDENCIAS PARA YOLOv8-SEGMENTATION\n",
            "================================================================================\n",
            "\n",
            "[1/3] Instalando Ultralytics YOLOv8...\n",
            "[2/3] Instalando librerías de procesamiento...\n",
            "[3/3] Verificando PyTorch y otras dependencias...\n",
            "\n",
            "================================================================================\n",
            "OK DEPENDENCIAS INSTALADAS CORRECTAMENTE\n",
            "================================================================================\n",
            "\n",
            "Mounted at /content/drive\n",
            "OK Google Drive montado correctamente\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# IMPORTACIONES\n",
        "# =============================================================================\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from dataclasses import dataclass, asdict, field\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"OK LIBRERÍAS IMPORTADAS CORRECTAMENTE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Verificar disponibilidad de GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"OK GPU disponible: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\"ADVERTENCIA GPU no disponible - Se usará CPU (más lento)\")\n",
        "\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm3qXT5b7gyE",
        "outputId": "992389e1-61b7-438c-ab3d-bffca2c26370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "================================================================================\n",
            "OK LIBRERÍAS IMPORTADAS CORRECTAMENTE\n",
            "================================================================================\n",
            "OK GPU disponible: Tesla T4\n",
            "  VRAM: 14.74 GB\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONFIGURACIÓN\n",
        "# =============================================================================\n",
        "\n",
        "@dataclass\n",
        "class ModeloYOLO:\n",
        "    \"\"\"Información de un modelo YOLOv8-seg\"\"\"\n",
        "    nombre: str\n",
        "    nombre_corto: str\n",
        "    archivo_pesos: str\n",
        "    tamaño: str\n",
        "    parametros: str\n",
        "\n",
        "MODELOS_DISPONIBLES = {\n",
        "    'nano': ModeloYOLO(\n",
        "        nombre='YOLOv8 Nano Segmentation',\n",
        "        nombre_corto='nano',\n",
        "        archivo_pesos='yolov8n-seg.pt',\n",
        "        tamaño='nano',\n",
        "        parametros='3.4M'\n",
        "    ),\n",
        "    'small': ModeloYOLO(\n",
        "        nombre='YOLOv8 Small Segmentation',\n",
        "        nombre_corto='small',\n",
        "        archivo_pesos='yolov8s-seg.pt',\n",
        "        tamaño='small',\n",
        "        parametros='11.8M'\n",
        "    ),\n",
        "    'medium': ModeloYOLO(\n",
        "        nombre='YOLOv8 Medium Segmentation',\n",
        "        nombre_corto='medium',\n",
        "        archivo_pesos='yolov8m-seg.pt',\n",
        "        tamaño='medium',\n",
        "        parametros='27.3M'\n",
        "    ),\n",
        "    'large': ModeloYOLO(\n",
        "        nombre='YOLOv8 Large Segmentation',\n",
        "        nombre_corto='large',\n",
        "        archivo_pesos='yolov8l-seg.pt',\n",
        "        tamaño='large',\n",
        "        parametros='46.0M'\n",
        "    ),\n",
        "    'xlarge': ModeloYOLO(\n",
        "        nombre='YOLOv8 XLarge Segmentation',\n",
        "        nombre_corto='xlarge',\n",
        "        archivo_pesos='yolov8x-seg.pt',\n",
        "        tamaño='xlarge',\n",
        "        parametros='71.8M'\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "uP7rURWv7l1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ConfiguracionUmbrales:\n",
        "    \"\"\"\n",
        "    Configuración de umbrales optimizada para fotografía de retrato.\n",
        "\n",
        "    Referencias:\n",
        "    - Ultralytics YOLOv8 documentation (2023)\n",
        "    - COCO dataset best practices (Lin et al., 2014)\n",
        "\n",
        "    Parámetros clave para retrato:\n",
        "    - conf: Umbral de confianza para filtrar detecciones débiles\n",
        "    - iou: Umbral NMS para evitar duplicados (crítico en retratos)\n",
        "    - max_det: Número máximo de detecciones (limitado para retratos)\n",
        "    \"\"\"\n",
        "    nombre: str\n",
        "    valores_conf: List[float]\n",
        "    iou_threshold: float\n",
        "    max_det: int\n",
        "    descripcion: str\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Validación de parámetros\"\"\"\n",
        "        if not all(0 <= v <= 1 for v in self.valores_conf):\n",
        "            raise ValueError(\"Los valores de confianza deben estar entre 0 y 1\")\n",
        "        if not 0 <= self.iou_threshold <= 1:\n",
        "            raise ValueError(\"IOU threshold debe estar entre 0 y 1\")\n",
        "\n",
        "CONFIGURACIONES_UMBRALES = {\n",
        "    'fast_portrait': ConfiguracionUmbrales(\n",
        "        nombre='fast_portrait',\n",
        "        valores_conf=[0.25, 0.4, 0.5],\n",
        "        iou_threshold=0.6,  # NMS más agresivo para evitar duplicados\n",
        "        max_det=10,          # Limitado: enfoque en personas principales\n",
        "        descripcion='Rápida - Detecta personas principales con alta confianza'\n",
        "    ),\n",
        "    'balanced_portrait': ConfiguracionUmbrales(\n",
        "        nombre='balanced_portrait',\n",
        "        valores_conf=[0.15, 0.25, 0.35, 0.5],\n",
        "        iou_threshold=0.5,\n",
        "        max_det=15,\n",
        "        descripcion='Equilibrada - Balance entre velocidad y detección de personas secundarias'\n",
        "    ),\n",
        "    'sensitive_portrait': ConfiguracionUmbrales(\n",
        "        nombre='sensitive_portrait',\n",
        "        valores_conf=[0.05, 0.1, 0.2, 0.3, 0.4],\n",
        "        iou_threshold=0.45,  # Menos agresivo para capturar más personas\n",
        "        max_det=20,\n",
        "        descripcion='Sensible - Detecta incluso personas parcialmente visibles o en segundo plano'\n",
        "    ),\n",
        "    'quality_portrait': ConfiguracionUmbrales(\n",
        "        nombre='quality_portrait',\n",
        "        valores_conf=[0.1, 0.2, 0.3, 0.5, 0.7],\n",
        "        iou_threshold=0.5,\n",
        "        max_det=15,\n",
        "        descripcion='Calidad - Rango amplio para análisis de sensibilidad en retratos'\n",
        "    )\n",
        "}\n",
        "\n",
        "@dataclass\n",
        "class ConfiguracionEvaluacion:\n",
        "    \"\"\"Configuración principal del sistema\"\"\"\n",
        "    # Modelos a evaluar\n",
        "    modelos_evaluar: List[str] = None  # None = todos\n",
        "\n",
        "    # Configuraciones de umbrales a evaluar\n",
        "    configs_umbrales: List[str] = None  # None = ['balanced_portrait']\n",
        "\n",
        "    # Rutas\n",
        "    ruta_base: Path = Path(\"/content/drive/MyDrive/TFM\")\n",
        "    ruta_imagenes: Path = None\n",
        "    ruta_resultados: Path = None\n",
        "\n",
        "    # Procesamiento\n",
        "    max_dimension: int = 1024\n",
        "    img_size: int = 640\n",
        "    pausa_entre_imagenes: float = 2.0\n",
        "    pausa_entre_modelos: float = 5.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        if self.ruta_imagenes is None:\n",
        "            self.ruta_imagenes = self.ruta_base / \"0_Imagenes\"\n",
        "        if self.ruta_resultados is None:\n",
        "            self.ruta_resultados = self.ruta_base / \"2_Modelos\" / \"yolov8\"\n",
        "        if self.modelos_evaluar is None:\n",
        "            self.modelos_evaluar = list(MODELOS_DISPONIBLES.keys())\n",
        "        if self.configs_umbrales is None:\n",
        "            # DEFAULT: balanced_portrait (recomendado para fotografía de retrato)\n",
        "            self.configs_umbrales = ['balanced_portrait']"
      ],
      "metadata": {
        "id": "Wtux6Okq8R9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# UTILIDADES\n",
        "# =============================================================================\n",
        "\n",
        "class Utilidades:\n",
        "    \"\"\"Funciones auxiliares\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def cargar_imagen(ruta: Path, max_dim: int = None) -> Tuple[Image.Image, Dict]:\n",
        "        \"\"\"Carga imagen con opción de redimensionar\"\"\"\n",
        "        img = Image.open(ruta).convert(\"RGB\")\n",
        "        dim_orig = img.size\n",
        "\n",
        "        redim = False\n",
        "        if max_dim and max(img.size) > max_dim:\n",
        "            ratio = max_dim / max(img.size)\n",
        "            new_size = tuple(int(d * ratio) for d in img.size)\n",
        "            img = img.resize(new_size, Image.LANCZOS)\n",
        "            redim = True\n",
        "\n",
        "        info = {\n",
        "            'original': {'width': dim_orig[0], 'height': dim_orig[1]},\n",
        "            'procesada': {'width': img.size[0], 'height': img.size[1], 'redimensionada': redim}\n",
        "        }\n",
        "        return img, info\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_json(datos: Dict, ruta: Path):\n",
        "        \"\"\"Guarda JSON\"\"\"\n",
        "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(ruta, 'w', encoding='utf-8') as f:\n",
        "            json.dump(datos, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def guardar_mascara_npz(mascara: np.ndarray, ruta: Path):\n",
        "        \"\"\"Guarda máscara en NPZ comprimido\"\"\"\n",
        "        ruta.parent.mkdir(parents=True, exist_ok=True)\n",
        "        np.savez_compressed(ruta, mascara=mascara.astype(np.float32))\n",
        "\n",
        "    @staticmethod\n",
        "    def liberar_memoria():\n",
        "        \"\"\"Libera memoria GPU y RAM\"\"\"\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    @staticmethod\n",
        "    def obtener_memoria_gpu() -> Dict:\n",
        "        \"\"\"Info de memoria GPU\"\"\"\n",
        "        if not torch.cuda.is_available():\n",
        "            return {'disponible': False}\n",
        "        return {\n",
        "            'disponible': True,\n",
        "            'nombre': torch.cuda.get_device_name(0),\n",
        "            'asignada_mb': round(torch.cuda.memory_allocated(0) / 1024**2, 2),\n",
        "            'reservada_mb': round(torch.cuda.memory_reserved(0) / 1024**2, 2)\n",
        "        }"
      ],
      "metadata": {
        "id": "esSBfjml8VsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FILTRADO DE PERSONAS CON HEURÍSTICAS PARA RETRATO\n",
        "# =============================================================================\n",
        "\n",
        "class FiltradorPersonasRetrato:\n",
        "    \"\"\"\n",
        "    Filtrado de detecciones para fotografía de retrato.\n",
        "\n",
        "    Implementa heurísticas basadas en el estado del arte:\n",
        "    - Lin et al. (2014) \"Microsoft COCO: Common Objects in Context\"\n",
        "    - Dollar et al. (2012) \"Pedestrian Detection: An Evaluation\"\n",
        "    - Best practices de fotografía de retrato\n",
        "\n",
        "    Criterios de filtrado (mínimo 3 de 5):\n",
        "    1. Área: 5%-90% de imagen (personas significativas)\n",
        "    2. Aspect ratio: 0.3-1.5 (personas más altas que anchas)\n",
        "    3. Confianza YOLO: >= umbral configurado\n",
        "    4. Posición central: Distancia <= 0.35 (retratos suelen ser centrados)\n",
        "    5. Compacidad: >0.15 (evitar detecciones fragmentadas)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Parámetros basados en análisis de datasets de retrato\n",
        "        self.MIN_AREA_RATIO = 0.05      # Personas secundarias mínimas\n",
        "        self.MAX_AREA_RATIO = 0.90      # Evitar detecciones de imagen completa\n",
        "        self.MIN_ASPECT_RATIO = 0.3     # Personas muy anchas (sentadas/horizontales)\n",
        "        self.MAX_ASPECT_RATIO = 1.5     # Personas muy altas (de pie/verticales)\n",
        "        self.PREFERRED_CENTER_DISTANCE = 0.35  # Distancia normalizada al centro\n",
        "        self.MIN_COMPACTNESS = 0.15     # Compacidad mínima (evitar fragmentación)\n",
        "\n",
        "    def filtrar_detecciones(\n",
        "        self,\n",
        "        boxes: np.ndarray,\n",
        "        masks: np.ndarray,\n",
        "        scores: np.ndarray,\n",
        "        imagen_shape: Tuple[int, int]\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, List[Dict]]:\n",
        "        \"\"\"\n",
        "        Filtra detecciones que probablemente son personas en retratos.\n",
        "\n",
        "        Args:\n",
        "            boxes: Array (N, 4) con boxes en formato xyxy\n",
        "            masks: Array (N, H, W) con máscaras binarias\n",
        "            scores: Array (N,) con scores de confianza\n",
        "            imagen_shape: (H, W) de la imagen\n",
        "\n",
        "        Returns:\n",
        "            Tuple con arrays filtrados y metadatos de cada detección\n",
        "        \"\"\"\n",
        "        if len(boxes) == 0:\n",
        "            return (np.array([]), np.array([]), np.array([]), [])\n",
        "\n",
        "        h, w = imagen_shape\n",
        "        area_total = h * w\n",
        "        centro_x, centro_y = w / 2, h / 2\n",
        "\n",
        "        indices_validos = []\n",
        "        metadatos = []\n",
        "\n",
        "        for idx in range(len(boxes)):\n",
        "            box = boxes[idx]\n",
        "            mascara = masks[idx]\n",
        "            score = scores[idx]\n",
        "\n",
        "            # Geometría del box\n",
        "            x1, y1, x2, y2 = box\n",
        "            box_w = x2 - x1\n",
        "            box_h = y2 - y1\n",
        "            box_area = box_w * box_h\n",
        "\n",
        "            # Área de la máscara\n",
        "            mask_area = np.sum(mascara > 0.5)\n",
        "            area_ratio = mask_area / area_total\n",
        "\n",
        "            # Aspect ratio\n",
        "            aspect_ratio = box_w / box_h if box_h > 0 else 0\n",
        "\n",
        "            # Distancia al centro\n",
        "            box_centro_x = (x1 + x2) / 2\n",
        "            box_centro_y = (y1 + y2) / 2\n",
        "            dist_centro = np.sqrt(\n",
        "                ((box_centro_x - centro_x) / w) ** 2 +\n",
        "                ((box_centro_y - centro_y) / h) ** 2\n",
        "            )\n",
        "\n",
        "            # Compacidad (relación área máscara / área bbox)\n",
        "            compacidad = mask_area / box_area if box_area > 0 else 0\n",
        "\n",
        "            # Evaluar criterios\n",
        "            criterios_cumplidos = 0\n",
        "\n",
        "            if self.MIN_AREA_RATIO <= area_ratio <= self.MAX_AREA_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            if self.MIN_ASPECT_RATIO <= aspect_ratio <= self.MAX_ASPECT_RATIO:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # Confianza siempre cumplida (ya filtrada por YOLO)\n",
        "            criterios_cumplidos += 1\n",
        "\n",
        "            if dist_centro <= self.PREFERRED_CENTER_DISTANCE:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            if compacidad > self.MIN_COMPACTNESS:\n",
        "                criterios_cumplidos += 1\n",
        "\n",
        "            # Score de confianza de persona (0-1)\n",
        "            person_confidence = criterios_cumplidos / 5.0\n",
        "\n",
        "            # Aceptar si cumple al menos 3 de 5 criterios\n",
        "            if criterios_cumplidos >= 3:\n",
        "                indices_validos.append(idx)\n",
        "                metadatos.append({\n",
        "                    'id': idx,\n",
        "                    'area_pixels': int(mask_area),\n",
        "                    'area_ratio': float(area_ratio),\n",
        "                    'aspect_ratio': float(aspect_ratio),\n",
        "                    'center_distance': float(dist_centro),\n",
        "                    'compactness': float(compacidad),\n",
        "                    'criteria_met': criterios_cumplidos,\n",
        "                    'person_confidence': person_confidence,\n",
        "                    'yolo_confidence': float(score)\n",
        "                })\n",
        "\n",
        "        # Filtrar arrays\n",
        "        if indices_validos:\n",
        "            boxes_filtrados = boxes[indices_validos]\n",
        "            masks_filtrados = masks[indices_validos]\n",
        "            scores_filtrados = scores[indices_validos]\n",
        "\n",
        "            # Ordenar por person_confidence descendente\n",
        "            orden = np.argsort([m['person_confidence'] for m in metadatos])[::-1]\n",
        "            boxes_filtrados = boxes_filtrados[orden]\n",
        "            masks_filtrados = masks_filtrados[orden]\n",
        "            scores_filtrados = scores_filtrados[orden]\n",
        "            metadatos = [metadatos[i] for i in orden]\n",
        "\n",
        "            return boxes_filtrados, masks_filtrados, scores_filtrados, metadatos\n",
        "        else:\n",
        "            return np.array([]), np.array([]), np.array([]), []\n"
      ],
      "metadata": {
        "id": "qfvYEfcJ8bts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GESTOR DE CHECKPOINT\n",
        "# =============================================================================\n",
        "\n",
        "class GestorCheckpoint:\n",
        "    \"\"\"Maneja checkpoint para retomar procesamiento\"\"\"\n",
        "\n",
        "    def __init__(self, ruta: Path):\n",
        "        self.ruta = ruta\n",
        "        self.datos = self._cargar()\n",
        "\n",
        "    def _cargar(self) -> Dict:\n",
        "        if self.ruta.exists():\n",
        "            with open(self.ruta, 'r') as f:\n",
        "                return json.load(f)\n",
        "        return {\n",
        "            'completadas': [],\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "    def guardar(self):\n",
        "        self.ruta.parent.mkdir(parents=True, exist_ok=True)\n",
        "        with open(self.ruta, 'w') as f:\n",
        "            json.dump(self.datos, f, indent=2)\n",
        "\n",
        "    def marcar_completada(self, nombre: str):\n",
        "        if nombre not in self.datos['completadas']:\n",
        "            self.datos['completadas'].append(nombre)\n",
        "            self.guardar()\n",
        "\n",
        "    def obtener_pendientes(self, todas: List[str]) -> List[str]:\n",
        "        return [img for img in todas if img not in self.datos['completadas']]"
      ],
      "metadata": {
        "id": "h4rixNyT8xTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# GENERADOR DE VISUALIZACIONES 3-PANEL\n",
        "# =============================================================================\n",
        "\n",
        "class GeneradorVisualizaciones:\n",
        "    \"\"\"\n",
        "    Genera visualizaciones 3-panel avanzadas estilo SAM2.\n",
        "\n",
        "    Panel 1: Imagen original sin modificar\n",
        "    Panel 2: Bounding boxes + IDs + scores\n",
        "    Panel 3: Máscaras coloreadas con overlay semi-transparente\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def generar_visualizacion_3panel(\n",
        "        imagen: np.ndarray,\n",
        "        boxes: np.ndarray,\n",
        "        mascaras: np.ndarray,\n",
        "        scores: np.ndarray,\n",
        "        metadatos: List[Dict],\n",
        "        ruta_salida: Path,\n",
        "        modelo_nombre: str,\n",
        "        conf_threshold: float\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Genera visualización 3-panel con información completa.\n",
        "\n",
        "        Args:\n",
        "            imagen: Array RGB (H, W, 3)\n",
        "            boxes: Array (N, 4) con boxes xyxy\n",
        "            mascaras: Array (N, H, W) con máscaras\n",
        "            scores: Array (N,) con scores\n",
        "            metadatos: Lista de diccionarios con métricas\n",
        "            ruta_salida: Path para guardar PNG\n",
        "            modelo_nombre: Nombre del modelo YOLO\n",
        "            conf_threshold: Umbral de confianza usado\n",
        "        \"\"\"\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
        "\n",
        "        # PANEL 1: Original\n",
        "        axes[0].imshow(imagen)\n",
        "        axes[0].set_title('Imagen Original', fontsize=14, fontweight='bold')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        num_personas = len(boxes)\n",
        "\n",
        "        if num_personas > 0:\n",
        "            # Colores únicos para cada persona\n",
        "            colors = plt.cm.tab20(np.linspace(0, 1, num_personas))\n",
        "\n",
        "            # PANEL 2: Bounding boxes + info\n",
        "            axes[1].imshow(imagen)\n",
        "\n",
        "            for idx, (box, score, meta) in enumerate(zip(boxes, scores, metadatos)):\n",
        "                x1, y1, x2, y2 = box\n",
        "                color = colors[idx]\n",
        "\n",
        "                # Bounding box\n",
        "                rect = mpatches.Rectangle(\n",
        "                    (x1, y1),\n",
        "                    x2 - x1,\n",
        "                    y2 - y1,\n",
        "                    linewidth=3,\n",
        "                    edgecolor=color,\n",
        "                    facecolor='none'\n",
        "                )\n",
        "                axes[1].add_patch(rect)\n",
        "\n",
        "                # Label con ID y score\n",
        "                label_text = f\"P{idx+1}\\n{score:.2f}\"\n",
        "                axes[1].text(\n",
        "                    x1, y1 - 10,\n",
        "                    label_text,\n",
        "                    color='white',\n",
        "                    fontsize=11,\n",
        "                    fontweight='bold',\n",
        "                    bbox=dict(\n",
        "                        boxstyle='round,pad=0.5',\n",
        "                        facecolor=color,\n",
        "                        alpha=0.9,\n",
        "                        edgecolor='white',\n",
        "                        linewidth=1\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            axes[1].set_title(\n",
        "                f'Detecciones: {num_personas} persona(s) | conf≥{conf_threshold}',\n",
        "                fontsize=14,\n",
        "                fontweight='bold'\n",
        "            )\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            # PANEL 3: Máscaras coloreadas\n",
        "            axes[2].imshow(imagen)\n",
        "\n",
        "            for idx, (mascara, meta) in enumerate(zip(mascaras, metadatos)):\n",
        "                color = colors[idx]\n",
        "\n",
        "                # Overlay de máscara semi-transparente\n",
        "                color_mask = np.zeros((*mascara.shape, 4))\n",
        "                color_mask[mascara > 0.5] = [*color[:3], 0.5]  # Alpha 0.5\n",
        "                axes[2].imshow(color_mask)\n",
        "\n",
        "                # Añadir ID en el centro de la máscara\n",
        "                coords = np.where(mascara > 0.5)\n",
        "                if len(coords[0]) > 0:\n",
        "                    center_y = int(np.mean(coords[0]))\n",
        "                    center_x = int(np.mean(coords[1]))\n",
        "\n",
        "                    axes[2].text(\n",
        "                        center_x, center_y,\n",
        "                        f\"P{idx+1}\",\n",
        "                        color='white',\n",
        "                        fontsize=16,\n",
        "                        fontweight='bold',\n",
        "                        ha='center',\n",
        "                        va='center',\n",
        "                        bbox=dict(\n",
        "                            boxstyle='circle,pad=0.3',\n",
        "                            facecolor=color,\n",
        "                            alpha=0.9,\n",
        "                            edgecolor='white',\n",
        "                            linewidth=2\n",
        "                        )\n",
        "                    )\n",
        "\n",
        "            axes[2].set_title(\n",
        "                f'Máscaras de Segmentación',\n",
        "                fontsize=14,\n",
        "                fontweight='bold'\n",
        "            )\n",
        "            axes[2].axis('off')\n",
        "\n",
        "        else:\n",
        "            # Sin detecciones\n",
        "            axes[1].imshow(imagen)\n",
        "            axes[1].set_title(\n",
        "                f'Sin detecciones | conf≥{conf_threshold}',\n",
        "                fontsize=14,\n",
        "                fontweight='bold'\n",
        "            )\n",
        "            axes[1].axis('off')\n",
        "\n",
        "            axes[2].imshow(imagen)\n",
        "            axes[2].set_title('Sin máscaras', fontsize=14, fontweight='bold')\n",
        "            axes[2].axis('off')\n",
        "\n",
        "        # Título general\n",
        "        fig.suptitle(\n",
        "            f'{modelo_nombre} - Portrait Segmentation',\n",
        "            fontsize=16,\n",
        "            fontweight='bold',\n",
        "            y=0.98\n",
        "        )\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "        ruta_salida.parent.mkdir(parents=True, exist_ok=True)\n",
        "        plt.savefig(ruta_salida, dpi=150, bbox_inches='tight')\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "CYL0qFBE80OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# PROCESADOR YOLOV8\n",
        "# =============================================================================\n",
        "\n",
        "class ProcesadorYOLO:\n",
        "    \"\"\"Procesador optimizado para modelos YOLOv8-seg en fotografía de retrato\"\"\"\n",
        "\n",
        "    def __init__(self, modelo_info: ModeloYOLO, config: ConfiguracionEvaluacion):\n",
        "        self.modelo_info = modelo_info\n",
        "        self.config = config\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.filtrador = FiltradorPersonasRetrato()\n",
        "\n",
        "        print(f\"  Cargando: {modelo_info.nombre}\")\n",
        "        print(f\"  Device: {self.device}\")\n",
        "\n",
        "        # Cargar modelo YOLO\n",
        "        self.model = YOLO(modelo_info.archivo_pesos)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        print(f\"  Modelo cargado correctamente\")\n",
        "\n",
        "        # ID de clase \"person\" en COCO (clase 0)\n",
        "        self.person_class_id = 0\n",
        "\n",
        "    def procesar_imagen(\n",
        "        self,\n",
        "        ruta_imagen: Path,\n",
        "        config_umbral: ConfiguracionUmbrales,\n",
        "        ruta_resultados: Path\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Procesa una imagen con todos los umbrales de una configuración.\n",
        "        Guarda UN JSON POR IMAGEN (no consolidado).\n",
        "\n",
        "        Args:\n",
        "            ruta_imagen: Path a la imagen\n",
        "            config_umbral: ConfiguracionUmbrales con múltiples valores\n",
        "            ruta_resultados: Directorio para guardar resultados\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados completos\n",
        "        \"\"\"\n",
        "\n",
        "        nombre_foto = ruta_imagen.stem\n",
        "        timestamp_inicio = time.time()\n",
        "\n",
        "        # Cargar imagen\n",
        "        img_pil, info_dim = Utilidades.cargar_imagen(ruta_imagen, self.config.max_dimension)\n",
        "        img_array = np.array(img_pil)\n",
        "        h_img, w_img = img_array.shape[:2]\n",
        "\n",
        "        # Info GPU inicial\n",
        "        gpu_ini = Utilidades.obtener_memoria_gpu()\n",
        "\n",
        "        # Inferencia con umbral mínimo para obtener todas las detecciones\n",
        "        t_inf_ini = time.time()\n",
        "\n",
        "        results = self.model.predict(\n",
        "            img_array,\n",
        "            imgsz=self.config.img_size,\n",
        "            conf=min(config_umbral.valores_conf),  # Umbral mínimo\n",
        "            iou=config_umbral.iou_threshold,        # NMS threshold\n",
        "            max_det=config_umbral.max_det,          # Máximo de detecciones\n",
        "            classes=[self.person_class_id],         # Solo clase person\n",
        "            device=self.device,\n",
        "            verbose=False,\n",
        "            retina_masks=True  # Máscaras de alta resolución\n",
        "        )[0]\n",
        "\n",
        "        tiempo_inferencia = (time.time() - t_inf_ini) * 1000\n",
        "\n",
        "        # GPU pico\n",
        "        gpu_pico = Utilidades.obtener_memoria_gpu()\n",
        "\n",
        "        # Procesar por umbral\n",
        "        resultados_umbrales = {}\n",
        "\n",
        "        for umbral in config_umbral.valores_conf:\n",
        "            resultado_umbral = self._procesar_umbral(\n",
        "                results,\n",
        "                img_pil,\n",
        "                umbral,\n",
        "                nombre_foto,\n",
        "                ruta_resultados,\n",
        "                (h_img, w_img)\n",
        "            )\n",
        "            resultados_umbrales[f'umbral_{umbral}'] = resultado_umbral\n",
        "\n",
        "        # GPU final\n",
        "        gpu_fin = Utilidades.obtener_memoria_gpu()\n",
        "\n",
        "        tiempo_total = (time.time() - timestamp_inicio) * 1000\n",
        "\n",
        "        # Construir resultado completo PARA ESTA IMAGEN\n",
        "        resultado = {\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'nombre_imagen': ruta_imagen.name,\n",
        "            'modelo': self.modelo_info.nombre_corto,\n",
        "            'dataset': 'COCO',\n",
        "            'configuracion': config_umbral.nombre,\n",
        "            'arquitectura': self.modelo_info.nombre,\n",
        "            'modelo_info': {\n",
        "                'tamaño': self.modelo_info.tamaño,\n",
        "                'parametros': self.modelo_info.parametros\n",
        "            },\n",
        "            'dimensiones': info_dim,\n",
        "            'configuracion_inferencia': {\n",
        "                'iou_threshold': config_umbral.iou_threshold,\n",
        "                'max_det': config_umbral.max_det,\n",
        "                'img_size': self.config.img_size,\n",
        "                'umbrales_conf': config_umbral.valores_conf\n",
        "            },\n",
        "            'procesamiento': {\n",
        "                'tiempo_inferencia_ms': round(tiempo_inferencia, 2),\n",
        "                'tiempo_total_ms': round(tiempo_total, 2),\n",
        "                'gpu_inicial_mb': gpu_ini.get('asignada_mb', 0),\n",
        "                'gpu_pico_mb': gpu_pico.get('asignada_mb', 0),\n",
        "                'gpu_final_mb': gpu_fin.get('asignada_mb', 0),\n",
        "                'dispositivo': gpu_ini.get('nombre', 'CPU')\n",
        "            },\n",
        "            'resultados': resultados_umbrales\n",
        "        }\n",
        "\n",
        "        # GUARDAR JSON INDIVIDUAL POR IMAGEN\n",
        "        ruta_json = ruta_resultados / \"json\" / f\"{nombre_foto}.json\"\n",
        "        ruta_json.parent.mkdir(parents=True, exist_ok=True)\n",
        "        Utilidades.guardar_json(resultado, ruta_json)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def _procesar_umbral(\n",
        "        self,\n",
        "        results,\n",
        "        img_pil: Image.Image,\n",
        "        umbral: float,\n",
        "        nombre_foto: str,\n",
        "        ruta_resultados: Path,\n",
        "        imagen_shape: Tuple[int, int]\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Procesa un umbral específico con filtrado avanzado.\n",
        "\n",
        "        Args:\n",
        "            results: Resultados de YOLO\n",
        "            img_pil: Imagen PIL\n",
        "            umbral: Umbral de confianza actual\n",
        "            nombre_foto: Nombre base de la foto\n",
        "            ruta_resultados: Directorio de resultados\n",
        "            imagen_shape: (H, W) de la imagen\n",
        "\n",
        "        Returns:\n",
        "            Diccionario con resultados del umbral\n",
        "        \"\"\"\n",
        "\n",
        "        # Extraer detecciones que superan el umbral\n",
        "        boxes_raw = []\n",
        "        masks_raw = []\n",
        "        scores_raw = []\n",
        "\n",
        "        if results.masks is not None and len(results.masks) > 0:\n",
        "            for idx in range(len(results.boxes)):\n",
        "                box = results.boxes[idx]\n",
        "                conf = float(box.conf[0])\n",
        "\n",
        "                # Filtrar por umbral\n",
        "                if conf >= umbral:\n",
        "                    # Box en formato xyxy\n",
        "                    bbox_xyxy = box.xyxy[0].cpu().numpy()\n",
        "                    boxes_raw.append(bbox_xyxy)\n",
        "\n",
        "                    # Máscara redimensionada\n",
        "                    mascara = results.masks[idx].data[0].cpu().numpy()\n",
        "                    h, w = img_pil.size[1], img_pil.size[0]\n",
        "                    mascara_resize = cv2.resize(\n",
        "                        mascara,\n",
        "                        (w, h),\n",
        "                        interpolation=cv2.INTER_LINEAR\n",
        "                    )\n",
        "                    masks_raw.append(mascara_resize)\n",
        "                    scores_raw.append(conf)\n",
        "\n",
        "        # Convertir a arrays numpy\n",
        "        if boxes_raw:\n",
        "            boxes_array = np.array(boxes_raw)\n",
        "            masks_array = np.array(masks_raw)\n",
        "            scores_array = np.array(scores_raw)\n",
        "\n",
        "            # Aplicar filtrado inteligente para retrato\n",
        "            boxes_filtradas, masks_filtradas, scores_filtradas, metadatos = \\\n",
        "                self.filtrador.filtrar_detecciones(\n",
        "                    boxes_array,\n",
        "                    masks_array,\n",
        "                    scores_array,\n",
        "                    imagen_shape\n",
        "                )\n",
        "        else:\n",
        "            boxes_filtradas = np.array([])\n",
        "            masks_filtradas = np.array([])\n",
        "            scores_filtradas = np.array([])\n",
        "            metadatos = []\n",
        "\n",
        "        num_detecciones_raw = len(boxes_raw)\n",
        "        num_personas = len(boxes_filtradas)\n",
        "\n",
        "        print(f\"    [Umbral {umbral}] Detecciones brutas: {num_detecciones_raw} | \"\n",
        "              f\"Personas filtradas: {num_personas}\")\n",
        "\n",
        "        # Guardar máscaras si hay personas\n",
        "        ruta_mascara_npz = None\n",
        "        ruta_visualizacion = None\n",
        "\n",
        "        if num_personas > 0:\n",
        "            umbral_str = str(umbral).replace('.', '_')\n",
        "            nombre_npz = f\"{nombre_foto}_umbral{umbral_str}.npz\"\n",
        "            ruta_mascara_npz = ruta_resultados / \"mascaras\" / nombre_npz\n",
        "\n",
        "            # NPZ simplificado: solo máscaras binarias\n",
        "            # La imagen original está en 0_Imagenes\n",
        "            # La geometría se calcula en notebook 03 desde las máscaras\n",
        "            ruta_mascara_npz.parent.mkdir(parents=True, exist_ok=True)\n",
        "            np.savez_compressed(\n",
        "                ruta_mascara_npz,\n",
        "                masks=masks_filtradas.astype(np.uint8)\n",
        "            )\n",
        "\n",
        "            # Generar visualización 3-panel\n",
        "            nombre_vis = f\"{nombre_foto}_umbral{umbral_str}.png\"\n",
        "            ruta_visualizacion = ruta_resultados / \"visualizaciones\" / nombre_vis\n",
        "\n",
        "            GeneradorVisualizaciones.generar_visualizacion_3panel(\n",
        "                np.array(img_pil),\n",
        "                boxes_filtradas,\n",
        "                masks_filtradas,\n",
        "                scores_filtradas,\n",
        "                metadatos,\n",
        "                ruta_visualizacion,\n",
        "                self.modelo_info.nombre,\n",
        "                umbral\n",
        "            )\n",
        "\n",
        "        # Construir resultado del umbral\n",
        "        resultado = {\n",
        "            'umbral_confianza': umbral,\n",
        "            'detecciones_brutas': num_detecciones_raw,\n",
        "            'personas_filtradas': num_personas,\n",
        "            'estadisticas_personas': metadatos,\n",
        "            'ruta_mascaras_npz': str(ruta_mascara_npz) if ruta_mascara_npz else None,\n",
        "            'ruta_visualizacion': str(ruta_visualizacion) if ruta_visualizacion else None,\n",
        "            'scores_yolo': {\n",
        "                'min': float(scores_filtradas.min()) if len(scores_filtradas) > 0 else None,\n",
        "                'max': float(scores_filtradas.max()) if len(scores_filtradas) > 0 else None,\n",
        "                'mean': float(scores_filtradas.mean()) if len(scores_filtradas) > 0 else None\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return resultado"
      ],
      "metadata": {
        "id": "5sZB7W_I837N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EVALUADOR PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "class EvaluadorYOLO:\n",
        "    \"\"\"Coordinador principal del sistema de evaluación\"\"\"\n",
        "\n",
        "    def __init__(self, config: ConfiguracionEvaluacion):\n",
        "        self.config = config\n",
        "\n",
        "        # Crear estructura de directorios\n",
        "        self.dir_ejecucion = config.ruta_resultados / f\"evaluacion\"\n",
        "        self.dir_ejecucion.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"EVALUADOR YOLOv8-SEGMENTATION\")\n",
        "        print(f\"{'='*80}\")\n",
        "        print(f\"Directorio de ejecución: {self.dir_ejecucion}\")\n",
        "        print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "\n",
        "    def evaluar_modelo(\n",
        "        self,\n",
        "        modelo_key: str,\n",
        "        config_umbral_key: str\n",
        "    ) -> Optional[Path]:\n",
        "        \"\"\"Evalúa un modelo con una configuración de umbrales\"\"\"\n",
        "\n",
        "        modelo_info = MODELOS_DISPONIBLES[modelo_key]\n",
        "        config_umbral = CONFIGURACIONES_UMBRALES[config_umbral_key]\n",
        "\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"MODELO: {modelo_info.nombre}\")\n",
        "        print(f\"CONFIG: {config_umbral.descripcion}\")\n",
        "        print(f\"UMBRALES: {config_umbral.valores_conf}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Crear directorios específicos (como SAM2)\n",
        "        dir_modelo = self.dir_ejecucion / f\"{modelo_info.nombre_corto}_{config_umbral.nombre}\"\n",
        "        dir_modelo.mkdir(parents=True, exist_ok=True)\n",
        "        (dir_modelo / \"mascaras\").mkdir(exist_ok=True)\n",
        "        (dir_modelo / \"visualizaciones\").mkdir(exist_ok=True)\n",
        "        (dir_modelo / \"json\").mkdir(exist_ok=True)  # JSON por imagen\n",
        "\n",
        "        # Checkpoint\n",
        "        checkpoint_path = dir_modelo / \"checkpoint.json\"\n",
        "        checkpoint = GestorCheckpoint(checkpoint_path)\n",
        "\n",
        "        # Obtener imágenes\n",
        "        imagenes = sorted(self.config.ruta_imagenes.glob(\"*.jpg\"))\n",
        "        if not imagenes:\n",
        "            imagenes = sorted(self.config.ruta_imagenes.glob(\"*.png\"))\n",
        "\n",
        "        pendientes = checkpoint.obtener_pendientes([img.name for img in imagenes])\n",
        "        imagenes_procesar = [img for img in imagenes if img.name in pendientes]\n",
        "\n",
        "        print(f\"\\nImágenes totales: {len(imagenes)}\")\n",
        "        print(f\"Completadas: {len(imagenes) - len(pendientes)}\")\n",
        "        print(f\"Pendientes: {len(pendientes)}\")\n",
        "\n",
        "        if not imagenes_procesar:\n",
        "            print(\"OK Todas las imágenes ya procesadas\")\n",
        "            return dir_modelo\n",
        "\n",
        "        # Cargar modelo\n",
        "        try:\n",
        "            procesador = ProcesadorYOLO(modelo_info, self.config)\n",
        "        except Exception as e:\n",
        "            print(f\"ERROR Error cargando modelo: {e}\")\n",
        "            return None\n",
        "\n",
        "        # Procesar imágenes (cada una guarda su propio JSON)\n",
        "        for idx, imagen_path in enumerate(imagenes_procesar, 1):\n",
        "            print(f\"\\n[{idx}/{len(imagenes_procesar)}] {imagen_path.name}\")\n",
        "\n",
        "            try:\n",
        "                # Procesar imagen (guarda JSON automáticamente)\n",
        "                procesador.procesar_imagen(\n",
        "                    imagen_path,\n",
        "                    config_umbral,\n",
        "                    dir_modelo\n",
        "                )\n",
        "\n",
        "                # Marcar completada\n",
        "                checkpoint.marcar_completada(imagen_path.name)\n",
        "\n",
        "                # Pausa\n",
        "                if idx < len(imagenes_procesar):\n",
        "                    time.sleep(self.config.pausa_entre_imagenes)\n",
        "\n",
        "                # Liberar memoria cada 10 imágenes\n",
        "                if idx % 10 == 0:\n",
        "                    Utilidades.liberar_memoria()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ERROR Error procesando {imagen_path.name}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        print(f\"\\nOK Configuración completada\")\n",
        "        return dir_modelo\n",
        "\n",
        "    def ejecutar_evaluacion_completa(self) -> Dict[str, List[Path]]:\n",
        "        \"\"\"Ejecuta evaluación de todos los modelos configurados\"\"\"\n",
        "\n",
        "        resultados_generados = {}\n",
        "\n",
        "        total = len(self.config.modelos_evaluar) * len(self.config.configs_umbrales)\n",
        "        actual = 0\n",
        "\n",
        "        for modelo_key in self.config.modelos_evaluar:\n",
        "            if modelo_key not in MODELOS_DISPONIBLES:\n",
        "                print(f\"ERROR Modelo '{modelo_key}' no encontrado\")\n",
        "                continue\n",
        "\n",
        "            directorios_modelo = []\n",
        "\n",
        "            for config_key in self.config.configs_umbrales:\n",
        "                if config_key not in CONFIGURACIONES_UMBRALES:\n",
        "                    print(f\"ERROR Configuración '{config_key}' no encontrada\")\n",
        "                    continue\n",
        "\n",
        "                actual += 1\n",
        "                print(f\"\\n{'='*80}\")\n",
        "                print(f\"PROGRESO: {actual}/{total}\")\n",
        "                print(f\"{'='*80}\")\n",
        "\n",
        "                directorio = self.evaluar_modelo(modelo_key, config_key)\n",
        "\n",
        "                if directorio:\n",
        "                    directorios_modelo.append(directorio)\n",
        "\n",
        "                # Pausa entre configuraciones\n",
        "                if actual < total:\n",
        "                    time.sleep(self.config.pausa_entre_modelos)\n",
        "\n",
        "                # Liberar memoria\n",
        "                Utilidades.liberar_memoria()\n",
        "\n",
        "            if directorios_modelo:\n",
        "                resultados_generados[modelo_key] = directorios_modelo\n",
        "\n",
        "        return resultados_generados"
      ],
      "metadata": {
        "id": "AUEpc2iZ9FWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FUNCIÓN PRINCIPAL\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "\n",
        "    # Configuración optimizada para fotografía de retrato\n",
        "    config = ConfiguracionEvaluacion(\n",
        "        # TODOS los modelos YOLOv8-seg disponibles\n",
        "        modelos_evaluar=['nano', 'small', 'medium', 'large', 'xlarge'],\n",
        "\n",
        "        # TODAS las configuraciones de retrato\n",
        "        configs_umbrales=[\n",
        "            'fast_portrait',\n",
        "            'balanced_portrait',\n",
        "            'sensitive_portrait',\n",
        "            'quality_portrait'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Validar rutas\n",
        "    if not config.ruta_imagenes.exists():\n",
        "        print(f\"ERROR: Directorio de imágenes no existe: {config.ruta_imagenes}\")\n",
        "        return\n",
        "\n",
        "    # Crear evaluador\n",
        "    evaluador = EvaluadorYOLO(config)\n",
        "\n",
        "    # Ejecutar\n",
        "    print(\"\\nIniciando evaluación completa...\")\n",
        "\n",
        "    resultados = evaluador.ejecutar_evaluacion_completa()\n",
        "\n",
        "    # Resumen final\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EVALUACIÓN COMPLETADA\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Directorio: {evaluador.dir_ejecucion}\")\n",
        "    print(f\"\\nModelos evaluados: {len(resultados)}\")\n",
        "    for modelo, paths in resultados.items():\n",
        "        print(f\"  - {modelo}: {len(paths)} configuraciones\")\n",
        "\n",
        "    print(f\"\\nProceso finalizado exitosamente\")"
      ],
      "metadata": {
        "id": "xI1a32ei9GMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-Ya-qth9vLo",
        "outputId": "03a001a8-fc64-444d-ba45-ffe4521378a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EVALUADOR YOLOv8-SEGMENTATION\n",
            "================================================================================\n",
            "Directorio de ejecución: /content/drive/MyDrive/TFM/2_Modelos/yolov8/evaluacion\n",
            "Device: GPU\n",
            "\n",
            "Iniciando evaluación completa...\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 1/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Nano Segmentation\n",
            "CONFIG: Rápida - Detecta personas principales con alta confianza\n",
            "UMBRALES: [0.25, 0.4, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 2/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Nano Segmentation\n",
            "CONFIG: Equilibrada - Balance entre velocidad y detección de personas secundarias\n",
            "UMBRALES: [0.15, 0.25, 0.35, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 3/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Nano Segmentation\n",
            "CONFIG: Sensible - Detecta incluso personas parcialmente visibles o en segundo plano\n",
            "UMBRALES: [0.05, 0.1, 0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 4/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Nano Segmentation\n",
            "CONFIG: Calidad - Rango amplio para análisis de sensibilidad en retratos\n",
            "UMBRALES: [0.1, 0.2, 0.3, 0.5, 0.7]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 5/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Small Segmentation\n",
            "CONFIG: Rápida - Detecta personas principales con alta confianza\n",
            "UMBRALES: [0.25, 0.4, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 6/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Small Segmentation\n",
            "CONFIG: Equilibrada - Balance entre velocidad y detección de personas secundarias\n",
            "UMBRALES: [0.15, 0.25, 0.35, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 7/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Small Segmentation\n",
            "CONFIG: Sensible - Detecta incluso personas parcialmente visibles o en segundo plano\n",
            "UMBRALES: [0.05, 0.1, 0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 8/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Small Segmentation\n",
            "CONFIG: Calidad - Rango amplio para análisis de sensibilidad en retratos\n",
            "UMBRALES: [0.1, 0.2, 0.3, 0.5, 0.7]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 9/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Medium Segmentation\n",
            "CONFIG: Rápida - Detecta personas principales con alta confianza\n",
            "UMBRALES: [0.25, 0.4, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 10/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Medium Segmentation\n",
            "CONFIG: Equilibrada - Balance entre velocidad y detección de personas secundarias\n",
            "UMBRALES: [0.15, 0.25, 0.35, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 11/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Medium Segmentation\n",
            "CONFIG: Sensible - Detecta incluso personas parcialmente visibles o en segundo plano\n",
            "UMBRALES: [0.05, 0.1, 0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 12/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Medium Segmentation\n",
            "CONFIG: Calidad - Rango amplio para análisis de sensibilidad en retratos\n",
            "UMBRALES: [0.1, 0.2, 0.3, 0.5, 0.7]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 13/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Large Segmentation\n",
            "CONFIG: Rápida - Detecta personas principales con alta confianza\n",
            "UMBRALES: [0.25, 0.4, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 14/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Large Segmentation\n",
            "CONFIG: Equilibrada - Balance entre velocidad y detección de personas secundarias\n",
            "UMBRALES: [0.15, 0.25, 0.35, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 15/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Large Segmentation\n",
            "CONFIG: Sensible - Detecta incluso personas parcialmente visibles o en segundo plano\n",
            "UMBRALES: [0.05, 0.1, 0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 16/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 Large Segmentation\n",
            "CONFIG: Calidad - Rango amplio para análisis de sensibilidad en retratos\n",
            "UMBRALES: [0.1, 0.2, 0.3, 0.5, 0.7]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 20\n",
            "Pendientes: 0\n",
            "OK Todas las imágenes ya procesadas\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 17/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 XLarge Segmentation\n",
            "CONFIG: Rápida - Detecta personas principales con alta confianza\n",
            "UMBRALES: [0.25, 0.4, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 19\n",
            "Pendientes: 1\n",
            "  Cargando: YOLOv8 XLarge Segmentation\n",
            "  Device: cuda\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-seg.pt to 'yolov8x-seg.pt': 100% ━━━━━━━━━━━━ 137.4MB 94.5MB/s 1.5s\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/1] _DSC0987.jpg\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "OK Configuración completada\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 18/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 XLarge Segmentation\n",
            "CONFIG: Equilibrada - Balance entre velocidad y detección de personas secundarias\n",
            "UMBRALES: [0.15, 0.25, 0.35, 0.5]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 0\n",
            "Pendientes: 20\n",
            "  Cargando: YOLOv8 XLarge Segmentation\n",
            "  Device: cuda\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    [Umbral 0.15] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.25] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.35] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "OK Configuración completada\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 19/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 XLarge Segmentation\n",
            "CONFIG: Sensible - Detecta incluso personas parcialmente visibles o en segundo plano\n",
            "UMBRALES: [0.05, 0.1, 0.2, 0.3, 0.4]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 0\n",
            "Pendientes: 20\n",
            "  Cargando: YOLOv8 XLarge Segmentation\n",
            "  Device: cuda\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    [Umbral 0.05] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.1] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.2] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.4] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "OK Configuración completada\n",
            "\n",
            "================================================================================\n",
            "PROGRESO: 20/20\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODELO: YOLOv8 XLarge Segmentation\n",
            "CONFIG: Calidad - Rango amplio para análisis de sensibilidad en retratos\n",
            "UMBRALES: [0.1, 0.2, 0.3, 0.5, 0.7]\n",
            "================================================================================\n",
            "\n",
            "Imágenes totales: 20\n",
            "Completadas: 0\n",
            "Pendientes: 20\n",
            "  Cargando: YOLOv8 XLarge Segmentation\n",
            "  Device: cuda\n",
            "  Modelo cargado correctamente\n",
            "\n",
            "[1/20] _DSC0023.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[2/20] _DSC0036.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[3/20] _DSC0071.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[4/20] _DSC0084.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[5/20] _DSC0119.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[6/20] _DSC0139.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[7/20] _DSC0143.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[8/20] _DSC0147.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[9/20] _DSC0281.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[10/20] _DSC0283.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[11/20] _DSC0411.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[12/20] _DSC0441.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[13/20] _DSC0449.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[14/20] _DSC0472.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[15/20] _DSC0545.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[16/20] _DSC0584.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[17/20] _DSC0592.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[18/20] _DSC0859.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[19/20] _DSC0962.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.2] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "[20/20] _DSC0987.jpg\n",
            "    [Umbral 0.1] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.2] Detecciones brutas: 2 | Personas filtradas: 2\n",
            "    [Umbral 0.3] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.5] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "    [Umbral 0.7] Detecciones brutas: 1 | Personas filtradas: 1\n",
            "\n",
            "OK Configuración completada\n",
            "\n",
            "================================================================================\n",
            "EVALUACIÓN COMPLETADA\n",
            "================================================================================\n",
            "Directorio: /content/drive/MyDrive/TFM/2_Modelos/yolov8/evaluacion\n",
            "\n",
            "Modelos evaluados: 5\n",
            "  - nano: 4 configuraciones\n",
            "  - small: 4 configuraciones\n",
            "  - medium: 4 configuraciones\n",
            "  - large: 4 configuraciones\n",
            "  - xlarge: 4 configuraciones\n",
            "\n",
            "Proceso finalizado exitosamente\n"
          ]
        }
      ]
    }
  ]
}